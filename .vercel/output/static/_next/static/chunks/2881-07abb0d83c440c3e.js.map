{"version":3,"file":"static/chunks/2881-07abb0d83c440c3e.js","mappings":"0EAAA,sBAEA,mFAEA,oDAEA,gBACA,SAEA,OACA,IACA,IACA,sBAEA,CAEA,OACA,gBACA,oCACK,CACL,mBACA,eACA,cACA,eACA,aACA,CAAK,CACL,gBACA,kBACA,aACA,mBACA,OACA,SAEA,CAAK,CACL,kBACA,qBACA,MACA,CAAK,CACL,iBACA,sBACA,qBACA,CACA,CACA,0BCxCA,WACA,YACA,WACA,cACA,aACA,QACA,UACA,cACA,iBACA,gBACA,UACA,YACA,QACA,WACA,SACA,aACA,UACA,gBACA,gBACA,cACA,WACA,gBACA,QACA,UACA,UACA,UACA,SACA,gBACA,SACA,UACA,eACA,QACA,UACA,MACA,WACA,UACA,SACA,UACA,UACA,YACA,aACA,gBACA,YACA,aACA,eACA,UACA,WACA,WACA,UACA,SACA,UACA,UACA,WACA,UACA,UACA,eACA,UACA,SACA,UACA,UACA,YACA,WACA,aACA,YACA,WACA,UACA,QACA,eACA,aACA,QACA,SACA,WACA,mBACA,cACA,UACA,SACA,UACA,QACA,UACA,UACA,aACA,WACA,eACA,SACA,gBACA,yBACA,kBACA,yBACA,kBACA,qBACA,SACA,SACA,UACA,SACA,UACA,UACA,SACA,UACA,SACA,UACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,UACA,WACA,WACA,aACA,WACA,YACA,SACA,WACA,UACA,oBACA,yBACA,WACA,WACA,SACA,oBACA,iBACA,gBACA,iBACA,iBACA,mBACA,iBACA,kBACA,kCACA,4BACA,aACA,cACA,cACA,aACA,cACA,aACA,cACA,eACA,YACA,YACA,kBACA,gBACA,aACA,WACA,oBACA,eACA,WACA,gBACA,kBACA,aACA,YACA,YACA,YACA,WACA,WACA,WACA,WACA,UACA,UACA,UACA,UACA,UACA,OACA,OACA,OACA,OACA,sBACA,gBACA,yBACA,mBACA,+BACA,yBACA,kCACA,sBACA,6BACA,gDACA,wCACA,8BACA,4BACA,uCACA,wCACA,+BACA,6BACA,kCACA,yBACA,mCACA,oDACA,kBACA,0BACA,uBACA,0BACA,6BACA,4BACA,6BACA,iCACA,gCACA,oBACA,oBACA,mBACA,qBACA,sBACA,yBACA,0BACA,6BACA,mCACA,wBACA,qBACA,4BACA,uBACA,+BACA,4BACA,oBACA,iBACA,yBACA,mBACA,wBACA,0BACA,4BACA,wBACA,ybACA,iBACA,mBACA,mBACA,mBACA,8BACA,gCACA,yBACA,mBC5OA,iBAA+C,sBCU9C,cACD,aAGA,OACA,gBACA,MAAiB,CACjB,MAAiB,CACjB,kBACA,EAKA,cAEA,6CACA,SAIA,YAAwB,WAAkB,IAC1C,6CACA,SAGA,QACA,CAEA,gBAMA,0CACA,CAEA,gBAMA,oBACA,CAEA,cAWA,OANA,UACA,kBACA,UACA,kBACA,SAGA,CAEA,gBAMA,8CACA,8CACA,gBAiBA,OAfA,gBACA,gBACA,YAEA,gBACA,gBACA,YAEA,gBACA,gBACA,YAEA,gBACA,YAEA,8BAGA,gBAMA,8CACA,8CACA,gBA6BA,OA3BA,gBACA,gBACA,YAEA,gBACA,gBACA,YAEA,gBACA,gBACA,YAEA,gBACA,gBACA,YAEA,gBACA,gBACA,YAEA,gBACA,gBACA,YAEA,8CACA,YAEA,8BAGA,uBASA,IAFA,QAGA,YACU,KACV,2CAEA,MACA,0CAEA,CAEA,uBASA,GAFA,QAGA,EACU,KACV,8BAEA,eAIA,gBAMA,2BACA,CAEA,cAaA,OALA,IADA,oBACA,yBAEA,IADA,oBACA,yBACA,mBAGA,CAKA,2BAKA,6BAGA,OAYA,QAVA,aACA,aAEA,IAEA,IAKA,IAAwB,IAAY,KAIpC,IADA,IAFA,uCAJA,YAOA,IAGA,GAFA,MAPA,YAWA,IADA,UACA,cAKA,OAFA,IAEA,GACA,OACA,aAEA,QACA,YAEA,QACA,QAEA,IADA,MA1BA,YA2BA,IAEA,GADA,MA3BA,WA6BA,CAKA,OAHA,YACA,WAEA,EACA,EAEA,4BAKA,6BAIA,OAmBA,QAlBA,cACA,aAEA,IACA,IACA,IACA,IAEA,IACA,IACA,IACA,IAOA,IAAwB,IAAY,MACpC,uCACA,yCACA,2CACA,6CAGA,IADA,MAXA,YAYA,IAEA,GADA,MAZA,YAiBA,IADA,EADA,QACA,EACA,cAGA,IADA,MAnBA,YAoBA,IAEA,GADA,MApBA,YAyBA,IADA,EADA,QACA,EACA,aAGA,IADA,MA3BA,YA4BA,IAEA,GADA,MA5BA,YAiCA,IADA,EADA,QACA,EACA,cAGA,IADA,MAnCA,YAoCA,IAEA,GADA,MAxCA,YA6CA,IADA,EADA,QACA,EACA,cAQA,OALA,IACA,IACA,IACA,IAEA,GACA,QACA,cAEA,SACA,aAEA,SACA,WAEA,IADA,MA3DA,YA4DA,IAEA,GADA,MAhEA,WAmEA,SACA,cAEA,SACA,cAEA,SACA,YAEA,QACA,UAEA,IADA,MA5EA,YA6EA,IAEA,GADA,MA7EA,WAgFA,QACA,aAEA,QACA,aAEA,QACA,YAEA,QACA,UAEA,IADA,MA7FA,YA8FA,IAEA,GADA,MA9FA,WAiGA,QACA,aAEA,QACA,aAEA,QACA,YAEA,QACA,QAEA,IADA,MA9GA,YA+GA,IAEA,GADA,MA/GA,WAiHA,CA0BA,OAxBA,YACA,YACA,YACA,YAEA,KACA,KACA,KACA,KACA,KACA,KAEA,OACA,OACA,OACA,OAEA,KACA,KACA,KACA,KACA,KACA,KAEA,gLACA,EAEA,4BAKA,6BAGA,OAcA,QAZA,cACA,aAEA,QACA,QAEA,QACA,QAEA,0BACA,0BAEA,IAAwB,IAAY,MACpC,+CACA,iCACA,qDACA,mCAGA,IADA,SACA,IAKA,IADA,IAFA,MADA,UAGA,IACA,GACA,+BAGA,IADA,SACA,IAKA,IADA,IAFA,MADA,UAGA,IACA,GACA,+BAMA,OAHA,QACA,QAEA,GACA,QACA,wBAEA,SACA,wBAEA,SACA,wBAEA,SACA,wBAEA,SACA,wBAEA,SACA,sBAEA,QAGA,IADA,IADA,kBACA,GACA,IAEA,MADA,SAGA,QACA,uBAEA,QACA,uBAEA,QACA,uBAEA,QACA,uBAEA,QACA,uBAEA,QACA,uBAEA,QACA,sBAEA,QAGA,IADA,IADA,gBACA,GACA,IAEA,MADA,SAEA,CAcA,OATA,IAHA,oBACA,qBAGA,SAKA,IAHA,OACA,QAGA,SAEA,4LACA,EASyC,WACzC,gBAGQ,aAAmB,EAwB3B,CAAC,yBCnkBD,YACA,oBAEA,cAMA,OAJA,oBACA,kBACA,cACA,MACA,UACA,EAEA,cACA,gBAEA,IADA,KACA,MACA,GADoB,GACpB,aAD4B,OAI5B,QACA,cACA,0BAEA,gBACA,CACA,qBACA,iBACA,SACA,CACA,gBACA,0BAEA,iBACA,OACA,mBACA,0BAEA,eACA,QACA,2BACA,0BAEA,yBACA,QACA,kCACA,0BAEA,kCACA,QACA,0CACA,0BAEA,0CACA,SACA,yBACA,CACA,EAMA,GAJA,cACA,sBACA,GAEA,KAEA,SAEA,SAEA,cACA,cAgBA,IAfA,IACA,KACA,MACA,IACA,yBACA,4BACA,KACA,MACQ,2BACR,IACA,IACA,QAGA,IACA,aACA,sBACA,2BACQ,WACR,wBACA,8BACU,wBACV,8BAEA,WAGA,MAEA,gBACA,wBAEA,IACA,CACA,SACA,2BAEA,aAGA,aACA,gBACA,UACA,sBACA,uCAQA,GANA,GACA,iCAEA,GACA,OAEA,uCACA,IACA,kBACA,CAAU,SAEV,+BACA,CACA,WAAyB,KAAQ,MACjC,yCACA,eACA,KACA,CAEA,EAAQ,gBACR,4BACA,gBACA,gBACA,qDAGA,mCAEA,IACA,qCACA,CAAQ,SAER,sCACA,CACA,uBACA,uCAEA,uCACA,0BACA,2BACA,gCACA,wDACA,mFACA,kEACA,CAoCA,OAlCA,uCAIA,CAHA,iEACA,aAEA,gBACA,0DAEA,0DAEA,EAEA,6BAIA,OAHA,SACA,MAEA,4CACA,EAEA,gCACA,UAIA,IAHA,gBACA,eACA,IACA,MACA,YACA,IACA,GAEA,EAEA,gCACA,mCAGA,CAEA,CAAG,GAED,SAAe,GAEf,SAAe,GAEf,SAAe,GAEjB,CAAC,6BC/MD,kBAAkD,oDC4BlD,SACA,wBACA,MAHA,yBAGA,iCACA,CACA,+BACA,sBACA,EAEA,oCAGA,qDAFA,SAKA,4BACA,8CACA,OAEA,uBACA,gCACA,CACA,mBACA,qBACA,SAEA,yBACA,gBAEA,6BACA,gDAEA,wFACA,CACA,yBACA,kCACA,qBACA,CACA,4BACA,8BACA,+BACA,CACA,oBACA,wBACA,oBACA,2BACA,SAEA,YAAwB,WAAkB,IAC1C,eACA,SAGA,QACA,CACA,wBACA,EAKA,EAJA,8CAGA,6CACA,KAGA,iCACA,sBAGA,EAVA,KAaA,QACA,eACA,gBAEA,wBACA,IACA,gBACA,2BACA,WACA,mBAEA,iCACA,6BAEA,SAEA,CAEA,eACA,iBACA,qBAAwC,EAAE,mBAAmB,EAAE,iBAAiB,EAAE,MAClF,oBACA,SACA,qBACA,sCACA,2BACA,YAAwB,WAAc,IACtC,qBAEA,gBAEA,mBACA,wBACA,KACA,YAAwB,WAAgB,IACxC,6BAGA,OADA,6BAEA,CACA,CACA,QACA,wBACA,yBACA,kBACA,KACA,YAAwB,eAA4B,KAEpD,uBADA,kBAGA,QACA,CACA,0BACA,kCACA,kBACA,YAAwB,WAAiB,IACzC,mCAEA,QACA,CACA,CACA,QACA,gBACA,qBACA,SACA,CACA,mBACA,qBACA,SACA,CACA,sBACA,qBACA,SACA,CACA,4BACA,wBACA,wBACA,WACA,2BACA,cACA,uBACA,WACA,oBACA,cACA,uBACA,iBACA,0BACA,eACA,uBACA,aACA,cACA,oBACA,SACA,yCAA6D,EAAI,GACjE,CACA,CACA,8BACA,MACA,0BAEA,wBACA,WACA,6BACA,cACA,yBACA,WACA,sBACA,cACA,yBACA,iBACA,4BACA,eACA,yBACA,aACA,cACA,sBACA,SACA,yCAA6D,EAAI,GACjE,CACA,CACA,mBACA,8BACA,yBAEA,KADA,2BAImB,EAAM,0BAEzB,CACA,qBACA,2BACA,MACA,0BAEA,kBACA,qEAEA,yBACA,yBAGA,eAAkC,EAAM,yBAGxC,wBACA,2BACA,MACA,0BAEA,qBACA,iEAEA,mFACA,CACA,sBACA,+EACA,CACA,mDACA,UACA,YACA,yBACA,YACA,sBACA,aACA,cACA,sBACA,eACA,WACA,yBACA,SACA,yCAA6D,EAAS,GACtE,CACA,CACA,iDACA,UACA,YACA,uBACA,YACA,oBACA,aACA,cACA,oBACA,eACA,WACA,uBACA,SACA,yCAA6D,EAAS,GACtE,CACA,CACA,qBACA,eACA,oBACA,YAAwB,IAAkB,IAC1C,qBAEA,gBAEA,mBACA,wBACA,KACA,YAAwB,WAAgB,IACxC,6BAEA,QACA,CACA,gBACA,wBACA,KACA,WACA,YAAwB,IAAS,KACjC,WACA,MACA,SAEA,iBACA,CACA,QACA,CACA,kBACA,2BACA,MACA,0BAEA,eACA,0DAEA,aACA,OAA4B,GAAU,EAEtC,iCACA,YAAwB,WAAsB,MAC9C,oBACA,sBACA,CACA,gBAEA,6BACA,sBACA,CACA,+BACA,wBACA,CACA,wBACA,mBACA,OACA,YAA4B,IAAc,IAC1C,OAGA,QACA,CACA,uBACA,qDACA,CACA,CACA,+BAwCA,IAA6B,GAC7B,IAAe,oBC1Yf,MAAmB,EAAQ,KAAe,EAE1C,EAAe,EAAQ,KAAe,CAFZ,CAG1B,EAAuB,EAAQ,KAAmB,CAD5B,CAEtB,EAAoB,EAAQ,KAAuB,CADrB,CAG9B,UAF2B,CAE3B,WACA,iCACA,WACA,4BAEA,YACA,kDAGA,MACA,OACA,yCAGA,QACA,IACA,IACA,YACM,QACN,0BACA,IACA,WAEA,IACA,IACA,IACA,UAGA,EAAI,IACJ,OACA,0CAYA,OATA,OACA,IACA,YACM,sBACN,IACA,IACA,UAGA,0BACA,IACA,oBACA,WACA,CAAQ,SACR,IACA,CACA,CAAK,CACL,CAEA,IACA,oBACA,gBACA,CAAI,SACJ,IACA,CACA,CAEA,QAAc,UACd,UAAgB,uBAChB,WAAiB,gCAGjB,UAAgB,6BAChB,oBACA,CAAC,aCvED,qBACA,6FCKA,MAAsB,uBAAgC,EAgBtD,eAAuB,aACvB,kBAEA,wBACA,OACA,yCACA,QAEA,YAAkB,MAAkB,IACpC,cAKA,OAFA,UAEA,WACA,EAsBA,cAAoB,aACpB,SACA,uBACA,WAEA,YAAkB,IAAe,IACjC,YAAoB,IAAe,IAEnC,gBACA,kBACA,kBAIA,GAJ8C,GAI9C,cAIA,QACA,mBClFA,MAAa,EAAQ,IAAQ,EAW7B,GACA,wCACA,oDACA,oDACA,oCACA,CAEA,cACA,yBACA,WACA,CAEA,4BACA,+BACA,EAEA,iCACA,yBAGA,qCACA,wCACA,EAEA,8BACA,MAIA,QAAc,sBAA2B,MAEzC,iCAGA,6BAGA,WACA,CAIA,oBACA,gCAEA,EAEA,uBC1DA,aACA,eACA,aACA,CAEA,aAEA,gBACA,sBACA,mCACA,CAAG,CAEH,kBACA,YAAoB,IAAY,IAChC,6BAEA,CAAG,CAEH,2BACA,mBACG,CAEH,mBACA,+BACA,wBACA,oBAGA,GACA,sCAGA,aACA,CACA,EAEA,sBC/BA,cACA,WACA,gEAGA,aACA,8BACA,oCACA,CAWA,kCACA,mBACA,gBACA,2BACA,EASA,8BACA,iCAWA,gCACA,2BACA,EASA,qCACA,wCAGA,6BChEA,MAAmB,EAAQ,KAAa,EACxC,EAAa,EAAQ,IAAQ,EADH,SAG1B,EAFoB,CAEpB,EACA,iBACA,oBACA,SAEA,2BACA,CAEA,4BACA,UACA,EAEA,iCACA,yBAGA,qCACA,wCACA,EAEA,8BACA,+BAAwC,IAAO,IAC/C,qBAEA,EAEA,6BC7BA,MAAgB,EAAQ,KAA0B,EAElD,GAEA,OAJuB,CAKvB,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,SACA,UACA,UACA,UACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,WACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,CAEA,GAEA,WACA,YACA,YACA,YACA,YACA,aACA,cACA,cACA,eACA,eACA,eACA,eACA,gBACA,gBACA,gBACA,gBACA,gBACA,gBACA,gBACA,gBACA,gBACA,gBACA,gBACA,gBACA,iBACA,iBACA,kBACA,kBACA,kBACA,kBACA,kBACA,kBACA,kBACA,mBACA,mBACA,mBACA,mBACA,mBACA,mBACA,mBACA,CAUA,gBAAsB,eACtB,UACA,SACA,mBACA,UACA,yBACA,IACA,yBACA,IACA,4BAEA,MACA,CACA,EAUA,wBAA8B,eAC9B,UACA,SACA,yBACA,IACA,yBACA,IACA,yBACA,IACA,4BAEA,MACA,CACA,iBCtIA,GAAS,EAAK,OACd,GAAS,EAAK,OACd,GAAS,EAAK,OACd,GAAS,EAAK,OA+Bd,SAAe,aACf,0BACA,iBACA,EAEA,MAAY,eACZ,gBACA,SAGA,IACA,OAxCA,YACA,sBACA,qCAKA,OAFA,iBAGA,QACA,UACA,eAEA,IACA,aACA,eAEA,IACA,eACA,eAEA,IACA,WACA,UAEA,SACA,mCACA,CACA,EAaA,EACA,CAAI,SACJ,QACA,CACA,kBCjDA,MAAsB,uBAAgC,EAUtD,YAAoB,aACpB,WAEA,OAEA,MAEA,GAhBA,EAgBA,GAEA,KAlBA,EAkBA,CACA,mBCpBA,MAAc,EAAQ,KAAS,EAI/B,UAJqB,KAIrB,CAFA,MAcA,gBAAsB,eACtB,iBACA,QAEA,4BACA,4BAMA,gBAxBA,KAyBA,gBC5BA,0BACA,uBASC,WACD,QACA,YAAkB,MAAS,IAC3B,OACA,OAMA,IAJA,KAIqB,CAJrB,GAKA,SAQA,cAAoB,MAAS,IAC7B,cAEC,GAQD,KAAW,aACX,iCACA,aASA,KAAW,aACX,aAUA,KAAW,sBACX,eAIA,+BCnEA,MAAa,EAAQ,IAAQ,EAC7B,EAAc,EAAQ,KAAS,EADX,SAGpB,CAFqB,CAErB,GACA,kBACA,WACA,CAEA,4BACA,WACA,EAEA,iCACA,uBACA,EAEA,qCACA,wCACA,EAEA,8BACA,MAKA,QAAc,mBAAsB,KACpC,6BAGA,sBAEA,cAGM,sBAEN,cAEA,YACA,6EAMA,0BAGA,WACA,CACA,EAEA,2BCjDA,UAAgB,EAChB,aACA,aACA,aACA,aACA,aACA,aACA,aACA,YACA,EAMA,OACA,KACA,KACA,MACA,KACA,EAQA,SAAe,aACf,6CACA,EASA,MAAY,aACZ,yCACA,EASA,cAAoB,aACpB,aACA,IACA,IACA,IACA,OACA,OAEA,YAAoB,IAAY,KAChC,MACA,SAEA,YAAsB,IAAY,KAClC,gBACA,OACA,KAEA,sBACA,IACA,KAIA,CADA,gBACA,EACA,KAEA,sBACA,IACA,IAEA,CAEA,sBACA,qBACA,CAEA,QACA,EAOA,cAAoB,aACpB,aACA,IAEA,YAAoB,MAAgB,IACpC,YAAsB,MAAgB,KACtC,iBACA,aACA,aACA,eAEA,mBACA,CAGA,eASA,cAAoB,aACpB,aACA,IACA,IACA,IAEA,YAAoB,IAAY,KAChC,MACA,YAAsB,IAAY,IAClC,uBACA,+BAEA,uBACA,8BAEA,CAEA,eAWA,cAAoB,aACpB,QACA,gBAEA,YAAkB,IAAkB,iBAIpC,YAFA,6BAEA,MAgCA,WAAiB,eACjB,aAEA,YAAoB,IAAY,IAChC,YAAsB,IAAY,IAClC,mBACA,UA3BA,gBACA,UACA,2CACA,yCACA,yCACA,4CACA,wEACA,iDACA,oDACA,sDAEA,0CACA,CACA,EAcA,OAGA,EAQA,aAAmB,eACnB,qCACA,IACA,MAEA,YAAkB,IAAiB,KACnC,KACA,iBAGA,MACA,kBACA,kBACA,kBACA,kBAGA,iBAEA,MACA,IACA,IAEA,CAEA,QACA,kBCzOA,MAAqB,EAAQ,KAAiB,EAC9C,EAAc,EAAQ,KAAS,CADH,CAU5B,SAAe,EACf,aACA,MACA,iBACA,EAWA,cAAoB,EACpB,kBACA,MACA,kBAQA,MAAY,EACZ,UACA,MACA,kBAYA,OAAa,EACb,WACA,MACA,kBASA,OAAa,EACb,MACA,EAUA,uBAA6B,eAC7B,6CAEA,iBACA,0CAGA,uBACA,iBACA,WACA,EAQA,oBAA0B,oBAC1B,2BACA,qCACA,uBACA,QASA,UAAgB,aAChB,6BACA,qBACA,EAQA,SAAe,aACf,2BAsCA,MAAY,eACZ,gBACA,SAGA,IACA,gBAnCA,GACA,sBACA,qCAKA,OAFA,iBAGA,cACA,qBACA,eACA,0BACA,QACA,mBACA,OACA,sBAEA,+BACA,CACA,EAgBA,EACA,CAAI,SACJ,QACA,CACA,mBCtKA,MAAa,EAAQ,IAAQ,EAE7B,cACA,oBACA,sBACA,CAEA,4BACA,yCACA,EAEA,iCACA,yBAGA,qCACA,wCACA,EAEA,kCACA,IAIA,QAAc,sBAA2B,KAEzC,WADA,sBACA,IAEA,YAKA,yBACA,MAEA,WADA,oBACA,IAEA,eAEA,EAEA,6BC1CA,MAAW,EAAQ,IAAgB,EASnC,KAAW,MATO,IASP,KACX,0CAEA,YAAkB,WAAe,IACjC,YAAoB,WAAe,IACnC,yBAIA,QACA,EASA,KAAW,eACX,wBAEA,4BACA,WAEA,YAAoB,WAAoB,IACxC,oBAIA,QACA,+BACA,YACA,CAEA,QACA,EASA,sBAA4B,aAC5B,0BACA,YAAkB,IAAY,IAC9B,wCAGA,QACA,mBC7DA,MAAc,EAAQ,KAAS,EAC/B,EAAgB,EAAQ,KAA0B,CAD7B,CAErB,EAAkB,EAAQ,KAAc,CADjB,CAEvB,EAAkB,EAAQ,IAAc,EADf,EAEA,EAAQ,IAAqB,EACtD,CAFyB,CAEH,EAAQ,IAAkB,EAChD,CAFgC,CAEZ,EAAQ,KAAgB,EADf,EAEd,EAAQ,KAAyB,CADrB,CAE3B,EAA2B,EAAQ,KAAwB,CADrC,CAEtB,EAAgB,EAAQ,KAAW,CADD,CAElC,EAAmB,EAAQ,KAAe,CADnB,CAEvB,EAAa,EAAQ,IAAQ,EADH,EAET,EAAQ,KAAY,EADjB,SAsIpB,CArIwB,CAqIxB,WAGA,IAFA,aACA,wBAGA,QAAc,KAAQ,IACtB,cAGA,IACA,gBACM,IACN,kBAEA,qBAIA,IACA,oBACM,IACN,uBAEA,qBAKA,iBACA,CA2SA,QAAc,mBAMd,EACA,EANA,sBACA,6BAGA,UAeA,OAXA,aAEA,qCACA,oBACA,wBAEA,cACA,mCAhHA,sBACA,EAEA,oBACA,sBACI,uBACJ,QAEA,OACA,oBAGA,8BACA,CAIA,uBACA,EAAI,IACJ,4BAIA,mCAGA,MACA,uEAIA,KAII,QACJ,oIAEA,QAEA,MARA,IAUA,eA7LA,OAEA,YAEA,sBAEA,oBASA,uDAGA,UACA,CAAG,EAGH,IAEA,GAFA,6BACA,6BACA,IAgBA,IATA,0BACA,WAQA,0BACA,YAOA,gCACA,YAAkB,IAAmB,IACrC,oBAGA,OAYA,oBAoDA,IAlDA,mCAMA,IAHA,8BAMA,wBAGA,MACA,MAEA,kBAEA,kBACA,MAGA,MAGA,WAEA,IACA,WACA,WACA,IACA,2BAGA,YAAkB,IAAmB,KACrC,aAGA,qBAGA,oBAEA,KACA,eACA,CAIA,wBACA,IAIA,QAAc,IAAiB,IAC/B,QAAgB,IAAmB,IACnC,eACA,iBAMA,QAAc,IAAa,IAC3B,QAAgB,IAAmB,IACnC,eAIA,QACA,EAnFA,MACA,EAuIA,OAIA,QADA,oBAiCA,OAzZA,cACA,aACA,oBAEA,YAAkB,WAAgB,KAClC,cACA,UAEA,aAAqB,KAAQ,IAC7B,yBAEA,aAAuB,KAAQ,IAC/B,kBAEA,4BACA,4BACA,uBACA,qBAEA,qBAIA,CACA,EAoWA,KA3VA,YACA,aAEA,YAAkB,MAAc,KAChC,aACA,gBACA,eACA,CACA,EAoVA,GACA,SA3UA,KACA,wBAEA,YAAkB,WAAgB,KAClC,cACA,UAEA,aAAqB,KAAQ,IAC7B,aAAuB,KAAQ,IAC/B,8BACA,aACA,qBAEA,oBAIA,CACA,EAyTA,KAMA,SAEA,MAzTA,kBAGA,MAFA,aACA,sBAGA,YAAkB,KAAQ,IAC1B,kBACA,YACA,cAEA,gBACA,eAEA,EA6SA,KA/PA,cACA,aACA,KACA,MACA,IACA,IAEA,cAA2B,IAAS,KAGpC,IAFA,aAEA,CACA,YAAsB,IAAO,IAC7B,yBACA,SAEA,YACA,oBAGA,eAGA,UACA,IACA,IAEA,CAKA,GAFA,OAEA,SACA,KACA,KACA,KACA,CACA,CAEA,EA6NA,KAEA,UAEA,mBACA,mBAIA,iBAGA,SAEA,CACA,UACA,UACA,uBACA,cACA,UACA,CACA,EA+BA,QACA,mBC9eA,MAAmB,EAAQ,KAAc,EAEzC,UAF0B,CAE1B,GACA,oBACA,cAEA,yCACA,CAQA,mCAEA,cACA,gDACA,EAQA,+BACA,iBACA,uCAKA,2CACA,SAIA,4BAKA,uBACA,QACA,kCAGA,OAFA,WAEA,CACA,CAEA,QACA,EAEA,2BCvDA,eAEA,qNAMA,gCAFA,yBAEA,kBAEA,OAAa,eACb,YAAkB,qCAClB,MAAY,eACZ,SAAe,eACf,cAAoB,QAbpB,oBAaoB,KAEpB,wBACA,oBACA,mCAEA,WAAiB,aACjB,gBACA,EAEA,aAAmB,aACnB,gBACA,EAEA,kBAAwB,aACxB,gBACA,mBC9BA,MAAa,EAAQ,IAAQ,EAC7B,EAAoB,EAAQ,KAAgB,EAC5C,EAAyB,EAAQ,KAAqB,CAD3B,CAE3B,EAAiB,EAAQ,KAAa,CADN,CAEhC,EAAkB,EAAQ,KAAc,CADhB,CAExB,EAAc,EAAQ,KAAS,CADN,CAEzB,EAAc,EAAQ,KAAS,CADV,CAErB,EAAiB,EAAQ,KAAY,CADhB,CASrB,UARwB,CAQxB,GACA,6CACA,CAUA,sBAEA,EADA,SAGA,2BACA,QACA,UACA,cACA,OACA,mBACK,EAGL,QACA,CASA,kBAGA,EACA,EAHA,+BACA,qCAcA,OAVA,wBACA,qBACA,yBAEA,2BACA,MAGA,gBAGA,mBACA,uBACK,EACL,gBACA,OACA,YACA,YACA,gBAEA,CAAK,CACL,CAUA,gBACA,UACA,eACA,yBACA,qBACA,yBACA,cACA,yBACA,aACA,yBACA,CACA,CAsIA,oBACA,EACA,8BAKA,GAHA,kBAGA,oBACA,mDACA,cACA,yCAQA,OAJA,qCACA,WAGA,GACA,eACA,eAEA,qBACA,eAEA,cACA,eAEA,aACA,eACA,CACA,CAiBA,WAAiB,aACjB,8BAOA,MANA,mBACA,kBACM,QACN,yBAGA,CACA,CAAG,IACH,EAUA,YAAkB,eAIlB,MA7HA,cACA,SACA,GAAkB,UAClB,YAEA,YAAkB,WAAkB,KACpC,WACA,KAEA,YAAoB,WAAsB,KAC1C,WACA,SAEA,UACA,MAAqB,oBACrB,QAEA,YAAsB,WAAwB,KAC9C,WAEA,+BACA,QACA,kCACA,yBAEA,2BAEA,gCAEA,2BACA,oCAEA,CACA,CAEA,GACA,CAEA,YAAkB,WAAwB,IAC1C,cAGA,OAAW,cACX,EAvFA,YACA,SACA,YAAkB,WAAiB,KACnC,WAEA,eACA,eACA,UACA,CAAY,gDAA6D,CACzE,CAAY,yCACZ,EACA,KACA,qBACA,UACA,CAAY,yCACZ,EACA,KACA,cACA,UACA,CAAY,0CACZ,EACA,KACA,aACA,QACA,CAAY,0CACZ,CACA,CACA,CAEA,QACA,EAwIA,6BAGA,GACA,mCAEA,KACA,YAAkB,aAAqB,IACvC,2BAGA,qBA7MA,qBACA,8CACA,mBACA,2BAIA,UACA,CACA,CAAG,KAqMH,EAYA,UAAgB,aAChB,mBACA,4BAEA,qBCzUA,EACA,OACA,EACA,qCACA,yCACA,kDACA,kDACA,GAQA,aAAqB,aACrB,2DACA,sEACA,aACA,EAQA,yBAA+B,aAC/B,WACA,EAQA,aAAmB,aACnB,QAEA,YACA,IACA,OAGA,QACA,EAEA,mBAAyB,aACzB,wBACA,qDAGA,GACA,EAEA,oBAA0B,YAC1B,iBACA,EAEA,QAAc,aACd,WACA,iBCxDA,SAAe,aACf,4BACA,mBCRA,MAAc,EAAQ,KAAS,EAC/B,EAAe,EAAQ,KAAyB,CAD3B,CAErB,EAAgB,EAAQ,KAA0B,CAD5B,CAEtB,EAAa,EAAQ,IAAQ,EADN,EAEF,EAAQ,KAAiB,EAD1B,EAKpB,QAJ4B,KAI5B,CADA,MAaA,gBAEA,qCACA,CAgCA,MAAY,sBACZ,aACA,eAGA,CACA,EAWA,aAAmB,iBACnB,iBACA,sCAIA,wBAGA,IAMA,KANA,2BAGA,6BAGA,IAEA,wBAEA,eAGA,UACA,eACA,yBAEA,qBACA,yBAEA,cACA,uBAEA,aACA,QACA,sBACA,CACA,EAUA,uBAA6B,mBAC7B,EAEA,oBAEA,qBACA,cACA,gBAzFA,KACA,YAA+B,MAAsB,IAErD,GAdA,cACA,QAOA,OALA,sBACA,kBACA,sBACA,CAAG,EAEH,CACA,EAIA,MACA,2BACA,QAKA,EAgFA,KAGA,gBACA,SAGA,QACI,IACJ,IAGA,OA/HA,gBACA,YAA+B,MAAsB,IACrD,2BACA,QAKA,EAuHA,uBACA,EAYA,gBAAsB,aACtB,sBACA,uCAGA,YAEA,4BACA,4BAGA,cACA,mBClKA,MAAc,EAAQ,KAAS,CAoB/B,SAAc,EApBO,QAoBP,WAlBd,EAmBA,QACA,GAEA,+BACA,IACA,UAGA,GACA,GAlBA,WACA,IACA,uCACA,CAAI,SACJ,mDACA,CACA,GAYA,EAGA,kBACA,wCAEA,qBACA,yBAMA,OALA,4BApCA,EAsCA,EArCA,kCAEA,sBACA,SAkCA,EAjCA,QAiCA,EAhCA,eAgCA,EAhCA,KACA,qBAgCA,sBAEA,CACA,EAEA,iBAAuB,iBACvB,OAEA,+BACA,IACA,UAGA,UAEA,sBAEA,sBACA,qBAEA,+BACA,mBC9DA,MAAc,EAAQ,KAAS,EAE/B,UAFqB,CAErB,KACA,cACA,mBAEA,WACA,+CACA,CACA,CAEA,kBACA,UAGA,OAFA,uBAEA,CACA,CAsCA,QAAc,iBACd,sBACA,iBACA,iBACA,eAEA,kBAEA,iCACA,6BAFA,GAIA,EACA,kCACA,gBAjDA,OACA,SACA,IACA,KACA,IAEA,YAAkB,WAAiB,KACnC,sBACA,kBAEA,aAEA,MACA,IAEA,mBACA,KACA,kBACA,WAEA,IACA,MAGA,gBACA,YACA,MAGA,GAEA,CAEA,QACA,EAeA,oBAMA,6CAFA,yDAFA,0BAIA,iDAMA,MAJA,sBACA,UAGA,CACA,iBChFA,cAKA,GAJA,oBACA,iBAGA,mBACA,qDAGA,0CACA,wCACA,qCAIA,8BACA,qDACA,YACK,IAIL,8BAEA,8BAEA,OACA,YACA,YACA,WACA,QACA,6BACA,CACA,CAEA,YAAkB,aAClB,UACA,sBAEA,yBACA,iBACA,WACA,EACA,SAEA,sCACA,aAEA,OACA,QACA,YACA,SACA,OACA,kCACA,mCACA,CAAK,CACL,YACA,+BACA,CACA,EAEA,UAAgB,eAChB,sCACA,uBACA,SAGA,eAAqB,eACrB,sBACA,mCACA,EAEA,eAAqB,iBACrB,qBACA,iBACA,kBACA,+BACA,aACA,+BAEA,YAAkB,IAAgB,IAClC,YAAoB,IAAgB,KACpC,gBACA,gBAEA,YACA,cAGA,OAFA,oBAEA,EADA,oBACA,OAGA,WACA,WACA,WACA,SAGA,0BCsIA,gBACA,aACA,CAEA,cACA,QAGA,OAFA,mBAEA,CADA,qCACA,+BACA,CAEA,gBACA,iBAGA,cACA,WACA,CAlPA,gBACA,cACA,mBACA,cACA,eACA,uBACA,oBACA,CAEA,SACA,sCACA,cAEA,SAEA,0BACA,kBACA,uBACA,0BAEM,CACN,QACA,SACA,oBACA,gBACA,sBAEA,KAEA,8BACA,sBACA,CACA,CAEA,SACA,kBACA,CAEA,OACA,iBACA,sCACA,UAGA,wBAGA,QAEA,OADA,wBACA,WACA,CAEA,aAEA,GADA,iBACA,qBACA,sCACA,wBACA,sBACA,CACA,oBAGA,WACA,QACA,oBACA,sBACA,GAEA,CAEA,OACA,QACA,qBACA,oBACA,2BACA,IAEA,QACA,CAEA,YACA,QACA,IACA,oBAEA,MADA,YACA,GACA,IAEA,QACA,CAEA,QACA,YACA,wBAEA,IADA,eAEA,IAEA,iBACA,CAEA,0BACA,4BACA,6BACA,UAEA,yBACA,IA7GA,EA6GA,QACA,WAIA,uCAGA,IADA,oBAEA,EANA,EAQA,CAEA,iBACA,mBA3HA,GA4HA,MACA,mCACA,wBAEA,QACA,CAEA,WACA,4BACA,0BArIA,EAqIA,CACA,CAEA,aACA,4BACA,4BA1IA,EA0IA,EACA,CAEA,yBACA,iBACA,QACA,KACA,iBACA,WACM,CAIN,aACA,uBACA,eACU,cACV,iBACU,CACV,4BACA,qDACA,OAEA,kBAEA,sBACA,sBACA,CACA,CAEA,qBACA,sBACA,CAEA,YACA,mBACA,mBAGA,oBACA,CAEA,eAKA,EAJA,SACA,IACA,IACA,IAEA,0BACA,mBACA,QACA,YACA,KAGA,oBAGA,GADA,GADA,SACA,GACA,IACA,OACA,KACA,QAEA,gBACA,UACA,IACA,IAEA,CAGA,qBAAkC,IAAO,IAEzC,OADA,KAEA,aAEA,MAIA,QACA,CAEA,eAEA,OADA,iBACA,iBACA,CACA,aCtOA,UAKA,gBACA,IAIA,EAJA,IACA,OACA,IACA,IAEA,WAEA,GACA,cAEA,MADA,UACA,sCAEA,SACA,QACA,WACA,sBACA,IACA,EAAI,QArBJ,IAqBI,CAIJ,OAFA,YAEA,CACA,aC5BA,UAOA,kBACA,sDAEA,MADA,UACA,sCAEA,QAIA,IAFA,MADA,OAGA,GAXA,YAYA,aAfA,IAgBA,OAEA,UACA,aAnBA,IAoBA,OAMA,OAJA,SAEA,cAEA,CACA,EA3BA,IAEA,wBCJA,WACA,OAAY,EAAQ,KAAa,EACjC,OAAY,EAAQ,CADD,IACc,EACjC,UADmB,KACC,EAAQ,KAAa,CACzC,WAD2B,ECQ3B,sBACA,OACA,EAZA,IAYA,EACA,EAZA,MAYA,EACA,EAZA,QAYA,EACA,EAZA,WAYA,EACA,EAZA,YAYA,EACA,EAZA,cAYA,EACA,EAZA,gBAYA,EACA,EAZA,kBAYA,EACA,EAZA,mBAYA,EACA,EAEA,aCxBA,WAAyB,EAA0B,UAAqB,4CAAoH,YAAY,yCAAyC,yCAAyC,iBAAiB,oFAAoF,4DAA4D,6BAA6B,oBAAoB,yBAAyB,EAAE,OAAO,EAAE,qBAAqB,yCAAyC,+BAA+B,oCAAoC,eAAwC,GAAzB,yBAAyB,gFAAuF,YAAY,yBAAyB,cAAc,kDAAkD,6BAA6B,sBAAsB,cAAc,kBAA92B,KAA82B,iBAAsC,uBAAuB,gDAAgE,OAAhB,sBAA39B,IAA29B,EAAgB,EAAS,sBAAsB,gDAAgD,qBAAqB,uBAAuB,qBAAqB,kCAAkC,IAAI,SAAS,wBAAwB,2BAA2B,aAAa,0BAA0B,cAAc,mCAAmC,cAAc,4BAA4B,cAAc,wBAAwB,cAAc,4BAA4B,cAAc,kBAAkB,6EAA6E,cAAc,wBAAwB,cAAc,0BAA0B,cAAc,yBAAyB,kBAAc,GAAmB,SAAnB,EAA4C,gBAAzB,aAAyB,EAAiB,aAAc,8BAA8B,qBAAqB,mCAAmC,yBAAyB,sBAAsB,EAAE,OAAO,mNAAmN,mFAAoF,SAAS,SAAkB,GAAW,EAAX,gBAAW,sBAAyC,CAApD,KAAoD,WAApD,KAAoD,WAApD,KAAoD,aAApD,KAAoD,CAA4C,cAAc,2DAAxyE,IAAwyE,gBAAxyE,IAAwyE,cAAxyE,IAAwyE,EAA8F,wCAAt4E,aAAs4E,iHAAt4E,KAAs4E,oBAAt4E,QAAs4E,IAAt4E,KAAs4E,8CAAgM,cAAc,kBAAkB,sBAAsB,gBAAgB,QAAQ,iBAAppF,WAAopF,EAAppF,cAAopF,IAAppF,cAAopF,IAAppF,aAAopF,EAAppF,aAAopF,MAAppF,cAAqsF,yDAA2C,wBAAwB,qBAAqB,cAAgC,EAAlB,cAAkB,MAAU,sDAAv0F,aAAu0F,IAAv0F,aAAu0F,IAAv0F,YAAu0F,EAAv0F,YAAu0F,eAAv0F,aAAk7F,OAAjB,YAAj6F,YAAi6F,GAAiB,yBAAgC,kBAAkB,gEAAgE,wBAAwB,qBAAqB,UAAU,eAAe,sBAAsB,gBAAgB,uDAAsD,gBAA8B,UAAd,eAAc,kCAAiD,0CAA8C,cAAc,yBAAyB,gBAAgB,4BAA4B,6GCY99G,EAAsB,OAAU,CAChC,cACA,mBAAY,GAAmB,QAAuB,GACtD,SAEA,GACA,eACA,oBACA,aACA,UACA,IANmB,OAAkB,GAMrC,QAEA,MAA2B,SAAG,CACxB,GAAM,QACZ,CACA,KACA,UAAmB,QAAE,yCACrB,OACA,EAEA,GAEA,gKClBA,EAAoB,OAAU,CAC9B,cACA,aAAY,eAAsB,EAClC,WAAY,QAA0B,QAAgB,IAEtD,GACA,IAFmB,OAAkB,GAErC,UACA,qBACA,EACA,EAAgB,aAAO,YACvB,MAA2B,SAAG,CAAC,IAAqB,EAAI,iBAAsC,SAAG,CAC3F,GAAM,KACZ,CACA,MACA,KACA,UAAmB,QAAE,6BACrB,QACA,iCACA,sBACA,yBACA,CAAS,GACT,EACA,CAAO,CACP,GAEA,wIC7BA,cACA,WAAU,gBAAuB,QAAuB,GACxD,cAAU,GAAiB,QAAmB,GAC9C,EAAqB,QAAE,uCAEvB,GACA,eACA,qCACA,qCACA,yBACA,IANiB,OAAkB,GAMnC,MAEA,MAAyB,SAAG,CACxB,GAAI,CACR,CACA,oBACA,iBACA,YACA,QACA,KACA,SAAgC,SAAG,CACnC,OACA,CACA,oBACA,gDACA,EAEA,EAEA,CACA,+LC7BA,0CACA,GACA,MACA,QAAc,iBAAqB,IAAkB,MAAO,CAC5D,SAAe,iBAAqB,IAAkB,MACtD,CAAG,CACH,OACA,QAAc,iBAAqB,IAAkB,MAAO,CAC5D,SAAe,iBAAqB,IAAkB,MACtD,CACA,EACA,GACA,OACA,iBACA,iBACA,aACA,gBACA,QACG,IACH,MACA,OACA,OAA6B,iBAA4C,CACzE,SACA,oCACA,6CAAsF,IAAS,eAC/F,CACA,CAAG,CACH,QACA,iBACA,eACA,aACA,gBACA,QACG,IACH,MACA,OACA,OAA6B,UAAY,CACzC,SACA,qCACA,8CAAuF,IAAS,iBAChG,CACA,CACA,EACA,EAAe,gBAAU,CACzB,QACA,IACA,KACA,gBACA,oBACA,mBACA,sBACA,QACA,YACA,aACA,gBACA,KACA,CAAM,EACN,MAAkC,cAAQ,KACtC,eAAS,MACb,sBACA,KACA,CAAO,EACP,yBACA,CAAK,KACD,QAAI,EACR,2BACA,8FACA,CAAK,EACL,iCACA,GACA,iBACA,eACA,iBACA,aAAwD,EAAxD,CAA+B,OAAS,aAAgB,cACxD,CACA,6BACA,8BACA,yBACA,wBACA,CACA,CACA,EACA,QACA,sBACA,MAA2B,SAAG,CAAC,GAAe,EAAI,gCAA0D,SAAG,CACzG,GAAM,KACZ,CACA,MACA,KACA,UAAmB,QAAE,sBACrB,OACA,kBACA,gBACA,KACS,CACT,SACA,WACA,oBACA,UACA,WACA,EACA,CAAO,CACP,GAEA,yBCxGA,MAAqB,OAAU,CAC/B,cACA,cAAY,sBAAkC,EAC9C,cAAY,GAAe,CAAE,OAAmB,GAChD,CAAY,0BAAwB,CAAE,OAAuB,GAC7D,SACA,EAAuB,QAAE,8BACzB,EAAmB,QAAkB,GACrC,GACA,gBAEA,MAAkC,SAAG,CAAC,GAAM,MAAQ,+BAA2D,SAC/G,EAGA,EAF6B,SAAG,CAAC,EAAQ,CAAI,KAAJ,GAAI,aAA6C,CAG1F,GAEA,oJCtBA,EAAkB,OAAU,eAC5B,UAAU,mCAA8C,EACxD,EAAgB,UAAQ,SACxB,EAAqB,QAAE,0BACvB,MAAyB,SAAG,CACxB,GAAM,KACV,CACA,MACA,oBACA,YACA,SACA,SACA,aACA,gBACA,cAAuB,QAAa,SAAkB,QAAY,GAClE,CAAO,CACP,OACA,oBACA,kBACA,oBACA,QACA,UACA,WACA,SACA,eACA,wBACA,oBACA,aACA,aACA,CAAS,CACT,sBACA,iBACA,CACA,CAAO,CACP,KACA,UACA,EAEA,CAAC,CACD,oIC5CA,EAAkB,OAAU,CAC5B,cACA,eAAY,mCAA8C,EAC1D,MAA2B,SAAG,CACxB,GAAM,GACZ,CACA,KACA,MACA,UAAmB,QAAE,8BACrB,8BACA,oBACA,OACA,kBACA,aACA,aACA,iBACA,gBACA,oBACA,MACA,OACA,SACA,aACA,aACA,CACA,CACA,EAEA,GAEA,EAAc,OAAU,eACxB,cAAU,QAAqB,EAC/B,MAAyB,SAAG,CACxB,GAAM,KACV,CACA,MACA,oBACA,KACA,UAAiB,QAAE,qBACnB,OACA,sDACA,oBACA,QACA,CACA,CACA,EAEA,CAAC,6IClBD,EAAY,OAAU,SACtB,MACA,MAAgB,OAAoB,GACpC,CAAU,oBAA2C,EACrD,EAAiB,QAAmB,UAAY,UAAoB,EAEpE,CACA,mBACA,WACA,yCACA,2CACA,aACA,KACA,CAAI,CARe,OAAgB,IASnC,cACA,yCACA,gBAEA,QACA,sCACA,GAAe,QAAO,gBAEtB,8DACA,CACA,gBACA,mBACA,gBACA,eACA,YACA,CAAI,CAAE,MAAQ,EACd,KACA,YACA,cACA,aACA,WACA,MACA,CAAG,EACH,eAnDA,KACA,SACA,KACA,iCACA,cACA,OAEA,OAEA,WACA,EAyCA,EAAqD,IAAe,EACpE,OACA,SACA,MACA,kBAAoC,QACpC,GACA,sBACA,oBACA,oBACA,iBACA,oBACA,gBAEA,GACA,sBACA,oBACA,wBACA,aACA,cAEA,GACA,kBACA,cACA,YAEA,MAAyB,UAAI,CAAC,GAAM,QAAU,gDAC1B,SAAG,UAAY,qCAAiD,EAChE,SAAG,CACjB,GAAM,MACZ,CACA,kCACA,KACA,OACA,GAEA,GAAgC,SAAG,CAC7B,GAAM,MACZ,CACA,gCACA,KACA,QACA,UACA,GAEA,CAAK,CACL,CAAC,EACD,wDmMDA,EgIjHA,wB3NAO,EIKA,EAMP,EAWO,EAoDA,EyCrEI,EiCiFJ,E2EhFA,EiBDA,EAsHA,EAiDA,I7HvKa,4xCnJNb,uBACP,qDACA,kCACA,SACA,sCACA,CACA,CACO,sBACP,kDACA,0BACA,SACA,mCACA,CACA,CACO,sBACP,oDACA,4BACA,SACA,qCACA,CACA,CACO,sBACP,4CACA,mBACA,SACA,6BACA,CACA,CEvBO,IAAM,EAAe,WAO5B,CCNO,QDDqB,SCCrB,YACP,wBACA,CACA,QAGQ,EAAe,SACvB,CACA,UAFuB,IAEvB,GACA,4BACA,QACA,EAEA,SAEA,wBACA,8BACA,oBACA,WACA,KACA,kBAEA,QACA,WACA,kCACA,CAAS,CACT,CACA,2BACA,kDACA,oBACA,WAGA,sBAA8B,EAAU,UACxC,iBACA,CACA,iBACA,6BACA,6BACA,UAGA,kBAA8B,EAAM,OACpC,uBAHA,CAKA,CACA,wBAAuC,EACvC,+CACA,CACA,CCtDO,wBAIA,cACP,qBACA,yDACA,CAcO,cACP,8DACA,SACA,4BACA,yBACA,yBACA,yDAEA,iDACA,CC0IA,MA9JA,QA8Je,CA9Jf,KACA,iBACA,QA4J8C,EAAC,MA5J/C,qBAGA,QADA,sBACA,IAAoB,WAAqB,IACzC,SAEA,YAAoB,WAAqB,KACzC,kBACA,kBACA,cACA,kCAEA,OACA,CAXA,IAYA,WACA,cACA,4BACA,CADiD,CACjD,0BA+DA,IA/DkD,KA+DlD,KACA,sBACA,mCAEA,gBACA,sBAEA,QAEA,WAFA,EAEA,EAMA,IAFA,QACA,IACA,UACA,IACA,IAMA,IAHA,2BACA,CADiE,CACjE,kBAEA,OAEA,yBAEA,WACA,OAGA,QADA,IACA,MAAqC,qBAA6C,QAClF,cACA,eACA,YAEA,SACA,8BAEA,IACA,GACA,CAEA,eAKA,IADA,UACA,iBACA,IAIA,IAFA,8BACA,IACA,OACA,cAEA,UACA,CAWA,OACA,OAhIA,YAUA,GARA,0BAEA,sBACA,qDAEA,kBACA,wBAEA,2BACA,uCAEA,gBACA,SAOA,IAJA,QACA,IACA,IACA,WACA,iBACA,IACA,IAMA,IAHA,oBACA,oBAEA,QAIA,QAHA,OAEA,IACA,MAAqC,qBAA6C,QAClF,gBACA,aACA,UAEA,SACA,8BAEA,IACA,GACA,CAGA,IADA,UACA,iBACA,IAIA,IADA,kBACe,IAAY,IAC3B,kBAEA,QACA,EA0EA,eACA,OAVA,YACA,WACA,KACA,QAEA,oBAA+B,GAAM,WACrC,CAKA,CACA,CC9JA,SACA,KACA,OACA,uBACA,OACA,YACA,cACA,iBACA,CACA,UACA,2BACA,SAAsB,YAAY,EAAE,mBAAuB,QAG3D,0CAEA,CACA,CAMA,QACA,KACA,OACA,WACA,eACA,oBACA,YACA,cACA,uBAEA,cACA,uCAEA,wBACA,iBACA,CACA,UACA,uBACA,2CACA,iDAAiE,kBAAqB,IAAI,WAAW,6CAA6C,YAAY,GAE9J,mDACA,CAEA,gDAEA,CACA,MACA,gBACA,CACA,CACA,QACA,qBACA,GACA,eACA,CACA,MACA,gBACA,CACA,UACA,WACA,mBACA,WACA,kBAGA,uDAAkE,kBAAsB,8BAA8B,4BAA4B,eAElJ,CACA,CACO,gBAEP,cACA,gBAA+B,aAAqB,CACpD,gBAAgC,aAAuB,CAClD,CACL,CACO,QACP,KACA,OACA,WACA,UACA,SACA,oBACA,SACA,YACA,cACA,kBACA,kBACA,0BACA,yBACA,CACA,UACA,6BACA,CACA,UACA,6BACA,CACA,CACO,iBAAgB,6BAA8B,EACrD,qBACA,CACO,iBAAiB,sBAAwB,EAChD,WAAY,YAAiB,EAAO,KACpC,UACA,SACA,OACA,SACA,UAA0B,EAAM,KAChC,CAAK,CACL,CAsEO,iBAAmB,oCAAqC,EAC/D,UACA,SACA,OACA,UACA,CApCA,gBACA,0BACA,WACA,KACA,IACA,CADkB,CAClB,EACA,CADoB,GACpB,QAAoB,WAAiB,IAKrC,IAHA,YACA,KAEA,KACA,KACA,aAQA,GAJA,OACA,iBAGA,EACA,wBACA,OAGA,SACA,EASA,OAEA,UACA,CA7EA,kBAEA,SACA,YAAoB,WAAqB,IACzC,UAGA,eACA,mBACA,IAGA,8BAEA,IACA,CADkB,CAClB,EACA,CADoB,CACpB,EACA,CADqB,GACrB,QAAoB,IAAS,KAE7B,cACA,cACA,yBAAyC,GAAM,YAG/C,SACA,QAEA,IACA,KACA,gBAEA,CAEA,yBACA,4CAEA,SACA,EAwCA,QAEA,CAAK,CACL,CCxMO,MAAe,EAAK,CAC3B,EAD2B,KAC3B,IACA,cACA,qBACA,CAAC,ECJM,EAAe,EAAO,CAC7B,IAD6B,GAC7B,IACA,cACA,4BACA,aACA,CAAC,EACM,EAAoB,EAAO,CAClC,IADkC,GAClC,IACA,mBACA,4BACA,aACA,CAAC,ECXM,GAAc,EAAO,CAC5B,IAD4B,GAC5B,IACA,aACA,cACA,aACA,CAAC,ECLD,ovFACA,uBAA6D,OAAU,GAAW,IAClF,uBACA,uBACA,WACA,kCAA8C,EAAE,GAGhD,OADA,OACA,CACA,CAAC,KAsBM,GAAqB,EAAI,CAChC,CADgC,MAChC,eACA,oBACA,MAAU,CAxBV,SAAS,CAAM,EACf,gBADe,CACf,MACA,SAEK,GACL,EAoBA,MAAU,CAnBV,SAAe,GACf,SACA,OAFe,CAEf,QACA,uBACA,WACA,kCAAkD,EAAK,GAEvD,YACA,WACA,2CAA2D,EAAK,GAEhE,SACA,CACA,wBACA,CAMA,CAAC,ECpCM,GAAe,EAAO,CAC7B,IAD6B,GAC7B,IACA,cACA,4CACA,aACA,CAAC,EACM,GAAoB,EAAO,CAClC,IADkC,GAClC,IACA,mBACA,4CACA,aACA,CAAC,EACM,GAAkB,EAAO,CAChC,IADgC,GAChC,IACA,iBACA,6CACA,aACA,CAAC,EACM,GAAuB,EAAO,CACrC,IADqC,GACrC,IACA,sBACA,6CACA,aACA,CAAC,EACM,GAAkB,EAAO,CAChC,IADgC,GAChC,IACA,iBACA,4CACA,aACA,CAAC,EACM,GAAuB,EAAO,CACrC,IADqC,GACrC,IACA,sBACA,4CACA,aACA,CAAC,EACM,GAAqB,EAAO,CACnC,IADmC,GACnC,IACA,oBACA,6CACA,aACA,CAAC,EACM,GAA0B,EAAO,CACxC,IADwC,GACxC,IACA,yBACA,6CACA,aACA,CAAC,EACM,GAAgB,EAAO,CAC9B,IAD8B,GAC9B,IACA,eACA,4CACA,aACA,CAAC,ECrDM,GAAe,EAAK,CAC3B,EAD2B,KAC3B,IACA,cACA,+CACA,CAAC,EACM,GAAoB,EAAK,CAChC,EADgC,KAChC,IACA,mBACA,+CACA,CAAC,ECTM,GAAkB,EAAK,CAC9B,EAD8B,GAC9B,YACA,WACA,qEACA,CAAC,EACM,GAAqB,EAAK,CACjC,EADiC,GACjC,eACA,WACA,qEACA,CAAC,ECTM,GAAe,EAAO,CAC7B,IAD6B,GAC7B,IACA,cACA,4EACA,aACA,CAAC,EACM,GAAkB,EAAO,CAChC,IADgC,GAChC,IACA,iBACA,6EACA,aACA,CAAC,EACM,GAAkB,EAAO,CAChC,IADgC,GAChC,IACA,iBACA,4EACA,aACA,CAAC,EACM,GAAqB,EAAO,CACnC,IADmC,GACnC,IACA,oBACA,6EACA,aACA,CAAC,ECvBM,GAAc,EAAO,CAC5B,IAD4B,GAC5B,IACA,aACA,oBACA,aACA,CAAC,ECJM,GAAiB,EAAI,CAC5B,CAD4B,MAC5B,KACA,gBACA,UZiCA,KYjCqB,aZiCrB,CYjC6B,KZiC7B,CYjC6B,GAC7B,UZ6BA,KY7BqB,UAAU,GZ6B/B,OY7B+B,EAC/B,CAAC,ECPD,mBACA,mBACa,GAAI,OACV,OACA,SAAS,GAAM,GACtB,KADsB,EACtB,4BACA,CACO,SAAS,GAAM,GACtB,KADsB,EACtB,wBACA,CCRO,IAAM,GAAI,MACJ,GAAI,GACV,EADU,OACD,GAAM,GACtB,IADsB,GACX,EAAM,EACjB,CACO,CAFU,QAED,GAAM,GACtB,IADsB,GACX,EAAM,EACjB,CCoEA,CDrEiB,GCqEjB,GANU,CACV,OA/DA,MAoEe,GApEN,EAAM,OACf,EAmE4B,EApEb,CACf,GAGA,IADA,MADA,OAEA,GAVA,YAWA,aAXA,IAYA,OAEA,KAdA,KAcA,GACA,aAfA,IAgBA,OAKA,OAHA,SAEI,EAAM,YACV,CACA,EAgDA,OAzCA,CAyCY,QAzCZ,OACA,oCACA,GACA,QAGA,MADA,UACA,sCAEA,SACA,QACA,CAfA,IAeA,MACA,CAhBA,IAgBA,iBACA,IACA,EAAM,QAlBN,IAkBM,CAGN,OADA,YACA,CACA,EAyBA,eAfU,CAeU,QAfsB,GAC1C,EAc0B,KAd1B,EAVA,IAUA,EACA,EAVA,MAUA,EACA,EAVA,QAUA,EACA,EAVA,WAUA,EACA,EAVA,YAUA,EACA,EAVA,cAUA,EACA,EAVA,gBAUA,EACA,EAVA,kBAUA,EACA,EAVA,mBAUA,EACA,EACA,CAKA,ECzEO,SAAS,GAAM,OAEtB,OADiB,GAAM,YACL,GAAM,cAEjB,qBAEP,OADI,GAAM,cACV,CACA,CACO,eACP,OAAW,GAAM,iBACjB,CCNO,SAAS,GAAM,KACtB,KADsB,CACtB,aACA,EAAuB,GAAqB,GAC5C,IAAsC,GAAqB,CADf,EAE5C,QAD2D,SAC3D,KAIA,OAHI,GAAe,OACf,GAAe,OACnB,WACA,IAAe,GAAM,QACrB,CAIO,CALc,QAKL,GAAM,GACtB,MAAkB,CADI,CACE,GACxB,MAA+B,GAAa,GAC5C,MAAiC,GAAa,eAC9C,kBACA,oBACA,gCAEA,WAAe,GAAM,QACrB,CAiBO,CAlBc,KAkBR,GACb,KACA,KAFmB,MAGnB,CACA,kBAIA,SACA,YACA,YACA,cACA,YACA,CACA,CClDO,IAAM,GAAQ,CAAK,IAAI,CANpB,EAMoB,IAAM,CAL1B,CAKW,UAAe,MAAQ,UAH5C,YACA,OAAW,GAJD,EAIqB,EAAM,GACrC,CAHqB,EAEG,CAAC,MAAY,ECLrB,GAAI,CAAG,CDKM,KCLN,iBAAoB,EAC3C,oBACA,CAKO,SACP,KACA,KACA,mBACA,OACA,YACA,YACA,aACA,CACA,UACA,4BACA,qBACA,+BACkB,GAAa,aAE/B,UAAwC,GAAa,aACrD,CAEA,gDAGA,CACA,CC5BA,eACA,+DACA,CACO,IAAM,GAAS,GAAI,CAC1B,OAD0B,KAAP,IAEnB,QACA,oBACA,CAAC,EACY,GAAS,GAAI,CAC1B,OAD0B,KAAP,IAEnB,QACA,oBACA,CAAC,ECNM,iBACP,UAAY,aAAiB,SAC7B,MAEA,SAuUA,OACA,WAAY,GAAS,EACrB,OAAmB,GAAS,OAC5B,0CAAkD,QAAW,WAE7D,eACA,WAMA,QANA,EACA,2BAEA,OADA,WACA,CACA,CAIA,EArVA,WAA8D,GAAS,SAEvE,SAoVA,OACA,WAAY,GAAS,EACrB,WACA,WAMA,QANA,EACA,kBAEA,OADA,WACA,CACA,CAIA,EA/VA,WAA+D,GAAM,QAErE,CASA,mBACA,eACA,gBACA,YACA,cAEA,OADA,YACA,CACA,CACA,QACA,CACO,MAAM,GACb,IACA,SACA,UACA,MACA,GAMA,sBACA,YACA,eACA,iBACA,aAGA,WACA,CAOA,YACA,YAGA,iBACA,6BAGA,iBACA,6BAEA,OACA,qBACA,OACA,iBAEA,GACA,SAAwB,eAAkB,KAC1C,UACA,wDAGA,eACA,kEAEA,OAAwB,GAAG,WAC3B,CACA,QACA,2CAA2D,cAAc,2CAEzE,CACA,CACA,OACA,qBACA,QACA,SAAwB,YAAe,eACvC,EAAkC,GAAa,KAC/C,KAD+C,EACvB,GAAG,qBAC3B,CACA,OACA,oBAGA,2CAA2D,cAAc,2CAEzE,CACA,CACA,UACA,OAAe,GAAG,cAClB,CACA,uBJnFsB,IIqFtB,aADA,GAEA,SAFA,EAEA,MACA,YAHA,EAGA,WJvFsB,EIwFG,gBJxFH,EIoFtB,EAIyB,YJlFzB,SADA,EACA,MACA,iBACA,+BACY,MAAU,GjB7Bf,KACP,SACA,SACA,+BACA,SAEA,YAAqB,eAAoB,IACzC,eACA,SAGA,QACA,EiBiBsB,iBIgFtB,CACA,YACA,iBACA,CACA,SACA,OAAiB,aACjB,CACA,OACA,YAEA,4BAEA,4CACA,aAAsB,gBAAgB,GAYtC,gBACA,WACA,YAGA,GADA,aAC6B,GAE7B,IAFgC,GADhC,EAKA,iBALA,CAKA,QALA,EAKA,OALA,EAKA,QALA,EAKA,CAMA,YAAoB,8BAXpB,EAYA,WAAuB,GAAG,yBAC1B,CACA,cAWA,WAXA,EAIA,YAAoB,sBAlBpB,EAmBA,EAA2B,GAAa,GACxC,OAAmB,GAAG,aACtB,CAMA,CAMA,qBACA,sBACA,qDAEA,oCACA,8BAEA,UACA,OACA,UAIA,WAA+B,GAAG,cAHlC,qDAA4E,GAAY,kBAMxF,SACA,sBACA,WAA2B,GAAG,QAC9B,CACA,QACA,8BAEA,CACA,CAIA,mBACA,OAAe,GAAG,cAClB,CAOA,qBACA,OAAe,GAAG,aAClB,CAQA,iBACA,SAAiC,GAAG,eACpC,gBACA,gCAEA,QACA,CAUA,sBACA,MAAsB,GAAG,gBACzB,yBACA,EAA+B,EAAM,iCACrC,kCACA,gCAEA,+CACA,MAA2B,GAAa,kCAIxC,OAHA,cACc,GAAG,YACH,GAAG,oBACjB,oBAWA,uBACA,QACA,OACA,SAAgC,GAAa,eAE7C,OADA,KACA,CACA,EACA,MACA,KASA,GARA,QAEA,IACA,KAGA,MAEA,aACA,wCAAwD,EAAQ,GAEhE,QACA,MACA,IADsC,EAEtC,IADmC,EAGnC,eAAiB,qDADjB,IACiB,OACjB,CAOA,kBACA,kBAUA,KACA,aAEA,SACA,SAAoC,GACpC,OACgB,GAAS,OACzB,YAAkC,GAAS,OAAQ,EAAE,EAAO,GAC5D,CAEA,KAAa,GAAS,QACtB,SAAoC,GACpC,MAD6C,CACzB,GAAS,oBAE7B,KAAa,GAAM,QACnB,SAAoC,GACpC,GAD0C,GAC1C,CAAoB,GAAM,oBAE1B,KAAa,GAAM,QACnB,SAAoC,GACpC,GAD0C,GAC1C,CAAoB,GAAM,oBAE1B,QACA,WACA,uGAEA,yBAGA,EAvCA,KACA,EAAoB,GAAG,UACvB,6BACA,sEAIA,OADA,eACA,CACA,CACA,CA0DA,WACA,MACA,mBACA,MAAuB,GAAqB,GAC5C,IAAoC,GAAqB,CADb,EAE5C,QADyD,SACzD,gBAIA,OAHI,GAAe,OACf,GAAe,OACnB,WACA,CACA,CACA,sCE1WO,IAAgB,GAAG,CAAY,IAAK,CAAK,IAAK,CAAK,IAAK,CAAM,IAAK,CAAM,IAAK,CAAM,IAAK,CAAM,IAAK,CAAM,IAAK,CAAM,IAAK,CAAY,ECXtI,iBACP,wBACA,CAMO,iBACP,wBACA,CCZA,qBACA,OACA,OACA,SACA,SACA,OACA,SACA,QACA,CAAS,CACT,SACA,QACA,CACA,CACA,CFCO,EAAiB,GAAG,CAAI,IAAK,CAAQ,GEA5C,wBAEA,IADA,wBACA,UACC,GACD,kBACA,wBAEA,sBACA,UACA,YAAoB,WAAgB,IACpC,6BAEA,QACA,CAAC,KAED,MAAgB,GADhB,QAC2B,MAD3B,KAC2B,QAC3B,YAAoB,WAAgB,IACpC,qBAEA,QACA,CAAC,EACD,IACA,QACA,WACA,IAAS,GAAK,OACd,UACA,SACA,UACA,GAAO,EAAK,ECpCL,SAAS,GAAU,YAC1B,MAAiB,CADS,CACJ,IACtB,WACA,qCAAiD,EAAS,IAG1D,2BAAkC,SAAY,EAAE,EAAO,EACvD,CCZO,CDWoD,QCX3C,GAAM,KACtB,KADsB,EACtB,EACA,SAEA,+BACA,SAEA,YAAoB,eAAkB,IACtC,eACA,SAGA,QACA,CCbO,SACP,GACA,EACA,iBACA,WACA,KANO,GAOP,4CAEA,mBACA,EAAmB,GAAe,GAClC,YAAwB,WAAe,IACvC,UAEA,cACA,SAEA,UACA,SACA,WACA,CACA,OACA,qCACA,CACA,iBACA,6BAGe,GAAgB,aAC/B,CACA,CChCO,iBACP,wCACA,CCAO,SACP,QACA,gBACA,iCACA,CACA,OACA,kBAAqC,GAAW,CAChD,uCAEA,6BACA,YAEA,CACA,OACA,kBAAqC,GAAW,CAChD,uCAEA,YAAwB,uBAA0B,IAClD,2BACA,mBACA,KACA,CAEA,QACA,CACA,QACA,kBAAqC,GAAW,CAChD,uCAEA,MAAkB,GAAY,0BAC9B,mBAEA,OADA,mBACA,CACA,CACA,UACA,kBAAqC,GAAW,CAChD,uCAEA,iCACA,oBAEA,OACA,sBACA,GAKA,CACA,CChDA,QACA,aACA,kBACA,+BACA,mDACA,+FACA,qLAGA,IACA,eACA,uBACA,wCACA,wEACA,wIACA,wPAGA,8CCVO,IAAM,GAAK,CAClB,QADkB,OD8CH,KC5CgB,ID4ChB,QAAuB,mBAAuB,EAAI,EACjE,UACA,+EAGA,uBACA,KACA,gBA5BA,OACA,gBACA,4EAGA,YACA,QACA,IAEA,kBACA,yBACA,kBACA,YAAsB,YAAwB,IAC9C,gBACA,uBAEA,CAEA,QACA,EASA,OAGA,cACA,CAEA,gBA/CA,KACA,YACA,QAGA,YAAqB,WAA2B,IAChD,gBACA,wBAGA,QACA,EAoCA,IACA,EC1D+B,GAC/B,OACA,CAAS,GAET,aACA,CAGO,YACP,qBAIA,OAHA,eACA,OAAkB,EAAI,GAEX,GAAoB,YAC/B,EAT8B,GAAK,EAQJ,EARI,MAEnC,CCdO,UACP,WACA,UACA,gBACA,SACA,MACA,KACA,iBACA,GACA,6BACA,gCACA,0CACA,aACA,gBACA,kBAAiC,GACjC,SADsC,CACtC,QAAiC,GAAY,OAC7C,CACA,CAF6C,GAE7C,GACA,oBACA,GAAmB,GAAoB,IAEvC,UAAgC,GAAW,4CAC3C,8CACA,+BAOA,GANA,uBACA,qBAAkC,GAAM,kBAExC,uBACA,qBAAkC,GAAM,kBAExC,+CAEA,OADA,aACA,GAEA,YACA,IAAqB,GAAY,qBACjC,iBACA,qBAAkC,GAAM,kBAExC,YAAwB,EAxCxB,IAwC4C,KAC5C,8BACA,YAOA,GAJA,+BACA,uBACA,qBAAsC,GAAM,kBAE5C,uBAEA,OADA,aACA,GAGA,SAEA,CACA,QACA,CACA,OACA,oBACA,GAAmB,GAAoB,IAEvC,UAAgC,GAAW,EAFJ,IAEI,sCAC3C,8CACA,8BACA,KACA,SAEA,mCACA,kCACA,CACA,UACA,oBACA,GAAmB,GAAoB,IAEvC,UAAgC,GAAW,EAFJ,IAEI,sCAC3C,8CACA,iCACA,KAEA,OADA,aACA,EAEA,mCACA,iCAIA,OAHA,GACA,aAEA,CACA,CACA,eACA,uDACA,CACA,CAEA,QACA,KACA,MACA,MACA,KACA,CCrGO,UACP,UACA,YACA,gBACA,MACA,aACA,KACA,iBACA,GACA,gCACA,qDACA,0CACA,sBACA,kBAAiC,GACjC,SADsC,CACtC,QAAiC,GAAY,QAC7C,CAD6C,GAC7C,eACA,IAAgB,GAAY,CAC5B,QAD4B,GAC5B,gBACA,2BACA,qCACA,eACA,eACa,EACb,CAEA,OAIA,GAHA,oBACA,GAAmB,GAAoB,IAEvC,YACA,GAHuC,GAGvC,GAEA,gCACA,YAaA,OAXA,UAEA,MAA0B,GAAY,CACtC,QADsC,GADtC,8DAGA,2BACA,qCACA,eACA,eACa,EACb,2BAEA,QACA,CACA,OACA,oBACA,GAAmB,GAAoB,IAEvC,YAAwB,GAFe,GAEf,qBAA8B,IACtD,+BACA,SAGA,QACA,CACA,UACA,oBACA,GAAmB,GAAoB,IAEvC,YAAwB,GAFe,GAEf,qBAA8B,IACtD,kCACA,SAGA,QACA,CACA,YACA,uCACA,UACS,EACT,CACA,CC1EO,uBACP,qCACA,+BACA,SACA,sBACA,CACA,CAwBO,MAAM,WAAsB,MACnC,YADmC,wBACnC,aACA,wBACA,SACA,kCACA,CACA,CAIO,uBACP,gDACA,wBACA,SACA,iCACA,CACA,CAoFO,MAAM,WAAa,MAC1B,GAD0B,IAC1B,iCACA,eACA,SACA,yBACA,CACA,CAwBO,uBACP,0CACA,iBACA,SACA,2BACA,CACA,CAIO,uBACP,gDACA,uBACA,SACA,iCACA,CACA,CAsHO,MAAM,WAAuB,MACpC,aADoC,wBACpC,aACA,0BACA,SACA,mCACA,CACA,CCjTe,cACf,SAOA,OALA,8BACA,YACA,UACA,CAAE,EAEF,CACA,CCRA,SACA,MACA,MACA,IACA,IACA,iBACA,GACA,sBACA,gEAEA,sBACA,cACA,WACA,WACA,cACA,CACA,eACA,iCAGA,wBACA,8BACA,GACA,CACA,QACA,4BACA,cAKA,OAFA,6BACA,8BACA,CACA,CACA,UACA,sCAEA,CACO,SACP,KACA,GACA,MACA,iBACA,IAA4B,EAC5B,0BACA,2BACA,oBACA,WACA,CACA,wBACA,oBACA,aAEA,CACA,CACA,QAIA,GAHA,gBACA,yCAEA,oBACA,gBACA,mDACA,iBACA,CACA,CACA,QACA,wBACA,qCACA,qBACA,oBACA,YACA,mBACA,CAIA,OAHA,gBACA,yCAEA,CACA,CACA,UACA,0BACA,CACA,CC/BO,MAAM,WAAU,MACvB,KACA,iBACA,KACA,sCACA,oBACA,wBACA,CACA,CACO,gBAA8B,EAerC,gBA6BA,SAIA,EACA,EACA,EAJA,OADA,SACA,MACA,MAAqB,GAIrB,CAJyB,CAIT,KAkChB,CAlCwB,CAkCxB,GACA,QACA,MAEA,UACA,GAEA,KAEA,CADA,MAAqB,GACrB,CADyB,KACzB,GACA,GAA4B,QAAY,GAExC,QAAsB,QAAY,EAClC,GAEA,MACA,KACA,SAGA,2CACA,8EAEA,UAA4B,gBAAoB,CAChD,EACA,KACA,EACA,GACA,KACA,gBAA+D,QAAY,GAkD3E,GAvCA,GACA,yBAAmC,YAAc,CACjD,KA3EA,UACA,IACA,gBACA,YAEA,KACA,OAAyB,SAEzB,iCACA,MACA,OACA,UACA,IACA,OACA,CACA,SACA,IACA,CACA,QACA,CACA,CAAa,CACb,QACA,CACA,aAGA,oBACA,YACA,EAA4B,IAC5B,CAAiB,CAEjB,CACA,EA4CA,OAZA,KACA,MAAqB,GACrB,CADyB,GAEzB,CAAiB,UAUjB,MARA,IACA,KACA,CAAiB,UAOjB,OACA,MACA,qBACA,cACS,CACT,sBAMA,EACA,EANA,gBAEA,GADA,qBACA,aAKA,SACA,uBACA,OACA,MAAmC,GACnC,EACA,SAF6C,SAE7C,WACA,EAAiB,EAEjB,IACA,oBACA,UACA,EACA,CACA,QACA,CACA,kBACA,iCAEA,EACA,CACA,EACA,QACA,SAEA,QAsCA,OArCA,GACA,yBAAmC,YAAc,CACjD,SACA,SAEA,UACA,WACA,UACA,KACA,UAEA,CAAqB,UAErB,YACA,WACA,UACA,IACA,UAEA,CAAqB,UAErB,OACA,QACA,SACA,UACA,KACA,UAEA,GAEA,qBACA,wBACS,CACT,WACA,YAEA,CAEA,EA7MA,IACA,gBACA,WACA,OAAqB,SAErB,iBACA,cAEA,OACA,iBAEA,cAEA,EACA,EACA,CCsCO,MAAM,WAAU,MACvB,EADuB,EACvB,CACA,iBACA,KACA,sCACA,oBACA,uBACA,wBACA,CACA,CAIO,2BAEP,UAAsB,GAAU,qCAChC,gBACA,kBAEA,oBACA,aACA,kCACA,2BACA,qBACA,qCAEA,CACA,UACA,IACA,uBACA,MAEA,CACA,SACA,IACA,KACA,MACA,CACA,IACA,IACA,EACA,MACA,IACA,WACA,EACA,OACA,IACA,IACA,EACA,+BACA,wBACA,qBACA,kCAEA,CAAK,CACL,CCvJO,uBACP,yCACA,wBACA,SACA,0BACA,CACA,CCpBO,MAAM,WAAU,MACvB,KACA,SAFuB,QAGvB,OACA,sCACA,oBACA,0BACA,wBACA,CACA,CAIO,6BAOP,EANA,WACA,SAEA,aACA,0BAAkC,GAAU,4CAI5C,UAAsB,GAAU,2CAChC,IACA,2BACA,EACA,oBACA,OACA,IACA,EACA,6BACA,CAAa,EACb,CACA,QACA,CACA,SACA,gCAEA,CACA,CCxCO,SACP,SACA,mBACA,GACA,cACA,cAAwB,KACxB,CAD8B,GAC9B,iCACA,mDACA,CACA,UACA,8CAAwD,GACxD,CACA,MAFkE,GAElE,CACA,sDACA,CACA,CCRO,SACP,GACA,GACA,QACA,WACA,MACA,UACA,uBACA,KACA,QAXA,GAAc,kDAAuD,EAAE,WAAW,EAYlF,qBACA,UACA,eACA,mBACA,eACA,kBACA,EACA,oCACQ,EAAe,4BACvB,oCACA,CACA,SACA,wBACA,CACA,UACA,8BACA,0BACS,MAGT,0BAAsC,IACtC,MADgD,MAChD,GAEA,CACA,eAA2B,EAC3B,UAA8B,GAAY,UAG1C,OAFA,wBACA,iDACA,mBAEA,YACA,sBACA,iCACA,IACA,wCACA,YAAiC,GAAU,SAC3C,mBAAsC,CACtC,8BACa,0BACb,4BACA,qBACA,CAAa,EACb,sBACA,CACA,SACA,4BACA,oBACA,CAAa,EACb,qBACA,QACA,CACA,kCACA,cACA,CACA,CACA,UACA,4BACA,YACA,mDACA,CAAS,CACT,CACA,CCrEO,iBAAoB,EAC3B,YACA,GAF4C,IAG5C,OACA,QACA,iBACA,IAAyB,EACzB,QACA,yDACA,iDACA,eACA,oBACA,6CACA,cACA,EACA,uBACA,qBACA,sCACA,CAEA,CAAa,EAEb,iBACA,cAEA,oBACA,iBAaA,OAVA,oBACA,+BACA,CAAa,EACb,kBAGA,oBACA,8BACA,CAAiB,EAEjB,GAEA,kCACA,MACA,wBACA,wBACA,IACA,KACA,QAEA,UAGA,iCACA,eACA,QACA,aAEA,YAAgC,oBAAuB,IACvD,sBACA,uBACA,KACA,CAEA,eACA,yBACA,8BACA,CAAa,EACb,GACA,CACA,QACA,CACA,WACA,mBACA,iBACA,0BAEA,CAIA,eAEA,GADA,4BACA,yBACA,UAAsB,GAEtB,UAAwB,CAFY,EAET,KAI3B,OAHA,gBACA,8BACA,yBACA,UACA,SACA,oCAAkD,SAAgB,EAClE,kCAAgD,YAAU,YAAe,EACzE,IAEA,UACA,uBAEA,aAAgC,oBAAuB,IACvD,sBACA,uBACA,KACA,CACA,CAIA,MAFA,gCAA8C,SAAa,EAC3D,kCAAgD,YAAU,WAAmB,EAC7E,CACA,CAAS,CACT,CAIA,QACA,sCACA,CAIA,QACA,uBACA,YAA0B,GAC1B,CAAS,EACT,IAFoC,CAEpC,OACA,CAMA,iBAEA,eAGA,MAAc,GAAS,uBACvB,CAYA,0BAEA,aAGA,MAAc,GAAS,uBACvB,sBACA,CAAS,CACT,CASA,gBAEA,mCAGA,MAAc,GAAS,sBACvB,CAIA,WACA,yBAKA,aACA,sCAKA,cACA,oBAYA,sBACA,4BACA,MAAuB,GAAQ,CAC/B,IAD+B,OAC/B,EACA,CAAS,EACT,MACA,QACA,aAGA,aAEA,QACA,EACA,MACA,gBACA,gBAEA,EACA,MACA,WACA,EACA,OACA,GACA,EAEA,OACA,MAAwB,GAAU,iBAClC,EAEA,qCACA,iCACA,gCACA,uCACA,IACA,OACA,QACA,CAEA,wCACA,oCACA,mCACA,0CAEA,GACA,CACA,CACA,CC5PO,iBAA8B,EACrC,eADsD,SACtD,CACA,SACA,KACA,IACA,OACA,aACA,YACA,WACA,2BACA,KACA,QACQ,EAAe,UACvB,UADuB,EACvB,KACA,qBACA,0CACA,sBACA,kClDvBO,EkDwBP,6BAD8E,GAC9E,ElDvBO,EkDuB0C,IACjD,cACA,WAF8E,QAE9E,CXsDO,qBACP,KWvDwD,EXuDxD,QACA,GAAW,QAAQ,CDiCZ,UAGP,MAZA,wBACA,OACA,EAEA,OACA,EAEA,CACA,EAIA,GAGA,eAFA,OAGA,oDLxHO,IKyHP,MADsG,CAEtG,aACA,MAH0H,KAG1H,EACA,iBACA,CACA,EC9CmB,KACnB,IAHO,SAGP,EAAyB,CACpB,CACL,EW3DwD,kBACxD,CACA,qBAAoC,EAEpC,MAAuB,GAAM,0BAC7B,uBACA,WAEA,OADA,2CACA,EAEA,MAAyB,KAEzB,CAF+B,EAC/B,+BACA,2BACA,QACA,uCACA,KACA,qCAAuD,UAAU,GAAG,EAAI,GACxE,yEAEA,oCACA,GACA,gDAEA,CACA,SAIA,MAA0B,GAAK,CAC/B,CAD+B,WAC/B,kBACS,EACT,iCAAiD,EACjD,iCACA,iHACA,yCACA,CAAS,EACT,iCAEA,KACA,0BACA,CAAS,EACT,+BACA,2BAKA,kBACA,eACA,2EAEA,YAAgC,qBAChC,0BADuD,KAIvD,sEACA,aACA,CAEA,gDAEA,mDACA,wBACA,mCACA,CAAa,EACb,UACA,0DACA,WACA,CAAa,CACb,CAAS,EACT,UACA,eACA,iCACa,CACb,kBACa,EACb,UACA,wBAKA,2DACA,CAAa,CACb,EAEA,oCAEA,6CACA,eACA,0BACa,CACb,UACA,CAAa,IAEb,UACA,wBAKA,2DACA,CAAS,EACT,IACA,8BAEA,CACA,uCACA,UACA,uBACA,CACA,CACA,SACA,+CACA,mDACA,SAGA,0BACA,CACA,aACA,qDACA,CACA,wBAEA,gDAIA,kBAIA,CACA,2BACA,MAAyB,KACzB,CAD+B,CAC/B,EAuCA,OApCA,kBACA,eAEA,mBADA,uEACA,6BACA,iDACA,MAEA,0BAGA,0DACA,uBAEA,mCACA,QACA,CAAiB,IAEjB,QACA,6BACA,aAGA,4CACA,sCACA,KACA,CACA,CAEA,GADA,8DACA,IACA,UAA0B,EAA0B,SAAU,GAAO,KAAK,GAAO,EAAE,EAA/B,EAA+B,OAAW,gBAAgB,EAAI,EAElH,CAAS,EACT,UACA,2FACA,WACA,CAAS,EACT,UAEA,CC1MO,SACP,QACA,SACA,OAGA,OAFA,aACA,aACA,KAGA,kBACA,iBACA,MAIA,OAHA,YACA,eAEA,CACA,CAEA,aACA,UACA,kCAGA,QACA,CAEA,WACA,oCAGA,8BAGA,WACA,oCAGA,gCAGA,iBACA,gCACA,sBACA,SAGA,QACA,CAAS,CACT,CAOA,qBACA,gCACA,WACA,+BAIA,UACA,CAAS,CACT,CAMA,oBACA,gCACA,QACA,IACA,kBACA,cACA,OAGA,iBAEA,QACA,+BACA,sBACA,cACA,OAEA,2BACA,oBAGA,QACA,CAAiB,EACjB,cACA,MAIA,GAFA,KACA,OACA,IAGA,KACA,YACA,KAJA,MAQA,QACA,MACA,OAEA,IAjCA,SAiCA,IACA,OAGA,CAEA,CAAS,CACT,CAEA,eACA,gCACA,wBACA,YAA4B,WAAgB,KAC5C,+DACA,cACA,MAEA,OACA,CACA,QACA,CAAS,CACT,CAEA,eAQA,UACA,YAA4B,aAAuB,KACnD,UAEA,iBACA,wDACA,cAKA,OAJA,UACA,YACA,YACA,YACA,SAGA,+DACA,cACA,aAEA,UACA,YACA,CACA,qBAEA,gCAEA,yBACA,WACA,UACA,SAGA,MAKA,kCAGA,iCAPA,OAYA,yBAEA,mBADA,WAIA,OADA,4BACA,CACA,CAAS,CACT,CAEA,aACA,+CACA,CACA,CCnMA,WAAmB,GCFZ,GDEkB,MCFlB,MACP,QAAmB,SDGH,CAAS,EACzB,GCJ4B,CDI5B,QADyB,CACzB,CAJA,EAIA,EAGA,iDACA,ECR4B,EAC5B,CAEO,eACP,QAAmB,SDMH,CAAS,EAKzB,GCX4B,EDQ5B,OAFyB,CAEzB,OACA,qBAEA,UAhBA,EAgBA,EAGA,iDACA,ECf4B,EAC5B,CAEO,eACP,QAAmB,SDaH,CAAO,EAKvB,CClB0B,EDe1B,OAFuB,GAEvB,OACA,qBAEA,UA3BA,EA2BA,EAGA,+CACA,ECtB0B,EAC1B,iBCgBA,QAzBA,YACA,aACA,gBACA,cACA,iBACA,gBACA,eACA,eACA,eACA,eACA,gBACA,iBACA,iBACA,eACA,kBACA,kBACA,iBACA,iBACA,kBACA,gBACA,kBACA,iBACA,cACA,qBACA,CACA,WAA4D,UAAO,KACnE,eACA,gBACA,iBACA,SAEA,QACA,CC9BA,UACA,iCAEO,MACP,EACA,SACA,iBAGA,SACA,WAIA,YACA,GAEO,MACP,EACA,+BACA,SACA,GAEa,GAAM,IACnB,EACA,GAFmB,GAEnB,sCACA,UAAmB,OAAO,CAC1B,GAEO,OACP,EACA,6CACA,UAAmB,OAAO,CAC1B,GAEO,OACP,EACA,UACA,eAGA,8BAIA,6CANA,SAOA,IACoB,GAAS,WAAY,KAAQ,EACjD,CACA,SACA,QACA,CAKA,iBACA,CAAS,CACT,eAAwB,OAAO,CAC/B,GAEO,OACP,EACA,UACA,eAGA,kBAFA,SAKA,IACgB,GAAS,YACzB,CACA,MACA,QACA,CACA,iBACA,CAAS,CACT,oBAA6B,SAAS,CACtC,GAEO,MACP,EACA,UACA,uBACA,OACA,EAEA,CACA,CAAS,CACT,oBAA6B,UAAgB,GAC7C,EAEa,GAAE,QACf,EACA,UACA,MACA,gBACA,gBAEA,SAIA,8BACA,KAEA,QACA,SAGA,CACA,CAAS,CACT,cAAuB,+BAAwC,GAC/D,EAEO,WACP,EACA,UACA,gBAEA,iBAEA,UACA,SAEA,GACA,CACA,QACA,CAAS,CACT,eAAwB,+BAAwC,GAChE,EAEO,kBACP,cACA,YACA,gBACA,iBACA,UACA,SAEA,GACA,CACA,QACA,CAYA,OACA,WACA,QAbA,YAEA,WADA,IAEA,EAWA,WAVA,YACA,iBACA,QAGA,YACA,CAKA,CACA,CChIA,OAAc,GAAG,GAAQ,QAAU,MACnC,GAAc,GAAG,GAAQ,QAAU,MACnC,GAAiB,GADwB,GACb,WAAa,MACzC,GAAa,GADkC,GACvB,OAAS,MAeb,GAAG,GAAQ,GAAS,KAAD,CAAO,CAe1B,GAAG,GAAQ,GAAS,KAAD,CAAO,CAgBvB,GAAG,GAAW,GAAS,KAAD,CAAO,CAgB7C,OAAY,GAAI,GAAE,aAAgC,GAAS,KAAD,CAAO,CACxE,GAAa,GAAG,GAAQ,OAAS,GAAK,CAAD,IACrC,CAD4C,EAC/B,GAAI,GAAO,OAAS,GAAK,CAAD,IACrC,CAD4C,EAChC,GAAE,OACd,GAAsB,GAAE,gBAgBI,GAAI,GAAE,GAAM,EAAN,CAAS,GAAG,aAAgC,GAAS,KAAD,CAAO,GAiB1E,GAAG,IAiBH,GAAG,IAcJ,GAAG,IACrB,OAAa,GAAG,GAAgB,GAAO,OAAS,MAChD,GAAa,GAAG,GAAgB,GAAO,OAAS,MAAM,GAahC,GAAI,GAAO,GAAS,KAAD,CAAO,EAa7B,GAAG,IACtB,OAAc,GAAG,GAAO,GAAO,SAC/B,GAAgB,GAAG,GAAO,GAAO,YACjC,GAAsB,GAAE,OAaJ,GAAG,IAaD,GAAG,IACzB,OAAa,GAAE,gBACf,GAAoB,GAAG,GAAG,EAAJ,CAAW,GAAO,MAAQ,GAAS,KAAD,CAAO,EAarC,GAAG,IAC7B,OAA0B,GAAG,GAAG,EAAJ,CAAW,GAAO,OAAS,GAAS,KAAD,CAAO,CAAM,GAAG,GAAO,GAAO,OAAS,GAAS,GAAG,EAAJ,CAAY,OAAS,OAAY,GAAO,EAAb,EAAa,EAAQ,GAAS,KAAD,CAAO,EAa7I,GAAG,IACnC,OAAsB,GAAG,GAAO,GAAO,iBAAmB,GAAS,KAAD,CAAc,EAAL,CAAc,KAAD,CAAc,EAAL,CAAc,KAAD,CAAO,CAazF,GAAG,IAC/B,OAAsB,GAAG,GAAU,GAAO,gBAAkB,GAAS,KAAD,CAAc,EAAL,CAAc,KAAD,CAAc,EAAL,CAAc,KAAD,CAAO,CAa3F,GAAG,IAC/B,OAAa,GAAE,MAAiC,GAAG,GAAO,GAAS,KAAD,CAAO,CAAM,GAAG,GAAgB,GAAS,KAAD,CAAO,CAAM,GAAG,GAAgB,GAAS,KAAD,CAAO,OAAoC,MAAM,GAa7K,IAcC,GAbN,GAAG,GAAO,GAAO,eAAiB,MAAM,CA2BnC,GAAG,GAbN,GAAG,EAAJ,CAAW,GAAO,eAAiB,GAAO,UAAY,GAAS,KAAD,CAAO,CAAM,GAAG,GAAO,GAAO,UAAY,GAAS,KAAD,CAAO,CAAM,GAAO,YA2B/I,OAAa,GAbN,GAAG,GAAG,EAAJ,CAAoB,GAAO,OAAS,KAAU,CAAJ,EAAW,QAAU,GAAS,KAAD,CAAO,CAAM,GAAG,GAAgB,GAAO,QAAU,GAAS,KAAD,CAAO,GA2BhJ,GAAc,GAAG,GAbN,GAAG,EAAJ,CAAoB,GAAO,OAAS,GAAG,GAAG,EAAJ,CAAY,OAAS,GAAO,SAAW,GAAG,KAAW,CAAJ,EAAW,WAAa,GAAS,KAAD,CAAO,CAAM,GAAG,GAAgB,GAAO,OAAS,GAAO,QAAU,GAAS,KAAD,CAAO,CAAM,GAAG,GAAgB,GAAO,SAAW,GAAS,KAAD,CAAO,GC9U3Q,SAAS,GAAQ,YACxB,GADwB,CACxB,EAAiB,EAAK,IACtB,C3BoCqB,E2BpCrB,QACA,qCAAiD,EAAS,IAG1D,uCACA,CCFO,SAAS,GAAc,GAC9B,KAZQ,IAaR,EADgB,CADc,IAE9B,CADkB,CAGlB,KAdQ,MAcQ,MAAE,CAClB,EAEA,KAhBQ,MAgBQ,EAChB,IADkB,GAClB,EAEA,KAlBQ,MAkBQ,KAChB,CADkB,MAClB,EAEA,KApBQ,MAoBQ,MAAE,OAClB,EAEA,KAtBQ,MAsBQ,MAAE,EAClB,SAEA,KAxBQ,MAwBQ,MAAE,IAClB,SAEA,4DACA,4CAEA,QACA,CACO,qBACP,OAAY,GAAc,IAC1B,OACA,IAF0B,EAE1B,OAjCS,EAiCoC,EAC7C,KADgD,CAGhD,QACA,aArCS,EAqCoC,EAC7C,KADgD,CAGhD,QACA,aAzCS,EAyCoC,EAC7C,KADgD,CAGhD,QACA,aA7CS,EA6CoC,EAC7C,KADgD,CAGhD,QACA,aAjDS,EAiDoC,EAC7C,KADgD,CAGhD,QACA,aArDS,EAqDoC,EAC7C,KADgD,CAGhD,QACA,aAzDS,EAyDoC,EAC7C,KADgD,CAGhD,QACA,aACA,OACA,KAEA,mCACA,CACA,QACA,CAwCO,iBACP,IACA,EADA,OAGA,GADA,EADA,EACA,MAAe,CAAI,CACnB,CADe,CA/GN,EAgHG,IAIZ,GAJe,CAIf,GAAgB,CADhB,UACgB,CAAI,IACpB,EArHS,EAqHG,KAIZ,EAJe,CAIf,KADA,UACgB,CAAI,KACpB,EA1HS,EA0HG,KAIZ,EAJe,CAIf,KADA,UACgB,CAAI,KACpB,EA/HS,EA+HG,KAIZ,EAJe,CAIf,KADA,UACgB,CAAI,CAxIZ,GAwIgB,MAAE,EAC1B,EApIS,EAoIG,KAIZ,EAJe,CAIf,IAAgB,CADhB,UACgB,CAAI,CA5IZ,GA4IgB,MAAE,GAC1B,EAzIS,EAyIG,KAIZ,EAJe,CAIf,KAAgB,CADhB,SACgB,CAAI,CAhJZ,GAgJgB,MAAE,KAC1B,EA9IS,EA8IG,KAIZ,EAJe,CAIf,KADA,UACgB,CAAI,CApJZ,GAoJgB,MAAE,OAC1B,EAnJS,EAmJG,GAlCZ,IAkCe,GAlCf,CAqCA,4CACA,CA6CO,SAAS,GAAM,eAItB,CAHA,SACA,GAAc,GAAY,GAAc,KAAf,UAAe,GAExC,YACA,UApIO,kBACP,OAAY,GAAc,IAC1B,OACA,IAF0B,CAE1B,WAxES,EAwEsC,GAC/C,IADkD,EAGlD,QACA,gBA5ES,EA4EsC,GAC/C,IADkD,EAGlD,QACA,gBAhFS,EAgFsC,GAC/C,IADkD,EAGlD,QACA,gBApFS,EAoFsC,GAC/C,IADkD,EAGlD,QACA,gBAxFS,EAwFsC,GAC/C,IADkD,CAClD,CAEA,QACA,gBA5FS,EA4FsC,GAC/C,IADkD,CAClD,CAEA,QACA,gBAhGS,EAgGsC,GAC/C,IADkD,CAClD,CAEA,QACA,iBACA,OACA,KAEA,mCACA,CACA,QACA,EAiGA,MAEA,CACO,SAAS,GAAM,cACtB,wBACA,QAGA,SA5DO,KACP,IACA,EADA,WAGA,GADA,EADA,EACA,CAzJU,IAyJV,CAAe,CAAI,CACnB,EA5JS,EA4JG,IAIZ,GAJe,CA1JL,IA6JV,cACgB,CAAI,IACpB,EAjKS,EAiKG,KAIZ,EAJe,CAIf,KAAgB,CADhB,aACgB,CAAI,KACpB,EAtKS,EAsKG,KAIZ,EAJe,CAIf,CAxKU,IAuKV,cACgB,CAAI,KACpB,EA3KS,EA2KG,KAIZ,EAJe,CAIf,CA7KU,IA6KM,CADhB,aACgB,CAAI,CApLZ,GAoLgB,MAAE,EAC1B,EAhLS,EAgLG,KAIZ,EAJe,CAIf,CAlLU,IAiLV,cACgB,CAAI,CAxLZ,GAwLgB,MAAE,GAC1B,EArLS,EAqLG,KAIZ,EAJe,CAIf,CAvLU,GAuLM,CADhB,cACgB,CAAI,CA5LZ,GA4LgB,MAAE,KAC1B,EA1LS,EA0LG,KAIZ,EAJe,CAIf,KAAgB,CADhB,aACgB,CAAI,CAhMZ,GAgMgB,MAAE,OAC1B,EA/LS,EA+LG,GAlCZ,IAkCe,GAlCf,CAqCA,4CACA,EAiBA,IAEA,CE3NO,iBACP,SACA,kCAEA,MAAmB,GAAW,GAC9B,IACA,CAF8B,GAE9B,WACA,WACA,YAEA,OAAW,CACX,CJiWsB,GAbN,GAAG,GAAI,CIrVA,CJqVL,CAAY,UAAY,KAAU,GAAS,IAAb,CAAY,CAAO,GMhW5D,sBACA,gBACP,4BACA,EAFO,IIEA,eACP,QAEA,MADA,uBACA,CACA,0BAIA,OAHA,2BACA,yBACA,CAAS,EACT,CACA,CACA,GAboB,GAapB,GAb0B,KAe1B,EADA,qBAEA,QAAoB,WAAqB,SAEzC,EAnBoB,GAkBpB,GAlB0B,CAkB1B,IAGA,WACA,KAA8B,GAAkB,wBAEhD,gBACA,aAAsC,GAAkB,uBAExD,CACA,aACA,iBACA,oBAEA,sBACA,iBACA,iBAEA,eACA,QAAwB,sBAA2C,KAEnE,YACA,iBAA0C,IAAO,IACjD,YAEA,mBACA,CACA,2BACA,QAAoB,WAAqB,KACzC,uBACA,iBACA,YACA,CACA,QACA,CACA,iCACA,EAEa,GAAQ,kBACrB,MACA,gBACA,6BACA,UACA,SAEA,YAAwB,IAAY,IACpC,eAEA,kBACA,CACA,WACA,SAEA,YAAwB,IAAY,KACpC,sCAEA,mBACA,uCACA,WAAwB,IAAI,OAC5B,CACA,QACA,ECjFO,MACA,MAyEA,SAAS,GAAW,GAC3B,qBAD2B,CAC3B,CACA,eACA,mBAEA,gCAAkD,EAAM,EACxD,CACA,uBACA,eACA,mBAEA,gCAAkD,EAAM,EACxD,CACA,yCAAiD,SAAa,EAC9D,CC1DO,iBAEP,OADqB,GAAW,GAChC,MACA,OACA,QACA,gBA8FA,GACA,MAAqB,GAAW,cAChC,WACA,kCAEA,IAAS,GAAO,GAChB,kCAEA,QACA,EAvGA,EACA,SAOA,QACA,QACA,QACA,QACA,SACA,SACA,SAZA,YACA,QACA,SACA,QACA,SACA,uBASA,UACA,gBA0IA,GACA,MAAiB,GAAa,GAC9B,IAD8B,KAC9B,CAA8B,GAAqB,IACnD,WADmD,GACnD,EACA,oCAEA,OAAW,GAAkB,cAC7B,CAD6B,CAhJ7B,EACA,UAEA,SADA,gBAoLA,GACA,4BACA,sBACA,EAAiB,GAAkB,YACnC,GADmC,EACnC,GACA,SAAc,EAAK,GAAG,EAAK,GAzL3B,EAGA,UACA,OAyHA,YACA,MAAiB,GAAa,GAC9B,IAD8B,KAC9B,CAA2B,GAAqB,IAChD,WADgD,GAChD,EACA,oCAEA,UAAiB,GAAkB,cACnC,CADmC,CA/HnC,EACA,UACA,2CACA,SACA,OAAmB,GAAkB,WACrC,CACA,CAFsD,EAAjB,OAG9B,QAEP,OADqB,GAAW,GAChC,MACA,OAEA,QAJgC,OAGhC,SAsDA,GACA,IAAS,GAAO,GAChB,kCAEA,OAAW,GAAU,EACrB,EA3DA,EAGA,SAOA,QACA,QACA,QACA,QACA,SACA,SACA,SAZA,YACA,QACA,SACA,QACA,SACA,yBASA,UACA,gBA0EA,OACA,EAEA,EADA,uBACa,GAAc,GAAS,OAAV,CAAU,GAAY,EAAK,UAGxC,GAAG,yBAGhB,sBAAiC,GAAa,WAC9C,OAAW,GAAgB,wBAC3B,EArFA,EACA,UACA,gBA4GA,GACA,mBACA,gBACA,8CAA0D,eAAkB,sCAE5E,oBACA,2CAAuD,MAAS,2BAGhE,MAAgB,GAAM,iBAEtB,oBACA,gBACA,qDAEA,YACA,OAAW,GAAgB,wBAC3B,EA7HA,EACA,UACA,gBA4HA,GACA,mBACA,gBACA,8CAA0D,eAAkB,sCAE5E,oBACA,2CAAuD,MAAS,4BAGhE,MAAgB,GAAM,WAAY,KAAQ,GAE1C,oBACA,gBACA,qDAEA,YACA,OAAW,GAAgB,wBAC3B,EA7IA,EACA,UACA,gBAgFA,GACA,mBACA,kBAAiC,GAAa,WAC9C,OAAW,GAAgB,wBAC3B,EApFA,EACA,UACA,2CACA,SACA,OAAmB,GAAoB,WACvC,CACA,CAFwD,CD/FxD,KC+FuC,CD/FvC,OACA,aACA,eACA,eACA,IARA,GAQA,WACA,gBACA,IAVA,GAUA,UACA,IAXA,GAWA,WACA,IAZA,GAYA,WACA,IAbA,GAaA,cACA,gBACA,eACA,0BACA,4BACA,uBACA,wBACA,iBACA,sBACA,cACA,cACA,KAxBA,GAwBA,cAIA,KA5BA,GA4BA,QAEA,KA9BA,GA8BA,OACA,gBACA,iBACA,mBACA,KAlCA,GAkCA,YACA,cACA,KApCA,GAoCA,OACA,eACA,kBACA,uBACA,KAxCA,GAwCA,YACA,aACA,cACA,6BACA,eACA,KA7CA,GA6CA,aACA,KA9CA,GA8CA,UACA,CAEA,YACA,eAIO,WACP,OACA,OACA,OACA,OACA,eACA,QACA,CACA,KAZA,EACA,cACA,YACA,CAAC,ECpCmB,GAAW,OACX,GAAW,OACR,GAAW,IAFH,MAqG/B,IApG+B,GAoG/B,OAnGkC,MAmGlC,CAA+B,IAAK,kBACpC,cACA,sBAEA,OADA,kCACA,CACA,CAAC,GAiBD,eACA,yBAGA,OAFA,gBACA,eACA,iBACA,CACA,eAEA,WADA,mBACA,uBACA,CACA,eACA,MAAgB,GAAoB,GACpC,gBADoC,CACpC,CAAiC,GAAa,WAC9C,OAAW,GAAgB,wBAC3B,CACA,eACA,MAAiB,GAAa,GAE9B,IAF8B,EAC9B,QAAoB,GAAqB,KACzC,UADyC,CAEzC,oCAEA,OAAW,GAAkB,EAC7B,CC3GO,YD0GsB,CC1GtB,EACP,SACA,KACA,OACA,IACA,kBACA,MAAqB,GAAa,KAClC,EADkC,GACK,GACvC,EAAkB,GAAW,GAC7B,IAFuC,OAkEvC,KACA,YACA,gBAEA,cACA,QAEA,EACA,MAAqB,GAAa,8CAClC,SAAsB,GAAqB,EAC3C,CACA,EA3EA,UAyE2C,EAzE3C,IACA,UACA,YACA,YACA,KAEA,QACA,CACA,yBAEA,IADA,QACA,SACA,GADgC,GAChC,kCAA8D,GAAkB,aAGhF,cACA,MAA2B,GAAe,KAE1C,GADA,IAD0C,EAC1C,QACA,aAIA,IACA,KACA,CACA,CACA,OACA,yBACA,aACA,SACA,eACA,MACA,CACA,CAIA,eACA,SASA,OARA,UACA,MAAsB,GAAW,MAKjC,OAJA,WADiC,EACjC,EACA,wBACA,aAEA,IACA,CAAK,EACL,eACA,CAIO,eACP,OAAW,GAAgB,UAC3B,MAAsB,GAAW,MACjC,kBAAkC,GAAa,SAI/C,OAHA,wBACA,GAAkB,GAAgB,WAElC,CACA,CAAK,EACL,CAwCO,eACP,oDACA,CACO,eACP,yCACA,CCrJA,gDACO,sDACP,IACI,GAAW,YACX,GAAW,SADA,GACA,CACX,GAAW,QADA,IACA,CACX,GAAW,QADA,GACA,KACf,OACA,CAFe,UAEf,MACA,uCACA,SACA,oCACA,CACA,CAIO,SACP,OACA,GACA,GACA,GACA,GACA,mBACA,OAKA,EACA,GAJA,SACA,OAGA,wBACA,EAAoB,GAAqB,QAEzC,UAFyC,GAEzC,UACA,iCACA,0BAA8C,EAAK,0BAEnD,EDpDO,YACP,QACA,ECkD0C,EDlD1C,KACA,KACA,OACA,wBACA,2BACA,OACA,qBACA,WACA,UACA,gBACA,SACA,EAEA,YAAoB,WAAkB,KAEtC,MAAsB,GADtB,MAEA,eACA,GAFiC,GAEjC,WACA,iBAEA,QACA,CAEA,iBACA,gCAGA,gBAIA,2BACA,eAAqC,GAAc,YACnD,mBACA,KACA,CACA,MAAsB,GAAc,aACpC,mBACA,eAAuC,GAAe,WACtD,CADsD,MAEtD,CACA,aACA,YACA,SACA,eACA,MACA,CACA,ECG0C,EAC1C,KACA,IAAiB,CEsHV,EFtHP,GEsHO,EFtHqB,EEuH5B,CFvH4B,EEuH5B,CAA2B,GAAM,CFtHjC,EEsHiC,GFtHQ,cAGzC,IAHyC,EAGzC,4DACA,CACA,mBACA,iBACA,iBACA,uBACA,eAEA,WACA,eAEA,SACA,sBACA,CACA,gBACA,EACA,EACA,EACA,EACA,SACA,EAAoB,GAAW,OAC/B,EAAoB,GAAW,OAC/B,EAAoB,GAFW,OAG/B,EAAoB,GAFW,OAG/B,EAAqB,GAAW,QAChC,EAAwB,EAFO,CAEI,WADH,IAEhC,SADmC,EACnC,oBACA,YACA,OAA2B,OAAY,EAGvC,iBACA,SACA,MACA,KAA0B,MAAY,EAAE,EAAK,EAC7C,kBAEA,2BACA,EAA4B,GAAW,QACvC,gBADuC,GAGvC,2BACA,EAA4B,GAAW,QACvC,KAA0B,MAAY,EAAE,EAAK,CADN,CAEvC,kBAGA,sCACA,oDAAoE,8BAA8B,EAAE,QAAQ,EAAE,SAAS,EAAE,KAAK,KAQ9H,MANA,CACA,SACA,OACA,YACA,MACA,CAEA,CACA,SACA,0CAA4D,CAAE,GAAW,IACzE,CACA,aACA,MAHyE,CAGzE,qBACA,CACA,aACA,0BAA4C,GAAW,QACvD,CACA,SACA,MAHuD,CAGvD,OACA,CACA,eACA,eAEA,eAEA,OADA,YACA,oCACA,CACA,eACA,mBACA,kBACA,mBACA,OACA,uBAAuC,iBAAiB,+BAA+B,aAAgB,GAEvG,2BACA,CACA,mBACA,oBACA,qBAAwC,KAAQ,IAChD,eACA,cAAqC,GAAa,eAGlD,WACA,CACA,YACA,IACA,SACA,sCACA,IAA6B,GAAK,UAClC,cAIA,IAA6B,EAAK,sBAClC,MAEA,CAAa,EAEb,cACA,iBACA,WAGA,0BACA,OAA2B,GAAmB,GAAS,WAAY,CAAtB,CAAgC,gBAG7E,OAAuB,GAAmB,GAAG,YAAJ,MAAI,mBAC7C,CACA,WACA,CACA,SACA,WACA,CACA,CACA,UACA,eAEA,UACA,OAAe,GAAgB,mBAC/B,CACA,iBACA,0CAEA,WACA,aAEA,MAAyB,GAAS,YAClC,WACA,0CAA4E,OAAqB,GAGjG,MADA,kBACA,OAAiC,GAAS,GAC1C,CACA,MAF0C,OAE1C,CACA,uBACA,4CACA,4EAA4F,YAAkB,2CAA2C,SAAS,IAElK,OACA,gBACA,eACA,YAEA,CACA,sBACA,gCACA,cAGA,iCAGA,gCAIA,CAaA,OACA,mBAA4B,QAAa,GAEzC,CEpJO,eA8FA,SAAS,GAAS,GACzB,OADyB,IACV,GAAc,EAC7B,CCpKA,GDmK6B,CCnK7B,IACI,GAAS,YACT,GAAS,SADA,EACA,CACT,GAAS,SADA,EACA,KACT,GAAS,KADA,GACA,KACT,GAAS,QADA,IACA,CACb,CACA,UAFa,EAEb,GACA,wBAEA,eACA,8BACA,QACA,GAEA,IAAe,EAAK,EAEpB,iBACA,MACA,IACA,EAAe,GAAS,QAExB,SAEA,MACA,CACA,iBACA,kBACA,WAGA,CACA,eACA,2BAA6C,GAAS,YACtD,CACA,WAFsD,CAEtD,OACA,SAAqC,GAAS,SAC9C,WACA,IAF8C,EAE9C,kCAAoD,GAAS,QAAqB,GAElF,aAF6D,OAG7D,IAA0B,GAAS,YACnC,IAAmB,EAAQ,GAE3B,CACA,CACA,CALmC,GAKnC,IACA,aACA,WACA,aACA,EAEA,IAAmB,EAAM,GAEzB,YACA,cACA,WACA,2CAEA,eAAwB,oBAAwD,GAAG,EAAM,EACpF,CACL,YACA,cACA,WACA,2CAEA,eAAwB,oBAAwD,GAAG,EAAM,EACpF,CACL,iBACA,cACA,cACA,aACA,aACA,cACA,WACA,2CAEA,SAAkB,oBAAwD,QAAQ,EAAM,EACnF,CACL,YACA,cACA,WACA,2CAEA,SAAkB,oBAAwD,OAAO,EAAM,EAClF,CACL,aACA,YACA,QACA,QACA,cACA,iBAA8B,EAAI,EAAE,EAAK,EAGzC,cACA,WACA,2CAEA,0BAGA,OADA,yBACA,GARA,uBAQ2B,EAAE,EAAQ,EAChC,CACL,oBACA,cACA,WACA,2CAEA,0BACA,wBACA,SAAkB,EAAQ,GAAG,EAAa,EACrC,CACL,YAGA,cACA,WACA,2CAEA,0BACA,CAAK,CACL,YAGA,cACA,WACA,2CAEA,0BACA,CAAK,CACL,cACA,cACA,WACA,2CAEA,0BAGA,OADA,yBACA,WAA0B,EAAQ,EAC7B,CACL,WACA,YACA,QACA,QACA,cACA,eAA4B,EAAI,EAAE,EAAK,EAGvC,cACA,WACA,2CAEA,0BAGA,OADA,yBACA,GAAkB,EARlB,iBAQ2B,EAAE,EAAQ,EAChC,CACL,YACA,cACA,WACA,2CAEA,0BAGA,OADA,yBACA,SAAwB,EAAQ,EAC3B,CACL,6BACA,cACA,WACA,2CAEA,SAAkB,oBAAwD,qBACrE,CACL,0BACA,cACA,WACA,2CAEA,SAAkB,oBAAwD,kBACrE,CACL,4BACA,cACA,WACA,2CAEA,SAAkB,oBAAwD,oBAE1E,CCpNO,UACP,KAOA,KAOA,GAMA,OAIA,KAMA,UACA,gBACA,KACA,uCACA,gEAA+E,kBAAkB,EACjG,CAUA,MACA,wBACA,OAAe,GAAM,SACrB,CAKA,uBACA,mCAKA,GAJA,oBAAkC,aAAe,EAGjD,uBACA,gBACA,iDAAiE,GAAK,eAAe,UAAU,6BAE/F,iBAEA,sBACA,OACA,SACA,EACA,+BACA,IACA,qBAoBA,OAnBA,UACA,UACA,sBACA,gBACA,SACA,iCACA,CAAqB,CACrB,mBACA,CAAiB,iBAEjB,GADA,iCACA,MAEA,MADA,UACA,2CAA6E,GAAK,eAAe,SAAS,GAG1G,OADA,UACA,qCACA,CAAiB,EACjB,kBAEA,OACA,CACA,SAGA,mBACA,0CAA8D,GAAK,eAAe,UAAU,aAG5F,OADA,UACA,2CAAiE,EAAI,EACrE,QACA,CACA,kCACA,iBACA,CACA,CASA,qBAKA,YACA,EAEA,UAEA,KAUA,2BACA,CAIA,yBACA,SACA,CACA,WACA,OACA,iBACA,eACA,sBACA,kBACA,8BAEA,CACA,CCtIO,+BACP,yCAEA,eAxBO,OACP,oBACA,GAAY,GAAK,eAAkC,GAAI,gBrBsEhD,QqBrEP,MAGgB,GAAG,aAGW,KrBgE9B,IADO,EqB/DuB,CrBgEhB,CqBhEgB,kBrBiE9B,MAzCA,sBAAiC,IAAI,eAAe,IAAI,SA0CxD,GACA,SAtCA,GACA,mBACA,cACA,SAEA,oCACA,gCAEA,UADA,GAAmB,8BAAsC,GAAG,4BAAmC,GAAG,8BAAsC,GAAG,4BAAmC,EAE9K,EA6BA,GAxBA,gBAA2B,IAAI,UAAU,IAAI,UAAU,IAAI,UAAU,IAAI,SAyBzE,GACA,SAxBA,GACA,mBAEA,UADA,cAEA,EAoBA,GACa,GAAM,UAnBnB,KAoBA,IAnBA,aAmBA,IAlBA,kBAA0B,IAAI,UAAU,IAAI,UAAU,IAAI,UAAU,IAAI,SAkBxE,IAjBA,oBAA4B,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,SAiB5F,IAhBA,qBAA6B,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,SAgBrI,IAfA,iCAAyC,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,SAejJ,IAdA,wBAAgC,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,SAcxI,IAbA,oBAA4B,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,gBAAgB,IAAI,SAaxJ,IAZA,qBAA6B,IAAI,UAYjC,IAXA,mCAWA,IAVA,iBAAyB,IAAI,UAU7B,SAEA,EqBtEA,UACA,SAAoB,GAAO,cAC3B,8DACA,QAEA,CACA,QACA,CAAK,CACL,EAIA,kBACA,gBACA,SAMA,MAAoB,SFwLb,KExL2B,IF0LlC,KADwB,GACxB,OADwB,KACxB,GACA,UACA,WACA,2CAEA,MAAqB,GAAS,MAC9B,aACA,KAF8B,IAE9B,EACA,wCAAoD,OAAc,GAElE,oBAmBA,OAlBA,oBAEA,2BAEA,EADA,aACA,WAA6B,EAAI,EAGjC,UAA4B,EAAI,GAGhC,oGAEA,0BAEA,eACA,8BAGA,CACA,EExNkC,KAClC,WAAkB,GAAgB,IAClC,CACA,CCpCA,ODkCkC,UClCI,GACtC,QACA,IAFqD,SAErD,CACA,UACA,kBACA,SACA,KACA,sCACA,CAAS,EACT,uBACA,oCAAmD,GACnD,mBADyE,SACzE,EAA6C,EAC7C,CACA,gBAFgE,IAEhE,OACA,kDACA,sCAGA,OAFA,mDACA,wBACA,CACA,CACA,8BAA6C,EAC7C,MAAe,GAAwB,gEACvC,CACA,iBACA,uBACA,CACA,YACA,0CACA,CACA,CCzBO,SACP,cACA,WACA,QACA,IACA,mBACA,MAAqC,EACrC,uEACA,qBACA,uBACA,oCAAmD,GACnD,mBADyE,SACzE,EAA6C,EAC7C,CACA,gBAFgE,CAEhE,IAAoC,EACpC,SACA,mBAAoC,GAAwB,kEAC5D,iDACA,IACA,sCACA,mDACA,IACA,uBACA,CACA,SACA,oEAEA,QACA,CACA,QACA,CACA,SASA,GARA,+DACA,mBACA,UAGA,kDAAwF,GAAK,eAAe,MAAY,IAGxH,wBACA,8FACA,KACA,CACA,CACA,CACA,cACA,4DAA2F,GAAK,kBAGhG,kDAAiE,GAAK,kBAEtE,CACA,kBAA8B,EAC9B,OAAe,ID1Bf,GC0B4C,CAC5C,mBACA,EAF4C,MAE5C,aACS,EACT,KACA,2BACA,iCACS,CACT,CACA,CCpEO,UACA,MACA,gBAAmC,EAC1C,cAA+B,GAA2B,IAC1D,CEcO,mBFfmD,0BGenD,sCC+DP,GA3EA,KA2Ee,EAAE,EAAC,CA3ElB,IACA,IACA,kCACA,gBAiBA,GAEA,GADA,cACA,WACA,mEAEA,iJACA,MACA,WAEA,uBACA,6BACA,UACA,YACA,WACA,UACA,SACA,QACA,OAtCA,SAsCA,CACA,aACA,WACA,QACA,OA3CA,OA2CA,CACA,YACA,UACA,QACA,cACA,aACA,WACA,UACA,SACA,QACA,aACA,eACA,aACA,WACA,UACA,QACA,OA9DA,IA8DA,CACA,eACA,aACA,WACA,UACA,QACA,OArEA,IAqEA,CACA,oBACA,kBACA,YACA,WACA,SACA,QACA,SAEA,wBAAwC,GAAM,2CAC9C,CACA,EAvEA,GAEA,mCACA,eA4FA,YACA,yBACA,GAvGA,MAwGA,OAxGA,MAwGA,OAEA,GA3GA,KA4GA,OA5GA,KA4GA,QAEA,GA/GA,IAgHA,OAhHA,IAgHA,UAEA,GAnHA,IAoHA,OApHA,IAoHA,UAEA,GAAc,GAAI,KA1GlB,YAyEA,GACA,yBACA,GApFA,MAqFA,GAAkB,aArFlB,OAqFqC,GAErC,GAxFA,KAyFA,GAAkB,aAzFlB,MAyFqC,GAErC,GA5FA,IA6FA,GAAkB,aA7FlB,KA6FqC,GAErC,GAhGA,IAiGA,GAAkB,aAjGlB,KAiGqC,GAErC,GAAc,EAAG,KAvFjB,EAEA,gDACA,CACA,SAIA,YA+GA,iBAlHA,GAkHA,OAlHA,GAkHA,YAlHA,EACA,GAAiB,UAAc,UAAU,kBAAsB,EAC/D,gCAEA,CACA,EAqGA,qBAEA,SAAc,iBAAoB,EAAE,EAAK,EADzC,SAC2C,OAAoB,CAC/D,CEtHA,kBA0MA,IAGA,mBACA,CACA,SAGA,CACA,IAcA,GAAe,KAAK,IDnOL,GA8Cf,kBACA,EAEA,EACA,EAFA,WAGA,iBAGA,cACA,OAIA,uBACA,UACA,CAJA,EAIA,OAJA,EAKA,OALA,EAMA,OACA,IACA,oBACA,uBAEA,gBAGA,OACA,2CAEA,YACA,SAEA,KAEA,sBACA,yBACA,WACA,SAzBA,EAyBA,GAEA,cACA,GACA,CACA,QACA,CAAa,EAGb,kBAlCA,EAkCA,GAEA,eACA,MArCA,EAqCA,EACA,CAiCA,OAhCA,cAEA,0BACA,yBACA,WACA,oBACA,CAD6C,MAC7C,4BACA,cACA,gBACA,QACA,SACA,GAGA,mBAEA,eACA,gBAEA,GAEA,QACA,GACA,CACA,CAAS,EAGT,2BAEA,UAGA,CACA,CACA,gBACA,6CAEA,OADA,eACA,CACA,CAuEA,cACA,oBACA,mCACA,sBACA,CAsBA,OAtOA,UACA,YACA,SAkNA,mBACA,mBACA,mBAEA,CACA,EAtNA,UAsKA,WACA,UACA,kBACA,6BACA,WAEA,OADA,aACA,CACA,EA5KA,SAwIA,gBAOA,EALA,UAEA,eACA,WACA,WAEA,gDACA,WACA,QAAoB,IAAS,IAC7B,OAKA,OADA,4BACA,IACA,0CAGA,gCAGA,EA9JA,UAkLA,gBAIA,EACA,EAJA,uBACA,SAIA,yBAAoD,IAAS,IAC7D,sBACA,SAGA,yBAAoD,IAAS,IAC7D,sBACA,SAGA,QACA,EAlMA,WAA2B,GAC3B,CADmC,CACnC,QAuNA,WACA,qJACA,EAxNA,2BAEA,UACK,EAIL,WACA,WAMA,gBAgBA,cATA,YACA,QACA,YAAwB,WAAsB,IAE9C,EADA,yBACA,EAGA,CAHuB,MAGvB,qCACA,EA6LA,gCAEA,mBAEA,CACA,ECLoB,CAAG,WA3GvB,YAOA,GANA,8BACA,eACA,2BACA,KACA,2BACA,IAAc,GAAQ,WACtB,gBACA,OAEA,2BACA,iCAIA,QACA,IACA,+BACA,WAGA,IACA,UAGA,MAEA,CAAK,EACL,eACA,EA8EuB,KAjEvB,YACA,IACA,EACA,uBAGA,uBAEA,CACA,SAGA,CACA,EAoDuB,KA9CvB,WACA,MACA,IACA,sBACA,CACA,SAGA,CAKA,MAHA,6DACA,iCAEA,CACA,EAgCuB,UAvIvB,iBAKA,2GAIA,0GAMA,kFAGA,sHAGA,6HAEA,8FACA,EA+GuB,gBAbvB,YAIA,gBACA,IACA,wBACA,CACA,SACA,+CAEA,CACA,EACuB,OA7NvB,CACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,UACA,CAgJuB,eAvEvB,oCAuEuB,CAA0E,CAAC,CEzE3F,CFyE4F,QEzE5F,MAEP,eA7FA,GACA,aAQA,OAPA,aACA,WACA,SACA,aACA,cACA,iBACA,eACA,CACA,EAmFA,GAAwC,EAAK,SAK7C,OAHQ,GAAK,WAAY,EAAK,UAAiB,MAAL,GAAK,0DAC/C,GAAgB,GAAK,GAAI,EAAJ,MAAS,IAE9B,cAAyB,GAAK,IAC9B,CAD8B,KDzJf,GC0JK,GAAI,CD1JJ,CC0JA,CD1JC,KC0JQ,GAC7B,OACA,CAAK,CACL,CAUA,eACA,YAIA,IADA,aACA,OAGA,QACA,CAxJA,GAAK,gBACL,oBAAqC,GAAS,cAG9C,GAAK,gBACL,oBAAqC,GAAM,cAG3C,GAAK,gBACL,oBAAqC,GAAM,cAG3C,GAAK,gBACL,iCAGA,GAAK,gBACL,iCAGA,GAAK,gBACL,iCAGA,GAAK,gBACL,iCAGA,GAAK,gBACL,oGC/DA,WAAsD,WAAS,EAC/D,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oFACA,oBAEA,uBACA,sBACO,kBAAqB,KAAM,CAClC,cACA,oBAKA,mBACA,mBACA,oBACA,oBACA,mBACA,mBACA,oBACA,mBACA,mBACA,oBACA,oBACA,mBACA,mBACA,mBACA,mBACA,kBACA,CAEA,MACA,IAAgB,iFAAiE,KACjF,wCAGA,qCACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,YACA,WACA,CACA,aAEA,YAAwB,KAAQ,SAChC,qBACA,wBAEA,aAAyB,KAAQ,KAEjC,iBACA,aACA,EAAwB,YAAU,QAAkB,YAAU,QAAkB,WAAS,QACzF,EAAwB,YAAU,QAAkB,YAAU,QAAkB,WAAS,QAEzF,YACA,YACA,EAAwB,YAAU,SAAiB,YAAU,SAAiB,WAAS,QACvF,EAAwB,YAAU,SAAiB,YAAU,SAAiB,WAAS,QAEvF,EAAyB,WAAS,uBAClC,EAAyB,WAAS,wBAClC,WACA,SACA,CACA,OAAc,8EAAiE,KAE/E,YAAwB,KAAQ,KAEhC,MAA4B,YAAU,SAAe,YAAU,SAAe,YAAU,SACxF,EAA4B,YAAU,SAAe,YAAU,SAAe,YAAU,SAExF,WACA,WAGA,EAAyB,WAAS,oBAClC,EAAwB,WAAS,sBACjC,MAEA,EAA4B,YAAU,SAAe,YAAU,SAAe,YAAU,SACxF,EAA4B,YAAU,SAAe,YAAU,SAAe,YAAU,SACxF,cACA,cACA,MACA,MACA,MACA,MACA,MACA,MACA,EAAe,SAAiB,SAAO,mBACvC,MACA,MACA,MACA,MACA,MACA,MACA,MAAwB,WAAS,QACjC,EAAiB,WAAS,UAC1B,KACA,CAEA,EAAW,SAAe,GAAE,MAAO,+BACnC,EAAW,SAAiB,SAAO,+BACnC,EAAW,SAAe,GAAE,MAAO,+BACnC,EAAW,SAAe,GAAE,MAAO,+BACnC,EAAW,SAAe,GAAE,MAAO,+BACnC,EAAW,SAAe,GAAE,MAAO,+BACnC,EAAW,SAAe,GAAE,MAAO,+BACnC,EAAW,SAAe,GAAE,MAAO,+BACnC,yCACA,CACA,aACA,WACA,UACA,CACA,UACA,oBACA,yCACA,CACA,CAsEO,IAAM,GAAyB,SAAe,CAAlC,IAAkC,wBC9NrD,wDAEA,uCAIO,SAAS,GAAG,KACnB,GADmB,CACnB,MACA,kBACA,CAuBO,SAAS,GAAI,OACpB,EADoB,EACpB,IACA,cACA,KACA,KAEA,QACA,CAEO,iBACP,iBACA,yDAAqE,GAAQ,MAAM,EAAO,GAI1F,MAAY,GAAG,KACf,GADe,CAGf,oBACA,cAEA,UACA,MACA,QACA,OAEA,wBACA,CAEA,GADA,IACA,GACA,sCACA,OAAW,GAAG,IACd,CA5DA,GA2Dc,IA3Dd,cAwLO,IAAM,GAAY,QAAqB,GAAG,MAAxB,CAAwB,OAEjD,IACA,kDACA,oCACA,4BACA,CAiFO,iBAEP,wCACA,iBACA,OAAa,2BACb,CAgBO,yBAAsD,EAC7D,SACA,6CAAyD,EAAM,GAC/D,IAAY,4BAAuC,QACnD,UACA,+DACA,eA7KO,GAKP,cAKA,gBACA,qBACA,iBAEA,sBACA,uCACA,QACA,CACA,CAEA,cACA,gBACA,qBACA,kBACA,aACA,aACA,uBACA,0BACA,sBACA,uCACA,QACA,CACA,CAwBA,OAhHO,gBAOP,MADA,gBAIA,eAA6B,UAAiB,WAG9C,SAAkB,cArEX,OACP,eACA,yCACA,UACA,UACA,SACA,WACA,MACA,UACA,QACA,OAEA,QACA,EAwDkB,cAA2C,KAG7D,UACA,gBACA,qBACA,iBACA,sBACA,uCACA,QACA,CACA,CAEA,gBACA,qBAEA,6BACA,uCACA,QAEA,0BACA,CAD8C,CAC9C,WACA,MADmC,CACnC,MACA,CAD8B,IAC9B,kBACA,mBACA,cAEA,CAFgC,GAEhC,IACA,mBACA,EADqC,IACrC,eAD4C,IAG5C,WAGA,EAHiC,EAGjC,6BACA,CAD4D,CAC5D,SACA,EAD4B,EAC5B,SACA,aACA,CAD8B,CAC9B,CACA,CACA,QACA,CACA,EAyDA,EACA,EAoHA,GACA,iBACA,QACA,OACA,QACA,KAAc,SAAO,IACrB,QACA,OACA,UAAyB,GAAG,KAC5B,GAD4B,KAC5B,IACA,sBACA,2DAA+E,SAAW,GAC1F,iBACA,CAAS,CACT,IAF8C,GAE9C,OACA,qBACA,OAAsB,GAAG,MACzB,EADyB,EACzB,aACA,OAAsB,GAAG,OACzB,CADyB,GACzB,OAA2B,GAAG,OAC9B,CAD8B,GAC9B,OAA2B,GAAG,OAC9B,CAD8B,GAC9B,OAA2B,GAAG,OAC9B,CAD8B,GAC9B,iBA/GO,OAGP,QACA,kCACA,UACA,aACA,UACA,SACA,YACA,IACA,WACA,MACA,eACA,WACA,OAEA,SACA,EA6FA,OACA,WAA2B,GAAG,aAE9B,YACA,gBACA,gBACA,gBACA,eACA,yBACA,gBAjGO,cACP,sBAEA,oBACA,SACA,GACA,OACA,YACK,OAEL,WAQA,OANA,uBACA,SACA,GACA,mBACA,YACK,GACL,EACA,EA8EA,KAGA,oBACA,aAAkC,QAAe,MAAe,SAAe,MAC/E,cACA,gBACA,sCAA0D,EAAM,QAAQ,SAAa,GACrF,SAA0B,SAAe,IAAU,SAAe,GAClE,CAAS,CACJ,EACL,uBACA,CAkCO,eACP,sBACA,0CAEA,mBADA,mBACA,EACA,CAQO,eACP,YACA,uBACA,CC3YA,IAAM,GAAG,UACH,GAAG,UAGT,eACA,eAYO,GAZiC,MAYjC,QACP,cACA,iBACA,YACA,EACA,MACA,uCACA,iCAAiD,EAAE,kBAAkB,EAAK,GAC1E,EACA,MACA,KAGA,CAAiB,QAFjB,iBAEiB,CAFgC,UACjD,QACiB,GADwB,MAGzC,CACA,kBAEA,kBACA,aACA,IACA,OAAuB,IACvB,EAAwB,EADE,EAE1B,IAD2B,CAC3B,QACA,aACA,IAAsB,GAEtB,KAFyB,EAEzB,CACA,CAAS,CAWT,sBACA,IAAoB,wBAAsB,KAC1C,KACA,IACA,IACA,YAAiC,IAAkB,KACnD,IACA,UAEA,YAAgC,IAAgB,IAChD,WACA,UAEA,YACA,CACA,QACA,CAAS,CAQT,YAGA,YAAoB,gBAAsB,KAC1C,SACA,SACA,iBACA,CAD6C,CAC7C,KACA,YACA,YAAiC,IAAkB,KACnD,UAEA,cAEA,MAGA,MACA,KACA,GAAyB,IAUzB,IAV4B,EAU5B,gBACA,CAD8D,CAC9D,OACA,KACA,OAEA,cANA,EAMA,GAGA,kBAEA,CAMA,SAAqB,MACrB,CAAS,CACT,kBACA,mBAEA,YAMA,OALA,IACA,6BACA,OACA,gBAEA,gBACA,CAAS,CAIT,mBACA,KACA,YACA,YACA,CAAS,CAET,CAYO,qBAOP,6DACA,mEACA,kBACA,iBACA,qCAAqD,EAAE,EACvD,CAAK,EACL,kBACA,qBACA,oCAAoD,EAAE,EACtD,CAAK,EACL,MAAkB,SAAM,mBACxB,yBACA,CADuF,CACvF,SACA,0BACA,CADsD,CACtD,2BACA,SACA,YAA2B,KAAQ,MACnC,eACA,YAAwB,WAAoB,KAE5C,cADA,KACA,oBACA,oBACA,CACA,aAEA,CAF2B,GAE3B,0BAAwD,IAAO,IAC/D,cACA,WAGA,GADA,WACA,MACA,YAA4B,IAAgB,IAC5C,YACA,CACA,QACA,CACO,eAYP,ODnBO,YAOP,CCCiB,GDDjB,oBACA,gBACA,GARA,CACA,eACA,cACA,sBACA,oBACA,GAKW,SAAc,KACzB,ECJiB,MACb,SAAc,IAClB,WACA,WACA,WACA,UACA,CAAK,EACL,2BACA,2BACA,CAAK,EAEL,eACA,GAAW,GAAO,kBAClB,KACa,aACR,CAD2B,CCrNhC,IAAM,GAAG,UAAc,GAAG,UAAc,GAAG,UAAc,GAAG,UAE5D,IAAyB,WCIzB,2FAEA,2FAEM,GAAG,UAAc,GAAG,UAAc,GAAG,UAAiB,CAAH,MAAG,GAE5D,CAF4D,GAEtD,GAAG,UAAc,GAAG,UA+B1B,iBAEA,MAAe,GAAG,MADlB,EACkB,EAGlB,CAHkC,CAhClC,YAEA,wDAGA,EADA,IADA,GAEA,EAFA,GAGA,GAD6B,EACT,EAAK,GAHzB,IAGoB,EAHpB,CAG4B,EAC5B,IAD4C,CACxB,EAAK,GAJzB,IAIoB,EAJpB,CAI4B,EAC5B,EAAiB,CAD0B,EACtB,EAAK,GAL1B,IAKqB,EALrB,CAK6B,EAC7B,KAAqB,IANrB,IAMqB,EANrB,GAOA,KAAqB,IAPrB,IAOqB,EAPrB,GAQA,KAAqB,IARrB,IAQqB,EARrB,GASA,KAAsB,IATtB,IASsB,EATtB,GAUA,KAAsB,IAVtB,IAUsB,EAVtB,GAWA,KAAsB,IAXtB,IAWsB,EAXtB,GAcA,OAAa,UAFb,GAA2B,EAAO,GAZlC,IAYqC,EAZrC,CAYqC,EAExB,KACb,EAiBA,EAFe,GAAG,MAFlB,EAEkB,GAAkB,SAEpC,CACA,EAAY,GAAG,MALf,EAKe,EACf,EAAgB,CADkB,EACf,MANnB,EAMmB,EACnB,CADmC,CACnC,EACA,CADqB,CACH,GAAG,KARrB,GAQqB,CACrB,QACA,CADgC,CAChC,IAF+C,GAEf,GAVhC,IAWA,CADgC,CAChC,IAA2B,GAAG,MAX9B,EAW8B,EAO9B,OANA,GACA,IAFyD,EAGzD,QACA,MACQ,CADW,EACC,EAhBpB,KAiBA,GAAY,GAAG,GAjBf,CAgBoB,EACL,GACF,qBACb,CAYA,OAAkC,GAAK,cA4BhC,GD7EA,SAAS,CAAc,EAC9B,MAxBA,YCoG8C,CD7EhB,GAtB9B,EAAiB,GAAa,GAa9B,OAb8B,GAC1B,EAAiB,IACrB,gBACA,WACA,WACA,sBACA,CAAK,EACL,6BACA,kBACA,mBACA,qBACA,CAAK,EAEL,eAA2B,KAAS,CACpC,EASA,GACA,IAAY,wDAA4F,EACxG,EAAiB,IAAG,YAA+B,GACnD,OADsD,GACtD,CACA,CAD4B,CACb,GAAK,kBAEpB,aACA,SACA,IACA,OAAyB,oCACzB,CACA,SACA,OAAyB,iBAAuB,EAAG,CACnD,CACA,EAAS,CACT,GAHmD,CAGnD,0BACA,EAD6E,EAC7E,QACA,WAEA,GADY,SAAK,aACjB,YACA,mDACA,QACA,EAAS,CAGT,EAHY,OAGZ,OACQ,KAAW,mBAA2B,GAAG,EACjD,CACA,IAFiD,KAEjD,KACA,qBACA,qCACA,CAGA,MAAyB,QAAQ,SACjC,IAAgB,gBAAsB,EACtC,SACA,UACA,KAAuB,GAAG,UAC1B,CADwC,GACxC,SACA,SACA,SACA,KACA,OAAqB,EAAG,GAAG,EAAK,EAAG,EACnC,CAD2B,EAC3B,GADmC,CAChB,GACnB,OADsB,KACtB,oBACA,OAAiB,QACjB,CAAK,EACL,EAA4B,QAAQ,KACpC,MAAgB,OAAO,EACvB,WACA,+BAGA,CAHgD,EAGhD,CAAgB,qBAA6B,EAC7C,SACA,CADgC,CAChC,OACA,CADgC,CAChC,OACA,CADgC,CAChC,OACA,SAGA,CAHkC,EAClC,cAAgD,EAChD,eAEA,EAF0D,IAE1D,+CAIA,GAFA,SACA,OAEA,qDACA,QACA,CAAK,CAGL,SACA,qBACA,UACA,UACA,UACA,UACA,SACA,SACA,SACA,SACA,mBACA,CACA,QACA,yBAEA,QACA,yBAEA,qBACA,kBACA,0CACA,MAAoB,OAAO,MAG3B,OAFA,SACA,SACA,UAAmC,GAAG,QAEtC,qBACA,oCACA,uDACA,CAEA,gBACA,OAAmB,GAAS,QAC5B,CAEA,kBACA,uBACA,CAGA,iBACA,OACA,CAEA,UACA,KACA,IAAoB,gBAAyB,KAC7C,CAAoB,gBAAyB,EAC7C,SACA,SACA,SACA,SACA,mBACA,CACA,MACA,0BACA,CACA,SAEA,qDACA,CAIA,SACA,MAAoB,GAAI,EACxB,CAAoB,gBAAyB,KAC7C,SACA,EADqC,EACrC,KACA,EADqC,EACV,GAAG,QAC9B,EADiD,EACjD,KACA,CADmC,CACnC,IACA,gBACA,CADuD,CACvD,IACA,CAD6B,CAC7B,IACA,CAD6B,CAC7B,IACA,CAD6B,CAC7B,OACA,CADoC,CACpC,OACA,CADoC,CACpC,OAEA,CAFoC,MAEpC,UADA,OACA,CADoC,CAEpC,CAIA,OACA,KACA,MAAoB,OAAO,EAC3B,CAAoB,qBAAiC,KACrD,CAAoB,qBAAiC,EAKrD,mBACA,qBACA,iBACA,SACA,OAA0B,GAC1B,OAD6B,IAC7B,UACA,CAD0C,GAC1C,MAAoC,GAAG,GACvC,IADuC,EACH,GAAG,GACvC,IADuC,EAEvC,MACA,MACA,SACA,SACA,SAEA,iBADA,OACA,EACA,CACA,aACA,EADqC,EACrC,KACA,EADqC,EACrC,OACA,EADyC,EACzC,KACA,EADqC,EACrC,iBACA,CAD2D,CAC3D,IACA,CAD6B,CAC7B,IACA,CAD6B,CAC7B,SACA,CADuC,CACvC,OACA,CADoC,CACpC,OACA,CADoC,CACpC,OAEA,CAFoC,MAEpC,UADA,OACA,CADoC,CAEpC,CACA,YACA,2BACA,CACA,QACA,wCACA,CAEA,YAEY,KAAW,UADvB,EACqC,GAAG,GACxC,IADwC,EACpB,KADoC,CACpC,CAAO,UAF3B,GAGA,8BAMA,wBAGA,CADY,KAAW,UADvB,EACqC,GAAG,GACxC,IADwC,IAExC,EACA,CAHwD,GAC/B,CAEzB,WAJA,IAIwC,GACxC,KACA,EAF2C,EAE3C,WACA,UAPA,GAOA,EACA,oBARA,EASA,CAKA,eACA,mCACA,CAGA,gBACA,mCACA,CAGA,YACA,gBACA,CACA,gBACA,IAAoB,KAAc,SAClC,IAA6B,GAC7B,KACA,EAFgC,EAEhC,kBACA,CAGA,uBACA,MAAoB,OAAO,EAC3B,UACA,EAAkB,SAAW,iBACjB,SAAK,aACjB,gBACA,CADwC,CACxC,MACA,eAAgD,IAChD,EAAsB,KAAkB,IAIxC,cACY,KAAW,gBAAkB,GAAG,GAG5C,IAH4C,EAG5C,OAGA,CAHoC,QAGlB,WAAoB,EAFtC,IAAgC,IAChC,KACuD,CADvD,GADsC,CACE,GAExC,GACA,mDACA,SAAgC,GAAG,GAAM,GACzC,OAD4C,CAC5C,CAD8C,EAC9C,EACA,CAD2D,EAC3D,QAAiC,IAAG,EAEpC,IAFoC,EAEpC,sCAGA,OAFA,OACA,UACA,CAD8B,CAC9B,cAAsC,MAAM,CAC5C,CACA,yBACA,kBAEA,aACA,MAAoB,OAAO,gBAC3B,EAA0B,IAAkB,YAE5C,CAF2D,MAC3D,iBAA2C,GAAG,MAC9C,CAD2D,CAG3D,KAF0B,EAE1B,CACA,OAAmB,KAAa,mBAChC,CACA,CAFqD,EAGrD,qBAA+C,GAAG,cAClD,aAA2B,GAAK,GAAK,GAAK,CAAZ,GAC9B,IAAY,EADiC,GACjC,UAAmB,EAC/B,EAAiB,GAAI,OAKrB,cACA,UAAoB,KAAkB,IAJpB,EAKlB,CAEA,cAEA,EAAc,SAAW,iBADzB,GAIA,MAAuB,SAAW,6BAJlC,GAKA,cALA,IAMA,UANA,EAMA,EANA,GAOA,KADmD,EAEnD,IADsC,QACtC,IACA,MAD0C,QAC1C,GACA,CAD+C,KAC/C,MAAiB,yCACjB,CAMA,kCAEA,aADoB,KAAc,OACO,SAAW,oBACpD,QA4CA,oBAiBA,CACA,QACA,aAtEA,YACA,wBAsEA,KA9DA,iBAA4C,EAC5C,EAAc,SAAW,cACzB,GACA,SACA,CADgC,EAChC,QAAgB,yBAA6B,KAC7C,mBACA,GADoE,CACpE,yBAEA,CAF8C,CApC/B,GAsCf,IADA,IArCkB,KAqClB,QACA,EAtCkB,CAqCyD,EAEnE,IADgC,CACrB,iBAAmB,GAAG,GACzC,IADyC,EACrB,KADqC,CACvB,EAAI,IAAkB,aACxD,MAAe,SAAW,gBAAkC,EAoD5D,OAjDA,iBADA,EACA,MAYA,MAXA,YAAgB,YAAkB,EAClC,UACA,CAD8B,CAChB,SAAW,oBACzB,EAAc,CADwC,EACxC,MAAW,cACzB,YACY,SAAK,aACjB,GACA,SACA,CADgC,GAChC,EAAkB,KAAkB,iBAIpC,IACA,iBACA,4BACA,qBACA,CACA,CAFsC,KAEtC,GACA,QACA,CACA,wBACA,SACA,2CAGA,OAFA,2BAEA,0CACA,EAuBA,gBACA,MAtBA,CACA,uBAEA,gCAOA,4BACA,oBACA,sBACA,EAEA,CAQA,CACA,GC1VA,aAGA,6BAH+C,6DAK/C,MAGA,yFAEA,EAAO,GAEP,OAFU,GAEV,iFACA,2FACA,KAAU,GACV,UADgB,CACD,OACf,kBA9DA,YAQA,OALA,UAEA,CAFqB,CAErB,SAEA,CAFsB,CAEtB,QACA,CADqB,EA2DrB,aA2IA,eACA,sBACA,sCACA,CAYA,aAAuC,GAAG,GAE1C,IAF0C,EAE1C,mBADiC,KACjC,oBAGA,eACA,MAAY,GAAI,SAChB,oBACA,OAP6G,GAO7G,WACA,IAnBgB,KAmBhB,KACA,OAAwB,GAAG,CAdY,MAevC,aACA,CAFgD,CAEhD,kBACA,CAD6C,QACnC,WAAgC,QAC1C,CAD4D,CAC5D,OACA,EAD0B,WAC1B,MAnB6H,CAoB7H,SACA,GACA,MACA,CADgB,EAEhB,MACA,CADe,GACf,SAA4B,GAAG,CAvBQ,KAuBR,GAC/B,CADwD,CACxD,IACA,aACA,CADiC,CACjC,UACA,IAAmB,GAAG,GACtB,EAD8B,EAAR,GACA,GACtB,EAD8B,EAAR,GACtB,8BA7B8H,EA6B9H,iBACA,CAQA,SAGA,EA/CiI,UA+CjI,GACA,SACA,CACA,qBACA,6CACA,CAQA,sBAGA,SADA,GADA,sCACA,cAGA,KADA,oBAEA,uBACA,CAMA,kBACA,mCACA,MAAgB,OAAO,SACvB,oBACA,qBACA,4EACA,QAGA,2DACA,eACA,aACA,IAAuB,GAAG,KAC1B,EADsC,EACf,GAAG,KAC1B,EAD0B,EAC1B,KACA,SACA,aACA,IAD4C,KAC5B,WAAoB,WACpC,IADiE,EACjE,GACA,EADgC,EAChC,OACA,CADoC,CACpC,WACA,EADmC,WACnC,MACA,UACA,CADyB,GACzB,SACA,EADgC,EAChC,KACA,CAD8B,EAC9B,2BAAoD,GACpD,OADuD,KACvD,GACA,uCAA6D,GAAG,GAChE,CAKA,GANgE,SAMhE,CACA,IAWA,EAXA,CAAc,qBAA6B,QAC3C,oBACA,qBACA,mBACA,CADiD,CACjD,OAEA,CAF+B,CAE/B,OACA,CAAgB,SAAiB,WACjC,IAD+D,EAC/D,GACA,EADsC,EACtC,KACA,EADsC,EACtC,OAEA,CAFuC,EAEvC,qBACA,QA1HgB,KA0HhB,GACA,YACA,IA5H+B,EA6H/B,EACA,IA1H0C,KA0H1C,EACA,MAEA,IAEA,EAFoB,WAEpB,QACA,UACA,CADyB,GACzB,aAGA,CAHkC,MAClC,mBACA,KAnIiI,CAmIjI,IACA,qBACA,CACA,CAFuC,MAEvC,CACA,oCACA,CACA,WACA,mBACA,CAEA,UACA,MACA,IAAgB,WAAiB,QACjC,CAAgB,WAAiB,KACjC,qBAEA,kBACA,kBACA,WACA,CACA,OAEA,OADA,MACA,yBACA,CACA,YAEA,OADA,MACA,8BACA,CACA,YACA,kCACA,CACA,kBACA,wCACA,CACA,SACA,+BACA,CACA,SACA,+BACA,CACA,CEjaO,SACP,eACA,gBACA,GACA,SAAmB,GAAgB,EDXnC,GCWyC,CAEzC,cACA,OAAe,GAAQ,OAAQ,GAAmB,MAClD,CACA,QACA,CAHkD,MAGnC,GAAG,gCAClB,CACA,WACA,OAAe,GAAS,6CACxB,CACA,gBACA,0CAGe,GAAgB,eAC/B,CACA,gBDWO,ECVP,OAAe,EAAoB,SDWxB,ECXwB,CDWtB,OCXsB,eDWtB,WCXsB,IDWtB,aCVb,CACA,CChBO,SAAS,GAAyB,GAEzC,WAAe,GADf,EAAY,GAAgB,EFhB5B,IEeyC,CAYlC,CAV6B,QAUpB,GAAgB,KAEhC,GADA,EAZ0D,CAY1D,QADgC,GAChC,aACA,WACA,UAAkB,GAAsB,sCAAuC,EAAO,QAAQ,SAAW,GAEzG,QACA,CClCA,8BACA,6BAIO,mBACP,QACA,WACA,aACA,aACA,aAgCA,8BACA,6BAIO,mBACP,QACA,WACA,aACA,aACA,aACA,aACA,aACA,aACA,aCvDA,uCACA,kCAUO,UACP,GACA,EACA,kBAMA,YAIA,WACA,CAIA,eACA,uBACA,qBACA,eAIA,OAHA,OACA,YAEA,kBACA,CACA,kCACA,CAIA,eACA,KACA,sDAEA,oBACA,qBACA,eAIA,OAHA,OACA,YAEA,6BACA,CACA,qDACA,CAIA,eACA,kCACA,CAIA,WACA,kBAGA,OAFA,0CACA,2BACA,KAKA,WACA,mBAGA,OAFA,0CACA,4BACA,KAKA,SACA,cACA,gCACA,eACA,aACA,MACA,QACA,UACA,cACA,QACA,UACA,cACA,UACA,CAIA,qBACA,UACA,UAEA,cACA,kCAEA,WACA,GACA,OAEA,aACA,aAWA,OAVA,IACA,QACA,QACA,SACA,KACA,QACA,SAIA,2BACA,CAIA,qBACA,SACA,UAEA,UACA,GACA,OAEA,YACA,wBAWA,OAVA,IACA,SACA,SACA,iBACA,IACA,gBACA,QAIA,WACA,CAIA,qBACA,mBACA,iBAEA,mBACA,iBAEA,mBACA,yBAEA,yDACA,CACA,CACA,kBACA,wBAA8B,WAC9B,mCAA8C,aAC9C,qBAA4B,UAC5B,mBCxGO,uBAEP,EACA,EAFA,EAEY,EAFZ,IAGA,YAAoB,WAAmB,IACvC,oBACA,IACA,UAEA,OACA,iBAGA,wDACA,gCACA,IACA,iBACA,qBAKA,iBACA,oBACA,iBAGA,UACA,CC3FA,iBACA,yCAA6C,OAAY,IAAI,MAAkB,IAAI,MAAW,EAC9F,CACA,iBACA,cACA,UACA,WACA,eACA,CAIO,SACP,IACA,IACA,IACA,iDACA,GAIA,WAIA,WAIA,kBAKA,SACA,iBAEA,GADA,+BACA,2BAEA,sCACA,4BAEA,uCACA,4BAEA,uCACA,4BAEA,sCACA,0BAXA,SAaA,0BAEA,MADA,kBACA,YAEA,QACA,CAIA,QACA,sBACA,CAIA,SACA,oBACA,qBACA,CAIA,OACA,wBACA,CAIA,UACA,uBACA,iBAGA,OADA,wBAEA,CAIA,WACA,uBACA,iBAGA,OADA,0BAEA,CAIA,YH/EO,IGgFP,uBACA,iBAEA,OHnFO,EGmF0B,GAAX,CAAW,KHnF1B,EGmF0B,SHlFjC,WACA,aACA,aACA,aACA,OGgFA,OADA,YACA,CACA,CAIA,aHxCO,IG0CP,uBACA,iBAEA,OH7CO,EG6C2B,GAAZ,CAAY,KH7C3B,EG6C2B,SH5ClC,WACA,aACA,aACA,aACA,aACA,aACA,aACA,aACA,OGsCA,OADA,YACA,CACA,CAIA,QACA,oBACA,WACA,aAEA,cACA,iBAGA,OADA,YACA,MACA,kBACA,sBACA,CAIA,SACA,mBACA,OAAe,SDtHK,WAKpB,EAGA,EANA,CAMW,EAPX,IACA,EACA,SAGA,SACA,IAEA,CAFe,IAEf,KACA,WACA,IACA,SAEA,aACA,2BAEA,cACA,6DACA,qBACA,uBAGA,2CAEA,SACA,sDACA,YAGA,SACA,KACA,uDAEA,YAEA,8CACA,ECiFwB,aACxB,CAIA,QACA,uBAEA,uBACA,gBAEA,YACA,MAEA,GAEA,sBACA,qBAEc,+BAEd,YAKA,YACA,UACA,OACA,YACA,KACA,QACA,aACA,KACA,QACA,yBACA,KACA,QACA,6BACA,iBAEA,KACA,QACA,aACA,KAEA,SACA,iCAAiD,GAAU,YAAY,SAAS,EAChF,CACA,YAEA,iBAEA,UAAyB,GAAQ,OACjC,EACA,wBACA,CADuC,IACpB,IAAO,IAG1B,GADA,8CACA,yBACA,SAMA,GAFA,6CACA,4CACA,yBACA,SAEA,GACA,KACA,CACA,KAAmB,IAAO,KAE1B,sBACA,eAIA,GADA,8CACA,yBACA,QAEA,CAGA,OADA,gDACA,CACA,CACA,uBACA,GADuC,GACpB,IAAO,IAG1B,GADA,gDACA,yBACA,QAEA,MAGA,KAAmB,IAAO,KAC1B,sBACA,eAIA,GADA,gDACA,yBACA,QAEA,CAEA,sCACA,CACA,cACA,uBACA,iBAIA,WAAmB,GAFnB,KAE2B,EAF3B,kBACA,yBAEA,CAIA,QACA,uCACA,CAKA,cACA,uCACA,CAIA,cACA,uCACA,CAIA,SACA,yCACA,CAKA,eACA,MAAsB,GAAgB,mBAEtC,OADA,UAAoB,GAAc,GAClC,CACA,CAIA,UANkC,IAMlC,CACA,yCACA,CAIA,SACA,kDACA,CAKA,eACA,kDACA,CAKA,eACA,kDACA,CAIA,UACA,oCACA,CAIA,gBACA,oCACA,CAIA,gBACA,oCACA,CAIA,WACA,oCACA,CAKA,iBACA,oCACA,CAIA,iBACA,oCACA,CACA,CCvWO,mBACP,MDwWA,mBCxW+B,CDwW/B,WCxW+B,EDwW/B,cCvWA,2BACA,CEQA,SAIA,GAIA,IAIA,KAIA,gBACA,OACA,UACA,WACA,iBACA,UACA,CACA,CAEA,EAJwB,OAIxB,MAIA,CAJoB,KAIpB,GAIA,KAIA,KAIA,IAIA,iBACA,GACA,iBACA,iBACA,eACA,mBAEA,CACA,OD7De,IC6DQ,KD7DR,OAGf,EAFA,MADe,UACf,KACA,QAEA,IACA,mBACA,YACA,OAAmB,GAAW,GAE9B,KAF8B,GAG9B,EAAmB,GAAW,GAC9B,KAD8B,IAG9B,qBAKA,MAJA,UAEA,YAEA,CACA,CACA,GC0DA,UAIA,IAIA,KAIA,KAIA,oBACA,CACA,WACA,yBACA,oBACA,gBACA,CAIA,aAGA,OAFA,uCACA,YACA,KAKA,UAaA,OAVA,oDACA,IACA,EACA,QACA,EACA,UACA,EACA,aACA,EACA,UACA,IACA,CAIA,SACA,WACA,iBAA4C,GAAQ,eACpD,cACA,CAIA,UACA,oCACA,CAIA,UACA,MAAqB,GAAQ,cAC7B,kCACA,CAIA,gBACA,kBAA0B,GAAkB,GAAc,KAC1D,CAIA,IAL0C,KAAgB,IAK1D,GACA,6BACA,CAIA,SACA,qBACA,CAIA,eACA,2BACA,CAIA,eACA,2BACA,CAIA,UACA,MAAqB,GAAQ,yBAC7B,kCACA,CAIA,gBACA,MAAqB,GAAQ,yBAC7B,kCACA,CAIA,gBACA,6BACA,CAIA,QACA,6BACA,CAIA,WACA,6BACA,CAIA,YACA,sBACA,CAIA,WACA,MAAqB,GAAQ,cAC7B,6CACA,CAIA,iBACA,MAAqB,GAAQ,cAC7B,6CACA,CAIA,iBACA,8BACA,CAIA,YACA,sBACA,CAIA,kBACA,4BACA,CAIA,kBACA,4BACA,CAIA,SACA,kBAA0B,GAAY,IACtC,CAQA,IATsC,GAStC,GACA,kBAA0B,GAAa,IACvC,CAIA,KALuC,CAKvC,GACA,0BACA,MACA,mBAEA,4BACA,CAIA,UACA,MAAoB,SJ7RJ,CAAM,CI6RS,CJ5R/B,QADsB,EAEtB,EACA,YAAoB,WAAmB,IACvC,oBACA,IACA,KAEA,OACA,KAEA,oDACA,IACA,MAGA,KAGA,QACA,EIyQ+B,GAC/B,aACA,qBAAqC,GAAU,KAC/C,kBACA,CAKA,OAIA,OAHA,yBACA,mCACA,WACA,KAKA,QAWA,OAVA,mBACA,2BACA,2BACA,yBACA,+BAGA,mCACA,YAEA,KAKA,SACA,gBACA,YACA,WAOA,OANA,uBACA,QACA,sBACA,CADwC,GACxC,QACA,aAEA,KAKA,aA5Qc,EA6Qd,qBACA,CADmC,EA7QrB,EA8QW,CAAL,GAAK,KA7QzB,IA6QyB,EA7QzB,kBACe,GAAW,GAE1B,KAF0B,EA6Q1B,IACA,cACA,gBACA,SACA,SAGA,QACA,CACA,CACA,mBACA,UACA,CACA,mBACA,YACA,iBACA,MAEA,OACA,CAMA,oBACA,iBACA,KACA,cACA,gBACA,CACA,CACA,mBACA,eACA,oBACA,6BACA,UAEA,eACA,oBACA,aAEA,aAEA,mBACA,WACA,iBACA,kBACA,aACA,CACA,mBACA,UACA,CAmBA,mBACA,UAEA,CACA,GAHuB,MAGvB,UACA,YAEQ,GAAU,OAGlB,kBAEA,iBAGA,MAAgB,GAAoB,KAEpC,CC3aO,aDya6B,CCza7B,GACP,MD+aA,EC/ac,ED+ad,GC3aA,OAJ0B,EAC1B,YACA,kBACA,CAAK,EACL,UACA,CCGO,SAAS,GAAW,SAC3B,KAD2B,CAC3B,CACA,OACA,OACA,SACA,QACA,CACA,CChBO,eACP,cAGA,yBACA,kCAEA,WACA,CAUA,OAAW,GAAW,OAAS,EAAW,KAApB,CAAoB,CAT1C,EAS0C,OAT1C,KACA,WACA,UACA,EACA,YAEA,SADA,UAEA,EAGA,CCnBO,iBACP,OAAW,GAAW,UAAY,EAAW,EAAvB,OAAuB,YAC7C,CJsYA,0BACA,+BACA,mBAKA,OAJA,eACA,KACA,mBAEA,IACA,EACA,gCACA,sCAKA,OAJA,eACA,KACA,mBAEA,OEtZA,YACA,uBACA,qBACA,2CACA,iCACA,6BACA,oBACA,CAAC,UAAkC,EIFnC,YACA,YACA,oBACA,uBACA,CAAC,UAA0B,EAE3B,YACA,iBACA,yBACA,4BACA,CAAC,UAA0C,EAE3C,CAGC,SAA0B,EAH3B,UACe,GAAW,GAI1B,KAJ0B,IAI1B,GACA,KACA,cACA,SACA,GAAqB,GAAO,SAAmB,IAC/C,wBACA,SAEA,eACA,YACA,4BAEA,eACA,aACA,iBAEA,wBACA,UAEA,CAAa,UAA4B,IACzC,SACA,wBACA,eACA,iBACA,cACA,OACA,2BACA,KAEA,QACA,iBACA,KAEA,SACA,eAGA,CACA,CACA,QACA,EAAa,EAEb,GAEA,YACe,GAAa,aAE5B,gBACe,GAAa,cAE5B,CAAC,UAA8B,EAE/B,YACA,KACA,cACA,SACA,GAAqB,GAAO,SAAmB,IAC/C,wBACA,SAEA,eACA,YACA,4BAEA,eACA,aACA,iBAEA,wBACA,UAEA,CAAa,UAA4B,IACzC,SACA,wBACA,eACA,iBACA,cACA,OACA,2BACA,KAEA,QACA,iBACA,KAEA,SACA,eAGA,CACA,CACA,QACA,EAAa,EAEb,GAEA,YACe,GAAa,aAE5B,gBACe,GAAa,cAE5B,CAAC,UAAgC,8BC3EjC,iBACA,QACA,gBACA,YAEA,qBAA2C,KAAQ,IACnD,mCAEA,QACA,CACA,sBAEA,QACA,IACA,gBACA,YAAoB,IAAO,KAC3B,YACA,EACA,OACA,qBACA,QAEA,CACA,OACA,0BAEA,kBAfA,GAgBA,EAhBA,CAiBA,CACA,wBACA,cAAkC,KAAQ,KAC1C,qBACA,0BACA,aACA,CACA,QACA,CACA,gBACA,CACA,yBACA,CAeA,kBACA,QACA,IACA,eACA,YAGA,qBADA,oBAEA,eACA,WACA,YAEA,QACA,CACA,cACA,oCACA,gCACA,2BACA,0BACA,QACA,4CAEA,CAEA,qBADA,2CAEA,YAAoB,2BAA8B,IAClD,MAEA,eACA,cAEA,iBADA,2CAEA,YAAoB,2BAA8B,IAClD,UAIA,OAFA,UAEA,GADA,KACA,CACA,CA4CA,iBACA,qBACA,cACA,SAEA,iBACA,WACA,YAAoB,IAAS,IAC7B,SAGA,OADA,WACA,SACA,CCnKA,cACA,8BACA,gFAEA,CACA,SAAS,GAAM,GACf,QACA,CAFe,CAEf,EACA,YAAoB,WAAoB,IAExC,GADA,KACA,WAEA,wBACA,YAAoB,WAAoB,KACxC,WACA,2BACA,eACA,CACA,gBAEA,SAAS,GAAiB,gBAC1B,OAD0B,MAC1B,WAIA,aAIA,KACA,sDACA,IAEA,KACA,sDACA,KAEA,uBACA,wGACA,KAbA,uDACA,KALA,4DACA,GAmBA,CAEA,SACA,cACA,cAEA,SACA,kBACA,CACA,QACA,OAAe,GAAM,WACrB,CACA,CAEA,6BACA,gBAYA,sBACA,qBACA,kBACA,kBACA,gBAEA,eACA,MACA,MAgDA,CAhDA,kBACA,kBACA,MACA,YACA,cACA,sDACA,6BAAsD,KAA+B,4BACrF,CACA,eACA,uCACA,CACA,gBACA,mCACA,CACA,eACA,mDACA,IAAqB,GAAiB,YACtC,UAEA,CAHsC,GAGtC,YAEA,CADA,kCACA,2BAIA,mBACA,IAJA,yCACA,EAIA,CACA,mBACA,eAIA,EACA,8CAEA,mEACA,yBACA,kCARA,gDACA,GAQA,CACA,SACA,OACA,kBACA,yBACA,SAA8B,KAAiB,yBAC/C,CACA,CACA,EAAS,CACT,gBACA,CACA,CAEA,SACA,yBAAkB,YA9DlB,EA8DkB,uCAAwF,EAAI,EAC9G,mBACA,aACA,gBACA,2BAAqC,KAA+B,gBACpE,CACA,mBACA,iBAEA,wBACA,iDAEA,yBACA,4CACA,CACA,SACA,OACA,gCACA,6BACA,iBACA,uBACA,kBAA+B,KAAiB,kCAChD,CACA,CACA,CACA,mBAEA,qBACA,eACA,8FACA,CACA,WACA,8FACA,CACA,CACA,oBAEA,yBACA,qBAAkB,IAAY,EAAI,EAAI,EACtC,YACA,QACA,GACA,qDACA,6BAAmD,KAA+B,6BAClF,qDACA,uDACA,+DAGA,iBACA,kBACA,sBAEA,CACA,YACA,QACA,sBACA,OACA,KACA,KACA,QACA,MACA,KACA,QACA,OACA,KACA,QACA,OACA,KACA,SAEA,OADA,+BACA,EACA,CAGA,GAFA,oBACA,QACA,oCACA,wBACA,OACA,qBACA,MACA,KACA,MACA,CACA,gBAEA,oBACA,MAA+B,GAAkB,kBACjD,oBACA,eACA,sBAEA,GADA,UACA,IACA,YAAgC,MAAgB,IAChD,gBACA,YAEA,gBAEA,qDAEA,GADA,UACA,IACA,wBACA,YAA4B,aAA0B,IACtD,eACA,+CAEA,gBAEA,eACA,MAA0B,KAA+B,iBACzD,IAAa,GAAiB,YAC9B,UAEA,CAH8B,GAG9B,oBACA,gBAEA,OADA,gCACA,GAGA,OADA,UAEA,OACA,gBACA,KACA,SACA,gBACA,KACA,UACA,gBACA,KACA,UACA,gBACA,KACA,SAEA,OADA,+BACA,EACA,CACA,iCACA,kBACA,cACA,UACA,iBACA,uBAEA,CACA,QACA,wCACA,MACA,gBAGA,GAFA,gBAEA,cAEA,OADA,mEACA,GAEA,UAEA,qBADA,QAEA,YAAoC,WAA+B,IACnE,UACA,qCACA,CACA,CACA,qBACA,gBACA,wBACA,YAA4B,IAAW,IACvC,UAEA,CADA,uCACA,OACA,oBACA,eAAiC,GAAoB,MAErD,GAFqD,CAErD,cACA,6DAEA,CACA,sBACA,mBACA,uBACA,OACA,OACA,OACA,OACA,OACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAEA,OADA,0DACA,EACA,CAEA,0BAEA,SACA,OACA,kBACA,uBACA,yBACA,iCAEA,CACA,CACA,6BAEA,qBACA,sBAAkB,IAAa,EAAI,EAAI,EACvC,UACA,QACA,mEACA,2DACA,+CACA,CACA,eACA,MAAqB,KAA+B,iBACpD,IAAa,GAAiB,YAC9B,UAEA,CAH8B,GAG9B,oBACA,gBAEA,OADA,gCACA,GAEA,cAEA,OADA,uDACA,GAGA,GADA,iCACA,sBAEA,OADA,mBACA,mBAGA,GADA,+BACA,uBAGA,OAFA,iBACA,mBACA,mBAEA,eACA,OAEA,OADA,6BACA,GAEA,gBAEA,OADA,mEACA,GAEA,UACA,oBAOA,OANA,YACA,qDACA,YAAsB,GAAoB,KAC1C,IAD0C,CAC1C,gCACA,4DACA,qBACA,mBAEA,YACA,MACA,EAGA,GAFA,iBACA,uBACA,sBAMA,OALA,qBACA,QAEA,EADA,oBACA,SAEA,EAEA,sBACA,MAA+B,GAAkB,eACjD,oBAEA,OADA,4BACA,GAGA,GADA,kCACA,EACA,SACA,uBAEA,CADA,qBACA,qBACA,YAA4B,eAA2B,IACvD,YACA,QACA,CAMA,OALA,qBACA,QAEA,CADA,qBACA,iBAEA,CACA,CACA,SACA,OACA,kBACA,uCACA,+BACA,mBAEA,CACA,CACA,sBAEA,SAEA,qBACA,kBAAkB,EArXlB,EAqXkB,uCAAwE,EAAI,IAC9F,SACA,YACA,gBACA,GACA,yBAEA,uBACA,wBACA,oCACA,CACA,eACA,gGACA,OACA,kCAGA,2BACA,6CACA,4BACA,8CACA,8BACA,iDACA,CACA,CACA,WACA,gBACA,GACA,SAwDA,KACA,+BACA,gCACA,MACA,iCAIA,mCACA,EAjEA,MAEA,4BAEA,GADA,WACA,+BACA,sCACA,2BACA,gCAEA,CACA,8BACA,mCACA,6BACA,WACA,UACA,QACA,EAGA,GAFA,SAGA,CACA,SACA,OACA,kBACA,8BACA,gCACA,oCACA,eACA,wBAIA,OAFA,sBACA,kDACA,CACA,CACA,0BACA,YACA,uBAEe,KAAiB,oBAChC,CACA,kBACA,SAAkB,uBAAuB,IAAI,KAAiB,8CAA8C,EAE5G,kBACA,UAGA,+BAKe,SD/Xf,IC+XoC,CD9XpC,+BACA,SAEA,wBACA,oBACA,YAAoB,WAAkB,IACtC,eACA,SAGA,QACA,ECiXA,aACA,UAEA,CACA,CACA,mBAYA,qBACA,mBAAkB,EArdlB,EAqdkB,OAAsC,EAAI,IAC5D,WACA,GACA,kBAEA,CACA,WACA,6BAEA,YACA,uBACA,CACA,eACA,gGACA,OACA,kCAGA,8CACA,2BACA,6CACA,4BACA,8CACA,8BACA,iDACA,CACA,CACA,kBACA,SAAkB,uBAAuB,KAAK,sBAAsB,EACpE,CACA,CACA,yBAEA,yBACA,uBAAkB,WAAkC,EAAI,EACxD,SACA,gBACA,CACA,CACA,6BAGA,qBACA,gBAA+B,EAC/B,YACA,6BACA,CACA,CAkBA,8BACA,QACA,WAAuC,KACvC,SACA,IAAS,GAAiB,SAE1B,OADA,OAD0B,CAC1B,QACA,CACA,UACA,QACA,EAGA,IADA,kBACA,OAEA,OADA,6BACA,CACA,UACA,QACA,EAEA,+BAIA,GAHA,2BACA,sCAEA,OAEA,OADA,wBACA,CACA,UACA,QACA,EAQA,GANA,IACA,yBACA,4BACA,4BACA,uCAEA,OAEA,OADA,yBACA,CACA,UACA,QACA,EAIA,GAFA,IACA,0BACA,0BACA,4BAEA,OADA,kEACA,CACA,UACA,QACA,EAEA,SACA,GACA,IADA,oBAEA,4BACA,yBAEA,OADA,qEACA,CACA,UACA,QACA,EAEA,4BACA,OACA,4BACA,oBAEA,OADA,yCACA,CACA,UACA,QACA,EAEA,kBACA,KACA,QACA,aACA,KACA,QACA,aACA,KACA,QACA,eACA,KACA,QACA,iBACA,KACA,QACA,UACA,KACA,QACA,sBACA,KACA,SACA,gBACA,KACA,SACA,gBACA,KACA,SACA,8BACA,KACA,SACA,UACA,KACA,SAEA,OADA,uDACA,CACA,UACA,QACA,CACA,SACA,cACA,KACA,SACA,SACA,KACA,SACA,mBACA,KACA,SACA,qBACA,KACA,SACA,mBACA,KACA,SACA,oBACA,KACA,SACA,eACA,KACA,SACA,aACA,KACA,SACA,qBACA,KACA,SACA,mBACA,KACA,SACA,mBACA,KACA,SACA,mBACA,KACA,SACA,qBACA,KACA,SACA,qBACA,KACA,SACA,eACA,KACA,SACA,UACA,KACA,SACA,eACA,KACA,SACA,cACA,KACA,SACA,cACA,KACA,UACA,8BACA,mBACA,iBACA,oBACA,sBACA,sBACA,GACA,CACA,OAMA,0BACA,eACA,aAMA,OAFA,EADA,GAxMA,cACA,kBACA,SAEA,YAKA,OAJA,oBACA,sBACA,sBACA,gDACA,CACA,EA8LA,MACA,6DACA,sDACA,CACA,SACA,QACA,CACA,CAnNA,aAFA,GAIA,mBAoOA,qBACA,mBAAkB,iCAAsD,EAAI,EAC5E,SACA,aACA,uBACA,CACA,mBAZA,IAaA,MAAqB,KAA+B,iBACpD,IAAa,GAAiB,YAC9B,UAGA,CAJ8B,EAG9B,6CACA,sCAEA,OADA,yCACA,EAEA,QACA,6BAvBA,EAuBA,EAtBA,GACA,EAEA,CADA,EAoBA,IACA,gBACA,iBAGA,OAFA,0BACA,wCACA,GAMA,GAJA,WACA,uCACA,wBACA,0BACA,sDACA,KAEA,CASA,OARA,wBACA,sDACA,iBAGA,qDAGA,CACA,CACA,WACA,gBACA,YAAwB,oBAAuB,IAC/C,gCAEA,EAGA,GAFA,SAGA,CACA,SACA,OACA,kBACA,uCACA,QACA,EACA,wBACA,yBAEA,QACA,CACA,CACA,+BAGA,qBACA,gBAA+B,EAC/B,YACA,6BACA,CACA,eACA,gEACA,gGACA,OACA,kCAGA,2BACA,6CACA,4BACA,8CACA,8BACA,iDACA,CACA,CACA,kBACA,SACA,mCACA,mDAA0E,EAAE,eAE5E,gCACA,IAAkB,uBAAuB,GACzC,sBACA,gBACA,GAAiB,GAAW;AAAA,EAAK,aAAkB,EACnD,GAAiB,GAAW,GAE5B,CAGA,eAFA,GAIA,qBAEA,qBACA,eACA,QACA,CACA,SACA,SACA,CACA,CACA,oCAGA,qBACA,gBAA+B,EAC/B,YACA,wBACA,wBACA,CACA,CAGA,gBAFA,GAIA,UAGA,qBACA,gBAA+B,EAC/B,YACA,wBACA,wBACA,CACA,qBAQA,CAPA,wBACA,mEACA,2BACA,6CACA,4BACA,8CACA,oBACA,mBACA,2GACA,IAEA,GACA,CACA,WACA,yBACA,OACA,uBACA,QACA,MACA,CAIA,OAHA,GACA,WAEA,CACA,CACA,kBACA,SAAkB,sBAAsB,EAExC,CAGA,QAFA,GAIA,cAEA,yBACA,mBAAkB,QAAuB,EAAI,EAC7C,SACA,WACA,kBAAgC,KAA+B,0BAG/D,oCAEA,GACA,cAEA,CACA,YACA,+BACA,OACA,SAGA,QACA,CACA,aACA,4BACA,CACA,eACA,MAA0B,KAA+B,wBACzD,GAA8B,aAG9B,UAH8B,OAG9B,mBACA,KACA,iEACA,kBACQ,GAAoB,WAC5B,mBACA,KARA,EASA,CACA,QACA,gCACA,CACA,SACA,OACA,kBACA,gBACA,CACA,CACA,CACA,2BAGA,OAAM,WAAO,GACb,EADa,UACb,IAA+B,EAC/B,YACA,wBACA,wBACA,CACA,WACA,6BAEA,YACA,uBACA,CACA,kBACA,SAAkB,uBAAuB,IAAI,cAAc,CAC3D,CACA,CAGA,WAFO,GAIP,GAAO,UAJO,GAIP,CAEP,yBACA,2BAAkB,WAAuC,EAAI,EAC7D,SACA,oBACA,CACA,eACA,QACA,uBAGA,GAFA,kBAEA,KADA,0CAEA,SACA,YAA4B,oBAAuB,KACnD,qCACA,WACA,0BAIA,OADA,yFACA,GAHA,KAKA,CACA,UAEA,OADA,6DACA,EAEA,CACA,MAEA,kBACA,uBACA,mBAEA,QACA,CACA,kBACA,mBACA,kCACA,EACA,8CACA,iCAEA,SACA,OACA,kBACA,iCAEA,CACA,CACA,+BAGA,qBACA,qBAAkB,IAAY,cAAe,OAAkB,EAAI,EACnE,OACA,8GACA,OACA,SACA,8BACA,KACa,CACb,UACA,KACA,sCACa,CACb,KACS,KACT,wBACA,wBACA,CACA,eAGA,GAFA,yDACA,gEACA,MAKA,OAJA,+BACA,6CACA,gCACA,8CACA,EAEA,mCAEA,MADA,+CACA,gBACA,IACA,iBACA,0BACA,8BACA,kCAEA,CACA,CACA,SACA,CACA,CACA,2BACA,CACA,yBACA,mFACA,wCAEA,GAAkB,uBAAuB,IAAI,KAAiB,qCAAqC,EAEnG,WACA,+BACA,mDAEA,SACA,mCACA,iBACA,kCAGA,OAAe,KAA+B,UAC9C,CACA,CAGA,eAFA,GAIA,UAEA,yBACA,wBAAkB,6BAAuD,EAAI,EAC7E,SACA,kBACA,qBACA,8CAEA,eACA,MACA,SAEA,SACA,uBAEA,QADA,0CAEA,SACA,yBACA,yBACA,WACA,0BAIA,OADA,qFACA,GAHA,KAKA,CACA,UAEA,OADA,yDACA,GAEA,mBACA,qCAEA,OADA,8FACA,EAEA,8BAEA,QACA,CACA,MAA0B,KAA+B,iBACzD,IAAa,GAAiB,YAC9B,UAEA,CAH8B,GAG9B,oBAEA,GADA,qBACA,kBAEA,OADA,4DACA,GAEA,qBACA,oBACA,IACA,iBACA,0BACA,gCACA,uBAEA,CACA,CACA,SACA,CACA,CAGA,OAFA,gCACA,0BACA,GACA,CACA,WACA,sBACA,yCAEA,KACA,uDAEA,iCACA,UAEA,iDAGA,OAFA,qBACA,2BACA,SAEA,SACA,OACA,kBACA,2BACA,iCAEA,CACA,CACA,6BAGA,qBACA,qBAAkB,IAAY,cAAe,OAAkB,EAAI,EACnE,OACA,8GACA,OACA,SACA,8BACA,KACa,CACb,UACA,KACA,sCACa,CACb,KACS,KACT,wBACA,wBACA,CACA,eAGA,OAFA,yDACA,gEACA,oBACA,CACA,kBACA,sFACA,8CAEA,EACA,SAEA,aADA,6BAEA,sCAEA,iBACA,SAAsB,uBAAuB,IAAI,mDAAkE,EAEnH,CACA,CAwCA,eACA,gBACA,oBAAqC,KAAQ,KAC7C,0BACA,mBACA,qBAA8C,KAAQ,KACtD,sCACA,cACA,YACA,CACA,QACA,GAAyB,GAAsB,MAC/C,KAD+C,EAC/C,GACA,CAEA,aApDA,aAFA,GAIA,UA0FA,yBACA,mBAAkB,QAAuB,EAAI,EAC7C,SACA,iBACA,YACA,mBAEA,YACA,iBAEA,CACA,cACA,6BACA,6DACA,kBACA,mBAGA,kBACA,4BACA,gBAAiC,GAAoB,YAGrD,CACA,gBACA,iBACA,kBACA,iCD9yCA,YACA,iBACA,MACA,YAAoB,IAAO,KAC3B,SACA,QAEA,SADA,IACA,KACA,oBAEA,OADA,UACA,CACA,CACA,gBACA,oBACA,aACA,iBACA,oBAEA,iBADA,mCAEA,YAAgC,eAAwB,IACxD,YAEA,MACA,CACA,QACA,CACA,MACA,CACA,yBACA,ECixC+D,GAC/D,CACA,eACA,qBACA,CACA,mBACA,0BACA,UACA,SACA,wBAaA,OAZA,wBACA,gCAGA,OACA,aACA,cACA,eACA,0CAIA,CACA,CACA,YACA,wBACA,WACA,kBACA,CACA,gDACA,QACA,WACA,mBACA,CACA,KACA,8BAEA,+CAGA,CACA,oBACA,CACA,eACA,kCACA,QAGA,mBAFA,CAIA,CACA,SACA,SACA,0CACA,iCAEA,SACA,OACA,kBACA,uBAEA,CACA,eAIA,EAHA,mCACA,+CACA,IAEA,oBACA,KACA,KACA,yBAAyD,KAAiB,KAC1E,OACA,YAA4B,IAAO,IACnC,WACA,IACA,GACA,EA7IA,cACA,IAOA,EAPA,IACA,oBACA,oBACA,aACA,aACA,aACA,aAEA,IACA,YAAuC,KAAQ,QAE/C,IADA,oBAEA,GACA,IACA,cAGA,IACA,UAGA,OACA,gBAAuE,KAAQ,QAE/E,GADA,aACA,EACA,IACA,gBAEA,CACA,IACA,SACA,KACA,CAGA,gBACA,EAwGA,SACA,OAGA,WAlMA,KACA,0BACA,oBACA,oBACA,aACA,aACA,aACA,aACA,IACA,UACA,IACA,YAAsB,KAAQ,QAG9B,EAFA,IACA,WACA,mBAGA,aAEA,UACA,IACA,aACA,EAAgC,GAAsB,0BAGtD,YAKA,OAFA,QACA,GAAwB,GAAsB,MAC9C,CACA,EAmKA,UAGA,IACA,KAEA,CACA,YAAwB,WAAmB,IAC3C,MACA,OACA,GACA,qBAIA,MAFA,QACA,kBACA,CACA,CACA,CAEA,4BAEA,sBAHA,GAGA,sBACA,gBACA,oCACA,kBACA,CAAS,CACT,eACA,uCACA,CAAS,CACJ,CAIL,qBACA,gBAA+B,EAC/B,YACA,wBACA,wBACA,CACA,WAEA,OADA,KACA,kCACA,CACA,qBACA,KACA,gBACA,SACA,kCACA,iBAAoC,KAAiB,aACrD,QACA,6CACA,WAEA,MADA,YAAyC,KAAiB,UAAc,GACxE,EACA,EAA2B,KAA+B,cAAc,KAAiB,yBACzF,WACA,UACA,MAEA,UACA,6BAEA,WAKA,OAHA,QACA,kBACA,CAAS,CAET,CACA,eACA,cAAsC,sCAAwC,EAE9E,OADA,qBACA,CACA,CACA,iBACA,eACA,6CACA,yCACA,6BACS,CACT,CACA,kBACA,SAAkB,uBAAuB,IAAI,2BAA2B,EAExE,CAGA,WAFA,GAIA,iBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,cAFA,GAIA,oBAEA,yBACA,sBAAkB,2BAAmD,EAAI,EACzE,SACA,gBACA,iBACA,CACA,eACA,MACA,SAEA,MAA0B,KAA+B,iBACzD,IAAa,GAAiB,YAC9B,UAEA,CAH8B,GAG9B,mBACA,qCACA,YAAwB,MACxB,8BACA,mBACA,eAHyC,KAMzC,uCACA,YAAwB,mBAAsB,IAC9C,gCAGA,CADA,oBACA,iCACA,mEACA,KAEA,0BACA,6DACA,oBACA,cAA4B,GAAoB,sBAEhD,kBACA,0DAEA,mBACA,CACA,mBACA,KACA,4BACA,iBACA,QAEA,iCACA,YAAwB,WAAkB,IAC1C,yDAEA,iCACA,CACA,SACA,mBACA,KACA,qDACA,wBACA,mCACA,YAA4B,qBAA4B,IACxD,cAEA,OADA,4CACA,SAEA,MAA2B,GAAkB,iBAC7C,oBAEA,OADA,6CACA,GAEA,mCACA,OACA,wBACA,iBACA,YAA4B,IAAS,IACrC,cACA,UAEA,QACA,CACA,WACA,SACA,kBACA,EAAqB,KAAiB,+BAEtC,oBACA,oBACA,kBACA,OAEA,mBACA,OACA,QAGA,OACA,OAGA,eACA,MAEA,2BAEA,QACA,CACA,SACA,OACA,kBACA,uBACA,0BACA,CACA,CACA,CACA,kBAEA,qBACA,mBAAkB,EAnoDlB,EAmoDkB,OAAsC,EAAI,EAC5D,SACA,cACA,GACA,kBAEA,CACA,eACA,QACA,WACA,aAEA,QADA,qBACA,CACA,mBACA,mBACA,KACA,CACA,uBACA,kBACA,gCACA,iBACA,kBACA,CACA,QACA,CACA,SACA,SACA,YAAwB,oBAAuB,KAC/C,6BACA,oBAEA,OADA,+BACA,GAEA,SACA,CACA,OAAe,GAAM,EACrB,CACA,SAFqB,EAErB,GACA,cACA,QACA,IACA,KACA,KACA,GAOA,GAJA,EADA,KADA,qBAEA,eAEA,iBACA,MACA,GACA,oBACA,IACA,mBACA,OACA,KACA,QACA,KACA,KACA,QACA,KACA,KACA,SACA,cACA,MACA,CACA,qBACA,YACA,MACA,gBACA,IACA,KACA,CACA,aACA,8BACA,KACA,eACA,gBACA,MAGA,GADA,0BACA,kBACA,MAEA,qBACA,gBACA,MAEA,kBACA,OACU,OACV,CACA,WACA,SACA,KACA,YAAwB,oBAAuB,KAC/C,0BACA,8BACA,QACA,MAA4B,EAAO,IACnC,GACA,IAA2B,EAAE,GAAQ,EACrC,yBACA,MAAiC,EAAE,GAAQ,KAAK,EAEhD,MAGA,IACA,CACA,QACA,CACA,SACA,OACA,kBACA,sBACA,aAEA,YAAwB,oBAAuB,IAC/C,wCAEA,QACA,CACA,CACA,oCAGA,qBACA,gBAA+B,EAC/B,YACA,wBACA,wBACA,CACA,WACA,iCACA,CACA,YACA,6BACA,CACA,kBACA,SAAkB,uBAAuB,IAAI,oCAAsC,EAEnF,SACA,OACA,kBACA,qBACA,CACA,CACA,CAGA,oBAFA,GAIA,2BAEA,yBACA,sBAAkB,UAA8B,EAAI,EACpD,SACA,eACA,CACA,eACA,SACA,SACA,MAA0B,KAA+B,iBACzD,IAAa,GAAiB,YAC9B,UACA,CAF8B,GAE9B,mBACA,qCACA,YAAwB,MACxB,8BACA,mBACA,eAHyC,KAMzC,uCACA,YAAwB,mBAAsB,IAC9C,gCAEA,CADA,oBACA,iCACA,mEACA,KAEA,0BACA,6DACA,oBACA,cAA4B,GAAoB,sBAEhD,kBACA,0DAEA,mBACA,CACA,SACA,mBACA,KACA,qDACA,wBACA,mCACA,YAA4B,qBAA4B,IACxD,cAEA,OADA,4CACA,QACA,CACA,MAA2B,GAAkB,iBAC7C,oBAEA,OADA,6CACA,GAEA,mCACA,OACA,wBACA,iBACA,YAA4B,IAAS,IACrC,aACA,WAEA,eACA,CACA,WAOA,OALA,eACqB,KAAiB,0BAEtC,wBAGA,CACA,SACA,OACA,kBACA,uBAEA,CACA,CACA,0BAEA,qBACA,mBAAkB,EAh3DlB,EAg3DkB,OAAsC,EAAI,EAC5D,SACA,cACA,GACA,kBAEA,CACA,eACA,QACA,WACA,aAEA,QADA,qBACA,CACA,mBACA,mBACA,KACA,CACA,gCACA,iBACA,kBACA,CACA,QACA,CACA,WACA,SACA,YAAwB,oBAAuB,KAC/C,6BACA,oBAEA,OADA,+BACA,GAEA,SACA,CACA,OAAe,GAAM,EACrB,CACA,SAFqB,EAErB,GACA,cACA,QACA,IACA,KACA,GAGA,EADA,KADA,qBAEA,eAEA,iBACA,MACA,aAEA,GADA,0BACA,kBACA,MACA,kBACA,EAAU,aACV,QACA,CACA,WACA,SACA,KACA,YAAwB,oBAAuB,KAC/C,0BACA,8BACA,QACA,MAA4B,EAAO,IACnC,EAEA,GADA,IAA2B,EAAE,GAAQ,EAIrC,IACA,CACA,QACA,CACA,SACA,OACA,kBACA,sBACA,WACA,EACA,YAAwB,oBAAuB,IAC/C,wCACA,QACA,CACA,CACA,4CAGA,qBACA,gBAA+B,EAC/B,YACA,wBACA,yBACA,CACA,WACA,iCACA,CACA,YACA,6BACA,CACA,kBACA,SAAkB,uBAAuB,IAAI,oCAAsC,EAEnF,SACA,OACA,kBACA,qBACA,CACA,CACA,CAGA,4BAFA,GAIA,kCAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,YAFA,GAIA,kBAGA,OAAM,WAAG,GACT,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,OAFO,GAIP,GAAG,MAJO,GAIP,CAEH,yBACA,aAAkB,MAAgB,EAAI,EACtC,SACA,kBACA,WAlgEA,EAmgEA,CACA,SACA,OACA,kBACA,iBAEA,CACA,CACA,0BAEA,qBACA,CACA,gCAEA,qBACA,aAAkB,MAAgB,EAAI,EACtC,WACA,CACA,cACA,qDAAgE,KAA+B,iBAC/F,CACA,cACA,eACA,iDACA,YAAwB,IAAY,IACpC,oBACA,wBACA,CACA,CACA,uBAEA,qBACA,cACA,6BAAuC,KAA+B,iBACtE,IACA,sBAAoC,KAAiB,gBACrD,CACA,SACA,yDAAqE,EAAG,qBACxE,sBAAoC,KAAiB,YACrD,CACA,CACA,cACA,4CAAsD,KAAiB,oBACvE,uBACA,CACA,CACA,8BAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,cAFA,GAIA,oBAEA,qBACA,cACA,sBAAgC,KAAiB,kBACjD,6BAAuC,KAA+B,gBACtE,CACA,cACA,wBACA,4CAAsD,KAAiB,oBACvE,CACA,CACA,6BAGA,qBACA,aAAkB,MAAgB,EAAI,EACtC,SACA,wBACA,yBACA,CACA,CAGA,aAFA,GAIA,mBAEA,qBACA,cACA,wDACA,oBACA,YAAwB,WAAsB,KAC9C,YACA,cACA,SACA,QAEA,yEACA,CACA,cACA,eACA,mDACA,YAAwB,IAAe,KAEvC,qBAD4B,GAAkB,oBAE9C,cACA,SACA,iBACA,qBAAgD,KAAQ,IACxD,gBAEA,uBACA,CACA,CACA,mCAGA,qBACA,aAAkB,MAAgB,EAAI,EACtC,SACA,wBACA,yBACA,CACA,CAGA,mBAFA,GAIA,yBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,iBAFA,GAIA,uBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,mBAFA,GAIA,yBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,iBAFA,GAIA,uBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,kBAFA,GAIA,wBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,aAFA,GAIA,mBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,iBAFA,GAIA,uBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,iBAFA,GAIA,uBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,iBAFA,GAIA,uBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,mBAFA,GAIA,yBAGA,qBACA,mBAAkB,oBAAkC,EAAI,EAQxD,GAPA,SACA,YACA,aACA,WACA,YACA,cACA,cACA,GACA,mBACA,sDACA,YAA4B,WAAkB,IAC9C,+CACA,CACA,IACA,iBACA,8DAEA,wBACA,yBACA,CACA,cACA,+CAAwD,KAA+B,kBACvF,CACA,WACA,sBACA,4BACA,oBACA,YAAwB,WAAgB,IACxC,qBACA,QACA,CACA,YACA,6BACA,6BACA,wBACA,0BACA,8BACA,6BACA,CACA,SACA,4FACA,CACA,cAEA,MADA,KAA4B,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,MACjE,QACA,aACA,+CACA,MACA,CACA,uBACA,OACA,iBAEA,gBACA,6BACA,2BACA,4BACA,8BACA,6BACA,CACA,kBACA,cACA,eAQA,OAPA,KAA6B,GAAiB,8CAC9C,KAA6B,GAAiB,cAC9C,KAA6B,GAAiB,YAC9C,KAA6B,GAAiB,aAC9C,KAA6B,GAAiB,eAC9C,KAA6B,GAAiB,eAC9C,SACA,UACA,CACA,wBACA,CACA,kBACA,SAAkB,uBAAuB,IAAI,4BAA4B,EAEzE,SACA,OACA,kBACA,eACA,iBACA,aACA,eACA,mBACA,mBAEA,CACA,CAGA,WAFA,GAIA,iBAGA,qBACA,gBAA+B,EAC/B,MACA,SACA,8DACA,wBACA,yBACA,CACA,YACA,kBACA,uCACA,CACA,SACA,6GACA,CACA,cACA,IAIA,EAJA,KACA,KACA,KACA,IAEA,IACA,IACA,uBACA,4BACA,SAEA,CAEA,aADA,sBACA,WACA,iDACA,GACA,CACA,KACA,yBAEA,oBADA,qDAIA,CACA,QACA,iBACA,KAKA,GAJA,SACA,iBACA,MAEA,QAGA,GAFA,mBACA,mBACA,2BACA,iDACA,oCACA,sBACA,iDAEA,GADA,MACA,cAEA,SADA,kCACA,WACA,iDACA,KACA,CACA,CACA,CACA,qBAGA,GAFA,QACA,mBACA,QACA,qBAAqD,eAA4C,GACjG,sBACA,iDACA,cACA,kBACA,MAEA,IACA,WACA,kBAEA,GADA,OAA8B,EAAE,KAAK,EAAE,KAAK,EAAE,KAC9C,OACA,iDACA,KACA,oBAEA,GADA,OAA8B,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KACrD,QACA,UACA,2BACA,qBACA,0BACA,sBACA,8BACA,CACA,KACA,oBAEA,GADA,OAA8B,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAC5D,QACA,UACA,2BACA,sBACA,8BACA,CACA,KACA,oBAEA,GADA,OAA8B,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KACnE,QACA,WACA,+BACA,CACA,KACA,SACA,gDACA,CACA,gBACA,YACA,iDACA,YAAwB,WAAwB,IAChD,UACA,OACA,4BACA,KACA,QACA,6BACA,KACA,QACA,2BACA,KACA,QACA,8BACA,KACA,QACA,gCACA,KACA,QACA,8BACA,KACA,SACA,gDACA,CAEA,WACA,gGACA,8BACA,2BACA,uBACA,0BACA,8BACA,8BACA,uCACA,CACA,CACA,kBACA,cACA,SAYA,OAXA,OAA6B,GAAiB,cAC9C,OAA6B,GAAiB,eAC9C,OAA6B,GAAiB,aAC9C,OAA6B,GAAiB,cAC9C,OAA6B,GAAiB,gBAC9C,OAA6B,GAAiB,gBAC9C,uBACA,YACA,OAAiC,GAAiB,sBAElD,YACA,UACA,CACA,wBACA,CACA,SACA,OACA,kBACA,6BAEA,CACA,CAGA,mBAFA,GAIA,yBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,QAFA,GAIA,cAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,aAFA,GAIA,mBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,YAFA,GAIA,kBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,YAFA,GAIA,kBAGA,qBACA,gBAA+B,EAC/B,SACA,wBACA,yBACA,CACA,CAGA,QAFA,GAIA,cC9rFO,wBACP,6DACA,SACA,6BACA,CACA,CAIO,uBACP,wCACA,SACA,iCACA,CACA,CEzBA,ODGe,CACf,aCJe,GDIf,EACA,YCLwB,EAAC,CDMzB,mBACA,UAAsB,GAAqB,uRAM3C,QACA,CACA,CAAC,CEYM,CFZL,cEYoB,GAAa,OACnC,YAA4B,GAAS,EADF,CACE,6BACrC,yBACA,MAAgB,eAChB,CAAK,gBACL,OAAW,GAAS,qBAAuB,yBAA2B,4CACtE,CC7BO,SACP,WACA,KACA,KACA,uBACA,KACA,YACA,iBACA,CACA,UAIA,OAHA,iBACA,WCyDO,SDzDgC,CCyDhC,EACP,wBACA,UAAkB,GAAsB,8BAyBxC,MAvBA,IAAqB,GAAe,CACpC,IADoC,EACpC,CACA,IAAgB,GAAe,CAC/B,IAD+B,EAC/B,CAEA,IAAwB,GAAuB,CAC/C,YAD+C,gBAE/C,CAAqB,EACrB,IAAwB,GACxB,CACa,EAGb,IAAgB,GAAgB,CAChC,KADgC,IAChC,IAA8B,GAAe,CAC7C,IAD6C,EAC7C,CACwB,GAAc,cAAoB,GAAoB,mBACtD,GAAc,cAAoB,GAAoB,oBAE7D,SACjB,CAAa,EACb,CACK,EACL,QACA,uCACA,EDtFuC,YAEvC,UAEA,cACA,sBACA,CACA,QACA,OAAe,GAAG,6BAClB,CACA,WACA,OAAe,GAAS,6CACxB,CACA,gBACA,0CAGe,GAAgB,eAC/B,CACA,YACA,OAAe,GAAa,cAC5B,CACA,CCiEA,QDnE4B,CCmE5B,MACA,gCAEA,eACA,gBAEA,OAAW,GAAkB,cAC7B,CAD6B,SAE7B,MACA,SAQA,OAPA,sBACA,oBACA,eACA,OAAoB,GAAE,EAEtB,SACA,CAAK,EACL,uBACA,gBCtHO,kBAAmB,KAAI,CAC9B,iBACA,QACA,iBACA,kBACQ,SAAU,IAClB,MAAoB,SAAO,IAE3B,GADA,sBACA,qCACA,kEACA,mCACA,oCACA,oBACA,oBAEA,kDACA,YAAwB,WAAgB,IACxC,SACA,qBAEA,sBAEA,YAAwB,WAAgB,IACxC,UACA,qBACA,SACA,CACA,UAGA,MAFQ,SAAY,OACpB,qBACA,KAEA,cACQ,SAAY,OACZ,SAAW,mBACnB,iBACA,yBACA,qBACA,yBACA,cACA,CACA,SACA,2CAEA,OADA,mBACA,CACA,CACA,cAEA,mDAAiE,EACjE,UAAgB,yDAAyD,KAQzE,OANA,aACA,cACA,aACA,cACA,8BACA,8BACA,CACA,CACA,UACA,kBACA,qBACA,oBACA,CACA,CAWO,+CCxEP,eACA,iBACQ,SAAK,gBACb,oBACQ,SAAK,qBACb,CDoEA,6BCxCA,IAAQ,GAAe,GAAO,GAAU,IAAQ,GAQzC,IAEP,OAVoD,WAUpD,MACA,kBACA,QACA,CACA,CAAK,CAEL,MACA,eACA,IAAoB,OAAS,GAC7B,cACA,qCACA,cACA,yCACA,iBACA,EAAwB,KAAsB,IAC9C,kBACA,oDAEA,YAA2C,KAAsB,oBACjE,SAAsB,KAAsB,IAAM,EAAE,EAAO,EAAE,EAAI,EAAE,EAAK,EAC/D,CAET,YACA,IAAoB,OAAS,GAC7B,IACA,cACA,qCACA,0BACA,qCACA,aAEA,IACA,GAFA,MAIA,CAEA,YACA,MACA,iEACA,OACA,wDACA,CAD6E,GAC7E,oBACA,gBACA,qDACA,YACA,oDACA,eACA,SAEA,GADA,KACA,MACA,qDACA,MAlBA,IAmBA,wBACA,gBACA,8CACA,OAAqB,sBACrB,CAAS,CACJ,CAKL,MACA,UACA,IAAoB,OAAS,GAC7B,KAAsB,GACtB,WADyB,CACzB,8CACA,MAAsB,KAAsB,IAI5C,GAFA,4BACA,WACA,WACA,oCACA,QACA,CAAS,CACT,UACA,IAAoB,OAAS,GAC7B,YACA,mDACA,yBACA,mEACA,YACA,CAAS,CACJ,CACL,SAEA,IAAgB,qBAA+B,GAC/C,6BACQ,KAAS,IACjB,IAAgB,SAA+B,eAC/C,YACA,2DACA,IAAgB,SAA2B,cAC3C,CAAgB,SAA2B,cAC3C,YACA,2DACA,OAAiB,4BACjB,CAAK,CACL,cACA,IAAgB,eAAuB,GACvC,KAAuB,0BAAoC,EAAE,0BAAoC,EACjG,qBACA,CACA,EAGM,GAAG,UAAc,CAAd,EAAiB,UAA+B,CAA/B,GAAiB,UAAiB,CAAjB,MAAiB,IAAc,IAAG,iBEnJ7E,uEACA,gFACM,GAAG,UACH,GAAG,UACT,eAAsC,GAAG,GA6BnC,GAAK,GAAK,MAAR,EAAQ,UAAqC,KAxBrD,YAGA,sDAEA,uCACA,QALA,GAMA,GADgC,CAChC,IANA,GAOA,GADkC,EACd,IAPpB,IAOoB,EAPpB,GAQA,KAAoB,IARpB,IAQoB,EARpB,GASA,KAAqB,EAAK,GAT1B,IASqB,EATrB,GAS6B,EAC7B,GAAqB,IAVrB,IAUqB,EAVrB,GAWA,KAAqB,IAXrB,IAWqB,EAXrB,GAYA,KAAqB,IAZrB,IAYqB,EAZrB,GAaA,KAAsB,IAbtB,IAasB,EAbtB,GAcA,KAAsB,IAdtB,IAcsB,EAdtB,GAeA,KAAsB,IAftB,IAesB,EAftB,GAgBA,KAAoB,IAhBpB,IAgBoB,EAhBpB,GAiBA,KAAoB,IAjBpB,IAiBoB,EAjBpB,GAkBA,EAAiB,GAAI,EAAK,GAlB1B,IAkBqB,GACrB,CAAS,CADoB,EAClB,IAAK,GAAE,EAAP,CAAO,OAClB,uCACA,QACA,CACqD,CAAe,EAI7D,GDjCA,WCiC6B,CDjC7B,EACP,SAA6B,CD4lBtB,YACP,MAAkB,SArBG,GACrB,MAAiB,GAAa,GAU9B,OATI,EAFiB,CAEjB,EAAiB,IACrB,YACA,gBACA,sBACA,CAAK,EACL,oBACA,yBACA,cACA,CAAK,EACL,eAA2B,aAAqB,CAChD,EAS8B,GAC9B,IAAY,OAAqB,EACjC,YACA,CADwC,CACxC,YACA,CAD8C,QAC9C,KACA,OAAe,GAAO,IACtB,CAIA,GALsB,CAKV,uFAA2F,SAxdhG,GACP,eAjJA,GACA,MAAiB,GAAa,GAC1B,KAAiB,EADS,CACT,CACrB,UACA,SACA,CAAK,EACL,iCACA,yBACA,yBACA,yBACA,6BACA,qBACA,kBACA,CAAK,EACL,SAAY,YAAc,EAC1B,MACA,oBACA,iFAEA,uBACA,yBACA,iCACA,gFAEA,CACA,sBAA2B,KAAS,CACpC,EAuHA,GACA,IAAY,GAAK,EACjB,EAAe,GADW,EACF,gBACxB,aACA,WACA,mBACA,OAAmB,KAAc,oDACjC,EAAS,CACT,eACA,KAEA,oBAIA,OAAqB,EAFrB,mCAEqB,EADrB,0CACqB,CACrB,EAAS,CAKT,cACA,IAAgB,SAAO,EACvB,WACA,CAD8B,CAC9B,WACA,CADkC,MAClC,4BACA,CAKA,CANoD,EAMpD,4BACA,2DAOA,kBAUA,EATA,IAAgB,+DAAuE,EACvF,0BAIA,GAHgB,KAAU,KAC1B,GAAsB,KAAa,KAEnC,0CACA,2BACA,qBACA,CAEA,IACA,EACA,mBACA,EACsB,KAAkB,CAAC,SAAW,oBACpD,CACA,SACA,mCAAmD,GAAa,4BAA4B,SAAW,EACvG,CAIA,OAHA,GACA,GAAkB,GAAO,MACjB,CAD2B,CAAV,CACjB,EAAW,iBAAqB,GAAG,GAC3C,CADiD,CAGjD,MAH2C,GAG3C,KACA,qBACA,uCACA,CAKA,MAAyB,QAAQ,SACjC,IAAgB,gBAAsB,EAEtC,kBACA,SAAqB,OACrB,aAGA,UACA,qBACA,iBACA,aACA,aACA,KACA,OAAqB,mBACrB,mBACA,gCACA,OAAiB,QACjB,CAAK,EAGL,EAA4B,QAAQ,KACpC,YAIA,sCACA,MACA,+BACA,CAEA,MAAgB,OAAO,aAEvB,gCACA,wCACA,eACA,CADgC,CAChC,KACA,CAD8C,EAC9C,YACA,iDACA,sBACA,sDACA,QACA,CAAK,CAML,SACA,mBAIA,GAHA,UACA,UACA,UACA,uBACA,0BACA,0BACA,0BACA,0BACA,0BACA,mBACA,CAGA,qBACA,MAAoB,OAAO,MAC3B,oCACA,oCACA,kBACA,4CACA,gCAEA,WACA,OACA,gBACA,CACA,QACA,wBACA,CACA,QACA,yBAQA,qBACA,oCACA,uDACA,CAKA,kBACA,qBAAiD,SAAW,iBAE5D,OADA,mBACA,CACA,CAEA,yBACA,4BACA,CAEA,gBACA,OAAmB,GAAS,QAC5B,CAEA,kBACA,uBACA,CAEA,iBACA,OACA,CACA,WACA,IAAoB,KAAI,gBACxB,WACA,iBACA,2CACA,CAIA,UACA,KACA,IAAoB,gBAAyB,KAC7C,CAAoB,gBAAyB,EAC7C,+BACA,+BACA,WACA,CAIA,SACA,4CACA,CAKA,SACA,IAAoB,SAAO,EAC3B,UAAiC,IACjC,CAAoB,SADgB,CAChB,MAAyB,KAC7C,2BACA,CAD0D,CAC1D,WACA,EADqC,EACrC,SACA,aACA,aA4BA,OA3BA,aACA,EADiC,EACjC,SACA,aACA,aACA,aACA,aACA,EADiC,EACjC,SACA,aACA,aACA,aACA,aACA,aACA,aACA,aACA,aACA,aACA,EADiC,EACjC,SACA,aACA,aACA,aACA,aACA,EADiC,EACjC,SACA,aACA,aACA,aACA,aAEA,EAFiC,EAEjC,MADA,aAEA,CAKA,OACA,KACA,IAAoB,gBAAyB,KAC7C,CAAoB,gBAAyB,EAC7C,2BACA,CAD0D,CAC1D,IACA,YAAuC,IACvC,UAD0C,GAE1C,EADqC,EACrC,SACA,aACA,aACA,aACA,EADqC,EACrC,SACA,aACA,aACA,aACA,iBA+BA,EA/BqC,KACrC,aACA,aACA,aACA,aACA,aACA,EADiC,EACjC,SACA,aACA,aACA,aACA,aACA,EADiC,EACjC,SACA,aACA,aACA,aACA,aACA,EADiC,EACjC,SACA,aACA,aACA,aACA,aACA,aACA,aACA,aACA,aACA,aACA,EADiC,EACjC,SACA,aACA,aACA,aAEA,UADA,aAEA,CACA,CAHiC,QAGjC,GACA,2BACA,CACA,MACA,0BACA,CACA,QACA,wCACA,CAMA,kBACY,KAAW,YAAe,GAAG,KACzC,MADyC,EACzC,KACA,OAAuB,GACvB,SACA,EAF0B,CAE1B,IAAuB,GACvB,WAD0B,CAE1B,SAAoB,GAAO,EAC3B,MACA,8BAEA,UAAkB,qBAAuB,iBACzC,IACA,IACA,OACA,OAAwB,IAAG,EAAS,IACpC,EAAyB,EADE,EAE3B,IAFuC,CAEvC,KAD4B,CAC5B,EACA,EAAyB,IACzB,UAD4B,CAC5B,EACA,aACA,IAAuB,GACvB,IAAuB,GAOvB,IAR0B,GAG1B,GACA,CAH0B,EAG1B,YACA,GACA,eACA,sCACA,QACA,CAUA,gBAGA,IAFA,IAE6B,KAFT,OAAa,EAGjC,GAFY,KAAW,YAAmB,GAAG,GAE7C,GACA,KAH6C,KAGrB,qBAAuB,iBAC/C,CAAsB,SAAiB,aACvC,CAAsB,SAAiB,aACvC,yBACA,yBACA,sCACA,WACA,UACA,KACA,CACA,IAAwB,SAAO,aAC/B,IACA,GACA,CAEA,8BAQA,4BACA,aACA,CADkC,CAClC,OACA,IAAwB,IAAG,IAAU,IAAG,EAAb,MAAa,sCACxC,wBACA,uBACA,CAIA,YACA,gBACA,CACA,gBACA,IAAoB,qBAA6B,EACjD,OAA6B,GAC7B,SACA,EAFgC,CAEhC,CAD6B,CAE7B,gBACA,4EACA,CACA,gBACA,IAAoB,qBAA6B,SACjD,IAA6B,GAC7B,KACA,CAD6B,CAE7B,IAHgC,IAGhC,EACA,wBACA,CACA,iBAGA,MAFY,SAAK,mBACjB,sBACA,WACA,CACA,YAEA,MADY,SAAK,mBACE,KAAa,oBAChC,CACA,CACA,8BACA,kCACA,mBACA,EAAiB,GAAI,2BAErB,OACA,QACA,kBACA,yBACA,sBACA,mBAnZA,YACA,OAAe,KAAU,GAAM,GAAG,IAClC,CAkZA,CACA,EAgCuG,CACvG,EArbkC,CAqblC,EACA,eACA,mBACA,iBACA,EAAwB,KAAc,OAEtC,CADY,SAAK,mBACjB,GACA,yCAGA,wCAEA,CAAS,CACT,aACA,eACA,OACA,gBAEA,8BAKA,EAJA,MAA0B,KAAkB,IAC5C,IAAqB,KAAU,GAAI,GAAG,SACtC,EADsC,IACtC,+BACA,WAEA,CAFmD,EAEnD,CACA,WACA,CACA,EAFqC,IAErC,GAEA,oCADA,uCAEA,CAMA,MAHA,UAFA,IAAoC,GAAG,GAAM,GAAG,EAIhD,aACA,GAAyB,MACzB,CACA,gBAGA,OAAyB,EAFzB,mCAEyB,EADzB,0CACyB,CAGzB,gCAAmD,GAAK,wBAAwB,GAAe,sBAAsB,GAAiB,oBAEtI,CAAS,CACJ,EACL,KAAmC,KAAa,CAAC,KAAkB,mBASnE,WAAoC,KAAkB,cAItD,SACA,mBACA,SACA,SACA,gBACA,qBACA,CAEA,sBACA,oBAEA,eADA,EAAkB,SAAW,2BAC7B,gBACA,CAGA,kBACA,MAAoB,OAAO,SAAY,SAAW,WAClD,iBACA,CACA,iBACY,KAAW,YAAc,GAAG,GAC5B,KAAW,GADiB,EACjB,CADiC,GACjC,GAAc,GAAG,EACxC,CACA,QAFwC,GAAgB,IAExD,GACA,6BACA,CACA,oBACA,IAAoB,kBAAsB,KAC1C,IAAoC,SAAW,eAC/C,OADsE,EACtE,0BACA,mCACA,2BACA,cACA,0CACA,yBACA,oBACA,OApGyB,GAqGzB,EADmC,EACnC,MACA,EADsC,EACtC,KACA,EADqC,EACrC,iCACA,EADkE,CAClE,GACA,iCAEA,CAFsD,MACtD,mBACA,CACA,CAEA,WACA,cA1DA,KA2DA,CACA,aACA,mEAGA,gBACA,OAAmB,KAAa,iBAChC,CACA,WACA,sBAAoC,kBAAsB,CAC1D,CAEA,oBACA,OAAmB,KAAa,qBAChC,CACA,eACA,0BACA,CACA,CA8CA,cACA,MAAoB,KAAU,IAC9B,qBACA,0BACA,EACA,aACA,EACA,iBACA,cAGA,CAuBA,kBACA,YAGA,MAAwB,KAAkB,IAC1C,KADmD,CACnD,oBACA,CAD+D,MAC/D,kBACA,EACA,mBACA,YACA,cACA,EAEA,EAAuB,EAHmB,CAGnB,EAAU,eAIjC,cAGA,OAFQ,KAAW,YAAY,aAAiB,IAAQ,GAAG,GAE5C,KAAkB,GAF0B,EAE1B,YACjC,CA0DA,OAA6B,wBAC7B,GAA6B,+BAqB7B,yBAmEA,CACA,QACA,aAlNA,iBACA,wCACA,EAiNA,gBAvLA,mBACA,QACA,6CACA,SACA,6CAEA,SADA,WACA,OAD0C,CAC1C,oBACA,EAiLA,KA9EA,kBACA,SAAgB,WAAc,SApE9B,SACA,6CACA,mDACA,SAAgB,iBAAoB,EACpC,CAAc,iCAAmC,CACjD,KADyD,EACzD,GACA,OACA,CADyB,CACP,SAAW,cAC7B,MACA,GACA,GAAsB,SAAW,4BAIjC,WACA,OACA,cAEA,oBAEA,0BACA,GADkE,GAClE,CAA0B,SAAW,mBACrC,CA4BA,CA7B2D,KA6B3D,CAAiB,KA3BI,KAAc,OA2BlB,MAxBjB,EAHkD,OAGlD,GAEA,WACA,SACA,OACA,CADwB,GACxB,OA5QyB,EA4QO,CAChC,gCACA,CADyD,CACzD,OACA,CADiC,EACjC,IAAsB,GACtB,OAIA,IALyB,EAKzB,MAfA,EAeA,KAfyB,CAgBzB,CADkD,EAClD,IAAsB,GACtB,OACA,+BAA8D,IAC9D,IACA,MAnOA,EADA,CAkOoE,EAlOhC,GAqOpC,IArOA,MAIA,CAJuC,CAIvC,CAiOA,KACA,EADuC,CACvC,EAEA,CAF+B,MAE/B,YACA,CACiB,CACjB,EAiB8B,KApBwB,EAuBtD,IAHiE,GAGjE,GADqB,EAAiB,CADtC,EACsC,eADtC,EACsC,YADtC,EACsC,MACtC,IACA,EA0EA,IA3EkC,GAkBlC,wBASA,EADA,EAJA,GAFA,EAAkB,SAAW,cAC7B,EAAoB,SAAW,gBAC/B,aACA,kDACA,MACA,SAAgB,aAAgB,EAGhC,IACA,oBAVA,GAU0C,KAAU,CAVpD,GAaA,IACA,YAdA,EAeA,CACA,SACA,0BACA,QACA,gBAnBA,EAoBA,MAEA,oBAtBA,GAsBA,iBAtBA,EAsBA,oBAtBA,EAsBA,GACA,IAAwB,SAAO,EAC/B,YACA,MAEA,qBAEA,cACA,CACA,SACA,uBACA,8EACA,QACA,CACA,mBACA,SACA,GACA,cACA,MAAgB,OAAO,EACvB,OACA,EAjXe,GAiXf,EAD0C,CAhXjB,CAiXG,CAC5B,SACA,EADiC,EACjC,KACA,EADiC,EACjC,8CAA0E,KAC1E,KAEA,SACA,CACA,EAOA,kBACA,YACA,MA/PA,CACA,qBACA,IAEA,OADA,KACA,EACA,CACA,SACA,QACA,CACA,CAAS,CACT,yBAKA,sBACA,MAA2B,GAAoB,KAC/C,OAAmB,CAD4B,Q7BxWxC,K6ByW8B,C7BzW9B,IACP,eACA,QACA,QAEA,qBACA,wBAAoC,EAAO,4BAA4B,EAAI,GAG3E,MAAoB,GAFpB,EAAuB,MAEA,EAFA,CAAe,IAAQ,SAAe,IAEtC,SACvB,SAAkB,QAAe,MAAsB,SAAe,KACtE,E6B8VqC,qBACrC,CAAS,CAST,4BACA,oBACA,sBACA,CADuC,CAGvC,CAgOA,EACA,ECz+BwC,CAAG,KAN3C,KAM2C,EAL3C,eAAgC,GAKW,CALP,GAAY,SAAW,QAC3D,WAAmB,OAIuD,EAC1E,sBAA2B,iBAA4B,CACvD,EC8BoC,CACpC,YACA,YACA,EAAM,IACN,KAEA,2FACA,2FACA,YACA,QAOA,MACA,kFACA,gBAEA,mDACA,GAAwB,GAAG,6CAC3B,gDAEA,gDACA,CAD6E,CAC7E,OANA,IAOA,UAPA,IAQA,EAAqB,GAAG,UARxB,IASA,EAAqB,GAAG,OALxB,CAKwB,CATxB,IAUA,MACA,MAKA,GAJA,GACA,GAbA,GAaA,GACA,GACA,SACA,SACA,sDAEA,OAAqB,0BACrB,CAAS,CACJ,CACJ,CAAE,KAAM,EAGA,UAiBT,yBGnGO,GACP,iBACA,GACA,KACA,oBCIO,CDHP,WCoBO,YACP,IAEA,OADQ,GAAI,2BACZ,CACA,CACA,SACA,UAAkB,GAAqB,UACvC,CACA,ED5B8C,GAC9C,ECyBuC,EDzBvC,MCEO,CDFY,CAA0B,UCG3B,GAAI,YDHuB,GCGvB,2BDFtB,CACA,cACA,OAAe,GAAQ,OAAQ,GAAmB,IAA3B,EACvB,CACA,QACA,CAHkD,MAGnC,GAAG,gCAClB,CACA,WACA,OAAe,GAAS,6CACxB,CACA,gBACA,0CAGe,GAAgB,eAC/B,CACA,YACA,ODNO,SAAS,CAAa,MAC7B,MAAc,GAAM,YCKQ,IDLR,KADS,UACT,gBACpB,GDfA,CCeQ,KAAS,GDZjB,MCYiB,MDZjB,OCYiB,EDZjB,MACA,mBCWiB,EDXjB,OACA,6BCWA,uBAAyB,EAAQ,GAAK,GAAI,eAC1C,UACA,UAAsB,GAAiB,UACvC,CAAS,EAET,CAHuC,EAGvC,CACA,OAAe,GAAI,oBACnB,CACA,SACA,UAAkB,GAAiB,UACnC,CACA,ECR4B,CDMO,GCNP,UAC5B,CACA,CEuCO,eACP,SAAY,UAAe,EAAY,iBACvC,oBACA,UACA,KAAa,EAAU,QACvB,OAAmB,GAAyB,EAC5C,MAAa,EAAU,UACvB,OAAmB,CAFyB,GDpE7B,GCsE+B,EAC9C,SACA,IDxEsC,ECwEtC,IAAsB,EACtB,CACA,CAIO,CARuC,QAQvC,MACP,OAAW,EAAY,EAPsB,IAOtB,EACvB,KAAc,CAAU,SACxB,WACK,CACL,CCxFO,qCCkBD,GAAO,wCAGb,UACA,KACA,UACA,UACA,mBACA,GACA,iBACA,2BAEA,qCACA,cACA,WACA,CAAS,CACT,CACA,0BACA,gBAAyB,gBAAgB,GAEzC,CAAK,GAAY,GACjB,MADiB,KACjB,CAIA,OAHA,mBACA,aAA0B,GAAS,uCAEnC,YAEA,cACA,sBAIA,QACA,OAAe,GAAG,SA/BlB,IA+BkB,eAClB,CACA,SACA,sBACA,CAIA,UACA,WACA,SAEA,2BACA,OAAmB,GAAgB,wBAEnC,sBACA,2BAEA,iCACA,OAAmB,GAAgB,2CAGnC,4BAEA,CAaA,CAAK,GAAO,GACZ,SADY,KACZ,EAAyB,gBAAgB,EACzC,CACA,CACO,oBACP,UACA,uBACA,GACA,OAAgB,gBAAsB,EACtC,0BACA,CACA,CACO,oBACP,eACA,SACA,gBACA,OAAgB,oBAA0B,EAC1C,2BAEA,CACO,oBACP,iBACA,sBACA,GACA,OAAgB,sBAA4B,EAC5C,0BACA,CACA,CAGO,SACP,WACA,UACA,UACA,gBACA,GACA,sBACA,eAAyB,GAAQ,OAAQ,GAAoB,IAA5B,CAA4B,KAC7D,CACA,CAAK,GAAO,GACZ,CAH6D,KAG7D,GADY,KACZ,EAAyB,SAAS,GAElC,CAAK,GAAY,IACjB,KADiB,KACjB,CACA,8BACA,CACA,cACA,sBAEA,QACA,OAAe,GAAG,SArBlB,KAqBkB,mBAClB,CACA,SACA,sBACA,CACA,iBACA,UAGA,yBACA,GAAoB,GAAkB,IAEtC,WAFsC,IAEtC,gBACA,CACA,CCjIO,iBACP,MACA,wCAGA,EAAoB,GAAc,GAAS,OAAV,CAAU,GAAY,EAAI,QAE3D,CACA,WACA,UAAsB,GAAsB,iFAE5C,EAAoB,GAAa,YACjC,CACA,YACA,CAyBO,eACP,KAmCA,OAA8B,GAAM,KAlCpC,WAAmB,GAAc,WAAG,EAAW,EAE/C,GA6BA,SAA8B,GAAQ,KA5BtC,IACA,KA2BsC,CA3BR,GAAsB,GACpD,gBADoD,CACpD,KACA,WAA2B,GAAkB,WAAG,cAAsB,EAEtE,wBACA,WAA2B,GAAoB,WAAG,CAAH,CAAG,YAAsB,CAExE,CACA,SAGA,WAAuB,GAAc,QADb,GAAkB,WAE1C,CAEA,GAJ0C,GAI1C,IAAc,GAAqB,uCACnC,CACO,eACP,uDAhEqB,MAgErB,QA/DsC,GA+DuD,IAAe,OAC5G,IAD8H,EAC9H,EAD4G,EAC1F,GAAe,2BAD6H,cAG9J,cAEA,IAAmB,GAAc,QADb,GAAkB,sBAGtC,eACA,CC7FO,eACP,qCACA,aAEA,aADA,UACA,GACA,8BACA,gCAGA,CACA,gBACA,oBACA,IACA,KACA,CACA,2BACA,6BAEA,CAQA,eAEA,OADA,QARA,WACA,eACA,8BACA,gCAGA,EAGA,CACA,CCee,wBAA8D,EAC7E,oBACA,IACA,QACA,qBACA,UACA,MAEA,cACA,CACA,QACA,CACA,sBACA,iBAEA,eACA,CACA,CC5DA,QACA,SACA,SACA,SACA,SACA,CAEA,IACA,WACA,YACA,iBACA,oBACA,yBACA,gBACA,aACA,QACA,SACA,SACA,SACA,OACA,QACA,MACA,MACA,UACA,UACA,cACA,oBACA,WACA,UACA,MACA,cACA,YACA,aACA,oBACA,aACA,cACA,aACA,cACA,eACA,eACA,gBACA,iBACA,OC/CM,GAMN,OANU,KAMV,OACA,aACA,uBACA,YACA,eACA,CAGA,WACA,cAAmB,WAAW,IAAI,UAAU,CAC5C,CAMA,WAEA,mDACA,CACA,CAGA,GAAI,SAAY,GAAI,aACpB,GAAI,WAAc,GAAI,eACtB,GAAI,UAAa,GAAI,cACrB,GAAI,WAAc,GAAI,eACtB,GAAI,UAAa,GAAI,cACrB,GAAI,QAAW,GAAI,YACnB,GAAI,QAAW,GAAI,YACnB,GAAI,UAAa,GAAI,cACrB,GAAI,UAAa,GAAI,cACrB,GAAI,SAAY,GAAI,aACpB,GAAI,SAAY,GAAI,aACpB,GAAI,cAAiB,GAAI,kBACzB,GAAI,UAAa,GAAI,aAGrB,OAAM,GAMN,QANW,IAMX,OACA,YACA,aACA,qBAEA,yBAEA,qBACA,CAGA,WACA,eAAoB,UAAU,IAAI,WAAW,CAC7C,CACA,CC5DO,2BAEP,6BAEA,mBAEA,8CAEM,GAAW,gBACX,GAAW,gBAMjB,GANiB,MAMR,GAAQ,GAEjB,aAFiB,SAEjB,kBACA,CAMO,sBAEP,wBAGS,GAAQ,wDAFjB,kBAGA,CAEO,IAAM,GAAQ,GAOrB,SACA,OAGA,yDACA,UASA,SACA,OACU,GAAW,wBACrB,UAGa,GAAU,GAKvB,GACA,YANuB,WASvB,eACU,GAAW,GAOrB,GACA,YAAkC,CARb,EAQwB,UAAkB,GAAW,GAQnE,GARsC,GAS7C,UAT0E,CAS1E,QAGO,MAOP,SACA,GAAkB,GAClB,aADkB,EAClB,iBAEA,aASA,SACA,aAGa,GAAM,GAOnB,QAGA,GAVmB,CAUnB,+BACA,EAKA,2BAEA,mCASA,QACA,wBACA,IACA,eACA,qBAEA,6BAEA,WACA,YAEA,QACA,EAEa,GAAK,GAMlB,GAGA,OATkB,IASlB,sBAQA,GACA,kBA4GA,SAAS,GAAW,GACpB,SACA,IACA,GAHoB,CAGpB,QAAkB,WAAgB,KAClC,qBACA,OACA,UACM,OACN,iBAGA,gCACA,kCAEA,gDACA,iBACA,qBAIA,iBACA,oBACA,gBAEA,CACA,QACA,CAWA,mBACA,SAEA,WACA,WACA,OACA,4BAEA,WACA,YAEA,UACA,OACA,OACA,MAEA,KACA,QAEA,KADA,UACA,QAEA,CADA,kBACA,KACA,MAGA,KACA,QACA,SACA,SACA,4BACA,8BAEA,0BACA,MAGA,KACA,QACA,SACA,SACA,SACA,0CACA,yCACA,kBACA,KAGA,CACA,CAGA,UAGA,QACA,KACM,UAEN,SACA,0BACA,gBAGA,UACA,IACA,CAEA,YACA,CAWO,eACP,eACA,MARA,KASA,2CAIA,SACA,IACA,UACA,6BACA,OACA,aAlBA,OAqBA,QACA,CCtYO,SAIP,cANA,GAMA,EACA,iBAEA,cAEA,kBAEA,eAGA,yBACA,CAEA,QACA,cACA,kBACA,oBACA,iBAEA,8BACA,uCACA,6CAEA,CAKA,QACA,wCAEA,GADA,sBACA,kBAEA,8CAEA,UACA,EAAM,IAEN,MAEA,8CACA,aAEA,kDACA,6BAEA,CACA,sCAEA,EAAmB,GAAK,gBACxB,oBACA,yBACA,6BACA,yBAGA,aAGA,oBACA,yBAEA,CACA,sBAOA,cACA,MACA,2BACA,qBACA,2BAGA,qDACA,0BACA,gBAGA,EAAe,GAAK,gBAEpB,EAAM,IAEN,EAAa,GAAM,yBAKnB,OAHA,GACA,aAEA,CACA,CACA,CC3HA,4BACA,wBAEA,MAYA,mBACA,gBACA,eAAuB,IAAiB,0BAExC,CAfA,SACA,SACA,SACA,SACA,SCHO,iEAaA,mBACL,GAAgB,OAClB,MADkB,CAClB,IACA,0BACA,eAAuB,GAAe,CAAE,WAAF,iDAAE,GAExC,QACA,CAQO,mBACL,GAAgB,OAClB,MADkB,CAClB,cACA,0BACA,eAAuB,GAAe,CAAE,WAAF,iDAAE,GAExC,QACA,CAQO,mBACL,GAAgB,OAClB,MADkB,UAClB,qCACA,0BACA,eAAuB,GAAe,CAAE,WAAF,iDAAE,GAExC,QACA,CAQO,mBAEL,GAAgB,OAClB,MADkB,UAClB,qCACA,mDACA,oCACA,0BACA,eAAuB,GAAe,CAAE,WAAF,iDAAE,GAExC,8BACA,iBAEA,sBACA,QAEA,gBAAqB,GAAe,CAAE,WAAF,iDAAE,EACtC,CAyDO,iBACP,sBACA,CAOO,mBACP,YACA,gBAEA,aACA,EAAI,gBACJ,gBAEA,gBACA,EAAI,gBACJ,gBAEA,0BACA,EAAI,gBACJ,gBAEA,oDACA,EAAI,IACJ,gBACA,YAEA,2BAEA,+BACA,0CACA,YACA,MACA,WACA,MACA,WACA,MACA,WACA,WACA,MACA,WACA,MACA,WACA,MACA,WACA,SACA,EAAM,IACN,eAAyB,GAAe,CAAE,WAAF,mCAAE,EAE1C,CACA,CAMA,2BACA,8BACA,EAMA,kCACA,QACA,EAEA,QACA,EAEA,QACA,EAEA,QACA,EAEA,CACA,EAOA,+BACA,6CACA,ECtLA,kBACA,aA2BO,iBACP,cAEE,GAAoB,sBADtB,kCAEA,CC3DA,qBACE,GAAgB,SAClB,IADkB,EACJ,GAAK,aACnB,WAAa,GAAM,GAAI,KAAL,CAAK,MACvB,CASO,qBACP,kBACA,CAyDA,eAKA,OAJA,yBACA,yBAAwC,GAAI,UAAoB,oBAGhE,aAOO,iBACP,YACE,GAAoB,gCACtB,SACA,CCtFA,SAAS,GAAO,WAChB,EADgB,EAChB,MACE,GAAgB,OAClB,UAAkB,GAAM,GAAI,KAAL,CAAK,IAAiB,cAI7C,EAJ6C,IAC7C,0BACA,aAAoB,GAAK,YAEzB,CACA,CASO,qBACP,OAAS,GAAO,UAChB,CCtBA,EDqBgB,OCrBP,GAAO,SAChB,GADgB,IAChB,IAAa,GAAM,GAAI,KAAL,CAAK,IACvB,CASO,qBACP,OAAS,GAAO,QAChB,CAqEO,GAtES,MAsET,QACL,GAAoB,EAAM,GAAI,OAAV,WAAU,SAChC,CCpFA,SAAS,GAAO,SAChB,CADgB,MAChB,IAAa,GAAM,GAAI,KAAL,CAAK,EACvB,CASO,qBACP,OAAS,GAAO,QAChB,CAqEO,CAtES,QAsET,QACL,GAAoB,EAAM,GAAI,OAAV,SAAU,SAChC,CCrFO,qBACP,WAAa,GAAM,GAAI,KAAL,CAAK,EACvB,CAkDO,iBACL,GAAoB,EAAM,GAAI,yBAChC,CCfA,mBACA,MACA,oCACA,eAAyB,GAAe,CAAE,WAAF,iBAAE,GAE1C,6CACA,eAAyB,GAAe,CAAE,WAAF,sBAAE,EAE1C,CACA,WAAa,GAAM,GAAI,KAAL,CAAK,IACvB,CAwCO,mBACP,cAEA,UACA,QA/FA,GA+Fc,GAAI,0BACd,UACJ,QAhGA,GAgGc,GAAI,0BACd,YACJ,QAjGA,GAiGc,GAAI,0BACd,cACJ,QAlGA,MAkGkB,yBACd,CAEJ,SACA,oBACA,MAEA,IADA,UACA,iBACA,UACA,sBACA,OAEA,MAEA,IADA,WAEA,UACA,sBACA,QAIA,IAiJA,gBAhJA,EAgJA,IA/IA,SACA,UACA,sBAEA,CACA,CN5DA,2BACA,cACA,2CAGA,EAAiB,EAAmB,IACpC,EAEA,EAAiB,EAAmB,IACpC,EAEA,EAAiB,EAAmB,IACpC,EAEA,EAAiB,EAAmB,IACpC,EAEA,CACA,EAOA,+BAEA,6CACA,ECCA,2BACA,YACA,OAAS,GAAoB,gCAQ7B,mCASO,IARP,OAQO,EARP,MAQO,EARP,MASA,yCAAkE,OAAO,ELkIlE,KAEP,GAAM,GAAQ,IAAQ,GAAQ,GAG9B,MAHc,CAGd,MAH8B,GAG9B,IAEA,YAAkB,WAAe,IACjC,eAGA,sBAEA,QACA,EKhJyE,IARzE,EEnBA,iBAA4B,GAAe,cAM3C,2BACA,OAAS,GAAoB,oBAC7B,ECRA,iBAA0B,GAAe,cAMzC,2BACA,OAAS,GAAoB,oBAC7B,ECzCA,iBAA0B,GAAe,cAMzC,2BACA,OAAS,GAAoB,oBAC7B,ECsEA,6BACA,cAEA,2BACA,SAGA,uBACA,MACA,eACA,0BACA,SAIA,GAFA,MAEA,IADA,aAEA,QAEA,CACA,QACA,EAEA,0BACA,sBACA,wBAKA,eACA,WACA,8BACI,YACJ,8BACI,mBACJ,6BACI,CACJ,mBACA,sBACA,qBACA,YAGA,WAEA,8BACM,SAEN,gDACM,CAEN,CAFa,GAEb,OAGA,OAKA,kBACQ,MAIR,8CAEA,oDAEA,CACA,CACA,CAOA,qBAiBA,EAhBA,gBACA,eAAuB,GAAe,CAAE,WAAF,gBAAE,GAGxC,uBACA,aACA,WAEA,aACA,WAEA,aACA,WAEA,eACA,SAWA,OARA,EADA,MACA,uBACI,OACJ,mBAIA,cAEA,YACA,CAKA,eACA,qBACA,CAOA,iBACA,gBACA,eAAuB,GAAe,CAAE,WAAF,gBAAE,GAExC,0BACA,kDACA,CAcA,iBACA,gBACA,eAAuB,GAAe,CAAE,WAAF,gBAAE,GAExC,0BACA,kDACA,CCjRA,mBACA,eAAqB,GAAe,CAAE,WAAF,gBAAE,EAA6B,EAAM,cAAc,SAAgB,EACvG,CAMA,eACA,WAAiB,eAAmB,GAAe,CAAE,EAAE,EAAI,GAC3D,CD8QA,iBAA4B,GAAU,cC3Q/B,UAGP,YAAgB,MAAW,IAC3B,QAEA,QRuDO,EQvDM,ORuDN,IQvDsB,CRuDtB,IACP,WAAa,GAAM,GAAI,KAAL,EAAK,YACvB,EQxDA,ORiEO,EQjEM,ORiEN,SACP,WAAa,GAAM,GAAI,KAAL,EAAK,YACvB,EQlEA,OR2EO,EQ3EM,OR2EN,SACP,WAAa,GAAM,GAAI,mBACvB,EQ5EA,ORqFO,EQrFM,ORqFN,SACP,WAAa,GAAM,GAAI,KAAL,EAAK,YACvB,EQtFA,UACA,UACA,UACA,UAEA,aAAmB,MAAW,IAC9B,SAEA,OPlCO,EOkCM,OPlCN,SACP,WAAa,GAAM,GAAI,KAAL,CAAK,IAAc,GAAc,WACnD,EOiCA,OPxBO,EOwBM,OPxBN,SACP,WAAa,GAAM,GAAI,KAAL,CAAK,IAAc,GAAe,WACpD,EOuBA,OPdO,EOcM,OPdN,OOc2B,EPblC,WAAa,GAAM,GAAI,KAAL,CAAK,IAAc,GAAe,WACpD,EOaA,OPDO,EOCM,OPDN,SACP,MAAc,GAAe,SAC7B,uBACA,WACA,8BACA,WAAiB,GAAM,GAAI,KAAL,CAAK,KAE3B,CACA,sBACA,eAAuB,GAAe,CAAE,WAAF,iDAAE,GAExC,WAAa,GAAM,GAAI,KAAL,CAAK,gBACvB,EOVA,UACA,UACA,UACA,UAEA,aAAmB,MAAW,IAC9B,MAAY,GAEZ,ONvBO,EMuBM,MAFuB,CNrB7B,KMuBwB,CNvBxB,GACP,gBAA+B,GAAc,SAC7C,EMsBA,ONbO,EMaM,ONbN,SACP,gBAA+B,GAAe,SAC9C,EMYA,ONHO,EMGM,ONHN,MMGyB,CNHzB,EACP,gBAA+B,GAAe,SAC9C,EMEA,ONQO,EMRM,ONQN,MMRyB,CNQzB,EACP,MAAY,GAAe,SAC3B,sBACA,eAAuB,GAAe,CAAE,WAAF,+BAAE,GAExC,kBACA,EMbA,UACA,UACA,UACA,+DAEA,aAAmB,OAAW,IAC9B,MAAY,GAEZ,QL7BO,EK6BM,MAFyB,CL3B/B,SACP,OAAS,GAAO,MAAe,GAAc,WAC7C,EK4BA,QLnBO,EKmBM,OLnBN,SACP,OAAS,GAAO,MAAe,GAAe,WAC9C,EKkBA,QLTO,EKSM,OLTN,OKS2B,ELRlC,OAAS,GAAO,MAAe,GAAe,IAA9B,EAA8B,KAC9C,EKQA,QLEO,EKFM,OLEN,SACP,MAAY,GAAe,SAC3B,sBACA,eAAuB,GAAe,CAAE,WAAF,gCAAE,GAExC,OAAS,GAAO,UAChB,EKPA,CLMgB,CKNhB,SACA,WACA,WACA,gEAEA,cAAmB,OAAW,IAC9B,MAAY,EAEZ,SJlDO,EIkDM,KAFuB,EJhD7B,SACP,OAAS,GAAO,MAAe,GAAc,GAA7B,CAA6B,KAC7C,EIiDA,QJxCO,EIwCM,OJxCN,SACP,OAAS,GAAO,MAAe,GAAe,GAA9B,CAA8B,KAC9C,EIuCA,QJ9BO,EI8BM,OJ9BN,SACP,OAAS,GAAO,MAAe,GAAe,GAA9B,CAA8B,KAC9C,EI6BA,QJnBO,EImBM,OJnBN,MImByB,CJnBzB,EACP,MAAY,GAAe,SAC3B,sBACA,eAAuB,GAAe,CAAE,WAAF,+BAAE,GAExC,OAAS,GAAO,QAChB,EIcA,EJfgB,CIehB,QACA,WACA,WACA,QJRO,EIQM,OJRN,SACP,KIOwC,GJPxC,kBACA,eAAuB,GAAe,CAAE,WAAF,wBAAE,GAExC,OAAS,GAAO,UAChB,EADgB,IIMhB,UAAmB,OAAW,IAC9B,MAAY,EAEZ,SH9DO,EG8DM,GAFmB,IH5DzB,SACP,OAAS,GAAO,MAAe,GAAc,CAA7B,CAA6B,OAC7C,EG6DA,QHpDO,EGoDM,OHpDN,IGoDqB,CHpDrB,IACP,OAAS,GAAO,MAAe,GAAe,CAA9B,CAA8B,OAC9C,EGmDA,QH1CO,EG0CM,OH1CN,SACP,OAAS,GAAO,MAAe,GAAe,CAA9B,CAA8B,OAC9C,EGyCA,QH/BO,EG+BM,OH/BN,IG+BqB,CH/BrB,IACP,MAAY,GAAe,SAC3B,sBACA,eAAuB,GAAe,CAAE,WAAF,6BAAE,GAExC,OAAS,GAAO,QAChB,EADgB,EG2BhB,SACA,WACA,WACA,QHpBO,EGoBM,OHpBN,SACP,GGmBoC,CHnBpC,sBACA,eAAuB,GAAe,CAAE,WAAF,wBAAE,GAExC,OAAS,GAAO,YGkBhB,cAAmB,OAAW,IAC9B,MAAY,GAEZ,QFtFO,EEsFM,GAFmB,IFpFzB,SACP,WAAa,GAAM,GAAI,IAAM,CAAX,EAAyB,WAC3C,EEqFA,QF5EO,EE4EM,OF5EN,SACP,WAAa,GAAM,GAAI,IAAM,CAAX,EAAK,EAAqB,SAC5C,EE2EA,QFlEO,EEkEM,OFlEN,SACP,WAAa,GAAM,GAAI,IAAM,CAAX,EAAK,EAAqB,SAC5C,EEiEA,QFxDO,EEwDM,OFxDN,SACP,WAAa,GAAM,GAAI,IAAM,CAAX,EAAK,EAAqB,SAC5C,EEuDA,WACA,WACA,WACA,WAEA,cAAmB,OAAW,IAC9B,4CAEA,WACA,WACA,WACA,QDtGO,ECsGM,ODtGN,QCsG2B,CDrGlC,yBACA,eAAuB,GAAe,CAAE,WAAF,uBAAE,SACpC,6BACJ,IAAe,GAAM,GAAI,KAAL,EAAK,MAEzB,IAAa,GAAM,GAAI,KAAL,EAAK,YACvB,ECgGA,8CACA,QDxDO,ECwDM,ODxDN,SACP,wBACA,ECuDA,QD9CO,EC8CM,OD9CN,SACP,wBACA,EC6CA,QDpCO,ECoCM,ODpCN,SACP,wBACA,ECmCA,WACA,WACA,WACA,QD9FO,EC8FM,OD9FN,SACP,0BACA,eAAuB,GAAe,CAAE,WAAF,wBAAE,GAExC,WAAa,GAAM,GAAI,eACvB,EC4FO,UAEP,YAAgB,KAAQ,IACxB,UAAiB,GAAM,GAAI,UAG3B,aAAiB,OAAU,IAC3B,aAAsB,GAAM,GAAI,KAAL,CAAK,KAGhC,YAAkB,GAAM,GAAI,KAAL,CAAK,qBAE5B,WAAkB,GAAM,GAAI,KAAL,CAAK,OAE5B,YAAkB,GAAM,GAAI,KAAL,CAAK,KAE5B,YAAkB,GAAM,GAAI,KAAL,CAAK,GAE5B,YAAkB,GAAM,GAAI,YAE5B,YAAkB,GAAM,GAAI,WAE5B,YAAkB,GAAM,GAAI,KAAL,EAAK,MCtI5B,QACA,WACA,UAkWA,cAIA,uCACA,mCAGA,mBACA,8BAKA,SAFA,aAEA,oBAOA,OALA,OAGA,sFAEA,CACA,EAvXA,gBAAkB,CDyIX,YACP,eACA,KAAS,GAAI,MACb,CADa,MACA,GAAS,MACtB,MAAS,GAAI,KACb,EADa,KACA,GAAS,YACb,GAAI,KACb,EADa,KACA,GAAS,YACb,GAAI,MACb,CADa,EACb,gBACA,OAAe,GAAS,YAGxB,MAAS,GAAI,UACb,aACA,OAAe,GAAS,YAGxB,MAAS,GAAI,MACb,CADa,EACb,YACA,OAAe,GAAS,OAIxB,MACA,MAAS,GAAI,IACb,eACA,OAAe,GAAS,OAIxB,MACA,MAAS,GAAI,KACb,EADa,CACb,WACA,OAAe,GAAS,mBAExB,MACA,MAAS,GAAI,UACb,aACA,OAAe,GAAS,qBAExB,CACA,CClLA,EAGO,cACP,SASA,OARA,EAAW,GAAI,YAAe,GAC9B,EAAW,GAAI,EADyB,IACzB,QAAiB,GAChC,EAAW,GAAI,IAD6B,CAC7B,QAAgB,GAC/B,EAAW,GAAI,GAD2B,GAC3B,QNmDa,EMnDI,CAChC,EAAW,GAAI,GNkDwB,EMlDxB,CAD6B,CAC7B,MAAgB,GAC/B,EAAW,GAAI,GAD2B,CAC3B,OAAc,GAC7B,EAAW,GAAI,CADuB,EACvB,QAAc,GAC7B,EAAW,GAAI,CADuB,IACvB,QAAgB,GAC/B,CACA,CAEA,MAJ0C,CAI1C,KAEA,OAAgB,EAAE,OAGlB,GAKA,iBACA,WACA,aACA,CAMA,YAEA,WACA,GACA,aACA,eAEM,YACN,QACA,CAOA,wBACA,oBACA,eAAyB,GAAe,CAAE,WAAF,wBAAE,GAE1C,kBACA,CACA,CAEA,QACA,SAAY,GAAM,GAAI,KAAL,EAAK,IACtB,cAAiB,GAAM,GAAI,KAAL,EAAK,WAC3B,SAAY,GAAM,GAAI,KAAL,CAAK,GACtB,UAAa,GAAM,GAAI,UACvB,eAAkB,GAAM,GAAI,KAAL,CAAK,GAC5B,aAAgB,GAAM,GAAI,KAAL,CACrB,CAD0B,CAI1B,IAQA,kBACA,6CAEM,KACN,IAAiB,GAAM,GAAI,KAAL,EAAK,CAE3B,IAAiB,GAAM,GAAI,KAAL,CAAK,IAJ3B,IAAiB,GAAM,GAAI,KAAL,CAAK,GAe3B,kBACA,aACA,IAAiB,GAAM,GAAI,KAAL,EAAK,CAE3B,IAAiB,GAAM,GAAI,KAAL,CAAK,IAW3B,sBACA,IAAe,GAAM,GAAI,KAAL,CAAK,GAUzB,kBACA,IAAe,GAAM,GAAI,KAAL,CAAK,IAUzB,mBACA,mBAUA,gBACA,QAUA,qBACA,aAUA,uBACA,IAAe,GAAM,GAAI,KAAL,CAAK,mBAUzB,oBACA,IAAe,GAAM,GAAI,KAAL,CAAK,oDAUzB,eACA,mBACA,sBACA,mBAA6C,GAAM,GAAI,QAEvD,cAEA,sBACA,SACA,IACA,eACA,OAAqB,GAAc,cAEnC,IAFmC,YAEnC,CACA,KAAkB,GAAM,GAAI,KAAL,CAAK,gBAAkC,GAAM,GAAI,QAExE,KAAgB,GAAM,GAAI,KAAL,CAAK,aACvB,CASH,gBAEA,mBAEA,4BACA,oBACA,YACA,sBACA,iBAA2C,GAAM,GAAI,KAAL,EAAK,CAErD,YAEA,sBAEA,SACA,IACA,eACA,QACQ,GAAc,OACd,GAAc,QADA,GACA,UACtB,OAGA,CA2GA,aACA,oBA5GA,kBACA,KAAkB,GAAM,GAAI,KAAL,EAAK,MAA4B,GAAM,GAAI,QAElE,KAAgB,GAAM,GAAI,KAAL,EAAK,GAE1B,EAIA,aAFA,iBACA,wBACA,6FACA,MAAkB,EAAI,oBAStB,SAAS,GAAc,MAAmB,IAC1C,MAAc,EADS,OdvOhB,GACP,YACA,aAEA,cACA,kBAEA,kBACA,gBAEA,sBACA,eACA,EAIA,eACA,WAEA,iBACA,QAkBA,kBAhBA,EAgBA,sBAhBA,EAgBA,+BAhBA,GACA,SAEA,SAoBA,GACA,oDACA,kBACA,QAIA,EA3BA,IAKA,QACA,EcyMgB,GAChB,qBAAgG,aAArB,CAAqB,WAChG,SADgG,MAChG,UACA,iBACA,WACA,QAEA,CACA,YACA,MACA,eAAuB,GAAe,CAAE,WAAF,OAAE,EAAoB,EAAI,GAEhE,iBACA,CAkIA,mBACA,MAAiB,GAAc,KAC/B,aAD+B,IAC/B,yBACA,4BACA,KACA,SAEA,sBACA,kBAEA,UAAsB,EAAE,CADxB,oBAKA,GAHA,SAGA,oBACA,2DAAuE,GAAQ,YAE/E,OAAa,GAAK,YAClB,CACA,CAGA,OAFA,YACA,SArCA,WACA,oBACA,eACA,gBAGA,sBAEA,EA6BA,UACA,cACA,CAOA,SAAS,GAAM,KAEf,KAFe,EAEf,QADA,kBAA4B,OAE5B,CCncA,QACA,UACA,mBACA,kBACA,cACA,CAKA,UAKA,kBAAiC,EACjC,YACA,YACA,cACA,CAEA,MACA,iBAGA,OACA,mCAGA,OACA,2BACA,EAAgB,EAAK,IACrB,eACA,MAAsB,EAAI,IAG1B,MACA,eAA2B,GAAe,CAAE,WAAF,eAAE,EAA4B,OAAW,UAAU,+BAAkC,IAE/H,WACA,uCACA,CAGA,OADA,2BACA,CACA,CACA,CAEA,0BACA,uBA6IA,SAAS,GAAM,KACf,KADe,CACf,GAtBA,cACA,8BACA,eAAuB,GAAe,CAAE,WAAF,wBAAE,GAGxC,MADA,mBAA4B,QAC5B,uBACA,WA/CA,OAGA,YACA,UAGA,eAEA,YAAqB,GAAI,MACzB,CADyB,MACzB,GAGA,mBACA,eAGA,YAAqB,GAAI,MACzB,CADyB,MACzB,SAzFA,OACA,SACA,YAAkB,UAAiB,KACnC,aACA,WACA,iBAEA,KAEA,gBAAyB,GAAe,CAAE,WAAF,2BAAE,EAC1C,CACA,UACA,eAAyB,GAAe,CAAE,WAAF,6BAAE,EAA0C,EAAE,aAAa,QAAY,GAE/G,OACA,CACA,QACA,EAwEA,OAGA,YAAqB,GAAI,IACzB,GADyB,IAnEzB,gBACA,qBACA,cACA,mBACA,YAAkB,UAAiB,KACnC,aACA,WACA,iBAEA,KAEA,gBAAyB,GAAe,CAAE,WAAF,yBAAE,EAC1C,CACA,UACA,eAAyB,GAAe,CAAE,WAAF,2BAAE,EAAwC,GAAG,qBAAqB,QAAY,IAEtH,8BACA,eAAyB,GAAe,CAAE,WAAF,wBAAE,EAAqC,SAAW,IAE1F,kCAEA,0BACA,eAA2B,GAAe,CAAE,WAAF,WAAE,EAAwB,EAAI,IAGxE,aACA,UACA,eAAyB,GAAe,CAAE,WAAF,2BAAE,EAAwC,GAAG,uBAAuB,QAAY,IAExH,EAEA,WAGA,MAEA,CAEA,YACA,EA6BA,OAGA,YAAqB,GAAI,KACzB,EADyB,CACzB,4CACA,aACA,yBACA,CACA,eAAuB,GAAe,CAAE,WAAF,QAAE,EAAqB,QAAY,GACzE,CAEA,0BACA,EAaA,KACA,UACA,eAAuB,GAAe,CAAE,WAAF,uBAAE,GAExC,UACA,eAAuB,GAAe,CAAE,WAAF,SAAE,GAExC,+BASA,KACA,cACA,eAAuB,GAAe,CAAE,WAAF,4BAAE,GAExC,QACA,CE9MO,uBACP,iDACA,sCACA,SACA,kCACA,CACA,CACO,uBACP,qDACA,0CACA,SACA,sCACA,CACA,CACO,uBACP,6CACA,wBACA,SACA,8BACA,CACA,CACO,uBACP,mDACA,sCACA,SACA,oCACA,CACA,CACO,uBACP,8CACA,6BACA,SACA,+BACA,CACA,CACO,uBACP,+BACA,qEACA,SACA,6BACA,CACA,CACO,uBACP,iDACA,yBACA,SACA,kCACA,CACA,CACO,uBACP,wDACA,iCACA,SACA,yCACA,CACA,EChDA,gBAMA,MADA,EASA,CAXA,CACK,oCAAuE,EAD5E,UAIA,CADA,EAEK,SAAoD,CADzD,gBAGA,CAGK,mCAAuE,EAH5E,UACmB,GAAW,GAI9B,KAJ8B,EAI9B,MACA,SACA,GAAqB,GAAO,SAAmB,IAC/C,wBACA,SAEA,gBACA,aACA,kBAEA,sBACA,aACA,wBAEA,uBACA,aACA,iDAEA,mBACA,aACA,qBAEA,mBACA,aACA,sBAEA,cACA,aACA,iBAEA,iBACA,aACA,mBAEA,sBACA,aACA,wBAEA,eACA,aACA,iBAEA,wBACA,UAEA,CAAa,UAA4B,IACzC,SACA,wBACA,eACA,iBACA,cACA,OACA,kBACA,KAEA,QACA,wBACA,KAEA,QACA,gDACA,KAEA,QACA,qBACA,KAEA,QACA,sBACA,KAEA,QACA,iBACA,KAEA,QACA,mBACA,KAEA,QACA,wBACA,KAEA,QACA,iBACA,KAEA,SACA,eAGA,CACA,CACA,QACA,EAAa,EAEb,GAEA,YACe,GAAa,aAE5B,gBACe,GAAa,cAE5B,CAAC,CAAE,IAAc,EAAS,GAAK,ECjH/B,GDiHY,CCjHN,GDiHoB,GCjHR,GAAT,WACT,GAAoB,GAAoB,UAiCjC,eAEP,OAAW,GAAgB,CADL,EACK,CADe,qBACf,CAC3B,CACO,qBACP,kBACe,EAAS,QACxB,IADwB,EACL,GAAoB,SACvC,UADuC,EACvC,cACA,4BACA,SAAsB,GAAoB,YAC1C,OAD0C,EAC1C,WACA,UACA,gBACA,0BACA,YACS,EAGM,EAAS,QACxB,IADwB,GACxB,SACA,0BACA,YACS,CAET,CACO,eACP,MAAoB,EAAS,UAY7B,EAZ6B,CAE7B,kBACA,gCAGA,aACA,sBAKA,kCACA,UAAkB,GAA0B,+BAE5C,iBACA,WAkFO,GACP,MAAmB,GAAkB,UAErC,KAFqC,UAErC,MACA,SAGA,IACA,eAAwB,GAAG,4BAAiC,EAE5D,MAEA,CACA,IACA,eAAwB,GAAG,2BAAiC,EAE5D,MAEA,CACA,UAAc,GAAiB,qDAC/B,EAtGA,SACA,EAAqB,GAAkB,YACvC,sCAGA,OADA,SA8HA,GACA,gBACA,UAAkB,GAAsB,0BAExC,iBACA,IAAS,GAAgB,oCACzB,UAAkB,GAA0B,yDAE5C,IAAS,GAAgB,0CACzB,UAAkB,GAA0B,4DAE5C,mCACA,UAAkB,GAA0B,gEAE5C,2BACA,UAAkB,GAA0B,4DAE5C,iBACA,UAAkB,GAA0B,sDAE5C,EAlJA,GACA,CACA,QACA,aAA0B,EAAS,iBACnC,WACA,oBACA,UACA,gBACA,0BACA,0BACA,aAGA,uBAEA,OACA,QACA,aAA0B,EAAS,iBACnC,WACA,oBACA,UACA,gBACA,0BACA,YAIA,2EAEA,CACO,eACP,OAAW,GAAgB,CAC3B,EAD2B,CAE3B,QACA,CACA,CACO,eACP,MAAmB,GAAa,oBAChC,GApHA,IAqPA,QAjIA,OAiIA,KAhIA,UAAkB,GAAqB,sDAEvC,QACA,CAkBO,eACP,MAAiB,GAAY,GAC7B,OAD6B,EAC7B,aACA,eAA4B,EAAS,sBAGrC,UAAkB,GAAwB,oCAU1C,OARA,8BAEA,gCAEA,yBAEA,sBAEA,CACA,gBCpKA,IAAM,GAAM,GAAM,OAAT,WASF,oBAMP,EAFA,MAAmB,GAAmB,GAGtC,IACA,MAAiC,GAJK,EAIiB,MACvD,WADuD,KACvD,iBACA,CACA,SACA,IACA,CACA,MAEA,MADQ,GAAG,8CACX,IAAkB,GAA0B,wCAG5C,oBAAgC,EAAS,iBACzC,IAAY,aAAmB,2CAE/B,MADY,GAAG,4BACf,IAAsB,GAAkB,qBACxC,MAEA,wBAEA,MADQ,GAAG,0CACX,IAAkB,GAAwB,oCAEtC,GAAG,sCACP,EACO,2BAMP,EALA,gBArCA,MAsCA,UAAkB,GAAmB,2BAGrC,MAA6B,GAA2B,EAGzC,KD8Mf,QC7MA,GAAwB,GAAsB,GAJU,CAQxD,MAAyB,SDtClB,GACP,MACA,YCoCuD,KDpCvD,CACA,IACA,EzBWO,YACP,SAAY,UAAa,EAAc,UACvC,oBACA,UACA,KAAa,EAAU,IACvB,CADuB,MT2FhB,SAAS,CAAkB,EAClC,MA1EO,MSjB8B,GTiB9B,GACP,WAAY,GNwwBZ,OMxwBqC,ENwwBrC,GACA,kBACA,eAAuC,KAEvC,OADA,uCACA,CACA,UACA,QACA,CACA,CACA,UAAwB,KAA+B,wCACvD,EMlxBqC,GAGrC,6DACA,OACA,UACA,WACA,UACA,CACA,EAgEA,GACA,GAAQ,SF1FkB,GAC1B,YEyFkB,CFzFlB,IACA,IAF0B,EAE1B,IAAkB,GAAsB,oBAExC,MAFwC,GAExC,IACA,UAAkB,GAAsB,uBAGxC,GAHwC,IAGxC,KADsC,iBACtC,EADsC,IACtC,EEkFkB,GA7HX,KA8HP,UAAkB,GAAqB,yBAOvC,WAAe,GAAiB,EADb,GAnInB,GA+HiB,OAIQ,CAJR,CAAM,CAAC,EAAY,QACpC,KAAc,EAAU,IACxB,CADwB,IACxB,CACA,CAAK,IAGL,ESrGqC,EACrC,MAAa,EAAU,QACvB,OAAmB,GAAyB,EAC5C,MAAa,EAAU,UACvB,OAAmB,CAFyB,MAEE,EAC9C,SACA,UAAsB,EACtB,CACA,EAJ8C,EyBpBJ,OAC1C,CACA,SAEA,MzBkB6C,GyBnB9B,SACf,CACA,CAEA,WACA,QAEA,ECuB2B,GAAmB,KACS,EACvD,SAF8C,EAG9C,UAAkB,GAA6B,gEAG/C,IAAS,GAAgB,EADF,GAAyB,KACvB,QADuB,KAEhD,IAFgD,EAEhD,IAAkB,GAA6B,gDAG/C,cACA,CCtEe,eAAgB,GAAK,GACpC,KADoC,CACpC,QACA,0BACA,KACA,sBACA,oBACA,gCAGA,OADA,eAA0C,WAAc,EACxD,SACA,cACA,YAAwB,WAAkB,IAC1C,sBAEA,CAEA,KADA,iBAEA,qBAEA,gBCnBO,OAAM,WAAY,MACzB,KADyB,OACzB,GACA,SACA,wBACA,CACA,CAMO,MAAM,WAAU,MACvB,GADuB,SACvB,GACA,QACA,uBACA,cACA,CACA,CAKA,2CACA,IAAO,GAAU,GACjB,cADiB,GACjB,GAKA,OACA,wBACA,kCACA,SAEA,iCACA,EAEe,qBAQf,EAPA,IACA,eACA,WACA,UACA,gBAAkB,wBAAyB,CAC3C,CAAG,EAoEH,MAhEA,gBACA,wCACA,4EAAmF,EAAa,KAGhG,aACA,WAAU,GAAQ,CAClB,YACA,SAGA,WACA,QACA,EAEA,8BAAmD,QAAW,EAE9D,eACA,gCACA,CAAI,CACJ,CAEA,iCACA,YACA,MACA,CAGA,UAA2B,GAE3B,mBAFuC,CAEvC,YACA,MACA,IACA,MACA,CAAM,SACN,IACA,CAEA,MACA,CAEA,6BACA,WAGA,OACA,IACK,mBACL,MAEA,wCAAiE,GAAc,cAC/E,KAEA,CAAG,IAEH,WACA,IACA,UACA,CAAK,SACL,IACA,CACA,EAAG,EACH,CAAE,EAEF,aACA,SACA,CAAE,EAOF,OALA,aACA,8BACA,QACA,EAEA,CACA,CExHe,SACf,MACA,aAKA,OACA,UALA,GACA,WACA,KACA,EAEA,SACA,KACA,EACA,yDACA,gBACA,MACA,CACA,MDde,gBACf,QACA,WACA,WACA,sBACA,KACA,eACA,MACA,QAGA,GAEA,CACA,QACA,ECDgC,wCAChC,qBACA,CACA,UACA,sBACA,aACA,CACA,UACA,+DACA,CACA,WACA,sBAEA,CCvBe,iBAAqB,IAAY,CAChD,IACA,GACA,KACA,GACA,CACA,OACA,GACA,GACA,CACA,KACA,GAEA,KACA,GACA,EAMA,oBAEA,GAYA,GAXA,QAWA,kBATA,IACA,6BACA,qCACA,WACA,qCACA,aACA,WAAwB,GACxB,IACA,GACA,GAHqC,QAGrC,oBACA,gFAAgG,8BAAsC,MAAM,qBAA2B,IAEvK,sEACA,2EAA2F,2BAAmC,MAAM,kBAAwB,GAE5J,qCACA,iEACA,sBACA,mBACA,yBACA,qBACA,+BACA,uBACA,8BACA,yBAEA,SACA,gCAEA,SACA,uBAEA,KACA,UACA,UACA,iBACA,CACA,KACA,UACA,UACA,cACA,CACA,SACA,iBACA,qBACA,gBACA,UAYA,OALA,kBACA,yBACA,SACA,CAAqB,KAErB,EATA,0BAWA,CACA,QACA,CACA,KACA,oBAWA,OARA,SACA,uBAEA,eACA,mBACA,aACA,kBAEA,GAEA,aACA,eACA,qBACA,8BACA,MAGA,oBACA,IACA,GACA,UAEA,GACA,CACA,CACA,QACA,CACA,KACA,4BAGA,yBACA,SACA,CAAS,UACT,2BACA,CACA,KACA,oCACA,uBACA,gBAEA,0BACA,SACA,CAIA,KAEA,iBACA,CACA,kBACA,eAEA,mBACA,+BACA,gFAAgG,EAAe,MAAM,SAAsB,GAE3I,WACA,SACA,CACA,YACA,2BACA,gCACA,WACA,CAAa,EAAI,QAAY,CAC7B,CAAS,CACT,CACA,gBAAqC,EAMrC,OALA,GACA,qBACA,uBACA,MAEA,oBACA,0BACA,UACA,UACA,IACA,2BACA,SAAgD,gBAAwB,CACxE,YACA,GAAoC,GAAQ,oBAA+B,wBAA+B,EAE1G,UACA,wCAEA,cACA,KACA,wBACA,CACA,SACA,gBAAyC,IAAY,mBACrD,IACA,MACA,CACA,KACA,oBACA,QACA,CACA,SACA,CACA,CAAa,IACb,iBACA,SACA,CAAS,CACT,CACA,kBACA,iDACA,CAIA,eACA,UAGA,WACA,WAHA,IAKA,CAIA,QACA,UACA,CAIA,QACA,oBAOA,gBAEA,kBAGA,sBACA,CAQA,wBAEA,gBAGA,wCACA,CAMA,eAEA,iCAGA,qBACA,CACA,cACA,uBACA,WACA,YAGA,cACA,IACA,EACA,YACA,CAAS,CACT,CAIA,WACA,mBACA,CAMA,UAEA,gCAKA,cACA,eAKA,eACA,eAEA,CCrTO,uBACP,8CACA,qBACA,SACA,+BACA,CACA,CACO,uBACP,8BACA,+BACA,SACA,4BACA,CACA,CCoCA,OAdA,YACA,GAHA,GAgBe,GAhBf,EAgBoB,EAAC,KAhBrB,eAIA,iBACA,qBACA,QAGA,EAAS,GAET,eACA,QAGA,EC4BA,GA9BA,YAEA,iBA4BuB,EAAC,KA5BxB,eAEA,iDAEA,uCACA,KAEA,OACA,SACA,SAEA,SACA,SACA,CAAS,CACT,SACA,WACA,CACA,QACA,eACA,EAEA,SAEA,MACA,YAEA,CACA,ECNA,GAjCA,cACA,EAgCe,EAhCf,CAgCkB,CAhClB,CAgCmB,CA/BnB,GAJA,CAIQ,KAAe,CAJvB,aAIuB,QAJvB,EAKA,yBACA,qBACA,cAEA,CAAS,GAGT,MAAqB,GAAI,GACzB,OAAY,UAAc,SAC1B,UACA,oBAAgC,GAEhC,qBAEA,0BACA,kBAEA,mBADA,cACA,GACA,cAEA,CAAS,GAGT,YAEA,aADA,QACA,GACA,MAJA,EAIA,MAEA,CAAK,EACL,EC7DM,GAAc,GAAoB,UACxC,IADiB,KACjB,MACA,OAAW,GAAgB,aAAiB,GAAW,YAAc,GACrE,CAIO,CALgD,KAKhD,GACP,OANgF,YAOhF,GACA,aACA,CACA,2BAA0C,EAC1C,MAAe,GAAG,iCAClB,EACA,QACA,uBACA,EAEA,CACA,gBAEA,CACA,wBAEA,CACA,iBACA,UACA,OAEA,MAAuB,GAA2B,GAClD,EAAoB,GAAG,gBAD2B,EAE3B,GAAmB,EAC1C,cAD0C,IAC1C,eACA,CACA,eACA,UACA,UAAsB,GAAa,aAEnC,IAFmC,EAEZ,GAA2B,GAClD,EAAoB,GAAG,gBAD2B,GAElD,CACA,qCACA,OAAmB,GAAiB,EACpC,CACA,SAGA,EALoC,CAKpC,4BACA,UAA0B,GAAa,YAEvC,KAFuC,EAEvC,CACA,CACA,CACA,CAIO,SACP,mBACA,GACA,aACA,CACA,qBAAuC,EACvC,YAA2B,GAAK,2BAChC,WACA,OACA,QACA,uBAGA,WAAkB,GAAa,YAC/B,CACA,IAF+B,GAE/B,sBAA4C,EAE5C,CACA,CCtEA,IAAM,GAAM,GAAM,IAAT,oCACT,IACA,qBACA,WACA,CACO,UACP,QACA,UACA,mBACA,UACA,QACA,eACA,YACA,WACA,6BAIA,MAA8B,EAC9B,gBACA,4CACQ,EAAe,oCACvB,mBAA6B,GAAM,CACnC,EADmC,UACnC,4CACS,EACT,6CACA,mCACA,+BACA,uCACA,wBAAkC,GAA6C,MAC/E,qBAA+B,GAA0C,KACzE,CACA,IAAS,EAHsE,CAGlD,GAC7B,cAD6B,SAF4C,GAIzE,CACA,IAAS,GAAiB,GAC1B,WAD0B,CAC1B,YAEA,YACA,oBAEA,QACA,eACA,CACA,OACA,uBACA,gCACA,eACA,CACA,0BAAyC,EACjC,GAAG,6BACX,wCACA,EAAuB,GAAS,6CACxB,EAAe,SACvB,MAAwB,KADD,CACM,CACJ,KACzB,CAD8B,GAC9B,yBACA,YACA,YAEA,IACA,gBAEA,iBAAmC,eAAe,uBAAuB,aAAe,GACxF,2CAEA,oBADA,CAAiC,SAAW,8BAAgC,YAE5E,kBAGA,UAA0B,GAAa,6BAEvC,kBAGA,UAA0B,GAAmB,8DAE7C,gBACA,UAA0B,GAAgB,gCAE1C,oCACA,0BAEA,YADA,iBACA,WACA,gBACA,UACA,SAEA,MAGA,mBAA6C,GAAO,GAAI,KAAL,CAAK,IACxD,gBACA,UACA,SAEA,CAEA,CACA,SACY,GAAG,gCACf,QACA,CACA,UACA,YACY,GAAG,8BACf,CACA,CACA,sBAAwC,EAChC,GAAG,yBACX,wCACA,EAAuB,GAAS,6CACxB,EAAe,SACvB,MAAwB,KADD,CACM,CACJ,KACzB,CAD8B,GAC9B,yBACA,YACA,YAEA,IACA,gBAEA,iBAAmC,eAAe,mBAAmB,qBAA0B,GAC/F,2CAEA,oBADA,CAAiC,SAAW,8BAAgC,YAE5E,kBAGA,UAA0B,GAAa,6BAEvC,kBAGA,UAA0B,GAAmB,8DAE7C,gBACA,UAA0B,GAAgB,gCAE1C,oCACA,0BAEA,YADA,iBACA,OACA,gBACA,UACA,SAEA,MAGA,mBAAyC,GAAO,GAAI,KAAL,CAAK,IACpD,YADoD,CACpD,GACA,UACA,SAEA,CAEA,CACA,SACY,GAAG,4BACf,QACA,CACA,UACA,YACY,GAAG,0BACf,CACA,CACA,oBAAyC,EACjC,GAAG,wBACX,wCACA,EAAuB,GAAS,6CACxB,EAAe,SACvB,MAAwB,KACxB,CAD6B,CACJ,KACzB,CAD8B,GAC9B,yBACA,YACA,YAGA,SAA4B,eAAe,kBAAkB,EAAU,EACvE,IACA,gBAEA,oBADA,CAAiC,SAAW,0CAA4C,YAGxF,GADY,GAAG,gCACf,eAGA,UAA0B,GAAa,6BAEvC,kBAGA,UAA0B,GAAmB,8DAE7C,gBACA,UAA0B,GAAgB,iCAE1C,4BACA,mCAIA,MAHA,iBACA,MAAsB,GAAc,GAAyB,OAA1B,IAA0B,KAE1C,GAAmB,EACtC,CACA,SAEA,IAJsC,EAG1B,GAAG,mCACf,CACA,QACA,CACA,UACA,YACY,GAAG,yBACf,CACA,CACA,sBAAiD,EACzC,GAAG,wBACX,wCACA,EAAuB,GAAS,6CACxB,EAAe,SACvB,MAAwB,KADD,CACM,CACJ,KACzB,CAD8B,GAC9B,yBACA,YACA,YAGA,SAA4B,eAAe,kBAAkB,EAAU,EACvE,IACA,gBACA,MAAyB,GAAiB,GAE1C,WAF0C,GAE1C,EADA,CAAiC,sBAA0B,kDAAoD,mBAG/G,GADY,GAAG,gCACf,eACA,UAA0B,GAAgB,8CAE1C,CACA,SAEA,MADY,GAAG,yCACf,CACA,QACA,CACA,UACA,YACY,GAAG,yBACf,CACA,CACA,MACA,IACA,SACA,eAAiD,KAAS,GAQ1D,KAR0D,EAC1D,mBACA,uBAEA,mBACA,mBACA,mBAEA,CACA,KACA,cACA,GAAoB,GAAgB,MACpC,OADoC,CAEpC,WACA,CACA,CACA,SACY,GAAG,kDACf,CACA,CACA,UAEA,oCACA,mDACA,SACA,oCAEA,CACA,wCACA,uDACA,SACA,wCAEA,CACA,CACA,CGlSA,IAAM,GAAc,GAAoB,UACxC,SADwC,GACtB,GAClB,GAFiB,IAEN,GAAgB,aAAiB,GAAW,YAAc,GACrE,CACA,SACA,mBACA,EAJgF,EAIhF,EAA8B,EAC9B,YAAsB,SF0Df,MAA6D,EACpE,WAAe,GAAsC,ME3DM,EF2DN,KACrD,EE5D2D,IAC3D,CACA,mBAEA,CACA,0BACA,MAAe,GAAG,iCAClB,EACA,QACA,mBACA,sBACA,EAEA,CACA,iBACA,IAAa,GAAS,GACtB,OAEA,MAAuB,GAA2B,GAClD,EAAoB,GAAG,EAJD,EAIC,YACvB,EAAuB,GAAmB,EAC1C,cAD0C,IAC1C,eACA,CACA,eACA,IAAa,GAAS,GACtB,UAAsB,GAAa,aADb,IACa,EAEZ,GAA2B,GAClD,EAAoB,GAAG,gBACvB,IACA,qCACA,OAAmB,GAAiB,EACpC,CACA,SAGA,EALoC,CAKpC,4BACA,UAA0B,GAAa,YAEvC,KAFuC,EAEvC,CACA,CACA,CACA,oBACA,YAA2B,GAAK,2BAChC,WACA,OACA,QACA,uBAGA,WAAkB,GAAa,YAC/B,CACA,IAF+B,GAE/B,qBAEA,CACA,CAIO,iBAEP,yBADA,GD3EA,CACA,IC0E2B,YD1E3B,gBC0EuD,eD1EvD,+BACA,mEACA,EC0EA,CC9EA,sBAEA,6BACA,mBAAsB,GAAK,QAAQ,GAAK,aACxC,GAEA,gGAAwG,EAAE,EAE1G,gBAA+B,IAAI,EAEnC;AACA;AACA,KAAK,GAAU,GAAG,EAAE,KAAK,GAAU;AACnC,KAAK,GAAU,GAAG,EAAE,KAAK,GAAG,IAAI,GAAU;AAC1C,KAAK,GAAU,GAAG,EAAE,MAAM,GAAG,OAAO,GAAU,EAAE,IAAI;AACpD,KAAK,GAAU,GAAG,EAAE,SAAS,GAAU,EAAE,IAAI,GAAG,GAAG,OAAO,GAAU,EAAE,IAAI;AAC1E,KAAK,GAAU,GAAG,EAAE,SAAS,GAAU,EAAE,IAAI,GAAG,GAAG,OAAO,GAAU,EAAE,IAAI;AAC1E,KAAK,GAAU,GAAG,EAAE,SAAS,GAAU,EAAE,IAAI,GAAG,GAAG,OAAO,GAAU,EAAE,IAAI;AAC1E,KAAK,GAAU,GAAG,EAAE,SAAS,GAAU,EAAE,IAAI,GAAG,GAAG,OAAO,GAAU,EAAE,IAAI;AAC1E,aAAa,GAAU,EAAE,IAAI,GAAG,GAAG,OAAO,GAAU,EAAE,IAAI;AAC1D,iBAAiB,GAAG;AACpB,sDAGA,iBAAmC,GAAG,SAAS,GAAG,KAClD,cAA+B,GAAG,IAClC,cAA+B,GAAG,IAE5B,GAAO,cACb,GACA,aAAoB,MAAiB,EAAE,GAAG,EAAE,MAAiB,OAAO,MAAiB,EAAE,GAAG,EAAE,MAAiB,QAE7G,GAAO,8BAAoE,MAAiB,EAAE,GAAG,EAAE,MAAiB,OACpH,GAAO,8BAAoE,MAAiB,EAAE,GAAG,EAAE,MAAiB,OEjCpH,IAAO,QAAQ,KAAE,iBCEjB,IACA,WACA,eACA,cACA,WACA,WACA,WACA,ECGO,SAAS,GAAO,aAAiB,GAAjB,CAA0B,CAAI,EACrD,IACA,MAAS,SHbe,CAAe,GACvC,sBAOA,OALA,gCACA,yBAA4B,sBAAgC,GAC5D,eACA,CAAE,EAEF,EACA,EGIwB,IAAO,CDHhB,eAA0C,EACzD,GDTgB,ECSV,QAAQ,UDTN,GAAQ,KCSF,GACd,ODVgB,SCUhB,8BAGA,6BACA,6CACA,SAEA,mCAMA,OAJA,yCACA,YACA,YAEA,EACA,ECb0C,oBAAuB,EAAQ,GACzE,CAAG,SAKH,OACA,CACA,CChBA,QACA,WACA,EAUO,SAAS,GAAM,SACtB,WAfA,EAeA,GAIQ,GLYO,GKZQ,IAAK,CAAL,KAAK,GAAY,OACxC,CCgBA,QACA,UACA,YACA,QACA,SACA,EACA,+BCzCO,IAEP,iCAEA,uBACA,OAYA,GACA,qBACA,IAAyB,EACzB,uCAZA,YAEA,OADA,eACA,CACA,GAAY,GAAc,GAAG,OAAJ,CAAI,CAJS,KAImC,GAAQ,OAAQ,GAAoB,IAA5B,EACjF,YACY,CAFiG,QD0CtG,KCxCmB,GAF6C,CD4CvE,GADA,SACA,uBACA,QAAY,qBAAyB,SAarC,GACA,oBAEA,gBACA,iCAGA,aAAU,qBAA2B,WACrC,oBACA,MAgDA,YACA,gCAGA,cApDA,EACA,UACA,MAGA,sBAEA,QAEA,CACA,OAAa,2BACb,EAjCqC,GAWrC,OAAW,GALX,KAJA,KASoB,IAuBpB,KACA,oBAGA,GDxEA,CCwEQ,CAAM,EDxEd,OAxBA,ECgGc,GDpEN,GAAQ,GAAO,IAAK,CAAL,KAAK,GAAY,ECoE1B,EDpE0B,ICqExC,gBAEA,GAAQ,GAAM,GACd,MADc,CACd,SAIA,eACA,gCACA,GAAY,GAAM,GAClB,MADkB,CAClB,SAIA,YACA,EApDA,KAsDA,MArDA,GAqDA,KArDA,EAsDA,OAEA,QAxDA,EAyDA,OAzDA,EAyDA,CAEA,OA3DA,EA2DA,CAEA,YACA,gCAGA,WAhEA,GACA,CAEA,eAEA,8BACA,UAEA,ECvD0B,GAC1B,EAEA,EAIA,GACA,CACA,0BACA,iEACA,KACA,0CACA,CAAS,CACT,CACA,CAIO,gBAAqC,EAC5C,gBACA,CCvCO,eACP,sEAEO,wBACP,SACA,eACA,OACA,SAGA,mCACA,qBACA,qBAEA,CAAK,GACL,kCACA,eACA,CAAK,GACL,kCACA,oBACA,oBAEA,CAAK,EACL,CACO,wBACP,SACA,eACA,OACA,SAGA,mCACA,oBACA,oBAEA,CAAK,GACL,kCACA,cACA,CAAK,GACL,kCACA,mBACA,mBAEA,CAAK,EACL,CCvCO,uBACP,KACA,mBACA,KACA,SACA,YAEA,aACA,CACA,CCbO,eACP,OACQ,EAAU,EAClB,MADkB,EAElB,QACA,EAEA,iBACA,aACA,EAEA,EAEA,CACA,EACA,CCVO,eACP,OACA,mBACA,uBACA,uBACA,uBACA,uBACA,uBACA,8CACA,EACA,YACA,KAAsB,CAAU,SAChC,GAEA,wCACA,EACA,YACA,KAAsB,CAAU,SAChC,kBAnBO,GAoBP,kCAA0D,GAAkB,iBAG5E,CACA,CCFO,kBAAwC,EAC/C,UAA0B,GAAM,CAChC,EADgC,UAChC,oBAlBO,CAmBP,CAAK,EACL,mBAAoC,IACpC,0BACA,gBACQ,GAAQ,qBAEhB,gBAAwC,CAAU,IAClD,CAAS,EACT,mBAAiC,GAAmB,aAAgB,GAAhB,IAAgB,EAAc,GAElF,4BACA,qBAAuC,EAAI,GAAG,EAAa,GAC3D,SACA,6BACA,CAAiB,CACjB,gBACA,CAAa,EACb,kBACA,uCAA2D,UAAY,IAAI,aAAe,GAE1F,MAA6B,GAAa,gBAE1C,OADA,mBAAqC,GAAmB,uBAAmB,EAAkB,GAC7F,CACA,CAAS,EACT,gBACS,EACT,WACA,wCAEA,QACA,CACA,gBErDA,UACA,gBACA,GACA,SAAmB,GAAO,EAC1B,CACA,CAF0B,GAE1B,KACA,SACA,KACA,gBACA,2BACA,iBACA,KACA,KACA,CACA,YACA,CACA,KACA,OAAmB,GAAa,SAAG,CAAH,CAAY,CAE5C,CACA,gBACA,SAAuB,gBAAqB,GAAG,EAAK,EACpD,kBACA,YACA,QACA,UACA,sBAEA,cAAwB,UAAgB,KACxC,KACA,mCACA,KAAsB,CAAU,SAChC,CAAa,EAMb,OALA,cACA,mBAIA,CACA,CACA,SAEA,SACA,SAAuB,gBAAqB,GAAG,OAAY,EAC3D,sBACA,QACA,2BHjDO,EGiD2C,CAAW,KAC7D,OACA,CAAS,EACT,iBACA,CACA,YACA,SAAuB,gBAAqB,GAAG,EAAK,EACpD,kBACA,CACA,QACA,gBACA,CACA,CC7DO,MAAM,GACb,IADgB,KAChB,CACA,kBACA,GACA,kBACA,WD6DA,EC7DqB,ED6DrB,GC7D0B,aAN1B,KAOA,8BAA2C,oBAC3C,kBACA,QAGA,iBACA,MAAyB,EAAI,IAE7B,mBACA,CAAS,EAET,2BACA,qBFrBA,CACQ,CEoB0B,EFpBV,aEoByB,2BFnBzC,GAAgB,8BACxB,CEoBA,CASA,kBAAoC,EACpC,MAAsB,GAAQ,SAC9B,2CACA,WAEA,OADA,mBAAqC,GAAmB,aAAgB,GAAhB,IAAgB,EAAgB,GACxF,EAEA,SAAuB,mBAAwB,GAC/C,oDACA,uBAEA,KACA,gBAEA,0BACA,MAEA,IACA,iBACA,KACA,OACA,CAAiB,EACjB,sBACA,oBAEA,QACA,CACA,SACA,UACA,mBAAyC,GAAmB,aAAgB,GAAhB,IAAgB,EAAa,EACzF,CACA,CACA,gBACA,UAEA,yCAA0D,GAAQ,EAAE,GAAO,QAC3E,CACA,CC2BO,gBAAsB,EAC7B,WAAe,GAAQ,EACvB,EAZA,YACA,aACA,qBACA,kBACA,mBACA,CAAC,UAAgC,ECpDjC,OAVA,YACA,GAHA,CAGQ,EASO,GATQ,CAHvB,CAYoB,EAAC,KAZrB,UAGuB,GAHvB,EAIA,iBACA,sBACA,EAAS,GAGT,IAJ8C,IAI9C,QAEA,ECrCA,4BADA,KAEA,eAiBO,GACP,iBAKA,KACA,sBACA,UAAwB,GAAoB,QAE5C,WAF4C,KAE5C,WACA,iBAGA,2DAQA,GANA,SACA,OAEA,GACA,aAEA,4CACA,0BAEA,CAOA,mBACA,OAAe,GAAkB,YACjC,CAMA,EAPiC,UAOjC,CACA,iBAOA,0BACA,aAAsB,gBAAgB,GActC,yBACA,qBAnFA,KAoFA,CAYA,gBACA,oDACA,CAIA,uBACA,4CAEA,UAEA,gCAEA,uBAEA,IACA,CAMA,QAIA,GAHA,6CACA,eAEA,mBACA,6CACA,eACA,mBACA,WACA,CAEA,qEACA,kCAEA,CAOA,QACA,kBACA,WACA,YAAwB,WAAkB,KAC1C,gBACA,SAEA,WACA,OACA,OACA,SAEA,OACA,QAEA,CACA,yBAaA,UACA,uDACA,CAMA,aACA,kBACA,CAWA,gBACA,wBACA,qBAaA,OACA,6BA7MA,KA6MA,QACA,CAYA,OACA,gBAqJA,GACA,0BACA,WACA,GAEA,uBACA,EA3JA,qBACA,CAYA,OACA,gBAoJA,GACA,mBACA,oBACA,EAvJA,qBACA,CAaA,YACA,oCACA,CAYA,OACA,+BAKA,OAJA,WAvQA,MAwQA,IAxQA,GAwQA,EAGA,OADA,eAEA,CAYA,SACA,6BAEA,GADA,aA1RA,IA6RA,mBA7RA,KA8RA,CAaA,eACA,sBACA,EA7SA,MA+SA,aACA,KAEA,uCACA,CAaA,uBACA,gCAGA,wCACA,CAaA,wBACA,gCAGA,wCACA,CAMA,aACA,6BACA,CAOA,aACA,kDAkCA,aAlCA,2BACA,CACA,CE1WA,aAAoB,mCAA0C,EAAI,EAClE,kBAAa,6BACb,CAqFO,SACP,IACA,MACA,MACA,oBACA,KAAkB,kBAAmB,EACrC,gCACA,wCAEA,YACA,aACA,aACA,kBAEA,8BACA,SACA,WACA,WACA,YACA,CAAS,CACT,CACA,QACA,iBAjFA,OACA,oCACA,OAEA,MAAgB,GAAG,SAInB,eAHA,SACA,uBAEA,oBACA,qBACA,UAnCA,KACA,gCACA,oBACA,4BACA,eACA,EAA4B,GAAG,QAC/B,SACA,qBAEA,oBACA,cAEA,KAEA,CACA,MAAwB,GAAG,QAC3B,SACA,qBAGA,YAEA,EAEA,EAWA,IACA,CACA,EAqEA,cACA,CACA,OACA,iBAzDA,OACA,+BAGA,kCACA,cACA,mBACA,sDAA6F,OAAG,YAChG,iBAtBA,KACA,oBACA,4BACA,qBACA,YACA,oBAAmD,MAAH,GAAG,UACnD,cAEA,MAGA,YAEA,EASA,KAEA,CACA,EA8CA,cACA,CACA,WACA,OAhDA,cACA,QACA,4BAEA,SADA,SAEA,yCAAyD,0BAAyC,kBAAqB,aAAa,GAEpI,MAAoB,GAAG,SACvB,WACA,OAAqB,yCAErB,CACA,OAAa,QACb,EAmCA,wCACA,CACA,CAuCO,mBAAwB,wBAAsC,EAErE,iBACA,EACA,aACA,cACA,iFACA,eACA,MACA,QACA,OACA,CAAK,CACL,CCjKA,eACA,oBAGA,eAIA,OAHA,eACA,aAEA,IAAe,GAAG,GAAI,GAAqB,EAAE,WANlB,IAMmD,EAC9E,CACO,SACP,SACA,YACA,qBACA,OACA,iBACA,kBACA,eACA,CACA,iBAAgC,EAChC,YACA,+BACA,8BAEA,+BACA,OACA,wDAGA,UAA0B,GAAK,CAC/B,CAD+B,WA1B/B,CA4BA,CAAS,EACT,gCACA,KACA,OACA,CAAS,EACT,mBAEmE,MAAnE,mBAAmD,GAAgB,cAGnE,aACA,yBACA,IACa,GACb,QAEA,OACA,QACA,uBACA,CACA,4BAAyC,GAAY,KACrD,CAIA,IALqD,GAKrD,UACA,gBACA,OAEA,kCAEA,EAAsB,GAAY,CAAG,MADrC,EACkC,IADlC,yBACqC,cAAmB,EAGxD,oBAFA,QAEA,WACA,2BACA,aACA,KACA,eACA,CAAiB,EAGjB,CAIA,gBACA,UAA6B,GAAG,GAAI,GAAuB,EAAE,6BAA+C,GAC5G,GACA,WACA,aAEA,IACA,EAA0B,GAAY,8BACtC,CACA,SACA,4BACA,OAEA,CAEA,GADA,MAIA,mBACA,6BACA,+BACA,MACA,CAEA,2BAA2C,GAAY,MACvD,IADuD,QACvD,OAAiC,GAAmB,oBACpD,CACA,gBAA+B,EAC/B,YAEA,EAAoB,GADpB,UACgC,CADhC,mBAEA,kCAEA,UAA0B,GAAK,CAC/B,CAD+B,WA3G/B,CA6GA,CAAS,EACT,gCACA,KACA,cACS,EACT,oBACA,aACA,gCAAwE,GAAgB,YACxF,IACa,CACb,KACA,cACa,EACb,OAEA,CACA,cAA0B,EAC1B,kBAA2B,WAAa,wBACxC,0BAAqE,eAAqB,IAAQ,EAAF,EAAE,CAClG,CAAS,KACT,MAAwB,GAAG,gCAAoC,IAC/D,EADqE,GACjC,EACpC,OACA,CAFoC,GAEpC,EACA,KAEA,CACA,CACA,qBAAoC,EACpC,UAA6B,GAAG,GAAI,GAAuB,EAAE,6BAA+C,GAC5G,8BACA,CACA,eACA,YAEA,OAAe,GADf,8BAEA,CACA,yBACA,YAEA,EAAoB,GADpB,8BAEA,kBACA,2BAAyC,GAAY,KACrD,CACA,CChKO,GD8J8C,GC9J9C,WAAwB,GAC/B,EADoC,EACpC,GACA,yBACA,CACA,QACA,0BACA,2BAEA,CACA,CCmEA,OAnCA,eACA,GAkCe,CAlCf,KACA,CAiCqB,GAjCrB,WAJA,+BAMA,iBAGA,oBAEA,YACA,eACA,OAEA,CAAS,GAET,kBACA,MAAuB,GAAQ,CAC/B,IAD+B,OAC/B,EACA,CAAS,EACT,iCACA,IACA,kCACA,qBACA,SAEA,CAAiB,GACjB,OACA,CACA,SACA,QACA,CACA,CAAS,EACT,OACA,CAAK,EACL,CC1EO,UACP,IACA,QACA,sCACA,KACA,gDACA,2BACA,4DARA,CASA,CACA,cACA,MAAc,KAAK,cACnB,CACA,aACA,MAAc,IAAI,eAClB,CAKA,2BAA0C,EAC1C,2BACA,UAAsB,EAAuB,gCAM7C,UAA0B,GAAS,CACnC,KADmC,OACnC,+BACS,EAET,mBADA,iCAAiD,EAChB,GAAK,oDACtC,+BAGA,YAIA,4BAEA,sBACA,SAEA,gBACA,IACA,kCACA,2BACA,YAEA,QACA,CACA,SAEA,OADA,+DACA,IACA,CACA,CAAiB,EACjB,YACA,gBACiB,EACjB,UACA,8DACA,CAAiB,CACjB,CACA,QAEA,CAKA,oBAAmC,EACnC,2BACA,UAAsB,EAAuB,+BAE7C,8CACA,cACA,oBACA,CAAS,EACT,CAIA,iBACA,yCACA,cACA,kBACA,CAAS,EACT,CAKA,eACA,0CACA,aACA,YAEA,CAIA,oBACA,2BACA,UAAsB,EAAuB,6BAE7C,WAUA,mBATuB,MAAK,4BAC5B,0BACA,IACA,2BACA,CACA,SACA,cACA,CACA,EAAS,KAET,WAGA,QAEA,WAAkB,GAAa,iCAC/B,CAIA,6BAA4C,EAC5C,2BACA,UAAsB,EAAuB,6BAE7C,mBAAiC,MAAK,mCACtC,gCACA,SAGA,SAEA,CACA,CACA,iBACA,8BACA,CCnJA,UACA,OACA,iCACA,+BACA,CAAK,EACL,cACA,sCACA,+BACA,CAAS,CAET,EACA,4BACA,aACA,WAEA,aACA,EACA,+BACA,aAGA,aACA,iBACA,EACA,iCACA,aAGA,wBACA,EC7BO,kCACA,8BACA,4BACA,+BACA,+BACA,6BCLA,WACP,sCCEA,gBACA,QACA,mBACA,OAEA,OACA,iBACA,iBACA,4BACA,EACA,oCACA,MACA,YACA,kBAEA,eACA,OACA,YACA,wBACqB,EAErB,sBACA,UACA,iBACA,OAEA,OACA,iBACA,iBACA,6BAEA,2CACA,mCACA,IAEA,EACA,+BACA,CAAqB,CACrB,CACA,CACA,CAAS,EACT,EAEA,cACA,UACA,MAAmB,KAMnB,CANyB,MACzB,wBACA,OACA,aACA,MACA,CAAS,EACT,gBACA,UACA,iBACA,OAEA,OACA,iBACA,6BAEA,gCACA,4CAEA,OAEA,wBACA,OACA,aACA,MACA,CAAyB,CACzB,CAAqB,EAErB,EACA,wCACA,CAAS,CACT,EAEA,IACA,gBACA,EACA,GAAe,IAGf,GAFA,kBAA8B,OAC9B,qCACA,CACA,sBAGA,OAFQ,GAAQ,OH1DS,EAAC,OG0DV,kCAAiF,GAA0B,GAA0B,KAC7I,GAAQ,UADyG,GAA0B,CAAwB,EAC3J,mCAAkF,GAA2B,GAA2B,KACxJ,CACA,CACA,OACA,KAJ2H,GAA2B,CAAyB,CAI/K,EACA,iBAAwD,GAA0B,GAAwB,IAC1G,cADgF,CAAwB,CACxG,EAAyD,EADyE,CAC9C,GAAyB,GAC7G,CACA,CAAC,CCgBD,CDhBE,ECgBF,GAEA,ODpBkF,CAAyB,KAA2B,ECoBtI,YACA,EACA,sBACA,GACA,CAAK,EAUL,OATA,eAA+B,GAAQ,WACvC,sBACA,OACA,GACA,CAAa,CACb,CAAS,CACT,EAAK,IACL,uBACK,GACL,CACA,CACA,mBAQA,EAPA,mBACA,OACA,yBACA,0BACA,EAEA,UAA4B,GAAM,CAAG,EAAH,UAAG,EAAgB,EAErD,OACA,iBAEA,WACA,eAOA,MAJA,MAA4B,GAAM,CAClC,EADkC,UAClC,cACA,YACA,CAAa,EAGb,UAeA,OAdA,gBAGA,UAIA,iBACA,UACA,OACA,QAEA,CAAiB,CACjB,CAAa,EACb,CACA,CAAS,CACT,oBAIA,OACA,QAEA,CACA,EACM,GAAc,CACpB,YACA,EAFoB,UAEpB,IACA,cACA,gBACA,CCjLO,UACP,KACA,MACA,KACA,oBAIA,QAA8C,EAC9C,aACA,YACA,UDuKe,YACf,CCxKiC,GDwKjC,kBAAiC,CAAE,GAAc,GAwBjD,OAvBA,KADiD,CACjD,GAEA,KADA,GAAyB,GAAI,IAC7B,IAD6B,IAC7B,GAEA,yCACA,uBAGA,2BACA,4CAAkF,IAAY,EAC9F,CAAa,EACb,gDACA,uBAGA,4BACA,4CAAkF,IAAY,EAC9F,CAAa,GAGb,kBACA,0BAEA,UACA,ECjMiC,CACjC,2BACS,EACT,eACA,CACA,YACA,oBAEA,cACA,MAAc,GAAK,YACnB,eACA,CACA,aACA,MAAc,GAAI,YAClB,eACA,CACA,SACA,kBAKA,kBAAsC,EACtC,4BACA,iCACA,IACA,kCACA,QACA,CACA,GACA,CACA,CAIA,qBAAuC,EACvC,4BACA,iCACA,IACA,6BACA,QACA,CACA,GACA,CACA,CAIA,gBAA+B,EAC/B,4BACA,iCACA,IACA,gCACA,QACA,CACA,GACA,CACA,CAIA,qBAAqC,EACrC,4BACA,iCACA,IACA,6BACA,QACA,CACA,GACA,CACA,CAIA,mBAAkC,EAClC,4BACA,kCACA,IACA,+BACA,6BAEA,6BACA,QACA,CACA,GACA,CACA,CAIA,wBAAwC,EACxC,4BACA,kCACA,IACA,iBACA,wCACA,sBACA,4BACA,6BAEA,QACA,CACA,CAAa,KACb,QACA,CACA,GACA,CACA,CACA,gBAA+B,EAC/B,4BACA,iCACA,IACA,gCACA,QACA,CACA,GACA,CACA,CACA,kBAA8B,EAC9B,4BACA,iCACA,IACA,0BACA,QACA,CACA,GACA,CACA,CACA,mBAEA,OADA,4BACA,6BACA,CACA,CCnJA,WAA2B,GAAG,YAEvB,qBACP,qBACA,eAA4C,GAAoB,GAAI,GACpE,MACA,CAIA,MANoF,CAKpF,SADgB,GADhB,eACkC,EAClC,IAGA,+EAEA,CCIO,sBACP,yBACA,iCAGA,CACA,CAyDA,QACA,WACA,cACA,OAlDA,YACA,iCACA,YAEA,MAAc,GAAG,SAGjB,MACA,YAEA,2CAEA,OADA,iBACA,CACA,IAAQ,GAAY,GAAU,IA9C9B,CA8CmB,EAAW,CAC9B,IAAQ,GAAY,GAAU,SAC9B,EAoCA,UA1BA,WACA,wFACA,EAyBA,OAfA,YACA,mBACA,mFAEA,qBACA,wGAEA,WACA,CAQA,CACA,EAEO,IACP,MACA,cACA,kBACA,CACA,EAaA,IACA,mBACA,yBACA,YACA,iBACA,eAEA,UACA,WACA,0BAEA,SAEA,QAxHA,GAwHA,CApBA,YACA,YACA,0CAAkD,wBAElD,OAAS,GAAG,qBACZ,EAiBO,QACP,MACA,oBACA,EAEa,GAAI,WACJ,GAAI,IAOJ,CAPI,EAOE,GAAa,GAAY,MAO/B,GAAM,CAPA,EAOa,GAAY,SCvI5C,CDuI4C,MCvI5C,iBACA,cACA,QAEA,oBAMA,UACA,kDACA,IACA,SAA0B,GAAI,QAC9B,aACA,KAAqC,CAArC,UACA,cAGA,SAA0B,GAAI,MAC9B,CAD8B,CAC9B,WACA,KAAqC,CAArC,WACA,gBACA,GAD2C,GAC3C,OAEA,eAKA,CAMA,CAAG,GAAI,iBACP,eACA,sBACA,KACA,YAAoB,WAAe,IACnC,qBAEA,SACA,CAMA,CAAG,GAAI,mBAEP,KAAS,GAAI,gBACb,CAMA,CAAG,GAAI,kBACP,eAAuB,GAAe,CAAE,WAAF,iBAAE,EACxC,CAMA,CAAG,GAAI,mBACP,eAIA,MAAiB,GAAU,yBAC3B,mBAAgC,GAAK,KACrC,CAMA,CAAG,GAAI,kBACP,eACA,uBAA4B,KAAM,GAAI,iBAAqB,EAC3D,YACA,CAMA,CAAG,GAAI,gBACP,eACA,uBAA4B,KAAM,GAAI,eAAmB,EACzD,aACA,CAMA,CAAG,GAAI,CAPkB,EAOlB,cAMP,CAAG,GAAI,kBACP,0BACA,6BACA,MACA,YAA4B,GAAI,MAChC,CADgC,CAChC,gBACU,YAAyB,GAAI,IACvC,GADuC,GACvC,aAA+B,MAG/B,kCAAsD,0BAEtD,MACA,CAEA,+BAAyC,yBACzC,CACA,oBACA,eAAyB,GAAe,CAAE,WAAF,gBAAE,GAI1C,GADA,eACA,sBACA,0BACA,MACA,CAAM,0BACN,6BACA,MACA,CAAM,yBACN,0BACA,MACA,CAGA,sBACA,KACA,KACA,YAAoB,WAAe,IACnC,qBACA,iCAAuE,EAAvE,EACA,OAGA,IACA,EADe,IACf,KACA,YAEA,SACA,CACA,CAoIA,IAAM,GAAoB,CAAK,uBAAL,IAAoC,CAnB9D,SAAS,CAAS,IAClB,WADkB,KAClB,4BACA,eAAuB,GAAe,CAAE,WAAF,uBAAE,GAExC,WACA,OACA,YAAyB,GAAI,iBAA8B,GAAI,OAC/D,eAAuB,GAAe,CAAE,WAAF,0BAAE,GAExC,OACA,UAEA,OACA,QAGA,gBAAqB,GAAe,CAAE,WAAF,yCAAE,EACtC,CAE8D,EAO9D,SAAS,GAAM,KAEf,OADA,GADe,MACf,SAA4B,CAAE,GAAoB,GACzC,GAAY,WACrB,CCvSA,MDqSkD,GChSlD,kBAAiC,EACjC,YACA,YACA,eAEA,yBACA,iBACA,CAEA,MACA,iBAMA,OACA,mCAMA,KACA,2BACA,CAKA,cACA,+CAGA,iBACA,gBAEA,oCACA,yBAOA,UACA,uCACA,eAAyB,GAAe,CAAE,WAAF,yBAAE,EAAsC,UAAU,GAE1F,YAAoB,WAAgB,IACpC,iCACA,eAA2B,GAAe,CAAE,WAAF,kBAAE,EAA+B,UAAU,sBAAsB,0BAA4B,GAGvI,CAEA,cACA,gBACA,KACA,KAKA,MACA,oBACA,gBACA,iBACA,iBAEA,KAEA,CACA,EAOA,GAJA,MAA4B,GAA5B,QACA,KACA,aAEA,gBAEA,CAF4B,EAC5B,YACA,MAA8B,GAA9B,MAIA,WAAmB,GAAM,GAAI,mBAH7B,aACA,IAIA,CAEA,GADA,mCACA,mBACA,eAAyB,GAAe,CAAE,WAAF,kBAAE,EAA+B,UAAU,GAEnF,iCACA,CAD4C,EAC5C,EACA,eAA2B,GAAe,CAAE,WAAF,kBAAE,EAA+B,UAAU,GAErF,KACA,YACA,kCACA,CACA,qCAAmE,EAAnE,QACA,KACA,YACA,gDACA,GADoE,CACpE,QAEA,oCAGA,sEACA,uBACA,EACA,IAAiB,GAAM,GAAI,qBAE3B,uDACA,IAAiB,GAAK,KAAY,GAAZ,IAAgB,CAAQ,EAAR,CAAY,sBAElD,IAAe,GAAK,KAAY,GAAZ,IAAgB,CAAQ,EAAR,CAAY,6BAChD,CAKA,cAEA,SAA4B,GAA5B,MAEA,eAAyB,GAAe,CAAE,WAAF,sBAAE,EAAmC,YAAY,uBAEzF,aAIA,wBAAmC,4BAAqC,SACxE,mBACA,wBACA,GAD+C,GAG/C,WAEA,CAFuB,GAEvB,kEAEA,OADA,cACA,IAAmB,GAAM,GAAI,KAAL,CAAK,KAC7B,CACA,CAEA,gBACA,KAEA,OACA,iCACA,eAA2B,GAAe,CAAE,WAAF,2CAAE,EAAwD,UAAU,GAE9G,QACA,YAAsB,IAAO,KAC7B,gBACA,gBACA,GADoC,QAE1B,iBACV,GAD4C,CAC5C,WACU,gBACV,GAD2C,CAC3C,WAEA,eAA6B,GAAe,CAAE,WAAF,qCAAE,EAAkD,UAAU,GAE1G,SACA,WACA,CACA,QACA,EAGA,WAUA,QATA,gBACA,OAEA,4BAEA,gCACA,eAA2B,GAAe,CAAE,WAAF,6BAAE,EAA0C,UAAU,GAKhG,UAGA,OACA,OACA,MAEA,KACA,QAEA,KADA,0BACA,QAEA,CADA,kBACA,KACA,MAGA,KACA,QACA,yBACA,yBACA,4BAGA,CAFA,6BAEA,0BACA,MAGA,KACA,QACA,yBACA,yBACA,yBACA,0CACA,yCACA,kBACA,KAGA,CAGA,UAGA,QACA,KACQ,UAER,SACA,0BACA,gBAGA,UACA,YACA,EAIA,wBAEA,EADA,gBAEA,UACA,QAEA,GADA,YACA,YACA,eAA+B,GAAe,CAAE,WAAF,+BAAE,EAA4C,UAAU,GAItG,OAFA,YACA,YACA,GACA,QACA,QACA,QACA,QACA,UACA,KACA,SACA,UACA,KACA,UACA,UACA,KACA,UACA,WACA,KACA,UACA,WACA,KACA,UACA,WACA,KACA,UACA,YACA,KACA,SACA,eAAiC,GAAe,CAAE,WAAF,oCAAE,EAAiD,UAAU,EAC7G,CACA,KACA,SAEA,OADA,YACA,IAAqB,GAAM,GAAI,KAAL,CAAK,IAA8B,eAC7D,GAD6D,MAE7D,QACA,GADyB,GACzB,SAA+B,GAAe,CAAE,WAAF,2BAAE,EAAwC,UAAU,EACtF,QACZ,UACA,aAEA,GAEA,CACA,CAEA,eAAuB,GAAe,CAAE,WAAF,0BAAE,EAAuC,UAAU,EACzF,CAKA,aACA,kBACA,SAGA,MAHqB,CACrB,iCACA,YACA,IAAmB,GAAM,GAAI,KAAL,EAAK,GAC7B,SAGA,OAFA,mCACA,YACA,IAAmB,GAAM,GAAI,KAAL,CAAK,MAC7B,SACA,GADiB,IACjB,kBAEA,UAEA,OADA,+BACA,IAAmB,GAAM,GAAI,YAC7B,UAEA,OADA,kCACA,IAAmB,GAAM,GAAI,KAAL,CAAK,KAC7B,UAEA,OADA,+BACA,IAAmB,GAAM,GAAI,KAAL,CAAK,IAC7B,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,yBACA,SACA,eAA2B,GAAe,CAAE,WAAF,sBAAE,EAAmC,UAAU,EACzF,CACA,CAKA,OAEA,OADA,sBACA,oBACA,YAEA,OADA,qBACA,iBACA,mBAEA,GADA,qBACA,MAAgC,GAAhC,MAGA,OAFA,YACA,sBACA,IAAqB,GAAM,GAAI,KAAL,CAAK,UAE/B,SAAgC,GAAhC,MACA,eAA6B,GAAe,CAAE,WAAF,sBAAE,EAAmC,UAAU,6CAA6C,+BAA+B,IAKvK,OAHA,YACA,mCACA,sBACA,iBAEA,mBAEA,GADA,qBACA,MAAgC,GAAhC,MAGA,OAFA,YACA,sBACA,IAAqB,GAAM,GAAI,gBAI/B,OAFA,mCACA,sBACA,iBAGA,eACA,UAAiC,GAAjC,EAAsC,CAAtC,GAIA,OAHA,qBACA,YACA,sBACA,IAAqB,GAAM,GAAI,gBAE/B,SAAgC,GAAhC,MACA,eAA6B,GAAe,CAAE,WAAF,sBAAE,EAAmC,UAAU,8CAA8C,+BAA+B,GAExK,aACA,qBACA,kBAEA,CAF0B,EAC1B,qBACA,OAAiC,GAAjC,EAAsC,CAAtC,GAGA,OAFA,YACA,sBACA,IAAqB,GAAM,GAAI,KAAL,CAAK,UAE/B,yBAEA,GADA,sBACA,MAAgC,GAAhC,MACA,eAA6B,GAAe,CAAE,WAAF,sBAAE,EAAmC,UAAU,qDAAqD,+BAA+B,IAI/K,OAFA,YACA,iCACA,CACA,CACA,gBAIA,OAHA,qBACA,+BACA,sBACA,iBAGA,SACA,eAA2B,GAAe,CAAE,WAAF,wBAAE,EAAqC,YAAY,uBAC7F,CACA,CACA,CE7WA,eACA,MAAsB,GAAM,mBAC5B,OACA,IAAQ,GAAM,GAAI,KAAL,EAAK,IAClB,IAAQ,GAAM,GAAI,KAAL,CAAK,QAClB,IAAQ,GAAM,GAAI,KAAL,EAAK,IAClB,IAAQ,GAAM,GAAI,KAAL,CAAK,YAClB,IAAQ,GAAM,GAAI,KAAL,CAAK,aAClB,IAAQ,GAAM,GAAI,KAAL,CAAK,UAClB,IAAQ,GAAM,GAAI,KAAL,CAAK,UAClB,CAUA,eACA,6DACA,CAyCA,IAAM,GAAa,CACnB,aADmB,CAEnB,OA7FA,CA6FY,QA7FH,CAAU,EACnB,WADmB,EACnB,oBACA,YAEA,MAAc,GAAG,SAGjB,MACA,YAEA,mBAEA,OACA,IAAQ,GAAM,GAAI,KAAL,EAAK,IAClB,IAAQ,GAAM,GAAI,KAAL,CAAK,QAClB,IAAQ,GAAM,GAAI,KAAL,CAAK,aAClB,IAAQ,GAAM,GAAI,gBAClB,EA6EA,UACA,cACA,aACA,eACA,cACA,eACA,cACA,gBACA,gBACA,qBACA,iBACA,kBACA,YACA,YAjDA,YACA,4BACA,EAgDA,UAvCA,CAuCe,QAvCN,EACT,UAsC+B,EAtC/B,MADyB,sEAEzB,EAsCA,OA5BA,CA4BY,QA5BH,CAAa,EACtB,MA2ByB,IA3BzB,IADsB,CACtB,IACA,mFAEA,qBACA,wGAEA,WACA,CAqBA,CACA,CAKA,kBAA+B,GAK/B,MALkD,MAKlD,KACA,WAEA,oBAMA,OACA,gDACA,CAKA,eACA,0BAEA,uBAEA,YACA,CAOA,OACA,mBAEA,YAAuB,GAAI,KAC3B,EAD2B,EAC3B,eACA,YAA4B,GAAI,uBAChC,mBACA,YAAgC,GAAI,QAEpC,CAF+C,EAC/C,aACA,OAAkC,GAAI,MACtC,CADsC,KACtC,kCAGA,OADA,yBACA,IAAqB,GAAM,GAAI,KAAL,EAAK,EAC/B,CACA,YAAgC,GAAI,KACpC,EADoC,EACpC,eACA,YAAqC,GAAI,2BACzC,mBACA,YAAyC,GAAI,QAC7C,CADwD,GACxD,QAA8B,IAAO,IAErC,GADA,aACA,OAAwC,GAAI,MAC5C,CAD4C,KAC5C,oCAGA,MAA4B,GAAM,WAAY,QAAsB,GACpE,WAAyB,GAAM,GAAI,KAAL,CAAK,iBACnC,CACA,wBACA,CACA,wBACA,CACA,wBACA,CACA,wBACA,CACA,QACA,CACA,CAEA,IAAM,GAAa,CACnB,aADmB,GACnB,GACA,kBACA,YACA,iBACA,eAEA,UACA,WACA,0BAEA,SAKA,GAAa,SAAY,GAAG,EAAf,EAAe,EAErB,IAAM,GAAI,WACJ,GADI,IAQJ,GAAM,GAAa,GAAgB,CAP/B,CAOsC,IAO1C,GAAM,CAPA,GAQnB,EARgD,EAQhD,EAlPA,MAiPmB,GAjPA,KAkPK,KAjPxB,IADmB,SACnB,YACA,iCAGA,CACA,EA4OwB,GAExB,gBAAgC,GAAa,CAAI,aAAJ,CAAI,KAAqC,GAAa,CAAG,EACtG,OF4KA,IE7KmG,KF6K1F,CAAM,IAEf,IE9KyB,GF6KzB,MADe,GACf,QAA4B,sBAAyC,IAC5D,GAAO,IAChB,EE/KyB,IF8KT,EEtKH,GAAM,aAAgC,GAAM,IAEzD,YAFyD,OAS5C,GAAK,GAAa,GAAb,GAAmB,WACrC,EADqC,CACrC,gBClSM,GAAW,gBAejB,EAfiB,OAeR,GAAY,KACrB,QAEA,MAHqB,EAGrB,KAAwB,MAExB,SACA,yCAGA,eACA,gDAGA,aAEA,GADA,gCACA,MACA,KAEA,CACA,YAQA,qBACA,CACG,OAAoB,GAAY,KACnC,UAGA,IAJmC,CAInC,OACA,wCAGA,cACA,gDAGA,yBACA,CAOA,iBACA,MAGA,MAFG,MAAgB,GAAY,KAE/B,aCpEA,CDkE+B,GClEzB,GAAW,gBA4IjB,EA5IiB,OA4IjB,UAEA,MADA,SAGA,QA9IA,YA+IA,iBACA,OAGA,aACA,iBACA,OAKA,OAFA,OAEA,CACA,CAQA,mBAaA,MACA,EAVA,OAHA,QACA,IAEA,cAUA,GADA,EATA,IAxKA,cAoLA,eApLA,aAqLA,MAEA,WACA,QACA,OAEA,SACA,OACA,MArBA,CAuBA,QAvBA,MACA,CA0BA,QACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,gCACA,CCpMA,oBACA,2BAEM,GAAW,gBAOjB,iBACA,SACA,SAGA,aAAwB,GAAW,kBACnC,SAAwB,GAAW,kBAEnC,WACA,WAEA,4BAAwC,IAAS,IACjD,gBACA,OACA,OACA,KACA,CAGA,qBACA,CAOA,iBACA,6CACA,CAQA,eACA,6BACA,MAAiB,GAAG,SACpB,MACA,uCAEA,YAAa,EACb,CAEA,wCACA,uCAGA,SAEA,WACA,MAAc,GAAG,cACjB,IACA,KACA,wBACA,EAAgB,GAAG,cACT,8BACV,GAAgB,GAAG,gBAGnB,CAAM,MAAuB,GAC7B,SADwB,KAAK,EAC7B,wBAAkD,UAAU,EAC5D,CAEA,GACA,UAEA,CAEA,WACA,uCAWA,MARA,yBACA,gBAGA,0BACA,kBAGA,CACA,CAMO,eAKP,GAJA,+CACA,IAAa,SAGb,qCACA,uCAIA,SAEA,oBACA,2BACA,OAAiB,GAAW,oBACtB,gCACN,mBAEA,uCAIA,qBACA,0BACA,wBACA,sBAEA,4CAGA,WAGA,QACA,CAKO,SAAS,GAAQ,GAcxB,OAdwB,UAcxB,8EACA,uCAGA,aACA,+DAGA,oDACA,4DAGA,2BACA,8DAGA,YAAkB,iBAAuB,KACzC,iBAEA,+FACA,kDAGA,aACA,uEAGA,mBACA,+DAIA,0DACA,iEAGA,4CACA,oEAGA,qBACA,0CACA,uEAEA,aACA,sEAEA,CAEA,gCACA,2EAEA,CACA,CAOO,oBACP,WAAmB,eAA0B,CAC7C,CAQO,mBACP,WAAkB,sBAAoC,CACtD,CC9NO,IAAM,GAAI,SACJ,GADI,IAOV,QANU,CAMD,GAAM,GACpB,GAAQ,GAEV,KAHsB,CAGtB,CAFU,EAsBV,OAnBA,SACA,yBACA,SAUA,OATA,QACA,sBAEA,iBACA,gBAEA,kBACA,kBAEA,CACA,EAAK,EAEL,QACA,gBFaO,UEVY,EFWnB,eAuDA,GACA,QAEA,WACA,oBACA,YACA,CAEA,WACA,sBACA,eApCA,GACA,QAEA,WACA,oBACA,YACA,CAEA,4BACA,MAAc,GAAW,sBACzB,YACA,CAMA,MAJA,0BACA,mBAGA,CACA,EAkBA,GACA,YACA,CAGA,QACA,EAvEA,GACA,oBACA,IASA,GAPA,SACA,iBACA,gBACA,0BACA,SAGA,QACA,2BAA4C,KAAY,KACxD,MApDA,cACA,eAEA,6BACA,aACA,wCAEA,kCACA,4CAEA,oBACA,OACA,CAEA,4BACA,MAAsB,GAAW,eACjC,GADiC,EACjC,OACA,WACA,qBACA,OACA,CASA,OAPA,SACA,iBACA,gBACA,0BACA,SAGA,UACA,EAsBA,4BACA,KACA,cACA,OACA,CAGA,QACA,EEhCmB,EACnB,CAMO,SAAS,GAAM,GAEtB,MHiFO,KGnFe,IHmFf,OAIP,EAGA,EANA,eACA,IAGA,KAIA,WACA,QAGA,GAFK,gBAEL,MACA,oEAA8E,EAAS,GAGvF,UACA,KACA,wDAGA,eACA,GACA,MAEA,EAAM,kBAMN,EALA,KACA,iBAD6B,yCAErB,GACR,OAGO,cACP,gBAnGA,GAEA,SACA,WACA,IAEA,WACA,QAGA,GAFK,gBAEL,OACA,UACA,yDAEA,SACA,kDAA8D,EAAS,aAEvE,mBACA,wEAEA,oBACA,wEAGA,mBACA,EAAM,kBAWN,EAVA,mBACA,yDAEA,SACA,kDAA8D,EAAS,aAEvE,oBACA,wEAIO,eACP,OAAkB,GAAW,SAC7B,EAAM,cACN,oBACA,0DAEA,SACA,kDAA8D,EAAS,aAGvE,aAA4B,GAAY,IACxC,EAAM,IACN,SAFwC,GAExC,mEAAyF,EAAS,EAElG,CAGA,OACA,yDAGA,QACA,EAwCA,GACA,EAAM,IACN,4EAAsF,EAAS,EAE/F,CAGA,OACA,yDAIA,SAKA,OAJA,GACA,WAEA,cACA,CACA,EE0DA,yBACA,eCjMwB,EDiMxB,gBCjMwB,GAGxB,KAyBA,OAvBA,QACA,gBAGA,SACA,yBACA,SACA,IACA,OAAoB,GAAG,cACvB,CAAQ,UACR,WACA,8DAQA,OANA,iBACA,gBAEA,kBACA,kBAEA,CACA,EAAK,EAGL,CACA,CCvFO,SAAS,GAAS,GACzB,cADyB,EACzB,IACA,CGFO,uBACP,qCACA,uBACA,aACA,yBACA,iBACA,QACA,CACA,CACO,uBACP,sCACA,uBACA,cACA,yBACA,kBACA,QACA,CACA,CACO,uBACP,oCACA,sBACA,aACA,yBACA,gBACA,QACA,CACA,CACO,uBACP,oCACA,sBACA,aACA,yBACA,gBACA,QACA,CACA,CACO,uBACP,uCACA,wBACA,aACA,0BACA,mBACA,QACA,CACA,CACO,uBACP,4BACA,8BACA,aACA,yBACA,gBACA,QACA,CACA,CACO,MAAM,WAAa,MAC1B,mCACA,qBACA,KAAW,GAAa,KACxB,KAAW,GAAa,QADA,SAExB,IADwB,SACxB,EACA,QACA,CACA,CACO,MAAM,WAAU,MACvB,gCACA,mBACA,KAAW,GAAU,KACrB,KAAW,GAAU,CADA,GACA,aACrB,aACA,QACA,CACA,CEvEO,MAAM,GACb,SACA,OAF2B,QAE3B,wCACA,CACA,WACA,uDACA,CACA,oBACA,cAA2B,eAAa,IACxC,sBACA,OAEA,CACA,SACA,uDACA,CACA,oBACA,qBACA,MACA,MACA,yBACA,CAEA,CACA,YACA,0DACA,CACA,uBACA,qBACA,uBACA,OAEA,CAIA,iBACA,yCACA,CACA,CCnCO,iBAAiC,GACxC,gBADsD,EAEtD,GACA,QACA,YACA,CACA,gBACA,sBAGA,GAHmC,GAGnC,WAFA,EAKA,OANiD,GAMjD,SACA,CACA,OACA,wBACA,IADmC,GACnC,mBAEA,CAHiD,EAGjD,iBACA,UAAsB,GAEtB,qBAFmC,CAEnC,EACA,CACA,cACA,sBAGA,GAHmC,GAGnC,YAGA,QANiD,EAMjD,OACA,CACA,UACA,eAGA,GAHyB,GAGzB,WACA,SAJuC,EAIvC,gBAEA,CACA,iBACA,iBACA,qBAEA,EACA,CACA,CCkCA,OA3CA,cACA,KA0Ce,CA1Cf,EACA,GAJA,CAIQ,CAyCc,IAzCC,CAJvB,uBAKA,KADuB,EACvB,kBACA,qBACA,gBACA,SAGA,CAAS,GAGT,MAAqB,GAAI,GACzB,OAAY,OADa,CACb,EAAc,SAC1B,UACA,oBAAgC,GAEhC,qBAEA,0BACA,kBAIA,mBAHA,SACA,UAEA,GACA,gBACA,SAGA,CAAS,GAGT,YAIA,aAHA,QACA,UAEA,GALA,EAMA,QACA,SAGA,CAAK,EACL,ECxCA,SAAS,GAAS,GAClB,OADkB,GAClB,UACA,CA0CA,OAzCA,cACA,QACA,GAPA,CAOQ,CAuCc,EAAC,EA9CvB,wBAQA,MADuB,CACvB,kBACA,sBACA,eACoB,GAAS,IAC7B,MAD6B,EAG7B,OACA,CACA,CAAS,GAGT,MAAqB,GAAI,GACzB,OAAY,UAAc,SAC1B,UACA,oBAAgC,GAEhC,qBACA,2BACA,kBAEA,mBADA,QACA,IACA,eACoB,GAAS,IAC7B,MAD6B,EAG7B,OACA,CACA,CAAS,GAGT,YAEA,aADA,QACA,GACA,SACA,OAEA,CAAK,EACL,CC/EA,UACA,MACA,UACA,IACA,OACA,uBAIA,GACA,0DACA,qBACA,kBACA,eAAyB,GAAkB,cAC3C,CAD2C,GAC3C,uBAKA,kBAAsC,SACtC,2BACA,mBAAqC,GAAmB,2BACxD,IAEA,mBAAiC,GAAmB,kCACpD,kFACA,mBAAiC,GAAmB,gCACpD,sBACA,CAIA,qBAAuC,EAQvC,MAA2B,GAPG,GAAM,SAAkB,IAOpB,CAPoB,CAAlB,IACpC,gCAIA,OAHA,GACA,mBAAyC,GAAmB,gCAE5D,EACA,CAAS,EACyB,WAAyB,UAAY,IACvE,mBAAqC,GAAmB,uCACxD,iFACA,CAAS,CACT,oBAAiC,GAAmB,wCACpD,6BACA,CAIA,gBAA+B,EAC/B,+CACA,4CAEA,oBAAqC,GAAmB,+BACxD,iDACA,KACA,aACa,EAMb,OALA,mBAAqC,GAAmB,gCACxD,4BAEA,mBAAqC,GAAmB,kCACxD,kFACA,CACA,CAEA,OADA,mBAAiC,GAAmB,gCACpD,mBACA,CAIA,qBAAqC,EACrC,mBAAiC,GAAmB,wCACpD,yBAAkC,GAAO,YACzC,+CACA,4CAEA,oBAAyC,GAAmB,oCAC5D,iDACA,KACA,aACiB,CACjB,oBAAyC,GAAmB,qCAC5D,4BAEA,mBAAyC,GAAmB,uCAC5D,iFACA,CACA,CAAS,EACT,CAIA,mBAAkC,EAClC,mBAAiC,GAAmB,sCACpD,4BACA,CAIA,wBAAwC,EACxC,mBAAiC,GAAmB,8CACpD,8CACA,qBACA,OAEA,CAAS,KACT,CACA,gBAA+B,EAC/B,0BACA,CACA,kBAA8B,EAC9B,mBAAiC,GAAmB,uCACpD,0BACA,CACA,CAKO,oBACP,oBAIA,GACA,SACA,eACA,CACA,YACA,oBAEA,cACA,MAAc,GAAK,4CACnB,eACA,CACA,aACA,MAAc,GAAI,4CAClB,eACA,CACA,SACA,kBAEA,mBACA,0CACA,sBACA,EAEA,oBAEA,eACA,sBACA,eACA,yBACA,mBACS,EACT,MACA,CAAS,CACT,CACA,CAIA,oBACA,eACA,kBACA,SAIA,yCACQ,EAAe,iCACvB,wDAA2E,OAAU,EACrF,CACA,QACA,4BACA,CAIA,kBAAsC,EACtC,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,IAEvB,eACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CAIA,qBAAuC,EACvC,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,EAEvB,YACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CAIA,gBAA+B,EAC/B,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,IAEvB,aACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CAIA,qBAAqC,EACrC,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,EAEvB,YACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CAIA,mBAAkC,EAClC,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,EAEvB,WACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CAIA,wBAAwC,EACxC,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,EAEvB,eACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CACA,gBAA+B,EAC/B,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,IAEvB,aACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CACA,kBAA8B,EAC9B,MAAuB,GAAS,wCACxB,EAAe,OACvB,IACA,SAFuB,EAEvB,SACA,KACA,QACA,CAAa,CACb,QACA,CACA,SACA,CACA,CACA,CAIO,eACP,WACA,UAAkB,GAAsB,6CAA8C,8BAAgC,iIAEtH,iBAGA,kBAOA,IAAa,GAAgB,CANjB,GAAS,GACrB,GAK6B,GAL7B,EAGA,GAE6B,GANR,GAMQ,qBAE7B,UAAsB,GAAqB,mEAE3C,CACA,EAKA,2BACA,cACA,sBACA,EAAmB,GAAS,qBACxB,EAAe,gBACnB,IADmB,EACnB,GACA,eAhCA,+BAkCA,UAGA,IACA,2BACA,cACA,IACA,SACA,sBACA,KACA,SACA,qBACA,WACA,IACA,CACA,CAAiB,EAMjB,OALA,GAGA,WAEA,CACA,CACA,SAEA,MADA,4DACA,CACA,CACA,CAAS,EACT,QACA,CAGA,UACA,SACA,CACA,CC3VO,SACP,WACA,UACA,IACA,QACA,QACA,SACA,SACA,KACA,QACA,gBACA,GACA,sBlIkGA,CACA,CkInGqC,YlImGrC,CkInGkD,ElIoGlD,KAEA,EkIrGA,2CACA,eR1CO,iBACP,OACA,CAAS,GAAM,MAAQ,GACvB,CAAS,GAAM,GADA,CACA,EAAQ,GACvB,CAAS,EAFoB,CAEZ,GADF,CACE,EAAQ,EACzB,EAIA,EAN6B,EACZ,GAEjB,MAFiC,GAEjC,KACA,WACA,CAAK,EACL,UACA,WACA,qBACA,UAOA,IALA,EADgB,GAAS,GACzB,QAGA,GAEA,GANyB,CAMzB,GACA,CACA,WACA,QAEA,WAAkB,EAAyB,6CAA8C,eAAkB,gIAC3G,CACA,EQgBkC,wBAClC,cTvCO,QSuCyB,CTvCzB,QACP,OACA,CAAS,GAAU,CAAG,EACtB,CAAS,GAAQ,CAAG,EACpB,CAAS,CAFU,EAEE,CAAG,EACxB,CAAS,CADY,EACA,CAAG,EACxB,CAAS,EAHc,CAGL,EAClB,EAIA,GANqB,IAGrB,IAJ+B,KAI/B,CAFyB,CADM,GAI/B,WACA,CAAK,EACL,UACA,WACA,qBACA,UAOA,IALA,EADgB,GAAS,GACzB,QAGA,GAEA,GANyB,CAMzB,GACA,CACA,WACA,QAEA,WAAkB,EAAiB,4BAA6B,EAAK,EACrE,CACA,ESWgC,sBAChC,gBAA+B,GAAG,EAClC,uBAEA,OACA,wBACA,sBACA,mBACA,gBACA,yBACA,uBACA,aACA,qBACA,mBAAqC,CAErC,4BAAgD,GAAY,GAC5D,CAD4D,OAC5D,4BAEA,OACA,EACA,CASA,OAP+C,MAA/C,EAA2B,GAAoB,EAC/C,SAAwC,GAAoB,EAGhB,CAJG,KAI/C,EAA2B,GAAiB,EAC5C,SAAwC,GAAiB,EAEzD,CACA,CAAa,EACb,QAJyD,kBAIzD,4BACS,EACT,UAAqC,GAAgB,EACrD,WADqD,IAC7B,GAAQ,6BAChC,oBAA8B,GAAY,aAC1C,2BACA,CAAS,EACT,2BACA,qCACA,KAEA,CACA,cACA,MAAc,GAA+B,gBAC7C,MAAc,GAAK,GAD0B,CAC1B,wCACnB,CACA,aACA,MAAc,GAAI,4CAClB,CACA,aAAyB,EACzB,6CACA,IACA,WACA,2BACA,qBACA,MAAkB,GAAK,+BACvB,kBAAmC,GAAM,aACzC,IACA,8BACA,QAEA,SACA,mBAAiD,GAAmB,sBACpE,CACA,SACA,iCACA,mBAAiD,GAAmB,oBACpE,CAEA,CAAa,IACb,QACA,CACA,GACA,CACA,uBACA,CACA,CCtHO,iBAA+B,GACtC,gBADoD,EAEpD,CACA,QACA,iBACA,CACA,SAEA,OADA,cAAsB,GAAM,6BAC5B,CACA,CACA,OACA,oBAAkC,GAAM,2BACxC,WACA,UAAsB,GAEtB,QACA,CACA,OACA,KALmC,EAKnC,cAA6B,GAAM,0BACnC,CACA,gBACA,iBAAyB,GAAM,0BAC/B,CACA,gBACA,mCACA,MACA,IAAqB,GAAG,SAAU,GAAU,GAAc,EAAhB,CAAsB,OAAP,KACzD,OACA,CAEA,CACA,CE9BY,GAAM,0BG4ClB,OAhBA,SAAS,CAAG,EACZ,GAHA,CAEY,KAFZ,IAkBmB,KAlBnB,eAIA,EADuB,IACvB,WACA,SACA,qBACA,UAEA,QACA,EAAS,GAET,SACA,eACA,UAEA,QACA,ECQA,GAZA,iBAYe,IAdf,EAcoB,EAXZ,EAHR,wBAIA,MADuB,YAEvB,YAA8B,GAAG,EACjC,UADiC,GACjC,GACA,CAAS,GAET,YACA,MAAoB,GAAG,EACvB,UADuB,GACvB,GACA,CAAK,EACL,ECUA,GA9BA,iBA8Be,IA7Bf,EA6BoB,EA7BZ,EAAe,CAHvB,uBAIA,MADuB,YAEvB,QACA,UAGA,sBAGA,GAFA,QAEA,QACA,MAEA,CACA,CAAS,GAET,YACA,QACA,UAGA,gBAGA,GAFA,QAEA,QACA,MAEA,CACA,CAAK,EACL,CC9DO,UACP,WACA,uDACA,CACA,SACA,uDACA,CACA,SACA,uDACA,CACA,YACA,0DACA,CACA,qBAAuC,EACvC,kBAA2B,WAAa,IACxC,sBACA,OAEA,CACA,qBAAuC,EACvC,qBACA,MACA,MACA,yBACA,CAEA,CACA,wBAA0C,EAC1C,qBACA,uBACA,OAEA,CACA,QACA,SACA,KACA,OACA,SACA,YAA4B,UAAY,CACxC,CAAa,CACb,UACA,SACA,CAAa,CACb,iBACA,MAAsB,GAAK,mBAC3B,KACA,MAAsB,GAAK,sBAC3B,KAEA,CACA,CAKA,iBACA,uCACA,CAKA,qBACA,2CACA,CACA,WACA,qBACA,mBACA,eACA,EAAiB,GAAM,oCACvB,CAOA,GANA,0BACA,2BAA6C,GAAM,SAEnD,MAFmD,OAEnD,YACA,0BAA4C,GAAI,SAEhD,IAFgD,EAEhD,UACA,QACA,WACA,EAAiB,GAAM,aACvB,CAIA,CALuB,MAEvB,eACA,GAAiB,GAAI,YAErB,CAFqB,CAIrB,eACA,yBACA,mBACA,eACA,EAAiB,GAAM,gCACvB,CAOA,GANA,0BACA,2BAA6C,GAAM,SAEnD,yBACA,0BAA4C,GAAI,SAEhD,IAFgD,EAEhD,UACA,eACA,IACA,EAAiB,GAAM,aACvB,CAIA,CALuB,MAEvB,eACA,GAAiB,GAAI,YAErB,CAFqB,CAIrB,CC9GO,iBAA8B,GACrC,UADkD,QAElD,CACA,QACA,iBACA,CACA,SAEA,OADA,8BACA,CACA,CACA,OACA,kCACA,WACA,UAAsB,GAEtB,QACA,CACA,OACA,KALmC,EAKnC,2BACA,CACA,UACA,8BACA,CACA,QACA,mCACA,MAAoB,QAAS,GAAG,WAEhC,CACA,YACA,8BACA,UAAsB,GAAG,EAEzB,CACA,CClCO,oBACP,WACA,8BAGA,UACA,QACA,oBAGA,UAAkC,GAAe,IACjD,QACA,OACA,CACA,SAJiD,GAIjD,GAOA,GANA,YAEA,mBACA,mCAGA,WAEA,YAAwB,aAAoB,IAC5C,UACA,gBAIA,eACA,CACO,gBACP,MACA,iBACA,eAEA,QACA,EACM,GAAe,GACrB,0BADqB,CACrB,KAEA,MACA,2BAEA,MACA,SAGA,6BAEA,MACA,IACA,gBACA,sBASA,EARA,MAA2B,GAAQ,CACnC,IADmC,OACnC,EACA,CAAa,EACb,YACA,OACA,CAAa,KACb,QACA,CAAa,EAEb,eACA,GAAgB,GAAe,GAC/B,oBACA,MAF+B,EAG/B,OACA,OAEA,SACA,cACA,QACA,OACA,OAGA,8EAEA,OAAmB,GAAK,MACxB,CACA,OAFwB,EAExB,QO3BO,sBAAwC,EAC/C,uBAA4C,GAC5C,YAD2D,EAC3D,MAA8C,GAC9C,MAAsB,GAAU,CAChC,CADgC,EAD8B,CAE9D,CACA,YACA,aACA,8BACY,KACZ,CACA,UAF4B,OAE5B,GACY,GAAoB,8BACpB,KACZ,CACK,EAIL,MAHA,IAH8B,CAG9B,SACA,gBAEA,CACA,CLtEA,IAAqB,GAAG,CAAC,WAAW,GEAlB,yCIHX,IAAM,GAAW,CACxB,YACA,UAFwB,OAGxB,GACA,EAgBO,SAAS,GAAY,KAC5B,aACA,sCAEA,MAAY,SAAa,IAEzB,OADA,OAAoC,SAAa,EAAxB,IAAwB,EACjD,CACA,CCNA,QAEA,IAAuC,GAAoB,SAAL,GAAjC,EAAsC,eAK3D,CALuC,IAKC,GAAoB,SAAL,CAAK,EAAtC,EAAsC,qCAC5D,KAA4C,GAAoB,SAAL,GAArC,CAA0C,aAChE,IAAuC,GAAoB,CADf,MACe,EAAL,CAAK,EAAtC,EAAsC,gBAApB,EAAoB,6DAC3D,EAEA,IACA,kEACA,uCAAuE,IACvE,QADsF,GAA9B,CACxD,CAD2F,EAC3F,SAGA,EAJuE,EAIvE,QAAoB,WAAgB,KACpC,WAEA,YADA,qEAEA,OAEA,aACA,mBACA,YAAwB,WAAgB,KACxC,WAEA,YADA,qEAEA,OAEA,SACA,CACA,QACA,CACA,CACA,SACA,CAAG,CACH,WACA,sBAAsD,IACtD,QADqE,GAA9B,CACvC,CAD0E,EAC1E,OACA,IAFsD,GAItD,wBAEA,IACA,IACA,YAAoB,WAAoB,KACxC,cACA,UACA,YACA,CACA,uDACA,cACA,OAEA,iBACA,UAEA,KACA,YAAgC,IAAO,IACvC,mBAGA,SACA,CACA,CACA,KACA,eACA,CACA,IACA,mBACA,cACA,OAEA,iBACA,UAEA,KACA,YAAgC,IAAO,IACvC,mBAGA,WACA,CACA,CACA,KACA,SACA,MACA,CACA,CAEA,UAGA,QACA,CACA,EAEA,IACA,kEACA,uCAAuE,IACvE,QADsF,GAA9B,CACxD,CAD2F,EAC3F,SAGA,EAJuE,EAIvE,QAAoB,WAAgB,KACpC,WAEA,YADA,qEAEA,OAEA,aACA,mBACA,YAAwB,WAAgB,KACxC,WAEA,YADA,qEAEA,OAEA,SACA,CACA,QACA,CACA,CACA,SACA,CAAG,CACH,WACA,sBAAsD,IACtD,QADqE,GAA9B,CACvC,CAD0E,EAC1E,OACA,IAFsD,GAItD,wBAEA,IACA,IACA,YAAoB,WAAoB,KACxC,cACA,UACA,YACA,CACA,oDACA,cACA,OAEA,iBACA,UAEA,KACA,YAAgC,IAAO,IACvC,mBAGA,SACA,CACA,CACA,KACA,eACA,CACA,IACA,gBACA,cACA,OAEA,iBACA,UAEA,KACA,YAAgC,IAAO,IACvC,mBAGA,WACA,CACA,CACA,KACA,SACA,MACA,CACA,CACA,UAGA,QACA,CACA,EAEa,GAAqB,CAClC,iCACA,CAFkC,gBAElC,0BK1LO,eAAe,GAAU,KAChC,MAAiB,GAAY,CADG,KACH,aAC7B,KAD6B,EAC7B,EACA,gDAGA,MAAgB,GADhB,uBAEA,GAA2B,SAArB,GAAqB,WAC3B,wBAD2B,iBAG3B,2DACA,oCAA4C,UAAc,EAAE,yBAA4C,EAAc,MAAQ,GAE9H,kBAEA,2BACA,yCAEA,QACA,CAEA,oBACA,yCAEA,MNRO,SAAS,CAAc,EAC9B,iBMOiC,ENPjC,OAD8B,CAC9B,4BACA,IAYA,MAXA,CACA,UAEA,iBACA,qBACA,wBACA,CACA,2CACA,yCACA,2CACA,CAEA,EMPiC,gBN1CJ,GM0C0C,KAGvE,OAFA,gBADuE,GACvE,QAEA,cADA,MAAyB,GAAU,KACnC,EACA,CAMA,OARmC,QAQpB,GAAO,GACtB,SADsB,GACtB,gBACA,UAAmB,GAAW,iBAA0B,GAAW,GAArC,GAAqC,EAGnE,MAAsB,GADtB,MAFmE,EAEnE,EACmC,KADnC,SAEA,OAAW,GAAG,SAAW,GAAW,SACpC,CAEA,MAAkB,GAAY,IAHM,EAGN,aAC9B,KAD8B,EAC9B,EACA,uCAA+C,EAAQ,IAEvD,MAAgB,GAAY,mBAE5B,EAAoB,GADpB,UACiC,KADjC,CNLO,SAAS,CAAkB,EAKhC,SAAa,IACf,MAA2C,EMDY,CNCZ,MAAa,EANtB,IAMsB,CACxD,EAAiB,IADe,KACF,GADU,QACV,CAAgB,SAAa,SAI3D,OAFA,EAD6C,SAAa,OAC1D,CAGA,EMPuD,sBAEvD,OAAS,GAAG,aACZ,CAYO,eAAe,GAAa,GAGnC,YACA,EAAe,CAJoB,EAIR,mBAC3B,KAD2B,EAC3B,EACA,iDAEA,WACA,YAAoB,GAAO,GAC3B,SAD2B,EAC3B,SAEA,WAAW,yBACX,CAMA,qBACA,QAAU,iBAAmB,MAAQ,GAAa,GAElD,OAAW,MADX,EADkD,IAClD,gBACW,MACX,CAMA,qBACA,YACA,KAAU,0BAA2B,MAAQ,GAAa,GAC1D,OAAkB,QADwC,CACxC,4CAElB,OADA,sBACA,CACA,CAWO,SAAS,GAAa,GAC7B,eAD6B,EAE7B,YAAyB,GAAU,GACnC,YADmC,IACnC,MA+K2B,QAC3B,EA/KA,yBA8K2B,EA7KD,EA6KC,EA7KD,aA8K1B,IA9KA,EAiLA,CACA,cACA,WAnL0B,CAmL1B,UAIA,OAHA,cACA,sBAEA,CACA,CAAK,CAEL,sBACA,2BACA,gBACA,sCAKA,OAHA,GACA,OAEA,CACA,CAAK,CAEL,QACA,KACA,SACA,CAAK,CAEL,UACA,YACA,CACA,CA5MA,CACA,QACA,EAAG,GAEH,OACA,aAEA,gBAEA,IADA,QACA,4BACA,iBAEA,CAAK,CAEL,qBAEA,IADA,QACA,4BACA,iBAEA,CACA,CACA,CASO,SAAS,GAAW,GAC3B,QAGA,KAJ2B,CAI3B,CACA,cACA,uCAIA,sBACA,gBACA,sCAEA,wBAIA,OAHA,GACA,OAEA,CACA,CAAK,CAEL,QACA,IACA,CAAK,CAEL,UACA,QACA,CACA,CACA,CAyFO,SAAS,GAAmB,GACnC,qBADmC,OACnC,IAUA,gBA1FO,GACP,QACA,IACA,IACA,oBAEA,QAAyC,IACzC,QADiC,EACjC,GACA,GAFyC,CAEzC,kBACA,WACA,gBACA,WACA,KAIA,KAGA,GAHsB,KAGtB,IACA,uBAGA,UAEA,YAEA,gDACA,QACA,eACA,WACA,YAEA,GACA,EAGA,OACA,eACA,cACA,WAEA,wCAGA,sBAIA,GAHA,cACA,WAEA,aACA,sCAEA,wBAKA,OAJA,IACA,KACA,MAEA,CACA,CAAK,CAEL,QACA,KACA,IACA,CAAK,CAEL,UACA,QACA,CACA,CACA,EAaA,iBACA,4BACA,OACA,KAEA,SAIA,CFpSqB,KC8LrB,IAAM,GAAM,GAAI,CD9LqB,EC8LrB,EAAL,EAAK,IACV,GAAM,GAAI,KAAL,CAAK,YAChB,IAAM,GAAM,GAAI,QAChB,IAAM,GAAM,GAAI,KAAL,CAAK,UAGhB,IAAoB,GAAM,GAAI,KAAL,EAAK,OEjKvB,GAMP,mBACA,gBACA,cACA,gBACA,CAEA,cACA,qBAaA,iBACA,mBAMA,yBACA,sBAcA,0BACA,8BACA,qDAEA,UAAiC,GAAW,GAC5C,CAcA,YAf4C,CAe5C,gBACA,kDACA,6DAEA,UAAiC,GAAmB,GACpD,CACA,CAOA,qBACA,MAAkB,GAAa,GAC/B,SAAU,MADqB,EACrB,GAAiB,iBAE3B,kCACA,CC/GO,SAMP,mBACA,gBACA,cACA,iBACA,gBACA,CAEA,cACA,qBAMA,iBACA,mBAEA,CA8BO,oBAgBP,yBACA,iBACA,4CAGA,mBACA,wCAGA,OADA,iBACA,sCACA,CAcA,0BACA,YAAY,sBAA2B,MAAQ,GAAS,GACxD,YADwD,EACxD,MACA,CAcA,6BACA,YAAY,sBAA2B,YACvC,oBACA,CACA,CA8BO,oBAgBP,yBACA,iBACA,4CAGA,mBACA,uCAEA,kBACA,6CACA,OACA,aACA,4BACA,OACA,EAEA,CAAiB,0BACjB,CACA,CACA,CAcA,0BACA,YAAY,sBAA2B,MAAQ,GAAS,GACxD,YADwD,EACxD,MACA,CAeA,6BACA,YAAY,sBAA2B,YACvC,oBACA,CACA,CAMA,eAAe,GAAS,GACxB,YADwB,MACxB,YACA,qDAEA,UAAwB,GAAW,GACnC,CAMA,YAPmC,GAOnC,MACA,kDACA,6DAEA,UAAwB,GAAmB,GAC3C,CAOA,oBAR2C,CAS3C,MAAkB,GAAa,GAC/B,SAAU,MADqB,EACrB,GAAiB,iBAC3B,eAAW,8BACX,CExPO,eACP,MAAsB,GAAa,CAAG,QATtC,EASsC,KAAH,CAAG,EAAgC,EACtE,EAAsB,SAAa,WACnC,oCAGA,OAFA,WACA,kBACA,CACA,CCpBA,SAAS,KAAI,CC4CN,SAKP,MDjDa,MCiDb,KACA,gBAEA,0BACA,cACA,CAaA,aACA,4CACA,iCAA2C,YAAY,UAEvD,eACA,8BAEA,MAAgB,GAAG,aACnB,MACA,iCAA2C,YAAY,UAGvD,OADA,+DAAoE,gBAAyB,GAC7F,YAaA,cACA,eACA,8BAIA,OAFA,kBACA,eACA,qBACA,CAOA,UACA,8BACA,CAaA,iBACA,WAkGA,GACA,cACA,SAGA,sBACA,MAAgB,GAAG,SACnB,MACA,kEAEA,UAGA,SACA,gBACA,MAAkB,GAAG,SACrB,MACA,kEAEA,SACA,CACA,QACA,EAxHA,GACA,YAAY,cAAoB,KAGhC,OAAa,OAFb,YAEa,IADb,SACa,CACb,CAgBA,wBACA,YAAY,cAAoB,KAIhC,OAHA,iCAGA,CAAa,OAFb,aAEa,IADb,SACa,CACb,CAyBA,qCACA,MAAmB,GAAW,EAC9B,OAAU,GAAU,GACpB,CAF8B,GAE9B,EAAsB,GAAY,GADd,GAEpB,GADkC,IAClC,kBACA,2FAAqG,OAAY,uBAAuB,UAAkB,SAG1J,OADA,WACA,CACA,CACA,CAMO,SAIP,eACA,gBACA,CAEA,yBACA,mBACA,+CAGA,OADA,mBACA,eAEA,CAEA,cAGA,WAAU,cADG,SD3MG,EAEhB,SAEA,GCuM4B,IDtM5B,EAAwB,GACxB,KAEA,OACA,EAAwB,GAExB,CAN4B,CAM5B,KACA,GACA,QAJ4B,OAI5B,IACA,OACA,OACA,EAA4B,GAC5B,GACA,CACA,EAAO,EAEP,GA2BA,GAEA,IAlCgC,EAkChC,OACA,uBACA,GACA,cACA,IAEA,CAAiB,kBAGjB,GACA,IACA,CAAiB,wBAGjB,GACA,mBACA,OACA,OACA,EAA8B,GAC9B,YAEA,EAAS,EAGT,EANkC,CAQlC,EAEA,OAAW,OAnDX,CAKA,SACA,UACA,UAEA,OADA,IACA,CACA,CAAK,CAEL,YACA,KACA,UACA,IACA,OACA,CACA,EAiCW,WACX,IC+HA,OAAW,SFjLX,kBACA,WACA,OE8K+B,EF9K/B,QACA,CAAK,CAML,oBACA,QAAc,WAAa,CAC3B,8BAAwC,SAAa,4BACrD,uBACA,UAEA,gBAEA,CAAK,CAKL,cACA,MEyJ+B,EFzJ/B,KACA,CAAK,CAKL,YA3DA,GE+MW,WACX,CEvJA,SACA,uBACA,KACA,iBACA,CACA,kBACA,MAAc,GAAK,mCAAoC,GAAG,iBAAqB,UAAY,SAAQ,WAAmB,KACtH,CACA,oBACA,MAAyB,KACzB,CAD8B,CAC9B,uBAEA,MAA0B,GAAM,CAChC,EADgC,UAbA,CAcP,CAChB,EAQT,aAPA,cAFmD,GAGnD,WACA,CAAS,EACT,iBACA,UACA,WACA,CAAS,EACT,GACA,gBACA,+BAEA,8CAGA,uCACA,aAAuC,cAAY,EACnD,CAAiB,GACjB,CAAa,EACb,YAAgC,EAGhC,IACA,eACA,QACA,CACA,eACA,CACA,CACA,mBACA,WAAgB,SAAc,GAAW,UAKzC,mBAFA,mBACA,YAA4B,EAC5B,GACA,OAEA,CAKA,kBACA,6CACA,4CAIA,oBAHA,aACsB,GAAY,OAAG,EAAH,IAAG,UAAmB,EAExD,SACA,gBACA,sBACA,CAAa,CAEb,CACA,CEhIA,IAAM,GAAM,GAAM,CAAT,EAAS,KAClB,YAGA,IACA,gBACA,MALA,QAMA,EACO,CAPgC,cAOhC,iBAEP,UAA+B,GAAQ,sBACvC,EAAyB,EAAS,iBAClC,sBACA,mCACA,CAOA,qCAQA,EAPA,YACA,MAAwB,GAAoB,GAC5C,EtGsKO,YACP,EsGxK4C,CtGwK5C,SACA,eA+CA,GACA,GAHA,mBAGA,GAHA,MAIA,iBAGA,IACA,OAAe,GAAG,QAClB,CACA,MAEA,CACA,OAAW,GAAG,QACd,EA3DA,GAEA,kBA3LA,MA6LA,OACA,SAAgC,WAAa,IAAQ,EAErD,SAA4B,oBAAsB,EAElD,GAiCA,8BAhCA,eAA4B,GAAM,gBAAqB,EAGvD,0BACA,iCACA,QAEA,CACA,UAAc,GAAiB,qDAC/B,EsG3L0C,GAC1C,EAAyB,GAAoB,GAC7C,EtGuGO,csGxGsC,CtGwGtC,KACP,MACA,OAAyB,EAAS,iBAClC,SAGA,UAAkB,GAAwB,oCAS1C,OAAW,GAPX,CACA,QACA,CAKuB,QALvB,EACA,eACA,WACA,KACA,EAEA,EsGvH+B,WAC/B,EAAoB,GAAsB,GAC1C,gBAD0C,EAQ1C,GAHA,gBACA,GAAiB,GAAmB,cAEpC,EAFoC,GAEpC,gBAEA,OACA,QACA,YAHA,kBAIA,WACA,eACA,WACA,MACA,cACA,MACA,EAIA,OAHA,SACA,aAEA,CACA,CACA,CACA,OACA,QACA,WACA,eACA,WACA,MACA,cACA,MACA,EAIA,OAHA,SACA,aAEA,CACA,CACA,EASA,oBACA,IACA,MtG5CW,GAAgB,CsG4C4B,EtG5C5B,EADI,GsG6CwB,GtG5C5B,EsG6C3B,CADiC,MACjC,OtG9CmD,CsG8CnD,OACA,CAFuD,MAGvD,GAEA,MADQ,GAAG,4CACX,IAAkB,GAAsB,mCACxC,CACA,CE7FO,wBACP,+CACA,uBACA,SACA,gCACA,CACA,CACO,uBACP,uDACA,+BACA,SACA,wCACA,CACA,CACO,uBACP,6CACA,+CACA,SACA,2CACA,CACA,CACO,uBACP,yDACA,iCACA,SACA,0CACA,CACA,CACO,MAAM,WAAiB,MAC9B,OAD8B,KAC9B,gCACA,mBACA,SACA,6BACA,CACA,CC5BA,8BAA4E,EAC5E,SACA,wCAEA,0CACA,uBACA,KACA,OACY,EAAU,IACtB,CACK,EAEL,CAJsB,CAItB,gBACA,0CAEA,aADA,4CACA,GACA,IACA,aAKA,GAHA,oCACA,8BAEA,0BAEA,SAEA,wBAGA,gBAFA,4BAEA,WACA,CAD0E,EAC1E,WACA,IACA,MAAgC,GAAG,SAEnC,OACA,eAAwC,EAAI,EAAE,eAAsB,YAAe,KAAO,EAC1F,QACA,CACA,CACA,YAEA,eACA,IACA,MAAmC,GAAgB,GAEnD,OACA,GAHmD,GAGnD,SAAwC,EAAO,EAAE,eAAsB,YAAe,KAAO,EAC7F,QACA,CACA,CACA,OAEA,4BACA,KAKA,CAJA,iBAEA,6BAGA,gEACA,QACA,CACA,CACA,SACA,uEACA,CAGA,8DACA,uBACA,KACA,OACY,EAAU,MACtB,CACK,CAFiB,CAItB,kBACA,0CAEA,aADA,8CACA,GACA,IACA,iCACA,CACA,SACA,+DACA,CAEA,UAAc,GAAoB,wCAAyC,EAAO,EAClF,CACA,8BAA2E,EAC3E,SACA,wCAKA,2BACA,eAA6B,GAAO,EAEpC,IACA,0BACA,CACA,SAEA,uGACA,QAYA,UAPA,EAHA,0BAGA,0BAIA,YAAiC,EAAO,EAGxC,QACA,CACA,CACO,4BAA4D,EACnE,iCA1HyB,EA0H8C,CAAmB,MAC1F,CC/HO,SACP,UD6H0F,UC5H1F,GACA,cACA,CACA,kBAAuD,EACvD,IACA,6BACA,CACA,SACA,mBAAqC,GAAmB,8BACxD,CACA,CACA,gBAAsC,EACtC,IACA,kCACA,CACA,SACA,mBAAqC,GAAmB,8BACxD,CACA,wBACA,CACA,ECfA,YACA,KACA,cACA,SACA,GAAqB,GAAO,SAAmB,IAC/C,wBACA,SAEA,kCACA,aACA,gBAEA,sCACA,aACA,kBAEA,4CACA,aACA,0BAEA,wBACA,UAEA,CAAa,UAA4B,IACzC,OACA,IAAyB,GAAe,GACxC,MAA2B,GAAe,GAC1C,eACA,EACA,wBACA,eACA,iBACA,cACA,OACA,gBACA,KAEA,QACA,kBACA,KAEA,QACA,0BACA,KAEA,SACA,eAGA,CACA,CACA,QACA,EAAa,EAEb,GAEA,YACe,GAAa,aAE5B,gBACe,GAAa,cAE5B,CAAC,WEzCM,UACP,IACA,MACA,yBACA,OACA,8BACA,wCAEA,8BACA,yCAEA,YACA,aACA,mBACA,CACA,YACA,OAAe,EAAM,+BACrB,CAIA,mBACA,OACA,aACA,iBACA,aDlDO,YACP,yBACA,4CACA,yCACA,0CACA,4CACA,4CAEA,aADA,wBACA,gBACA,SAAc,EAAK,GAAG,EAAM,GAAG,EAAI,GAAG,EAAK,GAAG,EAAO,GAAG,EAAQ,GAAG,EAAY,ICyCtC,kBACzC,CACA,CAIA,sBACA,MAAoB,EAAM,UAC1B,qDACA,CAIA,2BACA,MAAyB,SDjDlB,GACP,aAEA,MAAU,EAAE,OAAO,EAAE,OAAO,EAAE,yCAK9B,4BACA,WACA,8BAEA,wBACA,sBACA,oBACA,oBAIA,iCAHA,kBACA,kBACA,+BAEA,EC6B2C,gBAC3C,eACA,oDAEA,iBACA,sDAGA,OADA,uBAEA,CACA,CCzEA,eACA,WAAe,GAAG,eAAkB,GAAkB,eACtD,CEwQA,IAAM,GAAM,GAAM,MAAT,QAKH,GAAc,gBAHpB,MAIM,GAAK,CACX,CAAK,GAAM,CADA,EACA,KAAU,GACrB,CAAK,EADsB,CACb,QAAU,EACxB,CACA,MAFiC,CAEjC,GACA,QACA,WACA,QACA,IACA,gBACA,QACA,cNnQA,OMoQiB,cACjB,EACA,CACA,gBFvRO,UEuR6B,EFtRpC,OACA,kBAA4D,EAC5D,IACA,YAGA,IACA,qBACA,EAA2C,GAAM,eACjD,GAAwB,GAAgB,WACxC,MAEA,CACA,SACA,4BACA,OAEA,CAEA,UAAmC,GAAM,aACzC,oBAAyC,GAAmB,+BAC5D,8BACA,CACA,SAEA,MADA,mBAAyC,GAAmB,mCAC5D,CACA,CACA,CAAS,CACT,gBAA0C,EAC1C,IACA,WACA,oBAAyC,GAAmB,+BAC5D,uBAEA,EAA+B,GAAM,eACrC,OACA,eACA,sBACA,CACA,CACA,SAEA,MADA,mBAAyC,GAAmB,mCAC5D,CACA,CACA,CAAS,CACT,gBAA0C,EAC1C,YACA,iBACA,CAAS,CACT,kBACA,YACA,oBACA,CACA,CACA,EEgOoC,aACpC,eACA,4CACA,CACA,sBAA0C,EAC1C,IACA,SACA,EAA+B,GAAyB,2BACxD,mCAEA,IAAwB,UAAS,+BAEjC,EADuC,GAAmB,GAC1D,YAGA,CAJ0D,GAI1D,QAAiC,GAAgB,kBAjCjD,MAiCiD,GACjD,EAAoC,GAAiB,GAMrD,OALA,IADqD,EACrD,2BACA,gBAEA,6CAAkE,mBAAoD,GAEtH,CACA,CACA,SAEA,MADA,mBAAqC,GAAmB,yBACxD,CACA,CACA,CACA,oBAAmC,EAEnC,MAA2B,GX9T3B,MW6TkC,GX1TlC,EW0TkC,OX1TlC,IW2ToD,EX3TpD,oCW0TkC,EX1TlC,OACA,6BACA,6BACA,kCACA,mBWsTkC,EXtTlC,OACA,4BWqTkC,mBAElC,qBACA,OACA,4BACA,QACA,CACA,CACA,2BAA6C,EAC7C,YAA8B,GAAc,uBAC5C,OACA,4BACA,gBAEA,CACA,cAA0B,EAC1B,sBACA,4CAKA,mBACA,gBACA,oBAAqC,GAAmB,yBAGxD,YADA,CADA,WACA,GAEA,KACA,eA5EA,KA4EA,EAEA,gBACA,cACoB,GAAG,6BACvB,CAAiB,CACjB,CAAa,GACb,CAjBA,wCACA,0BACA,CAAS,EAgBT,6BACA,cACgB,GAAG,6BACnB,CAAa,CACb,CAAS,aAxFT,MAyFA,CACA,eAAyC,EACzC,mBACA,IACA,WACA,mBAGA,EAUA,EAZA,WACA,mBAEA,oBACA,EAA0B,GAAS,WAAY,EAAI,QAEnD,GAA8B,MAAL,EAAK,IAC9B,EAA0B,EAAK,mBAG/B,UAA8B,GAA+B,iCAAkC,EAAO,IAGtG,IACA,EAA6B,GAAa,EAC1C,CACA,MACA,CAH0C,CAGb,GAAG,oBAEhC,GDrY2B,CCqYN,GDlYrB,QCkYqC,CAAoB,CAA7B,GDlY5B,OCmYA,CADyE,CAAT,IAChE,EADmD,EACrB,GAA8B,QAD2B,mBAC3B,KAAiC,OAAY,IAEzG,QAAwB,GAAM,wBAC9B,uBACA,OACA,MACA,MACA,CACA,CACA,eACA,MAA4B,GAAG,YAC/B,uBACA,OACA,MACA,MACA,CACA,CACA,CACA,SACY,GAAG,kCACf,CAEA,MADQ,GAAG,gCACX,IAAkB,GAAiB,gBACnC,CACA,IAFmC,EAEnC,SAAkD,EAClD,SAEA,GADA,gCAGA,GADY,GAAG,kCACf,eACA,IAEA,WAA4B,aAAkB,+BAC9C,wCAEA,MAA0B,GAAa,KACvC,6BAEA,MAAuC,GAAmB,GAG1D,aAH0D,EAG1D,EAA4D,GAAc,WAE1E,GADA,cACA,WAGA,OADA,iCACA,EAEA,kBAGA,OADA,4FACA,EAEA,uEAIA,SACA,CACA,SACA,wCACA,iCACA,MAGgB,GAAG,mDAGnB,kBACA,UAAsB,GAAa,sDAE3B,GAAG,+BACX,QAuBA,GAtBA,6CACA,MACA,IACA,iBACA,KACA,WACA,CAAiB,CACjB,CACA,SACgB,GAAG,qCACnB,MACA,CACA,IACA,MAAsB,GAAa,KACnC,KADmC,CACnC,GACA,CACA,SAEA,IACgB,GAAG,oCACnB,CACA,CAAS,GACT,cACA,OACA,UAA0B,GAA4B,GAAI,OAAsB,GAAc,YAAxC,MAAwC,CAAqB,wBAAwB,kBAAmC,SAE9K,WAAsB,GAAa,wCACnC,CACA,QTxeO,cACP,qBACA,OAAgB,GAAmB,GACnC,OACA,EAAK,EA2BL,EA7BmC,KAGnC,eAIA,wBACA,oBAEA,OACA,UAEA,OACA,SAEA,2BAAsC,EAAS,0CAA+C,EAAS,kBAEvG,MAAwC,aAAmB,6BAC3D,EAAwC,aAAmB,6BAC3D,2BACA,UAEA,2BACA,QAEA,CACA,QACA,CAAK,EACL,YSyc2C,MAE3C,OADA,iCACe,GAAmB,EAClC,CACA,CC5bA,OAhBA,KD0ckC,IC1clC,OAUA,CAMe,CAff,GAHA,CAGQ,CAeY,IAlBpB,wBAIA,GADuB,GACvB,WACA,MACA,qBACA,IAEA,QACA,EAAS,GAGT,eACA,IAEA,QACA,CClDO,wBACP,0BACA,4BACA,YACA,0BACA,cACA,QACA,CACA,CACO,MAAM,WAAa,MAC1B,YAD0B,eAC1B,QACA,qBACA,KAAW,GAAa,KACxB,KAAW,GAAa,aADA,IAExB,SADwB,IACxB,EACA,QACA,CACA,CACO,uBACP,qCACA,sBACA,cACA,yBACA,iBACA,QACA,CACA,CACO,uBACP,oCACA,qBACA,cACA,yBACA,gBACA,QACA,CACA,CACO,uBACP,2BACA,4BACA,cACA,yBACA,eACA,QACA,CACA,CACO,uBACP,oCACA,qBACA,cACA,yBACA,gBACA,QACA,CACA,CACO,uBACP,iCACA,mBACA,YACA,0BACA,uBACA,QACA,CACA,CACO,MAAM,WAAsB,MACnC,gBADmC,oBACnC,QACA,0BACA,KAAW,GAAsB,IACjC,MAAW,GAAsB,iBACjC,aADiC,SACjC,EACA,QACA,CACA,CCrEO,2BACP,QACA,IACA,kBACA,WACA,WAEA,UACA,KAAyB,EAAQ,GAAG,EAAK,EACzC,MAAiC,GAAG,YACpC,WACA,OACA,OACA,cACA,OACA,OACA,MACA,OACA,QACA,sBACA,0BACA,OACA,CACA,CAAqB,CACrB,MACA,MACA,OACA,OACA,WACA,CACA,EAEA,YAIA,UAAsB,GAAW,qBAAsB,GAAM,gBAAgB,EAAI,EAEjF,CACA,OACA,OACA,cACA,OACA,OACA,MACA,OACA,QACA,sBACA,0BACA,OACA,CACA,CACA,CACA,CCrDA,gCACA,uBAEA,OAAW,GADQ,GAAc,GACL,YAC5B,CAFiC,CCF3B,GAAO,yBACb,uBAEA,OAAW,GADQ,GAAc,GACL,YAC5B,CAFiC,CCcjC,GAlBA,kBAEA,MAgBe,OAhBf,EADA,WAiBmC,EAAC,EAjBpC,UAEA,UAGA,mBAEA,WAEA,8BAEA,WAEA,4BAEA,EACA,ECWA,GA3BA,cACA,gBACA,eACA,KAwBsC,EAAC,EAxBvC,GAOA,GANA,OACA,QAEA,KACA,MAEA,KACA,UAAkB,GAAsB,6CAExC,OACA,UAAkB,GAAsB,0CAExC,QACA,UAAkB,GAAsB,6CAExC,OACA,UAAkB,GAAsB,0CAExC,OACA,QACA,KACA,CACA,ECtBA,MACA,oBAAiD,EACjD,UAAgB,SAAa,GAAyB,4BACtD,EAAoB,GAAoB,SACxC,WADwC,EACxC,OAAiC,GAAmB,qCACpD,+BACA,eACA,6BACA,CAAS,GACT,OACA,EAGM,GAAO,yBACb,cACA,UAAkB,GAAa,iBAAkB,GAAM,MAAxB,YAAwB,EAAoB,EAAI,GAE/E,MAAgB,GAAS,mBACzB,OACA,OACA,gBACA,OACA,OACA,MACA,qBACA,QACA,6BACA,cAEA,CACA,ECjCM,GAAO,yBACb,uBAEA,OAAW,GADQ,GAAW,GACF,KADE,CACF,MAC5B,ECFM,GAAU,GAChB,QADgB,QAChB,IAAiD,EACjD,UAAgB,SAAa,GAAyB,4BACtD,EAAoB,GAAoB,SACxC,WADwC,EACxC,OAAiC,GAAmB,gCACpD,+BACA,eACA,6BACA,CAAS,GACT,OACA,EAGM,GAAO,yBACb,cACA,UAAkB,GAAa,iBAAkB,GAAM,MAAxB,YAAwB,EAAoB,EAAI,GAE/E,uBACA,OACA,OACA,WACA,OACA,OACA,MACA,QAAqB,GAAU,GAC/B,QACA,sBACA,MACA,CACA,CACA,CClCO,wBACP,sCACA,uBACA,cACA,yBACA,kBACA,QACA,CACA,ECDA,gBAEA,EASA,MADA,EAcA,CArBA,EADA,EAOK,2BAAiD,EANtD,UACA,wBACA,cACA,sBACA,oBACA,wBAIA,CADA,EAOK,UANL,gBACA,6BACA,mBACA,2BACA,yBACA,6BAGA,CAGK,2BAAiD,EAHtD,UACmB,GAAW,GAI9B,KAJ8B,EAI9B,MACA,SACA,GAAqB,GAAO,SAAmB,IAgB/C,GAfA,wBACA,SAEA,eACA,YACA,qCAEA,eACA,aACA,iBAEA,mBACA,aACA,sBAEA,mBACA,0BACA,aACA,WAGA,oBACA,aACA,sBAEA,iBACA,aACA,oBAEA,eACA,aACA,kBAEA,gBACA,aACA,6BAEA,wBACA,UAEA,CAAa,SACb,OACA,aACA,EACA,wBACA,eACA,iBACA,cACA,OACA,oCACA,KACA,QACA,iBACA,KACA,QACA,sBACA,KACA,QACA,8BACA,KACA,QACA,sBACA,KACA,QACA,oBACA,KACA,QACA,kBACA,KACA,QACA,uCACA,KACA,SACA,eAEA,CACA,CACA,QACA,EAAa,EAEb,GAEA,YACe,GAAa,aAE5B,YACe,GAAa,YAE5B,CAAC,UAAoB,EAErB,YACA,KACA,cACA,SACA,GAAqB,GAAO,SAAmB,IAC/C,wBACA,SAEA,kBACA,YACA,oBAEA,gCACA,aACA,oCAEA,wBACA,UAEA,CAAa,SACb,SACA,wBACA,eACA,iBACA,cACA,OACA,oBACA,KACA,QACA,oCACA,KACA,SACA,eAEA,CACA,CACA,QACA,EAAa,EAEb,GAEA,YACe,GAAa,aAE5B,YACe,GAAa,YAE5B,CAAC,UAA4B,EAE7B,YACA,KACA,cACA,SACA,GAAqB,GAAO,SAAmB,IAC/C,wBACA,SAEA,mBACA,aACA,sBAEA,wBACA,UAEA,CAAa,SACb,SACA,wBACA,eACA,iBACA,OACA,EACA,sBAGA,eAGA,CACA,QACA,EAAa,EAEb,GAEA,YACe,GAAa,aAE5B,YACe,GAAa,YAE5B,CAAC,UAA4B,ECzH7B,QACA,UACA,sBACA,YACA,oBACA,kBACA,kCACA,EACA,IACA,YACA,yBACA,CACA,sBACA,qBACA,UAIA,oBACA,MAAwB,EAAM,UAC9B,UACA,+CACA,YACA,wBACA,YACA,oBACA,CACA,yBACA,qCAEA,OACA,gBACS,EAGT,OADA,0BACA,CACA,CACA,KACA,KACA,WACA,SACA,OACA,MACA,MACA,0BACA,GACA,WACA,CAAK,EACL,SAAgB,0DAAwD,EACxE,2CACA,UAAsB,GAAgB,2BAEtC,qBACA,YACA,gBACA,cACA,sBACA,qBACA,YACA,YACA,CACA,YACA,QACA,oCAGA,iBAEA,CACA,WACA,kBAEA,cACA,6BACA,CACA,gBACA,uBACA,CACA,mBACA,2BACA,CAIA,WACA,sBAEA,UAEA,SAOA,OANA,4BACA,IACA,CAAS,EACT,iBACA,8BAEA,CACA,CAIA,cACA,EA2BA,EAUA,EApCA,kBACA,UACA,EAAuB,EAAM,aAC7B,KACA,iBACA,EAAuB,EAAM,mBAC7B,KACA,YACA,EAAuB,EAAM,cAC7B,KACA,gBACA,EAAuB,EAAM,kBAC7B,KACA,eACA,EAAuB,EAAM,iBAC7B,KACA,8BACA,EAAuB,EAAM,mBAC7B,KACA,SACA,UAA0B,GAAgB,SAAU,GAAM,CAAhB,WAAgB,EAC1D,CACA,gBAqBA,MApBA,yCACA,WAGA,kBACA,mDACA,wBACA,WAEA,4BACA,YAIA,kBACA,IACA,wBACA,uCACA,EAEe,EAAM,QACrB,OACA,OACA,mDACA,2BACA,uBACA,mBACA,OACA,OACA,CAAS,CACT,CACA,CCxOyB,GAAI,CAC7B,OAD6B,WAE7B,QACA,WAZA,YACA,aACA,YAAkB,IAAO,IACzB,WACA,MAEA,yBACA,EAK0C,MAAO,WACjD,CAAC,EAEM,OAAmB,GAAI,CAC9B,OAD8B,YAE9B,QACA,UAAqB,EAAc,KAAD,CAAQ,YAC1C,CAAC,EAGwB,GAAI,CAC7B,OAD6B,eAE7B,QACA,UAAqB,EAAc,KAAD,CAAQ,0BAC1C,CAAC,iBChCM,OAAM,GACb,SACA,CAFmB,QAEnB,CACA,QACA,aACA,UACA,gBACA,SACA,gBACA,iBACA,eACA,oBACA,mBAA6B,GAC7B,SADwC,IAExC,CACA,eACA,yCACA,sBACA,CACA,aACA,+BACA,WACA,eAGA,aACA,+BACA,qBACA,qBACA,sBAEA,CACA,YAEA,OADA,8BACA,cACA,aAAiC,GACjC,UADuC,GACvC,GAEA,IACS,EACT,CACA,gBACA,6BAEA,YACA,4BACA,CACA,kBAEA,aADA,8BAEA,aAAiC,GACjC,UADuC,YACvC,GAGA,OAGA,CACA,eAGA,yCACA,UACA,aAAqC,GACrC,UAD2C,QAC3C,OAGA,gBAGA,GAXA,IAaA,CACA,0BACA,mBACA,CACA,SACA,4BACA,CACA,cACA,8CACA,CACA,YACA,qCACA,CACA,oBACA,+BACA,sBACA,kBAA6B,GAAM,EAKnC,mBACA,QAEA,CACA,oBACA,4CAAuE,GAAoB,MAC3F,aAD2F,CAC3F,qBACA,+BACA,aAA6B,GAC7B,UADmC,EACnC,IAEA,CACA,YACA,MACA,OACA,eACA,CACA,CACA,8BACA,+BACA,mDAEA,UAA+B,GAAM,8BACrC,+BAEA,+CAEA,OADA,6DACA,8BACA,CAEA,QACA,CACA,cACA,yBACA,MACA,QACA,YACS,CACT,CACA,kBACA,6BACA,iBAEA,uBACA,CACA,UACA,UACA,+BAEA,8BACA,iBAEA,wBACA,aACA,CACA,SACA,0CACA,uBAEA,8BACA,2BAAkE,GAAM,EACxE,aACA,6BACA,OACA,sBACA,OACA,qBAEA,oCACA,CACA,MAEA,uCAGA,CACA,OACA,4BACA,CACA,CACA,eACA,SACA,CACA,iBACA,aAEA,eACA,QACA,CACA,yBACA,SACA,wCACA,gBAA6B,GAC7B,UADmC,CACnC,SAEA,CACA,iBACA,QACA,gCACA,UACA,CAAa,CACb,CAEA,WACA,CCxMA,QACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,IACA,CACA,IACA,EACA,EACA,EACA,GACA,GACA,GACA,IACA,IACA,OACO,GACP,OACA,gBACA,2BACA,GACA,cACA,gCACA,qBACA,CACA,gBACA,oDAEA,YACA,4BAEA,QACA,QACA,IACA,6BACA,wCACA,wBACA,gBACA,WAsBA,OAEA,UAGA,GAJA,EAIA,aAJA,IAIA,MAHA,KACA,EAzBA,SACA,WACA,KACA,uBACA,wBACA,sBACA,uBAEA,CACA,QACA,CACA,UAEA,IADA,uBACA,uBACA,uBACA,uBAEA,CACA,YACA,8BACA,CACA,CCjDO,SACP,OACA,QACA,OACA,eACA,mBACA,sBACA,KACA,8BACA,wCAEA,eACA,eACA,eACA,sBACA,2BACA,iBAEA,cACA,QACA,4BACA,8BAEA,QACA,WACA,8CACA,gCACA,YACA,WACA,KACA,uBACA,uBACA,0BAEA,CACA,QACA,CACA,UACA,QACA,WACA,8CACA,8CACA,YACA,KACA,uBACA,gEACA,cACA,2BAEA,CACA,CACA,yBACA,cACA,oBAAwC,GAAgB,0DAExD,MAA2B,GAD3B,aAC2C,KAD3C,KAEA,sBACA,sCACA,CACA,CEnEA,yBACA,aAAkB,GAAU,WAI5B,WAEA,SACA,EACA,kBACA,2CACA,mCACA,gBAEA,8CAEA,sBACA,0BACA,qBAAyC,GAAM,CAC/C,SAD+C,MAC/C,MACA,qBACa,OACb,MACA,CACA,mCACA,CAAK,EACL,EACA,UACA,EACA,aACA,cACA,gBACA,eAEA,OACA,eACA,KACA,sBACA,UACA,YAGA,OADA,UACA,WACA,EACA,sBACA,gBAIA,EAHA,gBACA,UAAsB,GAAc,qBAGpC,IACA,EAAkB,GAAM,iBACxB,CACA,SACA,UAAsB,GAAc,UACpC,CADoC,GAEpC,kCACA,UAAsB,GAAc,cAEpC,kBACA,UAAsB,GAAc,kBAEpC,MAA2B,SDnCpB,CCmC8B,MFlE9B,ECgCP,2BACA,+CAMA,WAAe,GAJf,CACA,SAGqB,EAHrB,IACA,MAAc,EAAQ,SDpCtB,mBACA,gBAEA,EAGA,WAEA,EC6BA,EAEA,EC0BqC,CACrC,UACA,gCACA,CAAS,EACT,GACA,aACA,YACA,YACA,CACA,CACA,6DACA,sCACA,iDACA,cACA,OACA,wBACA,4BACA,mCAEA,uBACA,gBACA,SAEA,4BACA,6BACA,OAIA,eAKA,CAAK,SACL,QACA,OAEA,sCACA,QAEA,cAGA,GADA,EAAW,GADX,uBAEA,SACA,ECzCM,GAAW,8BAMF,wBAA6C,EAC5D,IAUA,EAVA,qBACA,KACA,QAEA,iCACA,kBACA,KACA,EAAwB,KACxB,CAD6B,CACH,KAC1B,CAD+B,CAC/B,GAEA,KAsCA,oBACA,EACA,WAEA,mBACA,CAuCA,IAjFA,wCACA,WACA,CAAK,EACL,iCACA,IACA,sBAKA,GAJA,eACA,EAAoC,KACpC,CADyC,KACzC,WAEA,EACA,MAEA,OACA,OACA,EACA,UACA,IACA,SACA,UACA,QACA,UACA,oBAA8C,GAAW,iBACzD,CAAiB,KACjB,UACA,QACA,oBAA8C,GAAW,iBACzD,CAAiB,CACjB,CACA,KACA,oBAAsC,GAAW,iBACjD,CACA,SACA,IACA,oBAAsC,GAAW,iBACjD,CACA,CAAK,IA6CL,CAKA,GAJA,MACA,EAA8B,KAC9B,CADmC,KACnC,WAEA,QAEA,QAQA,GANA,EACA,MAhDA,YACA,6BACA,WAEA,GADA,UACA,KACA,mBAMA,MAFA,KACA,YACA,MAEA,WACA,CACA,IAoCA,MAnCA,YAGA,UACA,YAA4B,WAAgB,IAC5C,cACA,WAGA,GAFA,cACA,IACA,KACA,mBAKA,MAFA,KACA,YACA,MAEA,WACA,CAGA,IAgBA,gBAEA,KAEA,CACA,CEpLA,qCAUA,EARA,4BACA,MAAoB,GAAoB,SACxC,UACA,CAFwC,KAGxC,CACA,gBACA,UAAkB,GAAc,qBAGhC,IACA,EAAe,GAAM,iBACrB,CACA,SACA,UAAkB,GAAc,UAChC,CAEA,iBAEA,MAAoB,GADpB,OACwC,OACxC,MADwC,CACxC,GACA,uBACA,CACA,SACA,wCACA,UAAkB,GAAc,0CAEhC,YAAoB,iBAAuB,KAC3C,iBACA,IACA,cAD2C,EAC3C,IAUA,CAV0D,EAC1D,YACA,YACA,WACA,QACA,OACA,YACA,CAAa,EAEb,MACA,EACA,KAEA,CACA,MAAU,GAAI,KAAuB,GAAG,KACxC,OADwC,GAExC,iCACA,OACA,KACA,OACA,CACA,GACK,GAAe,GAAQ,GAC5B,EAD4B,MAC5B,GACA,mCACK,YACL,mBAA2B,wBAA0B,SACrD,EACA,oBACA,KAAqB,GACrB,EAA4B,GAAY,GACxC,IAF+B,CAG/B,MAFwC,GAGxC,IACA,CAF6B,IAG7B,SACA,UAAkC,GAAc,sBAAuB,YAAe,IACtF,MACA,CAGA,UAAmC,GAAM,CACzC,EADyC,UACzC,CACA,CAAa,EAEb,iBACA,QACA,CAAa,EAEb,gBACA,mBAAyC,GAAmB,6BAC5D,WACiB,GACjB,uBACA,CAAa,EAEb,gBACA,CACA,CAAK,EACL,MACA,OAEA,CA8CA,OA7CA,KA6Ce,EA7Cf,SA6C0B,CA5C1B,CA4C2B,eA5C3B,IAAiD,EACjD,mBACA,cACA,oCAEA,UAAgB,SAAa,GAAyB,qBACtD,EADsD,CACtD,OACA,OAEA,SACA,MACA,EAAsB,KAQtB,GAR8B,OAQ9B,SAPA,mBAAiC,GAAmB,6BACpD,KACA,CAAS,GACT,mBACA,UACA,QACA,CAAS,EACT,GACA,YAIA,IADA,yBACA,EAEA,MADA,QACA,IAA0B,GAAa,qGAEvC,OACA,QAEA,mBAAqC,GAAmB,wCACxD,YACA,aACA,UACA,CAAa,GACb,QAEA,OACA,UAAsB,GAAc,qDAEpC,ECpIA,mCAKA,EAJA,cACA,gBACA,UAAkB,GAAc,qBAGhC,IACA,EAAc,GAAM,iBACpB,CACA,SACA,UAAkB,GAAc,UAChC,CADgC,GAEhC,eACA,UAAkB,GAAc,kBAEhC,wCAsBA,cAAuB,WAAU,EArBb,GAAI,KAAkB,GAAG,KAC7C,OAD6C,GAE7C,4CACA,mBAWA,OAJA,EAAuB,GADvB,uBAEA,mBAAyC,GAAmB,+CAC5D,WACiB,GACjB,CAAyB,wBAXzB,EACA,0BAAiE,EAAK,GAAG,EAAK,cAC9E,OAAyB,mCACzB,CAUA,GACK,GAAa,GAAQ,GAC1B,EAD0B,MAC1B,GACA,mCACK,GAEL,OAEA,CCjDA,eACA,kCACA,cACA,EACA,IACA,IAAS,GACT,CADoB,IACV,GACV,CADqB,SHRrB,UGS+B,CHT/B,MACA,oBAAsD,EACtD,kBACA,2BACA,oBACA,oBAAiC,GAAmB,kCACpD,KACA,CAAS,GACT,MAAe,GAAI,KAAkB,GAAG,KACxC,OADwC,GAExC,iBACA,KAAoC,EAAK,GAAG,EAAS,EAErD,MADA,iCACA,QAES,GAAa,GAAQ,GAC9B,EAD8B,MAC9B,GACA,mCACS,KAAa,GAAM,cAC5B,CAD4B,CGR5B,yBDRA,iBACA,MCOyD,GDPzD,IAAmD,EAInD,OAHA,mBAAiC,GAAmB,+CACpD,KACA,CAAS,GACT,eACA,ECGA,0BACA,OAEA,yBACA,QCPM,GAAS,CACf,CAAK,GAAU,CDUf,CCVkB,KDUlB,ICXe,CACA,CDUf,iBAGA,EACA,EAFA,MAAiB,GADjB,kBAOA,GAHA,SACA,iBAEA,aACA,UAAkB,GAAc,qBAEhC,IACA,EAAiB,GAAM,iBACvB,CACA,SAEA,UAAkB,GAAc,UAChC,CAIA,GAHA,SACA,MAEA,gBACA,EAQA,UALA,EAFA,mCAEA,MAA4B,GAAY,SLiEb,CK9D3B,CL8D4B,EK9D5B,CAHwC,CAGxC,OAGA,UAAsB,GAAa,uBAGnC,GAHmC,CAGnC,YACA,KAA4B,EAAK,GAAG,EAAS,EAC7C,GACA,MACA,YACA,WACA,MACA,CACA,CACA,gCACA,WACA,UAAkB,GAAa,0CAE/B,gBACA,CACA,OACA,iBACA,OACA,OACA,MACA,UACA,SACA,QACA,OACA,iBACA,CAAa,CACb,MACA,EAEA,CACA,OACA,YACA,OACA,OACA,MACA,UACA,SACA,QACA,OACA,iBACA,CAAS,CACT,MACA,CACA,ECtFA,CAAK,GAAQ,CfoBE,CepBC,EAChB,CADa,GACI,CrBTF,CqBSK,EfmBE,CelBjB,CfkBkB,EN5BD,CCAP,CoBSoB,EAEnC,CAAK,GAAQ,EADsB,EACtB,EADI,CACI,EpBXC,CoBYjB,CpBZkB,EoBYT,EAAG,CACjB,EACM,CAFuB,EAEhB,CjBeS,EAAC,CiBlBc,ChBXf,CgBcT,ChBdU,CgBcV,eACb,MAAqB,EAAS,SAC9B,WACA,UAAkB,GAAe,wBAAyB,OAAS,GAEnE,iBAAgD,GAAO,MACvD,ECwBA,WAEA,GACA,OACA,+BACA,gBAEA,OACA,2BACA,OACA,IAAiB,GAAG,UACpB,cAGA,MAAgB,GAAG,SACnB,WACA,OACA,MACA,cAGA,uBACA,yBACA,mBAEA,YACA,OACA,IAAiB,GAAG,YACpB,oBACA,CACA,CACA,UAAc,GAAY,qBAAsB,EAAK,EACrD,EAkBO,0BAAuD,EAC9D,QAAU,eAAiB,MAC3B,eACA,IACA,WACA,QACA,YAA6B,GAAO,cD/Ed,CCgFtB,CDhFuB,ECgFvB,4BACA,UAAsB,GAAa,qBAAsB,EAAK,GAK9D,GAHA,eACA,gBAEA,aACA,OAGA,mBACA,aACA,cACA,cAEA,CAyBO,0BAAsD,EAC7D,YAAyB,GAAI,WAC7B,EAD6B,CAC7B,QACA,UAAkB,GAAa,qBAAsB,EAAK,GAA3B,OAE/B,CACA,CAmBO,0BAAwD,EAC/D,sBACA,aAGA,QACA,sBACA,0BACA,QAGA,sBACA,gCACA,QACA,yBAGA,sBACA,cAGA,CACA,CE3Ke,kBAA+D,EAC9E,MDzBO,WCyBqB,CDxB5B,YACA,yCACA,4BAEA,8CACA,iCAEA,6BACA,QAEA,CACA,GAHwB,GAGxB,gDACA,ECY4B,GA0B5B,qCAzBA,CACA,cACA,cACA,kBACA,CAAS,CACT,cACA,IACA,UAAwB,UAAc,eACtC,mBACA,OAEA,WACA,UACA,MACA,CACA,YACA,CACA,SACA,UACA,CACA,CAAS,CACT,SACA,kBACA,CACA,EACA,EACA,iBCjDA,qCACA,aACA,mCACA,YACA,KACA,WAEA,oBAAwB,IAA0B,GAAU,GAAO,CAAV,CAAe,CAExE,CAFmE,EAEnE,YACA,kCACA,wBACA,kBAA4B,EAAK,IAAI,EAAK,IAAI,EAAI,EAClD,EACA,8BACA,0BAEA,gBAEA,SACA,OACA,aACA,OACA,WACA,sBACA,qBACA,CACA,EAEA,SACA,cACA,GACA,CACA,cACA,SACA,yBAOA,aAJA,qBAEA,uBAEA,sBACA,IAEA,0BACA,CACA,EACA,gDACA,OACA,IAEA,KACA,saAMA,mCACA,CACA,CAEA,qBACA,eACA,iDAUA,YAEA,OACA,WACA,SACA,YACA,eACA,YACA,2BACA,GACA,KATA,IAWA,wBACA,eACA,SACA,YACA,CACA,CACA,SACA,KACA,cAEA,aACA,UACA,YACA,MACA,SACA,SACA,kBAEA,OADA,SACA,CACA,CACA,iBAEA,UACA,0DAGA,oBACA,aACA,CACA,QACA,0BACA,CACA,MACA,gCAEA,CAgBO,SAEP,IACA,GACA,GACA,GACA,GACA,EAIA,IAIA,cAIA,aAIA,cAIA,gBAIA,WAIA,eAIA,WAIA,cAIA,gBAIA,yBAIA,mBAIA,uBAIA,2BAIA,kBAEA,CACA,KACA,GACA,GACA,GACA,CACA,MACA,IACA,EACA,MACA,IACA,IACA,IACA,IACA,IACA,IACA,UAUA,yBACA,OAEA,aACA,WACA,YACA,YACA,aACA,aACA,UACA,WACA,WACA,aACa,CACb,WACA,aACa,CACb,WAEA,8BACA,0CACA,uBACA,oBACA,qBACA,mBACA,CACA,CAKA,UACA,eAKA,cACA,eAKA,qBACA,eAKA,WACA,eAKA,kBACA,eAEA,iBACA,eAKA,cACA,eAKA,mBACA,cACA,CACA,eACA,QAAgB,sVAA8U,EAC9V,iBACA,4DAEA,oBACA,MACA,qCAMA,GAJA,UACA,UACA,6BACA,uBACA,sBACA,gCACA,sFAEA,2CACA,sDAEA,CACA,eACA,qBACA,4DAGA,GADA,UACA,YACA,qBACA,+DAkCA,GAhCA,UACA,aACA,gBACA,8BACA,8BACA,iBACA,kBACA,WACA,WACA,sBACA,UACA,UACA,sBACA,YAEA,sBACA,UACA,cAGA,eACA,iBAEA,mBACA,mBACA,wBACA,qBACA,kCACA,oCACA,gCACA,0BAEA,uBACA,gBACA,aACA,mEAGA,0BACA,wEAEA,UACA,CAWA,GAVA,oBACA,4BACA,wBACA,wBACA,mBACA,aACA,EACA,EACA,sBACA,cACA,UACA,iBACA,+DAEA,UACA,CAEA,0CACA,oEAEA,2CACA,4BACA,QACA,UAGA,GAFA,gGAEA,8BAEA,CACA,CAKA,mBACA,2BACA,CACA,MACA,sBACA,iBACA,YACA,WACA,4BAGA,GAFA,eACA,OACA,0BACA,sBACA,aACA,6BAEA,CAAiB,KAGjB,UACA,SAGA,CACA,EACA,aACA,wBACA,EACA,iBACA,SACA,WACA,OAEA,UACA,MACA,SACA,UACA,aACA,aACA,mBACA,CACA,EAGA,QACA,OACA,eACA,yBACA,IACA,4CAGA,UACA,SAGA,CACA,QACA,CACA,0BACA,qBACA,cACA,SAEA,WACA,cACA,KAIA,EADA,aAFA,GAIA,EACA,aACA,WACA,OACA,4BACA,CACA,CAEA,YACA,WACA,WAEA,SACA,OACA,qBACA,WACA,WACA,aACA,cACA,MACA,EACA,qBAGA,eACA,SAEA,WACA,MACA,wBACA,sDAGA,OADA,UAEA,2EAEA,MAEA,6IAKA,QACA,EACA,mBAEA,GADA,OACA,SACA,mBACA,gBACA,YAEA,CACA,cACA,IACA,cACA,8BAEA,CACA,CACA,WACA,gBACA,eACA,QACA,oFAEA,QACA,GACA,gBAAgB,mBAA+B,EAAI,EACnD,WACA,mBAOA,CAPqC,GACrC,EAD0C,EAC1C,MAGA,mBACA,UAEA,eAIA,cAKA,iBAAiB,mBAA+B,EAAI,EACpD,WACA,mBAOA,CAPqC,GACrC,EAD0C,EAC1C,MAGA,mBACA,UAEA,eAIA,aAKA,OACA,mBACA,2BACA,CAKA,WACA,wBACA,qBACA,qBACA,sBACA,8BAGA,CAOA,YACA,wBACA,qBACA,qBACA,sBACA,8BAGA,CAKA,QACA,yBACA,sBACA,OACA,sBACA,SAEA,CACA,CAOA,SACA,yBACA,gBACA,aACA,sBACA,SAEA,CACA,CAKA,UACA,wBAEA,SADA,YAEA,sBACA,kBAGA,CAOA,WACA,wBAEA,SADA,YAEA,sBACA,kBAGA,CAKA,oBACA,qBACA,CAMA,gCAKA,WAA4B,EAC5B,yBACA,iBACA,cACA,uBACA,EACA,eAEA,qBACA,6BAEA,CACA,CAYA,kBACA,yBACA,iBACA,cACA,uBACA,CACA,aAEA,2BACA,CACA,CAKA,mBACA,yBACA,iBACA,cACA,uBACA,CACA,aAEA,2BACA,CACA,CAKA,aACA,SACA,uBAAyC,cAAkB,EAC3D,cACA,8BACA,MAGA,QACA,CAaA,QACA,qBACA,cACA,OACA,iBACA,cACA,uBACA,EACA,cACA,OACA,aAAwB,GACxB,uBACA,kBACA,cACA,SACA,oBACA,SACA,kBACA,CACA,CAIA,OAHA,UACA,qBAEA,CACA,CAcA,OACA,SACA,uBAAwC,cAAkB,GAC1D,iBACA,aACA,cACA,uBACA,EACA,0BACA,SACA,aAA4B,GAC5B,uBACA,kBAGA,2BACA,gCACA,CACA,UACA,qBAEA,gBACA,CACA,QACA,CAUA,QAEA,eADA,aACA,IACA,YAOA,yBACA,kBACA,CACA,qBACA,CACA,CA+BA,YAA6B,EAC7B,cAEA,OADA,eACA,KAEA,QAAgB,yGAA+G,EAC/H,aAAc,oBAAiC,EAC/C,4BAGA,0CAOA,OANA,IACA,aACA,2BAGA,kBACA,KAEA,wCACA,cAEA,cACA,SACA,oBACA,eACA,kBACA,aACA,QACA,aACA,aACA,iBACA,oBACA,qBACA,WACA,UACA,gBACA,GACA,cACA,SAEA,CAEA,YACA,iBACA,UACA,0BACA,6CACA,IAA4B,wBAA0B,CACtD,kBACA,UACA,qBAEA,UACA,4BAGA,KACA,KACA,UACA,qBAEA,UACA,6BAMA,GAHA,YACA,gBACA,aACA,GACA,gBACA,qBACA,uBACA,CACA,aACA,cACA,CACA,MACA,GACA,gBAEA,CAWA,GAVA,iBACA,WAEA,WACA,GACA,gBAEA,GACA,eAEA,4BAEA,EADA,eAEA,mBACA,eAEA,CACA,YAMA,MACA,IACA,eACA,wBAEA,GADA,aACA,YACA,2BACA,mCAGA,cACA,QAEA,CACA,QACA,CACA,2BAEA,EADA,eAEA,mBACA,eAEA,CACA,CACA,CACA,OACA,eACA,aACA,aA4BA,OA3BA,sBACA,4CAEA,uBACA,UACA,uBAEA,UACA,+BAGA,YAEA,IACA,kBACA,kBACA,kBAEA,aACA,oBACA,mBAGA,oBAEA,kBACA,UACA,CACA,CAiBA,UAA0B,EAC1B,mBAAgB,gCAA+C,EAC/D,iBACA,eACA,iBACA,gBACA,gCACA,SAEA,gBAQA,OAPA,GACA,YAEA,IACA,YACA,eAEA,GAEA,IACA,cACA,cAEA,MACA,GACA,eAEA,QACA,CAQA,WAA4B,EAC5B,eAAgB,mBAA+B,EAC/C,iBACA,eACA,gBACA,OAEA,iBAEA,2CACA,CACA,aACA,mCACA,eACA,SAEA,aACA,QAAgB,GAAS,EAEzB,mDACA,gBACS,EACT,OACA,gBACA,UACA,SACA,EACA,aACA,YAAoB,GAAU,SAC9B,uCAYA,CAXA,WACA,OACA,yBACA,oCACA,GACA,iCAGA,2BAGA,WAKA,iBACA,WAFA,EAGA,qBACA,kCAGA,qBAIA,UACA,2BACA,0BAGA,GAnBA,kBAoBA,EAQA,MACA,YAAoB,GAAU,SAC9B,8BACA,kCACA,gCAiBA,GAfA,iBAGA,mCAIA,GAKA,oCAPA,qBAUA,EAIA,OAHA,mBAjBA,EAiBA,sBACA,4BAlBA,EAoBA,qBAEA,GAtBA,EAsBA,aAtBA,EAuBA,OAEA,CAoBA,WACA,8BACA,kBArBA,QACA,uBACA,yBACA,oCAKA,uCACA,sBACA,4BACA,UAEA,0BACA,eAGA,CAAa,CACb,GAGA,OA3DA,IACA,WACA,0BACA,uBAEA,OAuDA,mBACA,oBACA,uBACA,iBACA,CAAS,EAST,OARA,YAEA,cAA8B,2BAAyC,EACvE,kBAGA,aAEA,CACA,CACA,aACA,YAGA,EADA,gBAEA,SACA,0CAHA,EAIA,+BACA,CACA,kBAAoC,EACpC,IAEA,+GAEA,mIAEA,mQAAiR,EACjR,aAGA,OAFA,GACA,gBACA,YACA,aACA,iBACA,qBACA,QACA,CAAa,EAEb,OACA,aACA,iBACA,qBACA,MACA,iBACA,OACA,kBACA,cACA,2BACA,6BACA,yBACA,mBACA,SACA,QACA,EACA,iBACA,eACA,GACA,iBACA,wBACA,qBACA,CACA,CAEA,iBACA,gBACA,yCAMA,OALA,IACA,mBACA,GACA,sBAEA,uCACA,CAGA,kBACA,UASA,OARA,GACA,gBACA,YACA,GACA,YAEA,GACA,cACA,EAIA,wBAEA,OADA,4BACA,EAMA,OALA,IACA,4BACA,MACA,sBAEA,uCACA,CACA,CACA,uBAAyC,EACzC,4BACA,cACA,0CACA,QACA,CACA,WAA4B,EAC5B,cACA,MACA,qDAEA,YAAgB,uBAAoC,EACpD,gBACA,kBACA,SACA,aACA,UACA,SACA,CAAS,EAET,OADA,gBACA,CACA,CAOA,UAA0B,EAC1B,eAAgB,8GAA4H,EAC5I,iBACA,eACA,iBACA,oBAGA,CAFA,GACA,cACA,aAIA,CAHA,GACA,gBAEA,IASA,GACA,GACA,iCACA,qBAEA,kCAbA,GACA,qBAEA,MACA,qBACA,YAmBA,CAPA,GACA,cAMA,GACA,wBAEA,YACA,GACA,YAEA,EAEA,CACA,GACA,cAEA,CACA,SACA,cACA,YACA,CACA,OASA,eACA,aACA,oBAGA,iCAEA,qBACA,WAEA,CAMA,UACA,2BACA,CACA,SACA,SACA,gBACA,qBACA,eAEA,GADA,KACA,YACA,gBAEA,CACA,YACA,iBAeA,GAdA,YACA,4CAEA,uBACA,UACA,iBAEA,UACA,yBAGA,kBACA,kBACA,kBACA,aACA,0BAEA,gBACA,wBAEA,CACA,kBACA,sBACA,iBACA,uBACA,CACA,UACA,gBACA,EAEA,CACA,mCAEA,EADA,eAEA,mBACA,eAEA,CACA,QACA,CAIA,QACA,yBACA,CACA,OACA,uBAA6C,cAAkB,GAC/D,iBACA,eACA,gDAEA,CACA,iBACA,UACA,iBAEA,UACA,uBAEA,CACA,CAgBA,GAfA,gBACA,qBACA,qBACA,qBACA,iBACA,kBAEA,UACA,iBAEA,WACA,WACA,kBACA,UACA,UACA,wBAEA,EADA,eAEA,mBACA,eAEA,CACA,CACA,CCpgDO,uBACP,4CACA,2BACA,SACA,6BACA,CACA,CACO,uBACP,4BACA,mCACA,SACA,0BACA,CACA,CACO,uBACP,qDACA,6BACA,SACA,sCACA,CACA,CE+CO,iBACP,SACA,qEAEA,CCvCO,SACP,QACA,eAIA,UACA,WACA,mBACA,IACA,kBACA,gBACA,UACA,QACA,qBACA,KAIA,GAHA,eACA,mEACA,wBFjDO,SEiDoC,CFjDpC,IACP,WACA,OAEA,wBACA,wBAEA,qBACA,uDACA,cAEA,gEACA,WAGA,WACA,EEiC2C,sBAC3C,+BACA,uBACA,yCACA,IACA,UAAwB,SAlCxB,YAIA,qDACA,mBACA,UAAkB,GAAiB,yBAEnC,UAAY,SAAa,SACzB,aAAa,QACb,EAwBqC,wBACrC,iDACA,6CACA,CACA,SACA,2DACA,4BACA,yBACA,CACA,uBACA,MAEA,4CACA,uBACA,4BACA,yBAEA,CACA,WACA,aAEA,iCArEA,kBAqEA,IApEA,OAEA,kDACA,aAEA,kBACA,QAEA,eAGA,KAVA,GAoEA,kEACA,CACA,UACA,iBACA,WAEA,OADA,+BACA,EAEA,mDAEA,OADA,qFACA,EAEA,qBACA,eACA,uBACA,iBAEA,CADA,kFACA,6BAEA,EAEA,uBAGA,oEACA,EACA,CAEA,iBACA,wBACA,2CAEA,OADA,kEACA,YACA,CAOA,eACA,sCACA,qDAEA,uBACA,CACA,cACA,sBAEA,0BACA,uBACA,oBAGA,2DAGA,oDAKA,CACA,wBACA,qBACA,kBAGA,yDAGA,sDAKA,CAKA,0BACA,wBACA,SAEA,4DAEA,OADA,2EACA,GAEA,4BAEA,OADA,2FACA,GAEA,0BAEA,OADA,yFACA,GAEA,6DAEA,+CAEA,OADA,mEACA,GAEA,4BAEA,OADA,8DACA,GAEA,0BAEA,OADA,4DACA,EAEA,QACA,gEACA,6FACA,GAGA,CAMA,aACA,wBACA,CAMA,oBACA,wEACA,EAEA,mBACA,eAEA,0CACA,CAkBA,mBACA,6DACA,iEACA,MACA,CACA,IACA,UAAoB,oBAAyB,SFvNtC,OACP,SEsNsE,CFtNtE,SACA,UAAkB,GAAiB,qEAEnC,6BACA,UAAkB,GAAiB,oFAEnC,4BACA,UAAkB,GAAiB,wEAEnC,gBACA,UAAkB,GAAiB,+DAEnC,iBACA,CAAiB,8BAEjB,iBAEA,QACA,KAAqB,GAErB,MACA,CAAqB,4BAErB,CAAiB,8BAEjB,iBACA,QAEA,OAAqB,GAIrB,CAAiB,SADjB,IACiB,YAFjB,GAEiB,EAEjB,CAAa,qCACb,EEmLsE,oFACtE,2EACA,iBACA,eACA,eACA,CACA,SACA,qDACA,sBACA,oBACA,oBACA,CACA,CAaA,8BACA,6BAEA,MADA,+EACA,IAAsB,GAAiB,yBAEvC,OAAe,SD9OR,CAAiC,iCAA8B,EACtE,aACA,CADmC,EACnC,iBACA,UAAkB,GAAiB,oFAEnC,oBACA,UAAkB,GAAiB,sFAEnC,2BAEA,QACA,WAA8B,EAAM,EAEpC,SAAwB,EAAU,GAAG,IAAa,GAAG,EAAS,EAE9D,qBAEA,WACA,iBAA8B,EAAM,EAEpC,UAEA,eADA,MAC8B,GAAG,EAAI,GAAG,EAAS,CACjD,QACA,iBAEA,WAA0B,EAAM,EAEhC,SAAoB,EAAU,GAAG,EAAQ,GAAG,EAAM,GCkNd,CACpC,yBACA,qBACA,+BACA,CAAS,CACT,CACA,CI5QA,QACA,CAAK,GAAW,EAChB,GADgB,gBAEhB,gCACA,mBACA,gCACA,2BACA,2BACA,mCACA,2BACA,CACA,CAAK,GAAW,EAChB,YADgB,OAEhB,gCACA,mBACA,gCACA,2BACA,2BACA,mCACA,2BACA,CACA,CAAK,GAAQ,EACb,mBACA,gCACA,mBACA,gCACA,2BACA,2BACA,mCACA,2BACA,CACA,CAAK,GAAS,EACd,UADc,iBAEd,mBACA,gCACA,mBACA,gCACA,2BACA,mCACA,2BACA,oBACA,CACA,CAAK,GAAO,EACZ,GADY,wBAEZ,2BACA,mCACA,gCACA,2BACA,oBACA,EAwEO,IACP,+BACA,+BACA,2CACA,2CACA,wBACA,wBACA,iDACA,uBACA,ECzIO,eACP,8BACA,wBAAsD,IAAmB,YAIzE,CACO,EALkE,OAKlE,MACP,wBACA,sBAA2C,IAAmB,YAI9D,CERO,EFIuD,aEJvD,YACP,4EACA,4BACA,CAAY,gBAA0B,eACtC,UAEA,MADA,uCACA,IAAkB,GA2BlB,OACA,IA5BgC,GAEhC,oBACA,eAEA,oBAAsC,GAAmB,0CACzD,YACA,CAAS,CACT,cACA,UAAoB,UAAc,eAClC,4BACA,YAAqC,GAAU,4CAC/C,UACA,MACA,CACA,WACA,UACA,oBAA8C,GAAmB,0CACjE,cAEA,UACA,MACA,CACA,oBAAsC,GAAmB,0CACzD,YACA,CACA,CAAK,EAGL,YACA,CACA,CC3CO,uBACP,KACA,iBACA,OACA,SACA,YACA,WACA,CACA,CACO,MAAM,WAAc,GAC3B,OAD2B,KAC3B,uBACA,0CACA,CACA,CAgBO,oBACP,qCACA,iDACA,CACA,CCoDA,IAAM,GAAM,0CACZ,iBACA,gBACA,2CAEA,QACA,gBACA,qBACA,OACA,OACA,MACA,SACA,EAEA,GACA,CACA,0CACA,CAcO,SAAS,GAAgB,GAChC,YAA2B,EADK,CACC,CAE1B,MAF0B,GAGjC,IACA,OACA,EAAK,EAHsB,CAGhB,gBACX,MACA,aACA,cACA,YACA,iBAEA,CACA,qBACA,gBAEA,iBACA,mBAKA,aACA,iBACA,CAIA,aACA,QACA,eACA,2BACA,gBACA,uBAEA,GAAqB,GAAgB,GACrC,cADqC,CACrC,CACA,+BAGA,gFAGA,eACA,CAIA,cACA,kBACA,CAIA,cACA,QACA,yBACA,2BACA,gBACA,0BAEA,GAAqB,GAAgB,GACrC,cADqC,CACrC,CACA,kCAGA,iFAGA,eACA,CAIA,OACA,sBACA,sBAKA,SACA,qBACA,iBACA,CAIA,aACA,2BACA,YAA4B,WAAgB,IAC5C,wBAGA,GAAiB,GAAgB,GACjC,YAA4B,WAAgB,IAC5C,4BAIA,+EAEA,CAIA,WAIA,iBAFA,mBAEA,QAIA,wBACA,aACA,cACA,MACA,CACA,yBACA,8BACA,2BACA,qCACA,sBAEA,CACA,sCACA,eACA,KACA,EAEA,CAOA,WACA,SAAgB,YAAe,mBAC/B,OAAe,GAAM,IACrB,CAOA,cACA,SAAgB,YAAe,0BAC/B,aACA,KAEe,GAAM,IACrB,CAMA,aACA,SAAgB,YAAe,mBAC/B,MAAyB,GAIzB,OAHA,WAEA,cACA,CACA,CACA,cASA,GARA,OACA,iBACA,KACA,kBAEA,KACA,kBAEA,mBACA,2CAEA,SACA,OAAqB,kBAErB,0BACA,OAAqB,mCAErB,SACA,IACA,YAAwB,mBAAsB,KAC9C,mBACA,IACA,iBAGA,GADA,IACA,KAEA,SAEA,gBACA,YACA,SAEA,iBAEA,UACA,KACA,CAEA,UACA,8BACA,KACA,CACA,MAEA,UAEA,UACA,QACA,CAEA,wBACA,QACA,CACA,MACA,UAEA,UACA,KACA,CAEA,0BACA,KACA,CAEA,SACA,CACA,YAAiB,aACjB,CACA,mBAuCA,EAtCA,IAAa,GAAgB,+BAC7B,+EAEA,6CAWA,GATA,MADA,iBAEA,MAEA,KACA,kBAEA,KACA,MAEA,aACA,mCAGA,mBACA,SACA,uDAIA,qBADA,KAGA,YAAwB,EAHxB,IAGmC,IAEnC,QAEA,YAAwB,IAAO,IAE/B,UAIA,mCACA,iBAEA,YAA6B,KAAgB,MAC7C,IACA,YAAuC,KAAQ,KAC/C,oBACA,aACA,qBACA,KACA,CACA,CACA,SACA,QAEA,CACA,SACA,CACA,WACA,2BAEA,OADA,iDACA,UACA,CACA,aACA,MAAoB,GAAW,GAC/B,KAD+B,QAC/B,oCACA,aACA,eACA,CACA,cACA,2BAEA,OADA,iDACA,aACA,CACA,gBACA,MAAoB,GAAK,GACzB,iDACA,gBACA,eACA,CACA,cACA,2BAEA,OADA,iDACA,aACA,CACA,gBACA,MAAoB,GAAK,GACzB,iDACA,gBACA,eACA,CACA,iBACA,2BAEA,OADA,iDACA,gBACA,CACA,mBACA,MAAoB,GAAK,GACzB,iDACA,mBACA,eACA,CACA,YACA,2BAEA,OADA,iDACA,WACA,CACA,cACA,MAAoB,GAAW,GAC/B,KAD+B,QAC/B,oCACA,cACA,eACA,CACA,eACA,2BAEA,WADA,6CACA,cACA,CACA,iBACA,MAAoB,GAAK,GAEzB,IADA,6CACA,iBACA,eACA,CACA,eACA,2BAEA,WADA,6CACA,cACA,CACA,iBACA,MAAoB,GAAK,GACzB,iDACA,iBACA,eACA,CACA,kBACA,2BAEA,OADA,iDACA,iBACA,CACA,oBACA,MAAoB,GAAK,GACzB,iDACA,oBACA,eACA,CACA,gBACA,2BAEA,WADA,6CACA,eACA,CACA,kBACA,MAAoB,GAAK,GACzB,iDACA,kBACA,eACA,CACA,gBACA,2BAEA,OADA,iDACA,eACA,CACA,kBACA,MAAoB,GAAK,GACzB,iDACA,kBACA,eACA,CACA,UACA,YAGA,eAA+B,GAAc,EAG7C,iCALA,SAQA,YAAwB,mBAAsB,IAC9C,IAAiB,GAAM,wBACvB,SAGA,QACA,CAKA,4BACA,UAAyB,GAMzB,OALA,QADuC,CAEvC,SACA,sCAEA,WACA,CACA,CACA,CCjiBoB,GAAoB,oBACtB,GAAoB,sBACF,gCIgDpC,OAlBA,YACA,GAHA,CAGQ,KAAe,CAHvB,UAoBwB,WApBxB,EAIA,QADuB,SAEvB,wBACA,qBACA,EAAyB,GAAgB,yBAEzC,QACA,EAAS,GAET,SACA,IACA,eACA,UACA,gBAEA,OAAW,GAAgB,IAC3B,EClDM,GAAc,GAAoB,kBAAvB,CAAuB,CACxC,GAAkB,GAAoB,eACtC,IADsC,QACtC,UAGA,eACA,UACA,WAkBA,QAjBA,QACA,YACA,QACA,eACA,QACA,wBACA,QACA,oBACA,QACA,iBACA,QACA,YACA,QACA,uBACA,QACA,kBACA,SAGA,CACA,EACM,GAAK,YACX,GADW,CACX,MACA,YAAoB,MAAS,IAC7B,QACA,cAAsB,MAAS,IAC/B,QACA,QACA,EACA,iBACA,2BACA,WACe,GAAoB,sCAExB,GAAoB,gDAC/B,EACA,eACA,MAAgB,GAAoB,cACpC,KADoC,EACpC,kCAIA,OAHA,qBACA,IAEA,GAAc,IAAa,EAAE,EAAI,CACjC,EAmBO,SAAS,GAAM,GACtB,aADsB,QACtB,KACA,SACA,KAIA,GAHA,qCACA,SAEQ,GAAoB,yBAC5B,YAEA,CAFqB,IAEV,GAAoB,oBAC/B,qBACA,UACA,YAEA,wCACA,cACA,QACA,GAA4B,sBAA+C,yBAG3E,YAAiC,GAAoB,2BAFrD,MAKA,MAAY,GAAoB,MAChC,aADgC,EAChC,YACA,uBACA,uBACA,yBACA,0CACA,OArGiB,GAqGS,WAC1B,UAD0B,MAC1B,EACA,MAAgB,GAAoB,iBAEpC,EAFoC,GAEpC,CAAY,GArGM,KAsGlB,SArGoB,KAsGpB,EAFuB,CACA,CADE,EAEzB,SACA,MAAgB,GAAoB,KAHC,CACA,CAED,OAEpC,KAFoC,CAEpC,SACA,MAAgB,GAAoB,cAEpC,KAFoC,CAEpC,yBACA,+BACA,SACA,MAAgB,GAAoB,QAEpC,SAAsB,EAFc,CAET,WAC3B,EACA,CCpHA,CDkH2B,EClH3B,QAAQ,2DAAsD,GAC9D,UAD4E,EAC5E,SACA,qBACA,wBAWA,SAAS,GAAU,UAEnB,EAFmB,CACnB,SAEA,qBAEA,iBACA,CACA,SAAS,GAAM,GACf,KADe,IACf,OACA,MAAwB,GAAc,GACtC,WACA,EAFsC,KAEtC,CAEA,CACA,OAAW,SAEF,CAAS,EAClB,EAHoB,EAGpB,EDkBO,KCnBW,IACqB,CDkBhC,EACP,QACA,eACA,8BAEA,kBACA,sCAEA,YACA,WACA,eACA,2CACA,6BAIA,OAAW,GAAoB,EAC/B,ECnCuC,GACvC,GACA,SDgC+B,QC/B/B,YACA,UACA,UACA,cACA,cACA,kBACA,oBACA,cACA,cACA,oBACA,mBACA,EACA,WAAe,GAAe,GAAc,YAAf,IAAe,QAA6C,GAAU,UAAoB,EAApB,CAAkC,CAAG,eAAH,CAAG,aAAoD,gCAC5L,EAnBoB,EACpB,CAmBO,cACP,0BACA,cAAyB,iBAA8B,KACvD,OACA,KACA,oCACA,aAlDA,cACA,aACA,4BACA,iCACA,0BACA,qBACA,wBACA,qBACA,CACA,EAyCA,QACA,0CACA,aACA,aACA,uBACA,EAIA,GAHA,oBACA,GAAuB,GAAoB,IAE3C,eAF2C,UAEG,GAAgB,IAC9D,aAD8D,EAC9D,CACA,MAAsB,GAAM,GAC5B,KAD4B,CACN,GAAgB,kBACtC,MAAsB,GAAU,QAChC,IADgC,IAEhC,CACA,yCACA,WACA,iEAEA,YAAkC,GAAkB,MAAO,GAAQ,IACnE,EADoD,IAC9B,GAAM,GAC5B,EAFmE,GACvC,GAE5B,CAEA,GADA,MAAkB,GAAM,GACxB,KADwB,IACxB,mCACA,SAEA,QACA,yBACA,YACA,CADyC,KACnB,GAAgB,kBAEtC,cACA,GAD2C,GAC3C,8BAAwD,GAAS,KAAK,QAAa,OAEnF,OAAkB,GAAU,OAC5B,CACA,IAF4B,EAE5B,EACA,CACA,CEhGA,kCAgBA,mBAdA,EACA,EAcA,wBACA,UAAkB,GAAc,GAAI,QAAY,OAAhB,aAAgB,GAEhD,OACA,QAjBA,0CACA,gBACA,QAeA,EAfA,iEAEA,CACA,KAYA,EAZA,KACA,OACA,QACA,YASA,EATA,MACA,mBAQA,EARA,uBACA,EAQA,EAIA,MAHA,mCACA,qBAEA,CACA,CACO,yBACP,YAAuB,GAAQ,OAC/B,oCACA,MAAe,GAAI,QAA+B,IAAI,EACtD,MACA,CACA,yBACA,MAAe,GAAK,CAAD,EAAU,UAA6C,GAAG,gBAAsD,EACnI,MACA,CACA,UAAc,GAAc,oBAC5B,CCtCO,SACP,gBACA,GACA,SAAmB,GAAO,EAC1B,CACA,CAF0B,GAE1B,GACA,sBACA,YACA,wCACA,mBACA,MACA,CACA,eAGA,CACA,WACA,sBAA4B,sBAAmC,CAC/D,CACA,cAEA,MADA,WAKA,CACA,UACA,kBACA,CACA,QACA,gBACA,CACA,CCnCA,WAAsB,GAAI,KAC1B,sGACA,qGACA,wHACA,wHAeO,eACP,2BACA,iBACA,YAjBA,GACA,kBACA,WACA,SACA,8BACA,WACA,SACA,cACA,iBACA,mCACA,oBACA,+BACA,6BACA,EAIA,WACA,gBAGA,gCAAwC,EAAU,qDAClD,CA8BA,kCAAiD,KAAK,gBA4B/C,6BAAgC,kBAAyB,QA2HhE,QAxHA,EACA,EAEA,EAsHA,EA3HA,8DACA,UAAY,+CAA6D,MAGzE,KAEA,cACA,IACA,EAAkB,GAAG,QAIrB,CACA,SACA,WACA,qDACA,MAKA,SADA,cAEA,QACA,SACA,gDAEA,KAEA,EADA,iDAEA,IASA,GANA,EADA,qCAC6B,GAAgB,GAIhB,GAAc,GAAG,OAAJ,GAE1C,kBACA,+DAEA,iCACA,SACA,UACA,gCACA,CACA,SACA,4BACA,SACA,kDACA,wDAAqF,EAAqB,KAAK,UAAY,MAG3H,2CACA,8CAA2E,EAAqB,KAAK,UAAY,IAEjH,CACA,YAEA,QAlFA,QAmFA,IAnFA,oCAoFA,EA1EA,yDA2EA,kDAEA,kDACA,IACA,8BACA,SACA,UACA,gCACA,CACA,SACA,4BACA,kDACA,SACA,CACA,CACA,CAEA,YACA,gBACA,iBAEA,qEAA6F,EAAU,GACvG,CACA,eAjIA,GACA,WACA,OAEA,oBACA,gBACA,uCACA,WACA,EAyHA,EACA,WAEA,SACA,wDAEA,mBAGA,SACA,wBAEA,aADA,aACA,CACA,qBACA,2BACA,CACA,kBACA,iCAEA,kBACA,kCAEA,CACA,OACA,WACA,MACA,MAWA,EAXA,EAWA,EAXA,MAYA,KACA,SACA,OAEA,YACA,MAAkB,cAAqB,EAAK,KAAU,EAAE,EAAQ,GAGhE,8BAEA,iBACA,mBAEA,gDAxBA,QACA,MACA,aAAsB,EAAS,GAAG,EAAqB,EAAE,oBAAwC,EAAQ,KAAO,EAEhH,CC7MA,mBACA,2BACA,cACA,gBACA,UAAsB,CACtB,SACA,CAAK,CACL,CACA,iBACA,cACA,CACA,iBACA,aACA,CACA,eACA,qBACA,CACO,mBACP,sBACA,QAAsB,CACtB,WACA,eACA,CAAK,EAOL,OANA,oBACA,MAEA,cACA,QACA,uCACA,CACA,CACO,mBACP,sBACA,QAAsB,CACtB,WACA,wBACA,CAAK,EAGL,OAFA,cACA,QACA,CACA,CACO,mBACP,sBACA,QAAsB,CACtB,WACA,4BACA,CAAK,EAIL,OAHA,kDACA,CAD+D,EAC/D,WACA,QACA,CACA,CACO,mBACP,sBACA,QAAsB,CACtB,WACA,2BACA,CAAK,EAGL,OAFA,cACA,QACA,CACA,CACO,mBACP,sBACA,QAAsB,CACtB,WACA,sBACA,CAAK,EAGL,OAFA,cACA,QACA,CACA,CAIO,mBACP,oBACA,cAEA,sBACA,QAAsB,CACtB,WACA,wBACA,CAAK,EAGL,OAFA,cACA,QACA,CACA,CACO,mBACP,yBACA,QAAsB,CACtB,WACA,+BACA,SACA,iBAAmC,CACnC,UACA,CACA,CAAK,EAGL,OAFA,cACA,QACA,CACA,CACO,iBAAsC,yBAAuB,QAOpE,EANA,qBACA,iBAEA,0BACA,iBAGA,IACA,kBACA,QAA0B,CAC1B,WACA,6BACA,SACA,iBAAuC,CACvC,0CAEA,CAAS,CACT,CACA,SAEA,OADA,8CACA,SACA,CAOA,OANA,oBACA,MAEA,cACA,QACA,uCACA,CACA,CAOO,mBACP,sBACA,QAAsB,CACtB,WACA,4CACA,CAAK,EAGL,OAFA,cACA,QACA,CACA,CC/IA,sBAEA,6BAAkC,IAAI,IACtC,EAEA,qBAA0C,EAAK,GAGxC,4BAAqC,oDAA0D,EACtG,mEACA,+EACA,YAEA,8BACA,4BACA,gBAEA,SADA,0BACA,iBAEA,OADA,6CACA,KAEA,sCAGA,IACA,MAAyB,GAAc,GACvC,QADuC,EACvC,GACA,YACA,aAOA,GANA,mCACA,UAAmC,SAAW,QAAQ,EAAW,EAGjE,UAAmC,uBAA8B,GAAG,WAAkB,GAAG,EAAW,EAEpG,iDAEA,OADA,4EACA,KAEA,gCAEA,OADA,8FACA,KAEA,mBAEA,OADA,iFACA,IAEA,sCAAmF,uBAA8B,kBAAmB,WAAkB,OACtJ,mCACA,mBAA2C,WAAgB,IAAI,EAAW,EAC1E,2BACA,8BAEA,IACA,iBAA8D,cAAgB,EAC9E,QAEA,OADA,mDACuB,GAAwB,oBAI/C,CAJ+C,MAG/C,uFACA,IAA0B,GAA0B,0BAEpD,CACA,SAEA,GADA,+BACA,gBAEA,OADA,0EACA,KAGA,OAAmB,GAAwB,oBAC3C,CAD2C,CAG3C,SAEA,+DACA,CACA,WACA,CC7EO,0BAAyC,WAAc,IAC9D,sBACA,OAAe,GAAc,CAAG,UAAH,EAAG,gBAAmC,IAEnE,MAAgB,GAAG,SACnB,WAEA,OACA,MACA,gBACA,QACA,QAAqB,CACrB,kBAA+B,aAAe,EAC9C,aACA,CAEA,0EAAiF,EAAS,EAC1F,CElBO,eAAe,GAAQ,WAE9B,EADA,EAD8B,EAC9B,KAEA,mBAA8B,GAAY,OAC1C,cACA,IAEA,WACA,UAAkB,GAAiB,6BAEnC,OACA,YACA,iBACA,CACA,CAUO,mBAAmC,qDAA+C,EACzF,IACA,aAAqB,GAAQ,KAAgB,UAAhB,GAA+B,GAAG,EAAK,IACpE,CACA,SAEA,GADA,4BACA,2EACA,OAAmB,GAAgB,GAGnC,OADA,GAFmC,IAEnC,8BACe,GAAkB,uBACjC,CACA,CCcA,QACA,gCACA,2BACA,2BACA,OAuBO,GACP,MACA,KACA,IACA,kBACA,+BACA,OAAkB,SAAa,IAC/B,aACA,uDACA,a3DoZO,Q2DpZ8B,C3DoZrB,CAAI,UAAe,MAAe,EAAI,EACtD,kBACA,E2DtZqC,GACrC,4CACA,4BAAsC,GAAQ,CAC9C,IAD8C,GAC9C,kBA7DA,IA8DA,qBA7DA,IA8DA,YACA,SACA,CACA,CAAS,EACT,gDACA,CACA,uBACA,MF1FO,YACP,MAAgB,GAAG,IEyF0B,CFzF1B,IACnB,WACA,gBAAyB,EAAI,EAE7B,IACA,gBAAyB,GAAG,oBAAuB,EAEnD,OACA,aAAY,0BAAiC,GAAgB,cAC7D,SAAc,EAAS,KAAK,EAAqB,GEgFJ,GAC7C,MACA,6BAEA,qCAKA,OAJA,UACA,2CACA,kCAEA,CACA,CAKA,iCAA6B,yBAA8B,MAI3D,EAHA,oCACA,OAAmB,GAAkB,uBAGrC,IACA,EAAqB,GAAgB,wBACrC,CACA,SAEA,OADA,6DACmB,GAAkB,IACrC,CAQA,UATqC,GASD,eAAkB,GAJ3B,GAAgB,CAC/B,EAD+B,CACX,QAGwC,EAFxE,SADgC,IAChC,SACA,EACwE,cACxE,sCAEA,EAAyB,GAAU,EADZ,GAAS,EACG,OADH,MACG,OAEnC,OADA,iEACA,CACA,CAKA,0BAAsB,4BAAiC,EAGvD,MAAuB,GADL,CvEXX,EuEWc,OvEXd,MAA6B,EACpC,IuEW8C,GvEX9C,WACA,GuESqB,CAAG,WADxB,4BACwB,6BAA2C,EACrB,aAC9C,EAAyB,GAAU,KAEnC,EAFmC,KACnC,wDAAwE,YACxE,CACA,CAKA,0BAAsB,mCAAuC,EAC7D,YAAyB,IAAS,SAAiB,EAAjB,CAClC,KAD0D,EACvC,GAAqB,kDAExC,kCAEA,EAAyB,GAAU,EADZ,GAAwB,EACZ,CADqB,SAAU,EAAI,GAAG,EAAK,GAAhC,CAAgC,KAG9E,OADA,kDACA,CACA,CACA,2BAAuB,4CAA+C,MAItE,EAHA,qCACA,kCACA,mBAEA,+DACA,IAIA,MAA4B,GAAkB,GAC9C,EAAuB,GAAkB,EACzC,CACA,KAH8C,CAG9C,GAEA,IAJyC,GAGzC,4EACuB,GAAqB,EAC5C,MAIA,IAEA,MAP4C,GAOT,KAEnC,EAFmC,KACnC,oDACA,CACA,CACA,qBAA0B,qDAA+C,MAmBzE,EAlBA,qCAEA,kCAEA,QAAkC,GAAiB,KAAG,SAAH,SAAG,sCAAyD,EAC/G,yBACA,SAEA,kBACA,GDzLA,CCyLY,UAAY,kBDzLxB,KC+LA,OADA,0DACmB,GAAoB,6CAEvC,QAPA,gBAOA,KAEA,+FAEA,SAEA,uCACA,IAIA,MAA4B,GAAkB,GAC9C,EAAuB,GAAkB,EACzC,CACA,KAH8C,CAG9C,GAEA,IAJyC,GAGzC,4EACuB,GAAqB,EAC5C,MAGA,IACA,EzBrOO,IyBgOqC,KzBhOrC,GACP,KyBoOwC,CzBpOxB,GAAM,GACtB,OADsB,SACtB,GACA,yBACA,YACA,iBACA,UACA,WACA,0BAKA,cACA,CAAK,EACL,gCAAoC,GAAM,GAC1C,EyBqNwC,EACxC,CACA,OzBxN0C,CyBwN1C,CACA,0BAEA,OADA,qGAC2B,GAAqB,GAEhD,eAFgD,+EAEhD,GACA,GACA,CAEA,MAAyB,GAAU,KAMnC,EANmC,KACnC,SACA,0EAEA,gCACQ,GAAY,KACpB,CACA,CACA,EAHoB,IAGpB,iBAAwB,wCAAuC,EAC/D,SACA,MAAqC,GAAgB,8BACrD,8BACA,QAAkC,GAAiB,KAAG,SAAH,SAAG,sCAAyD,EAC/G,yBACA,SAEA,kBACA,oBACA,QACA,0BACA,YAGA,GAFA,oDAEA,CACA,yBAEA,MADA,8EACA,6BAEA,0BAEA,OADA,sDAC2B,GAAwB,KAAc,EAAS,IAG1E,KAA8B,EAAS,GACvC,IACA,CACA,mBACA,IACA,uEACA,YAAoC,GAAQ,SAAU,EAAO,GAAG,EAAa,yBAC7E,iBACA,wBACA,CAAiB,EACjB,iEACA,IACA,QAEA,SAGA,OAFA,4BACA,2CACuB,GAAoB,uHAC3C,QACA,CACA,oBAA0C,GAAmB,8BAAiC,aAAiC,EAC/H,CACA,CAEA,2DACA,mCACA,gEAEA,eACA,WACA,gFACA,IAKA,OAJA,MAAgC,GAAQ,yBACxC,iBACA,wBACA,EAAa,EACb,SACA,iBACA,yBACA,SACA,QACA,CAAa,EACb,6CACA,WAAoB,gBAAqB,MAAQ,GAA0B,2BAC3E,yBACA,gBACA,CAAa,EACb,aAEA,MAA6B,GAAe,gCAAyC,eAAiC,EACtH,YACA,CAAa,EAGb,OAFA,iCACY,GAAY,KACxB,CACA,CACA,EAHwB,IAGxB,GAGA,GAFA,4BACA,8CACA,gDACA,OAAuB,GAAgB,GAEvC,OAAmB,GAFoB,EAEF,sCACrC,CACA,CACA,0BAAsB,4CAA+C,EAMrE,UAEA,OADA,0DACmB,GAAgB,sCAEnC,UAAqC,GAAgB,8BACrD,8BACA,mBACA,aACA,MAAyB,GAAe,gCAAyC,eAAiC,EAClH,aACA,CAAS,EAKT,OADA,yCA1SA,SAAsC,WAAiB,EAOvD,YAHA,CAFA,qCAEA,WACA,iBAA4B,OAC5B,iBACA,CACA,aACA,OAEA,sBACA,QAEA,CACA,EA2RA,CAAuF,4BAAmC,GAC1H,CACA,CACA,yDACA,MACA,gCACA,IACA,iCACA,kBACA,kCACA,GAA6B,CAAT,EAmJpB,WAnJ6B,CAC7B,UAD6B,EAC7B,CACA,UACA,KAEA,MACA,SACA,KAEA,CACA,SACA,8CACA,CAEA,oDACA,kCACA,CAKA,eACA,CAAS,GAAS,kBAClB,CAAS,GAAgB,iBACzB,CAAS,GAAQ,iBACjB,CAAS,GAAgB,oBACzB,CAAS,GAAO,gBAChB,CAAS,GAAQ,qBACjB,OAQA,eAKA,EACA,EACA,EACA,EACA,EACA,EAsBA,EACA,EA8CA,EA9EA,uBACA,eAzXA,OAIA,EAHA,WAUA,OALA,EADA,iBACA,OAGA,UAEA,CACA,KACA,QACA,CACA,EA0WA,GACA,oBAAkC,GAAmB,yCAAmC,EAAU,GAQlG,IACA,YAAiC,GAAa,GAAa,OAAb,EAAa,+BAA4C,IACvG,QACA,SACA,UACA,QACA,aACA,aAEA,SAGA,OAFA,4BACA,gDACmB,GAAkB,gBAErC,oBAAkC,GAAmB,sCAAqC,SAAW,GACrG,MpBnbO,gBAAmC,OoBmbU,GpBnbV,WAAwB,EAClE,wEACA,iBACA,0BAIA,GAHA,SACA,mCAEA,CAAS,SDUF,OAAuC,YAAgB,EAC9D,mBACA,ECZoC,OAAG,YAAgC,EAEvE,OADA,oFACA,EAEA,MFkIO,YACP,WACA,EEpIwD,KFoIxD,OEpIwD,WACxD,iBACA,yDAEA,QAOA,MALA,CAAS,GAAsB,IAAoB,GAAqB,KACxE,OAD+B,MAAyC,4EACxE,GACA,KAEA,sCACA,CACA,EoB4ZoD,OAAG,8CAA6D,EACpH,EtBxXO,cACP,EsBuXuC,EtBvXvC,aACA,WACA,gBAGA,KAoBA,aAnBA,EACA,WACA,QACA,uBAAuC,GACvC,OACA,YAAyB,KAAS,SAClC,gBAyCA,GAIA,GAHA,SACA,aAEA,yBACA,SAEA,4CACA,SACA,EAEA,CACA,EArDA,KACA,CACA,CAAK,EACL,YACA,oBACA,EAEA,kBACA,GAEA,GAEA,mBAEA,eACA,kBAGA,WAGA,uDAGA,oDARA,QAaA,EAvCA,IAEA,EsBmXuC,KAEvC,GADA,6BACA,iBACA,OAAmB,GAAqB,cAIxC,YAAuC,GAAmB,UAAG,MAAH,IAAG,iCAAmD,EAChH,WACA,SAEA,OAA8B,8EAC9B,0CAEA,gBACA,sCAEA,kCAEA,QACA,cACA,0BAAkD,aAAe,MACjE,+BAEA,kCAEA,QACA,cACA,0BAAkD,aAAe,MACjE,+BAEA,2BAEA,QACA,cACA,0BAAkD,aAAe,MACjE,8BAEA,CACA,kFAEA,iCACA,WACA,OAAuB,GAAoB,+BAAgC,QAAU,0GAErF,8CACA,sBACA,CAqBA,OApBA,qBvB7dO,OuB6dqC,EvB7drC,KAAmB,6CAA4C,EAEtE,qBAA8C,EAAU,EAIxD,MAHA,oBACA,QAAsB,OAAkB,GAAG,QAAgB,EAE3D,GAAc,CALd,cAKqB,GAAG,aAAe,EAAE,EAAO,IuBudJ,KAAG,sBAA6B,IACpE,S3B/dD,KAAiC,O2B+dX,I3B/dW,aAAyB,EACjE,MAEA,EADA,WACA,sCAEA,QAMA,sBAGA,mBAAyC,EAAI,EAE7C,gCACA,E2B8c6B,UAAG,mBAAyB,EACzD,+BAIA,iBACA,iBAGA,mBACA,SACA,aAEA,KAAoC,IAAqB,ExBhflD,YACP,QAQA,SwBuewF,exBvexF,YAPA,MACA,aAA4B,EAAS,GAErC,aAAwB,EAAU,GAAG,mBAAmB,sBAA6B,GwB2eG,YAAiB,GAEzG,SACA,uCAEA,oBAAkC,GAAmB,kCAAiC,SAAW,GACjG,CACA,CAIA,cACA,wBACA,CAIA,aACA,uBACA,CACA,CCmFO,2BA2BP,EAQA,EARA,EA1BA,EA4BA,qBACA,oBACA,aACA,eACA,gBA/BA,SAAqB,GAAe,CACpC,WADoC,EACpC,CACgB,GAAgB,CAChC,YADgC,EAChC,iBACA,wBACA,CAAiB,EACjB,CACA,YACA,oDAAwF,GAAoB,IAC5F,GAAkB,CAClC,cADkC,QAClC,mCACiB,EACjB,CACA,IAqBA,OADA,EApBA,iBAsBA,OAEA,iBACe,GAAG,CAClB,WACA,KACA,CACA,CAAS,EAEE,GAAG,WAAG,EAAW,CA9B5B,EAAS,EAET,UAAsC,GAAkB,CAAG,QAAa,IACxE,sBACA,mBACA,CAGA,OAFA,sBACA,wBACA,CACA,CClnBO,2BAIP,OAHA,SACA,SAAqB,IAAmB,EAExC,MACA,EACA,KAJwC,GAIxC,kBACA,gBACA,EACA,yBACA,eACA,4CGTA,kBACA,WACA,SAEA,iBACA,cACA,WACA,eACA,GFZA,YACA,iBACA,aACA,aACA,QAEA,cACA,wDAEA,CACA,EEE6B,GAC7B,WAAuC,OAAM,OAG7C,QAEA,CACA,QACA,CACA,aACA,cACA,2BDvBA,ECwBA,EDvBA,KCuBuB,EDvBvB,GCuB4B,IDvB5B,IACA,KAEA,YCqBA,CACA,WACA,cACA,SAEA,QACA,CACA,SACA,oBACA,OAgBA,gBACA,gBACA,SAEA,QACA,YAAwB,WAAqB,KAC7C,WACA,SAEA,iBAEA,WACA,EAEA,CACA,EA/BA,OAQA,QALA,EADA,2BACA,KAGA,UAEA,CACA,cACA,SAEA,QACA,CACA,CACA,iDCjDA,cACA,SACA,WACA,SACA,SAEA,QACA,KACA,KACA,KAKA,IAJA,uBACA,WACA,KAEA,MACA,WACA,EACA,gBAEA,UAEA,MACA,KAGA,KAGA,EACA,iBACA,IAEA,SACA,KACA,UACA,MAGA,KAIA,SACA,KACA,IACA,UACA,OAGA,QACA,IACA,UACA,MAIA,KAGA,GACA,CAIA,OAHA,GACA,UAEA,CACA","sources":["webpack://_N_E/./node_modules/hashlru/index.js","webpack://_N_E/./node_modules/iso-constants/index.browser.js","webpack://_N_E/./node_modules/murmurhash3js-revisited/index.js","webpack://_N_E/./node_modules/murmurhash3js-revisited/lib/murmurHash3js.js","webpack://_N_E/./node_modules/netmask/lib/netmask.js","webpack://_N_E/./node_modules/next/head.js","webpack://_N_E/./node_modules/pvtsutils/build/index.js","webpack://_N_E/./node_modules/qrcode/lib/browser.js","webpack://_N_E/./node_modules/qrcode/lib/can-promise.js","webpack://_N_E/./node_modules/qrcode/lib/core/alignment-pattern.js","webpack://_N_E/./node_modules/qrcode/lib/core/alphanumeric-data.js","webpack://_N_E/./node_modules/qrcode/lib/core/bit-buffer.js","webpack://_N_E/./node_modules/qrcode/lib/core/bit-matrix.js","webpack://_N_E/./node_modules/qrcode/lib/core/byte-data.js","webpack://_N_E/./node_modules/qrcode/lib/core/error-correction-code.js","webpack://_N_E/./node_modules/qrcode/lib/core/error-correction-level.js","webpack://_N_E/./node_modules/qrcode/lib/core/finder-pattern.js","webpack://_N_E/./node_modules/qrcode/lib/core/format-info.js","webpack://_N_E/./node_modules/qrcode/lib/core/galois-field.js","webpack://_N_E/./node_modules/qrcode/lib/core/kanji-data.js","webpack://_N_E/./node_modules/qrcode/lib/core/mask-pattern.js","webpack://_N_E/./node_modules/qrcode/lib/core/mode.js","webpack://_N_E/./node_modules/qrcode/lib/core/numeric-data.js","webpack://_N_E/./node_modules/qrcode/lib/core/polynomial.js","webpack://_N_E/./node_modules/qrcode/lib/core/qrcode.js","webpack://_N_E/./node_modules/qrcode/lib/core/reed-solomon-encoder.js","webpack://_N_E/./node_modules/qrcode/lib/core/regex.js","webpack://_N_E/./node_modules/qrcode/lib/core/segments.js","webpack://_N_E/./node_modules/qrcode/lib/core/utils.js","webpack://_N_E/./node_modules/qrcode/lib/core/version-check.js","webpack://_N_E/./node_modules/qrcode/lib/core/version.js","webpack://_N_E/./node_modules/qrcode/lib/renderer/canvas.js","webpack://_N_E/./node_modules/qrcode/lib/renderer/svg-tag.js","webpack://_N_E/./node_modules/qrcode/lib/renderer/utils.js","webpack://_N_E/./node_modules/sparse-array/index.js","webpack://_N_E/./node_modules/varint/decode.js","webpack://_N_E/./node_modules/varint/encode.js","webpack://_N_E/./node_modules/varint/index.js","webpack://_N_E/./node_modules/varint/length.js","webpack://_N_E/./node_modules/timestamp-nano/dist/timestamp.min.js","webpack://_N_E/./node_modules/@chakra-ui/accordion/dist/chunk-APVWO53B.mjs","webpack://_N_E/./node_modules/@chakra-ui/accordion/dist/chunk-I3JYRBXX.mjs","webpack://_N_E/./node_modules/@chakra-ui/accordion/dist/chunk-IXS34X2E.mjs","webpack://_N_E/./node_modules/@chakra-ui/transition/dist/chunk-LRMLOJAR.mjs","webpack://_N_E/./node_modules/@chakra-ui/accordion/dist/chunk-WA4Q3J7T.mjs","webpack://_N_E/./node_modules/@chakra-ui/layout/dist/chunk-DPSEBQMG.mjs","webpack://_N_E/./node_modules/@chakra-ui/layout/dist/chunk-UNOISFZK.mjs","webpack://_N_E/./node_modules/@chakra-ui/radio/dist/chunk-MEU4ZZ42.mjs","webpack://_N_E/./node_modules/@helia/interface/dist/src/blocks.js","webpack://_N_E/./node_modules/@helia/interface/dist/src/errors.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/events.browser.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/events.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/event-target.js","webpack://_N_E/./node_modules/multiformats/dist/src/bytes.js","webpack://_N_E/./node_modules/multiformats/dist/src/vendor/base-x.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base10.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base16.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base2.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base256emoji.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base32.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base36.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base58.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base64.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/base8.js","webpack://_N_E/./node_modules/multiformats/dist/src/bases/identity.js","webpack://_N_E/./node_modules/multiformats/dist/src/codecs/json.js","webpack://_N_E/./node_modules/multiformats/dist/src/codecs/raw.js","webpack://_N_E/./node_modules/multiformats/dist/src/vendor/varint.js","webpack://_N_E/./node_modules/multiformats/dist/src/varint.js","webpack://_N_E/./node_modules/multiformats/dist/src/hashes/digest.js","webpack://_N_E/./node_modules/multiformats/dist/src/hashes/identity.js","webpack://_N_E/./node_modules/multiformats/dist/src/hashes/hasher.js","webpack://_N_E/./node_modules/multiformats/dist/src/hashes/sha2-browser.js","webpack://_N_E/./node_modules/multiformats/dist/src/cid.js","webpack://_N_E/./node_modules/multiformats/dist/src/index.js","webpack://_N_E/./node_modules/multiformats/dist/src/basics.js","webpack://_N_E/./node_modules/uint8arrays/dist/src/alloc.js","webpack://_N_E/./node_modules/uint8arrays/dist/src/util/bases.js","webpack://_N_E/./node_modules/uint8arrays/dist/src/from-string.js","webpack://_N_E/./node_modules/uint8arrays/dist/src/equals.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/filters/fingerprint.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/filters/utils.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/filters/bucket.js","webpack://_N_E/./node_modules/@sindresorhus/fnv1a/index.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/filters/hashes.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/filters/cuckoo-filter.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/filters/scalable-cuckoo-filter.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/errors.js","webpack://_N_E/./node_modules/p-defer/index.js","webpack://_N_E/./node_modules/it-pushable/dist/src/fifo.js","webpack://_N_E/./node_modules/it-pushable/dist/src/index.js","webpack://_N_E/./node_modules/race-event/dist/src/index.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/errors.js","webpack://_N_E/./node_modules/race-signal/dist/src/index.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/queue/recipient.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/queue/job.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/queue/index.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/abstract-session.js","webpack://_N_E/./node_modules/@chainsafe/is-ip/lib/parser.js","webpack://_N_E/./node_modules/@chainsafe/is-ip/lib/parse.js","webpack://_N_E/./node_modules/@chainsafe/is-ip/lib/is-ip.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/private-ip.js","webpack://_N_E/./node_modules/@multiformats/multiaddr-matcher/dist/src/utils.js","webpack://_N_E/./node_modules/@multiformats/multiaddr-matcher/dist/src/index.js","webpack://_N_E/./node_modules/uint8arrays/dist/src/to-string.js","webpack://_N_E/./node_modules/uint8-varint/dist/src/index.js","webpack://_N_E/./node_modules/uint8arrays/dist/src/util/as-uint8array.js","webpack://_N_E/./node_modules/uint8arrays/dist/src/concat.js","webpack://_N_E/./node_modules/@chainsafe/netmask/dist/src/util.js","webpack://_N_E/./node_modules/@chainsafe/netmask/dist/src/ip.js","webpack://_N_E/./node_modules/@chainsafe/netmask/dist/src/cidr.js","webpack://_N_E/./node_modules/@chainsafe/netmask/dist/src/ipnet.js","webpack://_N_E/./node_modules/@chainsafe/netmask/dist/src/index.js","webpack://_N_E/./node_modules/@multiformats/multiaddr/dist/src/ip.js","webpack://_N_E/./node_modules/@multiformats/multiaddr/dist/src/protocols-table.js","webpack://_N_E/./node_modules/@multiformats/multiaddr/dist/src/convert.js","webpack://_N_E/./node_modules/@multiformats/multiaddr/dist/src/codec.js","webpack://_N_E/./node_modules/@multiformats/multiaddr/dist/src/multiaddr.js","webpack://_N_E/./node_modules/@multiformats/multiaddr/dist/src/filter/multiaddr-filter.js","webpack://_N_E/./node_modules/@multiformats/multiaddr/dist/src/index.js","webpack://_N_E/./node_modules/@multiformats/multiaddr-to-uri/dist/src/index.js","webpack://_N_E/./node_modules/@helia/block-brokers/dist/src/trustless-gateway/trustless-gateway.js","webpack://_N_E/./node_modules/@helia/block-brokers/dist/src/trustless-gateway/utils.js","webpack://_N_E/./node_modules/@helia/block-brokers/dist/src/trustless-gateway/session.js","webpack://_N_E/./node_modules/@helia/block-brokers/dist/src/trustless-gateway/broker.js","webpack://_N_E/./node_modules/@helia/block-brokers/dist/src/trustless-gateway/index.js","webpack://_N_E/./node_modules/@helia/block-brokers/dist/src/index.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/content-routing/index.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/peer-routing/index.js","webpack://_N_E/./node_modules/weald/node_modules/ms/dist/index.mjs","webpack://_N_E/./node_modules/weald/dist/src/common.js","webpack://_N_E/./node_modules/weald/dist/src/browser.js","webpack://_N_E/./node_modules/weald/dist/src/index.js","webpack://_N_E/./node_modules/@libp2p/logger/dist/src/index.js","webpack://_N_E/./node_modules/@noble/hashes/esm/sha512.js","webpack://_N_E/./node_modules/@noble/curves/esm/abstract/modular.js","webpack://_N_E/./node_modules/@noble/curves/esm/abstract/curve.js","webpack://_N_E/./node_modules/@noble/curves/esm/abstract/edwards.js","webpack://_N_E/./node_modules/@noble/curves/esm/ed25519.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/ed25519/index.browser.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/ed25519/ed25519.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/ed25519/utils.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/utils/float.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/utils/longbits.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/utils/utf8.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/utils/reader.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/decode.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/utils/pool.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/utils/writer.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/encode.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/codec.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/codecs/enum.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/codecs/message.js","webpack://_N_E/./node_modules/protons-runtime/dist/src/index.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/keys.js","webpack://_N_E/./node_modules/pvutils/build/utils.es.js","webpack://_N_E/./node_modules/asn1js/build/index.es.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/errors.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/webcrypto/webcrypto.browser.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/webcrypto/index.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/rsa/index.browser.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/rsa/rsa.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/rsa/utils.js","webpack://_N_E/./node_modules/@noble/hashes/esm/hmac.js","webpack://_N_E/./node_modules/@noble/curves/esm/abstract/weierstrass.js","webpack://_N_E/./node_modules/@noble/curves/esm/_shortw_utils.js","webpack://_N_E/./node_modules/@noble/curves/esm/secp256k1.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/util.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/secp256k1/index.browser.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/secp256k1/secp256k1.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/secp256k1/utils.js","webpack://_N_E/./node_modules/@libp2p/crypto/dist/src/keys/index.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/peer-id/index.js","webpack://_N_E/./node_modules/@libp2p/peer-id/dist/src/peer-id.js","webpack://_N_E/./node_modules/@libp2p/peer-id/dist/src/index.js","webpack://_N_E/./node_modules/any-signal/dist/src/index.js","webpack://_N_E/./node_modules/browser-readablestream-to-it/dist/src/index.js","webpack://_N_E/./node_modules/cborg/lib/is.js","webpack://_N_E/./node_modules/cborg/lib/token.js","webpack://_N_E/./node_modules/cborg/lib/byte-utils.js","webpack://_N_E/./node_modules/cborg/lib/bl.js","webpack://_N_E/./node_modules/cborg/lib/common.js","webpack://_N_E/./node_modules/cborg/lib/0uint.js","webpack://_N_E/./node_modules/cborg/lib/1negint.js","webpack://_N_E/./node_modules/cborg/lib/2bytes.js","webpack://_N_E/./node_modules/cborg/lib/3string.js","webpack://_N_E/./node_modules/cborg/lib/4array.js","webpack://_N_E/./node_modules/cborg/lib/5map.js","webpack://_N_E/./node_modules/cborg/lib/6tag.js","webpack://_N_E/./node_modules/cborg/lib/7float.js","webpack://_N_E/./node_modules/cborg/lib/jump.js","webpack://_N_E/./node_modules/cborg/lib/encode.js","webpack://_N_E/./node_modules/cborg/lib/decode.js","webpack://_N_E/./node_modules/cborg/cborg.js","webpack://_N_E/./node_modules/ipns/dist/src/errors.js","webpack://_N_E/./node_modules/ipns/dist/src/pb/ipns.js","webpack://_N_E/./node_modules/ipns/dist/src/utils.js","webpack://_N_E/./node_modules/ipns/dist/src/validator.js","webpack://_N_E/./node_modules/it-ndjson/dist/src/parse.js","webpack://_N_E/./node_modules/p-timeout/index.js","webpack://_N_E/./node_modules/p-queue/dist/lower-bound.js","webpack://_N_E/./node_modules/p-queue/dist/priority-queue.js","webpack://_N_E/./node_modules/p-queue/dist/index.js","webpack://_N_E/./node_modules/@helia/delegated-routing-v1-http-api-client/dist/src/errors.js","webpack://_N_E/./node_modules/it-first/dist/src/index.js","webpack://_N_E/./node_modules/it-peekable/dist/src/index.js","webpack://_N_E/./node_modules/it-map/dist/src/index.js","webpack://_N_E/./node_modules/@helia/delegated-routing-v1-http-api-client/dist/src/routings.js","webpack://_N_E/./node_modules/@helia/delegated-routing-v1-http-api-client/dist/src/client.js","webpack://_N_E/./node_modules/@helia/delegated-routing-v1-http-api-client/dist/src/index.js","webpack://_N_E/./node_modules/@helia/routers/dist/src/utils/delegated-http-routing-defaults.browser.js","webpack://_N_E/./node_modules/@helia/routers/dist/src/delegated-http-routing.js","webpack://_N_E/./node_modules/ip-regex/index.js","webpack://_N_E/./node_modules/function-timeout/browser.js","webpack://_N_E/./node_modules/is-regexp/index.js","webpack://_N_E/./node_modules/clone-regexp/index.js","webpack://_N_E/./node_modules/super-regex/index.js","webpack://_N_E/./node_modules/is-ip/index.js","webpack://_N_E/./node_modules/@multiformats/uri-to-multiaddr/dist/src/index.js","webpack://_N_E/./node_modules/@helia/routers/dist/src/http-gateway-routing.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/startable.js","webpack://_N_E/./node_modules/progress-events/dist/src/index.js","webpack://_N_E/./node_modules/@multiformats/dns/dist/src/utils/get-types.js","webpack://_N_E/./node_modules/@multiformats/dns/dist/src/utils/to-dns-response.js","webpack://_N_E/./node_modules/@multiformats/dns/dist/src/resolvers/dns-json-over-https.js","webpack://_N_E/./node_modules/@multiformats/dns/dist/src/resolvers/default.browser.js","webpack://_N_E/./node_modules/@multiformats/dns/dist/src/utils/cache.js","webpack://_N_E/./node_modules/@multiformats/dns/dist/src/dns.js","webpack://_N_E/./node_modules/@multiformats/dns/dist/src/index.js","webpack://_N_E/./node_modules/it-drain/dist/src/index.js","webpack://_N_E/./node_modules/interface-datastore/dist/src/key.js","webpack://_N_E/./node_modules/interface-datastore/dist/src/index.js","webpack://_N_E/./node_modules/multiformats/dist/src/block.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/pins.js","webpack://_N_E/./node_modules/@libp2p/utils/dist/src/peer-queue.js","webpack://_N_E/./node_modules/it-merge/dist/src/index.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/routing.js","webpack://_N_E/./node_modules/observable-webworkers/dist/src/index.js","webpack://_N_E/./node_modules/mortice/dist/src/constants.js","webpack://_N_E/./node_modules/mortice/dist/src/utils.js","webpack://_N_E/./node_modules/mortice/dist/src/browser.js","webpack://_N_E/./node_modules/mortice/dist/src/index.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/storage.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/utils/datastore-version.js","webpack://_N_E/./node_modules/@ipld/dag-cbor/src/index.js","webpack://_N_E/./node_modules/cborg/lib/json/encode.js","webpack://_N_E/./node_modules/cborg/lib/json/decode.js","webpack://_N_E/./node_modules/cborg/lib/json/json.js","webpack://_N_E/./node_modules/@ipld/dag-json/src/index.js","webpack://_N_E/./node_modules/@ipld/dag-pb/src/pb-decode.js","webpack://_N_E/./node_modules/@ipld/dag-pb/src/pb-encode.js","webpack://_N_E/./node_modules/@ipld/dag-pb/src/util.js","webpack://_N_E/./node_modules/@ipld/dag-pb/src/index.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/utils/is-promise.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/utils/get-codec.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/utils/get-hasher.js","webpack://_N_E/./node_modules/interface-store/dist/src/errors.js","webpack://_N_E/./node_modules/interface-store/dist/src/index.js","webpack://_N_E/./node_modules/blockstore-core/dist/src/base.js","webpack://_N_E/./node_modules/blockstore-core/dist/src/identity.js","webpack://_N_E/./node_modules/it-filter/dist/src/index.js","webpack://_N_E/./node_modules/it-foreach/dist/src/index.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/utils/networked-storage.js","webpack://_N_E/./node_modules/@helia/utils/dist/src/index.js","webpack://_N_E/./node_modules/blockstore-core/dist/src/memory.js","webpack://_N_E/./node_modules/blockstore-core/dist/src/black-hole.js","webpack://_N_E/./node_modules/blockstore-core/dist/src/tiered.js","webpack://_N_E/./node_modules/blockstore-core/dist/src/index.js","webpack://_N_E/./node_modules/datastore-core/dist/src/shard.js","webpack://_N_E/./node_modules/it-all/dist/src/index.js","webpack://_N_E/./node_modules/it-sort/dist/src/index.js","webpack://_N_E/./node_modules/it-take/dist/src/index.js","webpack://_N_E/./node_modules/datastore-core/dist/src/base.js","webpack://_N_E/./node_modules/datastore-core/dist/src/memory.js","webpack://_N_E/./node_modules/it-pipe/dist/src/index.js","webpack://_N_E/./node_modules/datastore-core/dist/src/keytransform.js","webpack://_N_E/./node_modules/datastore-core/dist/src/sharding.js","webpack://_N_E/./node_modules/datastore-core/dist/src/mount.js","webpack://_N_E/./node_modules/datastore-core/dist/src/tiered.js","webpack://_N_E/./node_modules/datastore-core/dist/src/namespace.js","webpack://_N_E/./node_modules/datastore-core/dist/src/index.js","webpack://_N_E/./node_modules/@helia/http/dist/src/index.js","webpack://_N_E/./node_modules/@ipld/car/src/decoder-common.js","webpack://_N_E/./node_modules/@ipld/car/src/header-validator.js","webpack://_N_E/./node_modules/@ipld/car/src/buffer-decoder.js","webpack://_N_E/./node_modules/@ipld/car/src/buffer-reader-browser.js","webpack://_N_E/./node_modules/cborg/lib/length.js","webpack://_N_E/./node_modules/@ipld/car/src/buffer-writer.js","webpack://_N_E/./node_modules/@ipld/car/src/decoder.js","webpack://_N_E/./node_modules/@ipld/car/src/indexer.js","webpack://_N_E/./node_modules/@ipld/car/src/iterator.js","webpack://_N_E/./node_modules/@ipld/car/src/reader-browser.js","webpack://_N_E/./node_modules/@ipld/car/src/encoder.js","webpack://_N_E/./node_modules/@ipld/car/src/iterator-channel.js","webpack://_N_E/./node_modules/@ipld/car/src/writer-browser.js","webpack://_N_E/./node_modules/@ipld/car/src/index-browser.js","webpack://_N_E/./node_modules/@helia/car/dist/src/index.js","webpack://_N_E/./node_modules/@libp2p/interface/dist/src/keys/index.js","webpack://_N_E/./node_modules/ipns/dist/src/index.js","webpack://_N_E/./node_modules/ipns/dist/src/selector.js","webpack://_N_E/./node_modules/@helia/ipns/dist/src/errors.js","webpack://_N_E/./node_modules/@helia/ipns/dist/src/dnslink.js","webpack://_N_E/./node_modules/@helia/ipns/dist/src/routing/helia.js","webpack://_N_E/./node_modules/@libp2p/record/dist/src/record.js","webpack://_N_E/./node_modules/@libp2p/record/dist/src/utils.js","webpack://_N_E/./node_modules/@libp2p/record/dist/src/index.js","webpack://_N_E/./node_modules/@helia/ipns/dist/src/routing/local-store.js","webpack://_N_E/./node_modules/@helia/ipns/dist/src/utils.js","webpack://_N_E/./node_modules/@helia/ipns/dist/src/index.js","webpack://_N_E/./node_modules/it-last/dist/src/index.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/errors.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/utils/resolve-object-path.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/dag-cbor.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/dag-json.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/utils/extract-data-from-block.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/utils/validate-offset-and-length.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/identity.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/json.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/raw.js","webpack://_N_E/./node_modules/ipfs-unixfs/dist/src/errors.js","webpack://_N_E/./node_modules/ipfs-unixfs/dist/src/unixfs.js","webpack://_N_E/./node_modules/ipfs-unixfs/dist/src/index.js","webpack://_N_E/./node_modules/@multiformats/murmur3/src/index.js","webpack://_N_E/./node_modules/hamt-sharding/dist/src/bucket.js","webpack://_N_E/./node_modules/hamt-sharding/dist/src/consumable-buffer.js","webpack://_N_E/./node_modules/hamt-sharding/dist/src/consumable-hash.js","webpack://_N_E/./node_modules/hamt-sharding/dist/src/index.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/utils/find-cid-in-shard.js","webpack://_N_E/./node_modules/it-parallel/dist/src/index.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/directory.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/file.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/content/hamt-sharded-directory.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/unixfs-v1/index.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/resolvers/index.js","webpack://_N_E/./node_modules/ipfs-unixfs-exporter/dist/src/index.js","webpack://_N_E/./node_modules/get-iterator/dist/src/index.js","webpack://_N_E/./node_modules/it-to-browser-readablestream/dist/src/index.js","webpack://_N_E/./node_modules/@helia/verified-fetch/node_modules/lru-cache/dist/esm/index.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/errors.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/request-headers.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/response-headers.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/byte-range-context.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/dag-cbor-to-safe-json.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/get-content-disposition-filename.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/get-e-tag.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/select-output-type.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/is-accept-explicit.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/get-resolved-accept-header.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/get-stream-from-async-iterable.js","webpack://_N_E/./node_modules/@helia/unixfs/dist/src/errors.js","webpack://_N_E/./node_modules/uint8arraylist/dist/src/index.js","webpack://_N_E/./node_modules/it-tar/dist/src/extract-headers.js","webpack://_N_E/./node_modules/it-reader/dist/src/index.js","webpack://_N_E/./node_modules/it-tar/dist/src/lte-reader.js","webpack://_N_E/./node_modules/it-tar/dist/src/extract.js","webpack://_N_E/./node_modules/it-to-buffer/dist/src/index.js","webpack://_N_E/./node_modules/it-tar/dist/src/pack-headers.js","webpack://_N_E/./node_modules/it-tar/dist/src/pack.js","webpack://_N_E/./node_modules/it-tar/dist/src/index.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/get-tar-stream.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/tlru.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/parse-url-string.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/responses.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/handle-redirects.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/parse-resource.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/resource-to-cache-key.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/utils/walk-path.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/verified-fetch.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/index.js","webpack://_N_E/./node_modules/@helia/verified-fetch/dist/src/singleton.js","webpack://_N_E/./node_modules/es-toolkit/dist/compat/_internal/isDeepKey.mjs","webpack://_N_E/./node_modules/es-toolkit/dist/compat/_internal/toKey.mjs","webpack://_N_E/./node_modules/es-toolkit/dist/compat/object/get.mjs","webpack://_N_E/./node_modules/es-toolkit/dist/compat/util/toPath.mjs"],"sourcesContent":["module.exports = function (max) {\n\n  if (!max) throw Error('hashlru must have a max value, of type number, greater than 0')\n\n  var size = 0, cache = Object.create(null), _cache = Object.create(null)\n\n  function update (key, value) {\n    cache[key] = value\n    size ++\n    if(size >= max) {\n      size = 0\n      _cache = cache\n      cache = Object.create(null)\n    }\n  }\n\n  return {\n    has: function (key) {\n      return cache[key] !== undefined || _cache[key] !== undefined\n    },\n    remove: function (key) {\n      if(cache[key] !== undefined)\n        cache[key] = undefined\n      if(_cache[key] !== undefined)\n        _cache[key] = undefined\n    },\n    get: function (key) {\n      var v = cache[key]\n      if(v !== undefined) return v\n      if((v = _cache[key]) !== undefined) {\n        update(key, v)\n        return v\n      }\n    },\n    set: function (key, value) {\n      if(cache[key] !== undefined) cache[key] = value\n      else update(key, value)\n    },\n    clear: function () {\n      cache = Object.create(null)\n      _cache = Object.create(null)\n    }\n  }\n}\n\n\n\n\n\n\n\n","\n'use strict';\n\nmodule.exports = {\n    'RTLD_LAZY': 1,\n    'RTLD_NOW': 2,\n    'RTLD_GLOBAL': 8,\n    'RTLD_LOCAL': 4,\n    'E2BIG': 7,\n    'EACCES': 13,\n    'EADDRINUSE': 48,\n    'EADDRNOTAVAIL': 49,\n    'EAFNOSUPPORT': 47,\n    'EAGAIN': 35,\n    'EALREADY': 37,\n    'EBADF': 9,\n    'EBADMSG': 94,\n    'EBUSY': 16,\n    'ECANCELED': 89,\n    'ECHILD': 10,\n    'ECONNABORTED': 53,\n    'ECONNREFUSED': 61,\n    'ECONNRESET': 54,\n    'EDEADLK': 11,\n    'EDESTADDRREQ': 39,\n    'EDOM': 33,\n    'EDQUOT': 69,\n    'EEXIST': 17,\n    'EFAULT': 14,\n    'EFBIG': 27,\n    'EHOSTUNREACH': 65,\n    'EIDRM': 90,\n    'EILSEQ': 92,\n    'EINPROGRESS': 36,\n    'EINTR': 4,\n    'EINVAL': 22,\n    'EIO': 5,\n    'EISCONN': 56,\n    'EISDIR': 21,\n    'ELOOP': 62,\n    'EMFILE': 24,\n    'EMLINK': 31,\n    'EMSGSIZE': 40,\n    'EMULTIHOP': 95,\n    'ENAMETOOLONG': 63,\n    'ENETDOWN': 50,\n    'ENETRESET': 52,\n    'ENETUNREACH': 51,\n    'ENFILE': 23,\n    'ENOBUFS': 55,\n    'ENODATA': 96,\n    'ENODEV': 19,\n    'ENOENT': 2,\n    'ENOEXEC': 8,\n    'ENOLCK': 77,\n    'ENOLINK': 97,\n    'ENOMEM': 12,\n    'ENOMSG': 91,\n    'ENOPROTOOPT': 42,\n    'ENOSPC': 28,\n    'ENOSR': 98,\n    'ENOSTR': 99,\n    'ENOSYS': 78,\n    'ENOTCONN': 57,\n    'ENOTDIR': 20,\n    'ENOTEMPTY': 66,\n    'ENOTSOCK': 38,\n    'ENOTSUP': 45,\n    'ENOTTY': 25,\n    'ENXIO': 6,\n    'EOPNOTSUPP': 102,\n    'EOVERFLOW': 84,\n    'EPERM': 1,\n    'EPIPE': 32,\n    'EPROTO': 100,\n    'EPROTONOSUPPORT': 43,\n    'EPROTOTYPE': 41,\n    'ERANGE': 34,\n    'EROFS': 30,\n    'ESPIPE': 29,\n    'ESRCH': 3,\n    'ESTALE': 70,\n    'ETIME': 101,\n    'ETIMEDOUT': 60,\n    'ETXTBSY': 26,\n    'EWOULDBLOCK': 35,\n    'EXDEV': 18,\n    'PRIORITY_LOW': 19,\n    'PRIORITY_BELOW_NORMAL': 10,\n    'PRIORITY_NORMAL': 0,\n    'PRIORITY_ABOVE_NORMAL': -7,\n    'PRIORITY_HIGH': -14,\n    'PRIORITY_HIGHEST': -20,\n    'SIGHUP': 1,\n    'SIGINT': 2,\n    'SIGQUIT': 3,\n    'SIGILL': 4,\n    'SIGTRAP': 5,\n    'SIGABRT': 6,\n    'SIGIOT': 6,\n    'SIGBUS': 10,\n    'SIGFPE': 8,\n    'SIGKILL': 9,\n    'SIGUSR1': 30,\n    'SIGSEGV': 11,\n    'SIGUSR2': 31,\n    'SIGPIPE': 13,\n    'SIGALRM': 14,\n    'SIGTERM': 15,\n    'SIGCHLD': 20,\n    'SIGCONT': 19,\n    'SIGSTOP': 17,\n    'SIGTSTP': 18,\n    'SIGTTIN': 21,\n    'SIGTTOU': 22,\n    'SIGURG': 16,\n    'SIGXCPU': 24,\n    'SIGXFSZ': 25,\n    'SIGVTALRM': 26,\n    'SIGPROF': 27,\n    'SIGWINCH': 28,\n    'SIGIO': 23,\n    'SIGINFO': 29,\n    'SIGSYS': 12,\n    'UV_FS_SYMLINK_DIR': 1,\n    'UV_FS_SYMLINK_JUNCTION': 2,\n    'O_RDONLY': 0,\n    'O_WRONLY': 1,\n    'O_RDWR': 2,\n    'UV_DIRENT_UNKNOWN': 0,\n    'UV_DIRENT_FILE': 1,\n    'UV_DIRENT_DIR': 2,\n    'UV_DIRENT_LINK': 3,\n    'UV_DIRENT_FIFO': 4,\n    'UV_DIRENT_SOCKET': 5,\n    'UV_DIRENT_CHAR': 6,\n    'UV_DIRENT_BLOCK': 7,\n    'EXTENSIONLESS_FORMAT_JAVASCRIPT': 0,\n    'EXTENSIONLESS_FORMAT_WASM': 1,\n    'S_IFMT': 61440,\n    'S_IFREG': 32768,\n    'S_IFDIR': 16384,\n    'S_IFCHR': 8192,\n    'S_IFBLK': 24576,\n    'S_IFIFO': 4096,\n    'S_IFLNK': 40960,\n    'S_IFSOCK': 49152,\n    'O_CREAT': 512,\n    'O_EXCL': 2048,\n    'UV_FS_O_FILEMAP': 0,\n    'O_NOCTTY': 131072,\n    'O_TRUNC': 1024,\n    'O_APPEND': 8,\n    'O_DIRECTORY': 1048576,\n    'O_NOFOLLOW': 256,\n    'O_SYNC': 128,\n    'O_DSYNC': 4194304,\n    'O_SYMLINK': 2097152,\n    'O_NONBLOCK': 4,\n    'S_IRWXU': 448,\n    'S_IRUSR': 256,\n    'S_IWUSR': 128,\n    'S_IXUSR': 64,\n    'S_IRWXG': 56,\n    'S_IRGRP': 32,\n    'S_IWGRP': 16,\n    'S_IXGRP': 8,\n    'S_IRWXO': 7,\n    'S_IROTH': 4,\n    'S_IWOTH': 2,\n    'S_IXOTH': 1,\n    'F_OK': 0,\n    'R_OK': 4,\n    'W_OK': 2,\n    'X_OK': 1,\n    'UV_FS_COPYFILE_EXCL': 1,\n    'COPYFILE_EXCL': 1,\n    'UV_FS_COPYFILE_FICLONE': 2,\n    'COPYFILE_FICLONE': 2,\n    'UV_FS_COPYFILE_FICLONE_FORCE': 4,\n    'COPYFILE_FICLONE_FORCE': 4,\n    'OPENSSL_VERSION_NUMBER': 805306608,\n    'SSL_OP_ALL': 2147485776,\n    'SSL_OP_ALLOW_NO_DHE_KEX': 1024,\n    'SSL_OP_ALLOW_UNSAFE_LEGACY_RENEGOTIATION': 262144,\n    'SSL_OP_CIPHER_SERVER_PREFERENCE': 4194304,\n    'SSL_OP_CISCO_ANYCONNECT': 32768,\n    'SSL_OP_COOKIE_EXCHANGE': 8192,\n    'SSL_OP_CRYPTOPRO_TLSEXT_BUG': 2147483648,\n    'SSL_OP_DONT_INSERT_EMPTY_FRAGMENTS': 2048,\n    'SSL_OP_LEGACY_SERVER_CONNECT': 4,\n    'SSL_OP_NO_COMPRESSION': 131072,\n    'SSL_OP_NO_ENCRYPT_THEN_MAC': 524288,\n    'SSL_OP_NO_QUERY_MTU': 4096,\n    'SSL_OP_NO_RENEGOTIATION': 1073741824,\n    'SSL_OP_NO_SESSION_RESUMPTION_ON_RENEGOTIATION': 65536,\n    'SSL_OP_NO_SSLv2': 0,\n    'SSL_OP_NO_SSLv3': 33554432,\n    'SSL_OP_NO_TICKET': 16384,\n    'SSL_OP_NO_TLSv1': 67108864,\n    'SSL_OP_NO_TLSv1_1': 268435456,\n    'SSL_OP_NO_TLSv1_2': 134217728,\n    'SSL_OP_NO_TLSv1_3': 536870912,\n    'SSL_OP_PRIORITIZE_CHACHA': 2097152,\n    'SSL_OP_TLS_ROLLBACK_BUG': 8388608,\n    'ENGINE_METHOD_RSA': 1,\n    'ENGINE_METHOD_DSA': 2,\n    'ENGINE_METHOD_DH': 4,\n    'ENGINE_METHOD_RAND': 8,\n    'ENGINE_METHOD_EC': 2048,\n    'ENGINE_METHOD_CIPHERS': 64,\n    'ENGINE_METHOD_DIGESTS': 128,\n    'ENGINE_METHOD_PKEY_METHS': 512,\n    'ENGINE_METHOD_PKEY_ASN1_METHS': 1024,\n    'ENGINE_METHOD_ALL': 65535,\n    'ENGINE_METHOD_NONE': 0,\n    'DH_CHECK_P_NOT_SAFE_PRIME': 2,\n    'DH_CHECK_P_NOT_PRIME': 1,\n    'DH_UNABLE_TO_CHECK_GENERATOR': 4,\n    'DH_NOT_SUITABLE_GENERATOR': 8,\n    'RSA_PKCS1_PADDING': 1,\n    'RSA_NO_PADDING': 3,\n    'RSA_PKCS1_OAEP_PADDING': 4,\n    'RSA_X931_PADDING': 5,\n    'RSA_PKCS1_PSS_PADDING': 6,\n    'RSA_PSS_SALTLEN_DIGEST': -1,\n    'RSA_PSS_SALTLEN_MAX_SIGN': -2,\n    'RSA_PSS_SALTLEN_AUTO': -2,\n    'defaultCoreCipherList': 'TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:DHE-RSA-AES256-SHA384:ECDHE-RSA-AES256-SHA256:DHE-RSA-AES256-SHA256:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!SRP:!CAMELLIA',\n    'TLS1_VERSION': 769,\n    'TLS1_1_VERSION': 770,\n    'TLS1_2_VERSION': 771,\n    'TLS1_3_VERSION': 772,\n    'POINT_CONVERSION_COMPRESSED': 2,\n    'POINT_CONVERSION_UNCOMPRESSED': 4,\n    'POINT_CONVERSION_HYBRID': 6\n};\n\n","module.exports = require('./lib/murmurHash3js');\n","/* jshint -W086: true */\n// +----------------------------------------------------------------------+\n// | murmurHash3js.js v3.0.1 // https://github.com/pid/murmurHash3js\n// | A javascript implementation of MurmurHash3's x86 hashing algorithms. |\n// |----------------------------------------------------------------------|\n// | Copyright (c) 2012-2015 Karan Lyons                                       |\n// | https://github.com/karanlyons/murmurHash3.js/blob/c1778f75792abef7bdd74bc85d2d4e1a3d25cfe9/murmurHash3.js |\n// | Freely distributable under the MIT license.                          |\n// +----------------------------------------------------------------------+\n\n;(function (root, undefined) {\n    'use strict';\n\n    // Create a local object that'll be exported or referenced globally.\n    var library = {\n        'version': '3.0.0',\n        'x86': {},\n        'x64': {},\n        'inputValidation': true\n    };\n\n    // PRIVATE FUNCTIONS\n    // -----------------\n\n    function _validBytes(bytes) {\n        // check the input is an array or a typed array\n        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {\n            return false;\n        }\n\n        // check all bytes are actually bytes\n        for (var i = 0; i < bytes.length; i++) {\n            if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    function _x86Multiply(m, n) {\n        //\n        // Given two 32bit ints, returns the two multiplied together as a\n        // 32bit int.\n        //\n\n        return ((m & 0xffff) * n) + ((((m >>> 16) * n) & 0xffff) << 16);\n    }\n\n    function _x86Rotl(m, n) {\n        //\n        // Given a 32bit int and an int representing a number of bit positions,\n        // returns the 32bit int rotated left by that number of positions.\n        //\n\n        return (m << n) | (m >>> (32 - n));\n    }\n\n    function _x86Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x86 mix of that block.\n        //\n\n        h ^= h >>> 16;\n        h = _x86Multiply(h, 0x85ebca6b);\n        h ^= h >>> 13;\n        h = _x86Multiply(h, 0xc2b2ae35);\n        h ^= h >>> 16;\n\n        return h;\n    }\n\n    function _x64Add(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // added together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] + n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] + n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] + n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += m[0] + n[0];\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Multiply(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // multiplied together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] * n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] * n[3];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[2] += m[3] * n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] * n[3];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[2] * n[2];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[3] * n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += (m[0] * n[3]) + (m[1] * n[2]) + (m[2] * n[1]) + (m[3] * n[0]);\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Rotl(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) rotated left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 32) {\n            return [m[1], m[0]];\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), (m[1] << n) | (m[0] >>> (32 - n))];\n        } else {\n            n -= 32;\n            return [(m[1] << n) | (m[0] >>> (32 - n)), (m[0] << n) | (m[1] >>> (32 - n))];\n        }\n    }\n\n    function _x64LeftShift(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) shifted left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 0) {\n            return m;\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), m[1] << n];\n        } else {\n            return [m[1] << (n - 32), 0];\n        }\n    }\n\n    function _x64Xor(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // xored together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        return [m[0] ^ n[0], m[1] ^ n[1]];\n    }\n\n    function _x64Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x64 mix of that block.\n        // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n        // only place where we need to right shift 64bit ints.)\n        //\n\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n\n        return h;\n    }\n\n    // PUBLIC FUNCTIONS\n    // ----------------\n\n    library.x86.hash32 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 32 bit hash\n        // using the x86 flavor of MurmurHash3, as an unsigned int.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 4;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n\n        var k1 = 0;\n\n        var c1 = 0xcc9e2d51;\n        var c2 = 0x1b873593;\n\n        for (var i = 0; i < blocks; i = i + 4) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n\n            h1 ^= k1;\n            h1 = _x86Rotl(h1, 13);\n            h1 = _x86Multiply(h1, 5) + 0xe6546b64;\n        }\n\n        k1 = 0;\n\n        switch (remainder) {\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h1 = _x86Fmix(h1);\n\n        return h1 >>> 0;\n    };\n\n    library.x86.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x86 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n\n        seed = seed || 0;\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n        var h2 = seed;\n        var h3 = seed;\n        var h4 = seed;\n\n        var k1 = 0;\n        var k2 = 0;\n        var k3 = 0;\n        var k4 = 0;\n\n        var c1 = 0x239b961b;\n        var c2 = 0xab0e9789;\n        var c3 = 0x38b34ae5;\n        var c4 = 0xa1e38b93;\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n            k2 = (bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24);\n            k3 = (bytes[i + 8]) | (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24);\n            k4 = (bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n            h1 ^= k1;\n\n            h1 = _x86Rotl(h1, 19);\n            h1 += h2;\n            h1 = _x86Multiply(h1, 5) + 0x561ccd1b;\n\n            k2 = _x86Multiply(k2, c2);\n            k2 = _x86Rotl(k2, 16);\n            k2 = _x86Multiply(k2, c3);\n            h2 ^= k2;\n\n            h2 = _x86Rotl(h2, 17);\n            h2 += h3;\n            h2 = _x86Multiply(h2, 5) + 0x0bcaa747;\n\n            k3 = _x86Multiply(k3, c3);\n            k3 = _x86Rotl(k3, 17);\n            k3 = _x86Multiply(k3, c4);\n            h3 ^= k3;\n\n            h3 = _x86Rotl(h3, 15);\n            h3 += h4;\n            h3 = _x86Multiply(h3, 5) + 0x96cd1c35;\n\n            k4 = _x86Multiply(k4, c4);\n            k4 = _x86Rotl(k4, 18);\n            k4 = _x86Multiply(k4, c1);\n            h4 ^= k4;\n\n            h4 = _x86Rotl(h4, 13);\n            h4 += h1;\n            h4 = _x86Multiply(h4, 5) + 0x32ac3b17;\n        }\n\n        k1 = 0;\n        k2 = 0;\n        k3 = 0;\n        k4 = 0;\n\n        switch (remainder) {\n            case 15:\n                k4 ^= bytes[i + 14] << 16;\n\n            case 14:\n                k4 ^= bytes[i + 13] << 8;\n\n            case 13:\n                k4 ^= bytes[i + 12];\n                k4 = _x86Multiply(k4, c4);\n                k4 = _x86Rotl(k4, 18);\n                k4 = _x86Multiply(k4, c1);\n                h4 ^= k4;\n\n            case 12:\n                k3 ^= bytes[i + 11] << 24;\n\n            case 11:\n                k3 ^= bytes[i + 10] << 16;\n\n            case 10:\n                k3 ^= bytes[i + 9] << 8;\n\n            case 9:\n                k3 ^= bytes[i + 8];\n                k3 = _x86Multiply(k3, c3);\n                k3 = _x86Rotl(k3, 17);\n                k3 = _x86Multiply(k3, c4);\n                h3 ^= k3;\n\n            case 8:\n                k2 ^= bytes[i + 7] << 24;\n\n            case 7:\n                k2 ^= bytes[i + 6] << 16;\n\n            case 6:\n                k2 ^= bytes[i + 5] << 8;\n\n            case 5:\n                k2 ^= bytes[i + 4];\n                k2 = _x86Multiply(k2, c2);\n                k2 = _x86Rotl(k2, 16);\n                k2 = _x86Multiply(k2, c3);\n                h2 ^= k2;\n\n            case 4:\n                k1 ^= bytes[i + 3] << 24;\n\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h2 ^= bytes.length;\n        h3 ^= bytes.length;\n        h4 ^= bytes.length;\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        h1 = _x86Fmix(h1);\n        h2 = _x86Fmix(h2);\n        h3 = _x86Fmix(h3);\n        h4 = _x86Fmix(h4);\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        return (\"00000000\" + (h1 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h3 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h4 >>> 0).toString(16)).slice(-8);\n    };\n\n    library.x64.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = [0, seed];\n        var h2 = [0, seed];\n\n        var k1 = [0, 0];\n        var k2 = [0, 0];\n\n        var c1 = [0x87c37b91, 0x114253d5];\n        var c2 = [0x4cf5ad43, 0x2745937f];\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = [(bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24), (bytes[i]) |\n                (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24)];\n            k2 = [(bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24), (bytes[i + 8]) |\n                (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24)];\n\n            k1 = _x64Multiply(k1, c1);\n            k1 = _x64Rotl(k1, 31);\n            k1 = _x64Multiply(k1, c2);\n            h1 = _x64Xor(h1, k1);\n\n            h1 = _x64Rotl(h1, 27);\n            h1 = _x64Add(h1, h2);\n            h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n\n            k2 = _x64Multiply(k2, c2);\n            k2 = _x64Rotl(k2, 33);\n            k2 = _x64Multiply(k2, c1);\n            h2 = _x64Xor(h2, k2);\n\n            h2 = _x64Rotl(h2, 31);\n            h2 = _x64Add(h2, h1);\n            h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n        }\n\n        k1 = [0, 0];\n        k2 = [0, 0];\n\n        switch (remainder) {\n            case 15:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));\n\n            case 14:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));\n\n            case 13:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));\n\n            case 12:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));\n\n            case 11:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));\n\n            case 10:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));\n\n            case 9:\n                k2 = _x64Xor(k2, [0, bytes[i + 8]]);\n                k2 = _x64Multiply(k2, c2);\n                k2 = _x64Rotl(k2, 33);\n                k2 = _x64Multiply(k2, c1);\n                h2 = _x64Xor(h2, k2);\n\n            case 8:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));\n\n            case 7:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));\n\n            case 6:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));\n\n            case 5:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));\n\n            case 4:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));\n\n            case 3:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));\n\n            case 2:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));\n\n            case 1:\n                k1 = _x64Xor(k1, [0, bytes[i]]);\n                k1 = _x64Multiply(k1, c1);\n                k1 = _x64Rotl(k1, 31);\n                k1 = _x64Multiply(k1, c2);\n                h1 = _x64Xor(h1, k1);\n        }\n\n        h1 = _x64Xor(h1, [0, bytes.length]);\n        h2 = _x64Xor(h2, [0, bytes.length]);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        h1 = _x64Fmix(h1);\n        h2 = _x64Fmix(h2);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        return (\"00000000\" + (h1[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h1[1] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[1] >>> 0).toString(16)).slice(-8);\n    };\n\n    // INITIALIZATION\n    // --------------\n\n    // Export murmurHash3 for CommonJS, either as an AMD module or just as part\n    // of the global object.\n    if (typeof exports !== 'undefined') {\n\n        if (typeof module !== 'undefined' && module.exports) {\n            exports = module.exports = library;\n        }\n\n        exports.murmurHash3 = library;\n\n    } else if (typeof define === 'function' && define.amd) {\n\n        define([], function () {\n            return library;\n        });\n    } else {\n\n        // Use murmurHash3.noConflict to restore `murmurHash3` back to its\n        // original value. Returns a reference to the library object, to allow\n        // it to be used under a different name.\n        library._murmurHash3 = root.murmurHash3;\n\n        library.noConflict = function () {\n            root.murmurHash3 = library._murmurHash3;\n            library._murmurHash3 = undefined;\n            library.noConflict = undefined;\n\n            return library;\n        };\n\n        root.murmurHash3 = library;\n    }\n})(this);\n","// Generated by CoffeeScript 1.12.7\n(function() {\n  var Netmask, atob, chr, chr0, chrA, chra, ip2long, long2ip;\n\n  long2ip = function(long) {\n    var a, b, c, d;\n    a = (long & (0xff << 24)) >>> 24;\n    b = (long & (0xff << 16)) >>> 16;\n    c = (long & (0xff << 8)) >>> 8;\n    d = long & 0xff;\n    return [a, b, c, d].join('.');\n  };\n\n  ip2long = function(ip) {\n    var b, c, i, j, n, ref;\n    b = [];\n    for (i = j = 0; j <= 3; i = ++j) {\n      if (ip.length === 0) {\n        break;\n      }\n      if (i > 0) {\n        if (ip[0] !== '.') {\n          throw new Error('Invalid IP');\n        }\n        ip = ip.substring(1);\n      }\n      ref = atob(ip), n = ref[0], c = ref[1];\n      ip = ip.substring(c);\n      b.push(n);\n    }\n    if (ip.length !== 0) {\n      throw new Error('Invalid IP');\n    }\n    switch (b.length) {\n      case 1:\n        if (b[0] > 0xFFFFFFFF) {\n          throw new Error('Invalid IP');\n        }\n        return b[0] >>> 0;\n      case 2:\n        if (b[0] > 0xFF || b[1] > 0xFFFFFF) {\n          throw new Error('Invalid IP');\n        }\n        return (b[0] << 24 | b[1]) >>> 0;\n      case 3:\n        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFFFF) {\n          throw new Error('Invalid IP');\n        }\n        return (b[0] << 24 | b[1] << 16 | b[2]) >>> 0;\n      case 4:\n        if (b[0] > 0xFF || b[1] > 0xFF || b[2] > 0xFF || b[3] > 0xFF) {\n          throw new Error('Invalid IP');\n        }\n        return (b[0] << 24 | b[1] << 16 | b[2] << 8 | b[3]) >>> 0;\n      default:\n        throw new Error('Invalid IP');\n    }\n  };\n\n  chr = function(b) {\n    return b.charCodeAt(0);\n  };\n\n  chr0 = chr('0');\n\n  chra = chr('a');\n\n  chrA = chr('A');\n\n  atob = function(s) {\n    var base, dmax, i, n, start;\n    n = 0;\n    base = 10;\n    dmax = '9';\n    i = 0;\n    if (s.length > 1 && s[i] === '0') {\n      if (s[i + 1] === 'x' || s[i + 1] === 'X') {\n        i += 2;\n        base = 16;\n      } else if ('0' <= s[i + 1] && s[i + 1] <= '9') {\n        i++;\n        base = 8;\n        dmax = '7';\n      }\n    }\n    start = i;\n    while (i < s.length) {\n      if ('0' <= s[i] && s[i] <= dmax) {\n        n = (n * base + (chr(s[i]) - chr0)) >>> 0;\n      } else if (base === 16) {\n        if ('a' <= s[i] && s[i] <= 'f') {\n          n = (n * base + (10 + chr(s[i]) - chra)) >>> 0;\n        } else if ('A' <= s[i] && s[i] <= 'F') {\n          n = (n * base + (10 + chr(s[i]) - chrA)) >>> 0;\n        } else {\n          break;\n        }\n      } else {\n        break;\n      }\n      if (n > 0xFFFFFFFF) {\n        throw new Error('too large');\n      }\n      i++;\n    }\n    if (i === start) {\n      throw new Error('empty octet');\n    }\n    return [n, i];\n  };\n\n  Netmask = (function() {\n    function Netmask(net, mask) {\n      var error, i, j, ref;\n      if (typeof net !== 'string') {\n        throw new Error(\"Missing `net' parameter\");\n      }\n      if (!mask) {\n        ref = net.split('/', 2), net = ref[0], mask = ref[1];\n      }\n      if (!mask) {\n        mask = 32;\n      }\n      if (typeof mask === 'string' && mask.indexOf('.') > -1) {\n        try {\n          this.maskLong = ip2long(mask);\n        } catch (error1) {\n          error = error1;\n          throw new Error(\"Invalid mask: \" + mask);\n        }\n        for (i = j = 32; j >= 0; i = --j) {\n          if (this.maskLong === (0xffffffff << (32 - i)) >>> 0) {\n            this.bitmask = i;\n            break;\n          }\n        }\n      } else if (mask || mask === 0) {\n        this.bitmask = parseInt(mask, 10);\n        this.maskLong = 0;\n        if (this.bitmask > 0) {\n          this.maskLong = (0xffffffff << (32 - this.bitmask)) >>> 0;\n        }\n      } else {\n        throw new Error(\"Invalid mask: empty\");\n      }\n      try {\n        this.netLong = (ip2long(net) & this.maskLong) >>> 0;\n      } catch (error1) {\n        error = error1;\n        throw new Error(\"Invalid net address: \" + net);\n      }\n      if (!(this.bitmask <= 32)) {\n        throw new Error(\"Invalid mask for ip4: \" + mask);\n      }\n      this.size = Math.pow(2, 32 - this.bitmask);\n      this.base = long2ip(this.netLong);\n      this.mask = long2ip(this.maskLong);\n      this.hostmask = long2ip(~this.maskLong);\n      this.first = this.bitmask <= 30 ? long2ip(this.netLong + 1) : this.base;\n      this.last = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 2) : long2ip(this.netLong + this.size - 1);\n      this.broadcast = this.bitmask <= 30 ? long2ip(this.netLong + this.size - 1) : void 0;\n    }\n\n    Netmask.prototype.contains = function(ip) {\n      if (typeof ip === 'string' && (ip.indexOf('/') > 0 || ip.split('.').length !== 4)) {\n        ip = new Netmask(ip);\n      }\n      if (ip instanceof Netmask) {\n        return this.contains(ip.base) && this.contains(ip.broadcast || ip.last);\n      } else {\n        return (ip2long(ip) & this.maskLong) >>> 0 === (this.netLong & this.maskLong) >>> 0;\n      }\n    };\n\n    Netmask.prototype.next = function(count) {\n      if (count == null) {\n        count = 1;\n      }\n      return new Netmask(long2ip(this.netLong + (this.size * count)), this.mask);\n    };\n\n    Netmask.prototype.forEach = function(fn) {\n      var index, lastLong, long;\n      long = ip2long(this.first);\n      lastLong = ip2long(this.last);\n      index = 0;\n      while (long <= lastLong) {\n        fn(long2ip(long), long, index);\n        index++;\n        long++;\n      }\n    };\n\n    Netmask.prototype.toString = function() {\n      return this.base + \"/\" + this.bitmask;\n    };\n\n    return Netmask;\n\n  })();\n\n  exports.ip2long = ip2long;\n\n  exports.long2ip = long2ip;\n\n  exports.Netmask = Netmask;\n\n}).call(this);\n","module.exports = require('./dist/shared/lib/head')\n","/*!\n * MIT License\n * \n * Copyright (c) 2017-2022 Peculiar Ventures, LLC\n * \n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to deal\n * in the Software without restriction, including without limitation the rights\n * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n * copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n * \n * The above copyright notice and this permission notice shall be included in all\n * copies or substantial portions of the Software.\n * \n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n * SOFTWARE.\n * \n */\n\n'use strict';\n\nconst ARRAY_BUFFER_NAME = \"[object ArrayBuffer]\";\nclass BufferSourceConverter {\n    static isArrayBuffer(data) {\n        return Object.prototype.toString.call(data) === ARRAY_BUFFER_NAME;\n    }\n    static toArrayBuffer(data) {\n        if (this.isArrayBuffer(data)) {\n            return data;\n        }\n        if (data.byteLength === data.buffer.byteLength) {\n            return data.buffer;\n        }\n        if (data.byteOffset === 0 && data.byteLength === data.buffer.byteLength) {\n            return data.buffer;\n        }\n        return this.toUint8Array(data.buffer)\n            .slice(data.byteOffset, data.byteOffset + data.byteLength)\n            .buffer;\n    }\n    static toUint8Array(data) {\n        return this.toView(data, Uint8Array);\n    }\n    static toView(data, type) {\n        if (data.constructor === type) {\n            return data;\n        }\n        if (this.isArrayBuffer(data)) {\n            return new type(data);\n        }\n        if (this.isArrayBufferView(data)) {\n            return new type(data.buffer, data.byteOffset, data.byteLength);\n        }\n        throw new TypeError(\"The provided value is not of type '(ArrayBuffer or ArrayBufferView)'\");\n    }\n    static isBufferSource(data) {\n        return this.isArrayBufferView(data)\n            || this.isArrayBuffer(data);\n    }\n    static isArrayBufferView(data) {\n        return ArrayBuffer.isView(data)\n            || (data && this.isArrayBuffer(data.buffer));\n    }\n    static isEqual(a, b) {\n        const aView = BufferSourceConverter.toUint8Array(a);\n        const bView = BufferSourceConverter.toUint8Array(b);\n        if (aView.length !== bView.byteLength) {\n            return false;\n        }\n        for (let i = 0; i < aView.length; i++) {\n            if (aView[i] !== bView[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    static concat(...args) {\n        let buffers;\n        if (Array.isArray(args[0]) && !(args[1] instanceof Function)) {\n            buffers = args[0];\n        }\n        else if (Array.isArray(args[0]) && args[1] instanceof Function) {\n            buffers = args[0];\n        }\n        else {\n            if (args[args.length - 1] instanceof Function) {\n                buffers = args.slice(0, args.length - 1);\n            }\n            else {\n                buffers = args;\n            }\n        }\n        let size = 0;\n        for (const buffer of buffers) {\n            size += buffer.byteLength;\n        }\n        const res = new Uint8Array(size);\n        let offset = 0;\n        for (const buffer of buffers) {\n            const view = this.toUint8Array(buffer);\n            res.set(view, offset);\n            offset += view.length;\n        }\n        if (args[args.length - 1] instanceof Function) {\n            return this.toView(res, args[args.length - 1]);\n        }\n        return res.buffer;\n    }\n}\n\nconst STRING_TYPE = \"string\";\nconst HEX_REGEX = /^[0-9a-f]+$/i;\nconst BASE64_REGEX = /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/;\nconst BASE64URL_REGEX = /^[a-zA-Z0-9-_]+$/;\nclass Utf8Converter {\n    static fromString(text) {\n        const s = unescape(encodeURIComponent(text));\n        const uintArray = new Uint8Array(s.length);\n        for (let i = 0; i < s.length; i++) {\n            uintArray[i] = s.charCodeAt(i);\n        }\n        return uintArray.buffer;\n    }\n    static toString(buffer) {\n        const buf = BufferSourceConverter.toUint8Array(buffer);\n        let encodedString = \"\";\n        for (let i = 0; i < buf.length; i++) {\n            encodedString += String.fromCharCode(buf[i]);\n        }\n        const decodedString = decodeURIComponent(escape(encodedString));\n        return decodedString;\n    }\n}\nclass Utf16Converter {\n    static toString(buffer, littleEndian = false) {\n        const arrayBuffer = BufferSourceConverter.toArrayBuffer(buffer);\n        const dataView = new DataView(arrayBuffer);\n        let res = \"\";\n        for (let i = 0; i < arrayBuffer.byteLength; i += 2) {\n            const code = dataView.getUint16(i, littleEndian);\n            res += String.fromCharCode(code);\n        }\n        return res;\n    }\n    static fromString(text, littleEndian = false) {\n        const res = new ArrayBuffer(text.length * 2);\n        const dataView = new DataView(res);\n        for (let i = 0; i < text.length; i++) {\n            dataView.setUint16(i * 2, text.charCodeAt(i), littleEndian);\n        }\n        return res;\n    }\n}\nclass Convert {\n    static isHex(data) {\n        return typeof data === STRING_TYPE\n            && HEX_REGEX.test(data);\n    }\n    static isBase64(data) {\n        return typeof data === STRING_TYPE\n            && BASE64_REGEX.test(data);\n    }\n    static isBase64Url(data) {\n        return typeof data === STRING_TYPE\n            && BASE64URL_REGEX.test(data);\n    }\n    static ToString(buffer, enc = \"utf8\") {\n        const buf = BufferSourceConverter.toUint8Array(buffer);\n        switch (enc.toLowerCase()) {\n            case \"utf8\":\n                return this.ToUtf8String(buf);\n            case \"binary\":\n                return this.ToBinary(buf);\n            case \"hex\":\n                return this.ToHex(buf);\n            case \"base64\":\n                return this.ToBase64(buf);\n            case \"base64url\":\n                return this.ToBase64Url(buf);\n            case \"utf16le\":\n                return Utf16Converter.toString(buf, true);\n            case \"utf16\":\n            case \"utf16be\":\n                return Utf16Converter.toString(buf);\n            default:\n                throw new Error(`Unknown type of encoding '${enc}'`);\n        }\n    }\n    static FromString(str, enc = \"utf8\") {\n        if (!str) {\n            return new ArrayBuffer(0);\n        }\n        switch (enc.toLowerCase()) {\n            case \"utf8\":\n                return this.FromUtf8String(str);\n            case \"binary\":\n                return this.FromBinary(str);\n            case \"hex\":\n                return this.FromHex(str);\n            case \"base64\":\n                return this.FromBase64(str);\n            case \"base64url\":\n                return this.FromBase64Url(str);\n            case \"utf16le\":\n                return Utf16Converter.fromString(str, true);\n            case \"utf16\":\n            case \"utf16be\":\n                return Utf16Converter.fromString(str);\n            default:\n                throw new Error(`Unknown type of encoding '${enc}'`);\n        }\n    }\n    static ToBase64(buffer) {\n        const buf = BufferSourceConverter.toUint8Array(buffer);\n        if (typeof btoa !== \"undefined\") {\n            const binary = this.ToString(buf, \"binary\");\n            return btoa(binary);\n        }\n        else {\n            return Buffer.from(buf).toString(\"base64\");\n        }\n    }\n    static FromBase64(base64) {\n        const formatted = this.formatString(base64);\n        if (!formatted) {\n            return new ArrayBuffer(0);\n        }\n        if (!Convert.isBase64(formatted)) {\n            throw new TypeError(\"Argument 'base64Text' is not Base64 encoded\");\n        }\n        if (typeof atob !== \"undefined\") {\n            return this.FromBinary(atob(formatted));\n        }\n        else {\n            return new Uint8Array(Buffer.from(formatted, \"base64\")).buffer;\n        }\n    }\n    static FromBase64Url(base64url) {\n        const formatted = this.formatString(base64url);\n        if (!formatted) {\n            return new ArrayBuffer(0);\n        }\n        if (!Convert.isBase64Url(formatted)) {\n            throw new TypeError(\"Argument 'base64url' is not Base64Url encoded\");\n        }\n        return this.FromBase64(this.Base64Padding(formatted.replace(/\\-/g, \"+\").replace(/\\_/g, \"/\")));\n    }\n    static ToBase64Url(data) {\n        return this.ToBase64(data).replace(/\\+/g, \"-\").replace(/\\//g, \"_\").replace(/\\=/g, \"\");\n    }\n    static FromUtf8String(text, encoding = Convert.DEFAULT_UTF8_ENCODING) {\n        switch (encoding) {\n            case \"ascii\":\n                return this.FromBinary(text);\n            case \"utf8\":\n                return Utf8Converter.fromString(text);\n            case \"utf16\":\n            case \"utf16be\":\n                return Utf16Converter.fromString(text);\n            case \"utf16le\":\n            case \"usc2\":\n                return Utf16Converter.fromString(text, true);\n            default:\n                throw new Error(`Unknown type of encoding '${encoding}'`);\n        }\n    }\n    static ToUtf8String(buffer, encoding = Convert.DEFAULT_UTF8_ENCODING) {\n        switch (encoding) {\n            case \"ascii\":\n                return this.ToBinary(buffer);\n            case \"utf8\":\n                return Utf8Converter.toString(buffer);\n            case \"utf16\":\n            case \"utf16be\":\n                return Utf16Converter.toString(buffer);\n            case \"utf16le\":\n            case \"usc2\":\n                return Utf16Converter.toString(buffer, true);\n            default:\n                throw new Error(`Unknown type of encoding '${encoding}'`);\n        }\n    }\n    static FromBinary(text) {\n        const stringLength = text.length;\n        const resultView = new Uint8Array(stringLength);\n        for (let i = 0; i < stringLength; i++) {\n            resultView[i] = text.charCodeAt(i);\n        }\n        return resultView.buffer;\n    }\n    static ToBinary(buffer) {\n        const buf = BufferSourceConverter.toUint8Array(buffer);\n        let res = \"\";\n        for (let i = 0; i < buf.length; i++) {\n            res += String.fromCharCode(buf[i]);\n        }\n        return res;\n    }\n    static ToHex(buffer) {\n        const buf = BufferSourceConverter.toUint8Array(buffer);\n        let result = \"\";\n        const len = buf.length;\n        for (let i = 0; i < len; i++) {\n            const byte = buf[i];\n            if (byte < 16) {\n                result += \"0\";\n            }\n            result += byte.toString(16);\n        }\n        return result;\n    }\n    static FromHex(hexString) {\n        let formatted = this.formatString(hexString);\n        if (!formatted) {\n            return new ArrayBuffer(0);\n        }\n        if (!Convert.isHex(formatted)) {\n            throw new TypeError(\"Argument 'hexString' is not HEX encoded\");\n        }\n        if (formatted.length % 2) {\n            formatted = `0${formatted}`;\n        }\n        const res = new Uint8Array(formatted.length / 2);\n        for (let i = 0; i < formatted.length; i = i + 2) {\n            const c = formatted.slice(i, i + 2);\n            res[i / 2] = parseInt(c, 16);\n        }\n        return res.buffer;\n    }\n    static ToUtf16String(buffer, littleEndian = false) {\n        return Utf16Converter.toString(buffer, littleEndian);\n    }\n    static FromUtf16String(text, littleEndian = false) {\n        return Utf16Converter.fromString(text, littleEndian);\n    }\n    static Base64Padding(base64) {\n        const padCount = 4 - (base64.length % 4);\n        if (padCount < 4) {\n            for (let i = 0; i < padCount; i++) {\n                base64 += \"=\";\n            }\n        }\n        return base64;\n    }\n    static formatString(data) {\n        return (data === null || data === void 0 ? void 0 : data.replace(/[\\n\\r\\t ]/g, \"\")) || \"\";\n    }\n}\nConvert.DEFAULT_UTF8_ENCODING = \"utf8\";\n\nfunction assign(target, ...sources) {\n    const res = arguments[0];\n    for (let i = 1; i < arguments.length; i++) {\n        const obj = arguments[i];\n        for (const prop in obj) {\n            res[prop] = obj[prop];\n        }\n    }\n    return res;\n}\nfunction combine(...buf) {\n    const totalByteLength = buf.map((item) => item.byteLength).reduce((prev, cur) => prev + cur);\n    const res = new Uint8Array(totalByteLength);\n    let currentPos = 0;\n    buf.map((item) => new Uint8Array(item)).forEach((arr) => {\n        for (const item2 of arr) {\n            res[currentPos++] = item2;\n        }\n    });\n    return res.buffer;\n}\nfunction isEqual(bytes1, bytes2) {\n    if (!(bytes1 && bytes2)) {\n        return false;\n    }\n    if (bytes1.byteLength !== bytes2.byteLength) {\n        return false;\n    }\n    const b1 = new Uint8Array(bytes1);\n    const b2 = new Uint8Array(bytes2);\n    for (let i = 0; i < bytes1.byteLength; i++) {\n        if (b1[i] !== b2[i]) {\n            return false;\n        }\n    }\n    return true;\n}\n\nexports.BufferSourceConverter = BufferSourceConverter;\nexports.Convert = Convert;\nexports.assign = assign;\nexports.combine = combine;\nexports.isEqual = isEqual;\n","\nconst canPromise = require('./can-promise')\n\nconst QRCode = require('./core/qrcode')\nconst CanvasRenderer = require('./renderer/canvas')\nconst SvgRenderer = require('./renderer/svg-tag.js')\n\nfunction renderCanvas (renderFunc, canvas, text, opts, cb) {\n  const args = [].slice.call(arguments, 1)\n  const argsNum = args.length\n  const isLastArgCb = typeof args[argsNum - 1] === 'function'\n\n  if (!isLastArgCb && !canPromise()) {\n    throw new Error('Callback required as last argument')\n  }\n\n  if (isLastArgCb) {\n    if (argsNum < 2) {\n      throw new Error('Too few arguments provided')\n    }\n\n    if (argsNum === 2) {\n      cb = text\n      text = canvas\n      canvas = opts = undefined\n    } else if (argsNum === 3) {\n      if (canvas.getContext && typeof cb === 'undefined') {\n        cb = opts\n        opts = undefined\n      } else {\n        cb = opts\n        opts = text\n        text = canvas\n        canvas = undefined\n      }\n    }\n  } else {\n    if (argsNum < 1) {\n      throw new Error('Too few arguments provided')\n    }\n\n    if (argsNum === 1) {\n      text = canvas\n      canvas = opts = undefined\n    } else if (argsNum === 2 && !canvas.getContext) {\n      opts = text\n      text = canvas\n      canvas = undefined\n    }\n\n    return new Promise(function (resolve, reject) {\n      try {\n        const data = QRCode.create(text, opts)\n        resolve(renderFunc(data, canvas, opts))\n      } catch (e) {\n        reject(e)\n      }\n    })\n  }\n\n  try {\n    const data = QRCode.create(text, opts)\n    cb(null, renderFunc(data, canvas, opts))\n  } catch (e) {\n    cb(e)\n  }\n}\n\nexports.create = QRCode.create\nexports.toCanvas = renderCanvas.bind(null, CanvasRenderer.render)\nexports.toDataURL = renderCanvas.bind(null, CanvasRenderer.renderToDataURL)\n\n// only svg for now.\nexports.toString = renderCanvas.bind(null, function (data, _, opts) {\n  return SvgRenderer.render(data, opts)\n})\n","// can-promise has a crash in some versions of react native that dont have\n// standard global objects\n// https://github.com/soldair/node-qrcode/issues/157\n\nmodule.exports = function () {\n  return typeof Promise === 'function' && Promise.prototype && Promise.prototype.then\n}\n","/**\n * Alignment pattern are fixed reference pattern in defined positions\n * in a matrix symbology, which enables the decode software to re-synchronise\n * the coordinate mapping of the image modules in the event of moderate amounts\n * of distortion of the image.\n *\n * Alignment patterns are present only in QR Code symbols of version 2 or larger\n * and their number depends on the symbol version.\n */\n\nconst getSymbolSize = require('./utils').getSymbolSize\n\n/**\n * Calculate the row/column coordinates of the center module of each alignment pattern\n * for the specified QR Code version.\n *\n * The alignment patterns are positioned symmetrically on either side of the diagonal\n * running from the top left corner of the symbol to the bottom right corner.\n *\n * Since positions are simmetrical only half of the coordinates are returned.\n * Each item of the array will represent in turn the x and y coordinate.\n * @see {@link getPositions}\n *\n * @param  {Number} version QR Code version\n * @return {Array}          Array of coordinate\n */\nexports.getRowColCoords = function getRowColCoords (version) {\n  if (version === 1) return []\n\n  const posCount = Math.floor(version / 7) + 2\n  const size = getSymbolSize(version)\n  const intervals = size === 145 ? 26 : Math.ceil((size - 13) / (2 * posCount - 2)) * 2\n  const positions = [size - 7] // Last coord is always (size - 7)\n\n  for (let i = 1; i < posCount - 1; i++) {\n    positions[i] = positions[i - 1] - intervals\n  }\n\n  positions.push(6) // First coord is always 6\n\n  return positions.reverse()\n}\n\n/**\n * Returns an array containing the positions of each alignment pattern.\n * Each array's element represent the center point of the pattern as (x, y) coordinates\n *\n * Coordinates are calculated expanding the row/column coordinates returned by {@link getRowColCoords}\n * and filtering out the items that overlaps with finder pattern\n *\n * @example\n * For a Version 7 symbol {@link getRowColCoords} returns values 6, 22 and 38.\n * The alignment patterns, therefore, are to be centered on (row, column)\n * positions (6,22), (22,6), (22,22), (22,38), (38,22), (38,38).\n * Note that the coordinates (6,6), (6,38), (38,6) are occupied by finder patterns\n * and are not therefore used for alignment patterns.\n *\n * let pos = getPositions(7)\n * // [[6,22], [22,6], [22,22], [22,38], [38,22], [38,38]]\n *\n * @param  {Number} version QR Code version\n * @return {Array}          Array of coordinates\n */\nexports.getPositions = function getPositions (version) {\n  const coords = []\n  const pos = exports.getRowColCoords(version)\n  const posLength = pos.length\n\n  for (let i = 0; i < posLength; i++) {\n    for (let j = 0; j < posLength; j++) {\n      // Skip if position is occupied by finder patterns\n      if ((i === 0 && j === 0) || // top-left\n          (i === 0 && j === posLength - 1) || // bottom-left\n          (i === posLength - 1 && j === 0)) { // top-right\n        continue\n      }\n\n      coords.push([pos[i], pos[j]])\n    }\n  }\n\n  return coords\n}\n","const Mode = require('./mode')\n\n/**\n * Array of characters available in alphanumeric mode\n *\n * As per QR Code specification, to each character\n * is assigned a value from 0 to 44 which in this case coincides\n * with the array index\n *\n * @type {Array}\n */\nconst ALPHA_NUM_CHARS = [\n  '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n  'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n  'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n  ' ', '$', '%', '*', '+', '-', '.', '/', ':'\n]\n\nfunction AlphanumericData (data) {\n  this.mode = Mode.ALPHANUMERIC\n  this.data = data\n}\n\nAlphanumericData.getBitsLength = function getBitsLength (length) {\n  return 11 * Math.floor(length / 2) + 6 * (length % 2)\n}\n\nAlphanumericData.prototype.getLength = function getLength () {\n  return this.data.length\n}\n\nAlphanumericData.prototype.getBitsLength = function getBitsLength () {\n  return AlphanumericData.getBitsLength(this.data.length)\n}\n\nAlphanumericData.prototype.write = function write (bitBuffer) {\n  let i\n\n  // Input data characters are divided into groups of two characters\n  // and encoded as 11-bit binary codes.\n  for (i = 0; i + 2 <= this.data.length; i += 2) {\n    // The character value of the first character is multiplied by 45\n    let value = ALPHA_NUM_CHARS.indexOf(this.data[i]) * 45\n\n    // The character value of the second digit is added to the product\n    value += ALPHA_NUM_CHARS.indexOf(this.data[i + 1])\n\n    // The sum is then stored as 11-bit binary number\n    bitBuffer.put(value, 11)\n  }\n\n  // If the number of input data characters is not a multiple of two,\n  // the character value of the final character is encoded as a 6-bit binary number.\n  if (this.data.length % 2) {\n    bitBuffer.put(ALPHA_NUM_CHARS.indexOf(this.data[i]), 6)\n  }\n}\n\nmodule.exports = AlphanumericData\n","function BitBuffer () {\n  this.buffer = []\n  this.length = 0\n}\n\nBitBuffer.prototype = {\n\n  get: function (index) {\n    const bufIndex = Math.floor(index / 8)\n    return ((this.buffer[bufIndex] >>> (7 - index % 8)) & 1) === 1\n  },\n\n  put: function (num, length) {\n    for (let i = 0; i < length; i++) {\n      this.putBit(((num >>> (length - i - 1)) & 1) === 1)\n    }\n  },\n\n  getLengthInBits: function () {\n    return this.length\n  },\n\n  putBit: function (bit) {\n    const bufIndex = Math.floor(this.length / 8)\n    if (this.buffer.length <= bufIndex) {\n      this.buffer.push(0)\n    }\n\n    if (bit) {\n      this.buffer[bufIndex] |= (0x80 >>> (this.length % 8))\n    }\n\n    this.length++\n  }\n}\n\nmodule.exports = BitBuffer\n","/**\n * Helper class to handle QR Code symbol modules\n *\n * @param {Number} size Symbol size\n */\nfunction BitMatrix (size) {\n  if (!size || size < 1) {\n    throw new Error('BitMatrix size must be defined and greater than 0')\n  }\n\n  this.size = size\n  this.data = new Uint8Array(size * size)\n  this.reservedBit = new Uint8Array(size * size)\n}\n\n/**\n * Set bit value at specified location\n * If reserved flag is set, this bit will be ignored during masking process\n *\n * @param {Number}  row\n * @param {Number}  col\n * @param {Boolean} value\n * @param {Boolean} reserved\n */\nBitMatrix.prototype.set = function (row, col, value, reserved) {\n  const index = row * this.size + col\n  this.data[index] = value\n  if (reserved) this.reservedBit[index] = true\n}\n\n/**\n * Returns bit value at specified location\n *\n * @param  {Number}  row\n * @param  {Number}  col\n * @return {Boolean}\n */\nBitMatrix.prototype.get = function (row, col) {\n  return this.data[row * this.size + col]\n}\n\n/**\n * Applies xor operator at specified location\n * (used during masking process)\n *\n * @param {Number}  row\n * @param {Number}  col\n * @param {Boolean} value\n */\nBitMatrix.prototype.xor = function (row, col, value) {\n  this.data[row * this.size + col] ^= value\n}\n\n/**\n * Check if bit at specified location is reserved\n *\n * @param {Number}   row\n * @param {Number}   col\n * @return {Boolean}\n */\nBitMatrix.prototype.isReserved = function (row, col) {\n  return this.reservedBit[row * this.size + col]\n}\n\nmodule.exports = BitMatrix\n","const encodeUtf8 = require('encode-utf8')\nconst Mode = require('./mode')\n\nfunction ByteData (data) {\n  this.mode = Mode.BYTE\n  if (typeof (data) === 'string') {\n    data = encodeUtf8(data)\n  }\n  this.data = new Uint8Array(data)\n}\n\nByteData.getBitsLength = function getBitsLength (length) {\n  return length * 8\n}\n\nByteData.prototype.getLength = function getLength () {\n  return this.data.length\n}\n\nByteData.prototype.getBitsLength = function getBitsLength () {\n  return ByteData.getBitsLength(this.data.length)\n}\n\nByteData.prototype.write = function (bitBuffer) {\n  for (let i = 0, l = this.data.length; i < l; i++) {\n    bitBuffer.put(this.data[i], 8)\n  }\n}\n\nmodule.exports = ByteData\n","const ECLevel = require('./error-correction-level')\r\n\r\nconst EC_BLOCKS_TABLE = [\r\n// L  M  Q  H\r\n  1, 1, 1, 1,\r\n  1, 1, 1, 1,\r\n  1, 1, 2, 2,\r\n  1, 2, 2, 4,\r\n  1, 2, 4, 4,\r\n  2, 4, 4, 4,\r\n  2, 4, 6, 5,\r\n  2, 4, 6, 6,\r\n  2, 5, 8, 8,\r\n  4, 5, 8, 8,\r\n  4, 5, 8, 11,\r\n  4, 8, 10, 11,\r\n  4, 9, 12, 16,\r\n  4, 9, 16, 16,\r\n  6, 10, 12, 18,\r\n  6, 10, 17, 16,\r\n  6, 11, 16, 19,\r\n  6, 13, 18, 21,\r\n  7, 14, 21, 25,\r\n  8, 16, 20, 25,\r\n  8, 17, 23, 25,\r\n  9, 17, 23, 34,\r\n  9, 18, 25, 30,\r\n  10, 20, 27, 32,\r\n  12, 21, 29, 35,\r\n  12, 23, 34, 37,\r\n  12, 25, 34, 40,\r\n  13, 26, 35, 42,\r\n  14, 28, 38, 45,\r\n  15, 29, 40, 48,\r\n  16, 31, 43, 51,\r\n  17, 33, 45, 54,\r\n  18, 35, 48, 57,\r\n  19, 37, 51, 60,\r\n  19, 38, 53, 63,\r\n  20, 40, 56, 66,\r\n  21, 43, 59, 70,\r\n  22, 45, 62, 74,\r\n  24, 47, 65, 77,\r\n  25, 49, 68, 81\r\n]\r\n\r\nconst EC_CODEWORDS_TABLE = [\r\n// L  M  Q  H\r\n  7, 10, 13, 17,\r\n  10, 16, 22, 28,\r\n  15, 26, 36, 44,\r\n  20, 36, 52, 64,\r\n  26, 48, 72, 88,\r\n  36, 64, 96, 112,\r\n  40, 72, 108, 130,\r\n  48, 88, 132, 156,\r\n  60, 110, 160, 192,\r\n  72, 130, 192, 224,\r\n  80, 150, 224, 264,\r\n  96, 176, 260, 308,\r\n  104, 198, 288, 352,\r\n  120, 216, 320, 384,\r\n  132, 240, 360, 432,\r\n  144, 280, 408, 480,\r\n  168, 308, 448, 532,\r\n  180, 338, 504, 588,\r\n  196, 364, 546, 650,\r\n  224, 416, 600, 700,\r\n  224, 442, 644, 750,\r\n  252, 476, 690, 816,\r\n  270, 504, 750, 900,\r\n  300, 560, 810, 960,\r\n  312, 588, 870, 1050,\r\n  336, 644, 952, 1110,\r\n  360, 700, 1020, 1200,\r\n  390, 728, 1050, 1260,\r\n  420, 784, 1140, 1350,\r\n  450, 812, 1200, 1440,\r\n  480, 868, 1290, 1530,\r\n  510, 924, 1350, 1620,\r\n  540, 980, 1440, 1710,\r\n  570, 1036, 1530, 1800,\r\n  570, 1064, 1590, 1890,\r\n  600, 1120, 1680, 1980,\r\n  630, 1204, 1770, 2100,\r\n  660, 1260, 1860, 2220,\r\n  720, 1316, 1950, 2310,\r\n  750, 1372, 2040, 2430\r\n]\r\n\r\n/**\r\n * Returns the number of error correction block that the QR Code should contain\r\n * for the specified version and error correction level.\r\n *\r\n * @param  {Number} version              QR Code version\r\n * @param  {Number} errorCorrectionLevel Error correction level\r\n * @return {Number}                      Number of error correction blocks\r\n */\r\nexports.getBlocksCount = function getBlocksCount (version, errorCorrectionLevel) {\r\n  switch (errorCorrectionLevel) {\r\n    case ECLevel.L:\r\n      return EC_BLOCKS_TABLE[(version - 1) * 4 + 0]\r\n    case ECLevel.M:\r\n      return EC_BLOCKS_TABLE[(version - 1) * 4 + 1]\r\n    case ECLevel.Q:\r\n      return EC_BLOCKS_TABLE[(version - 1) * 4 + 2]\r\n    case ECLevel.H:\r\n      return EC_BLOCKS_TABLE[(version - 1) * 4 + 3]\r\n    default:\r\n      return undefined\r\n  }\r\n}\r\n\r\n/**\r\n * Returns the number of error correction codewords to use for the specified\r\n * version and error correction level.\r\n *\r\n * @param  {Number} version              QR Code version\r\n * @param  {Number} errorCorrectionLevel Error correction level\r\n * @return {Number}                      Number of error correction codewords\r\n */\r\nexports.getTotalCodewordsCount = function getTotalCodewordsCount (version, errorCorrectionLevel) {\r\n  switch (errorCorrectionLevel) {\r\n    case ECLevel.L:\r\n      return EC_CODEWORDS_TABLE[(version - 1) * 4 + 0]\r\n    case ECLevel.M:\r\n      return EC_CODEWORDS_TABLE[(version - 1) * 4 + 1]\r\n    case ECLevel.Q:\r\n      return EC_CODEWORDS_TABLE[(version - 1) * 4 + 2]\r\n    case ECLevel.H:\r\n      return EC_CODEWORDS_TABLE[(version - 1) * 4 + 3]\r\n    default:\r\n      return undefined\r\n  }\r\n}\r\n","exports.L = { bit: 1 }\nexports.M = { bit: 0 }\nexports.Q = { bit: 3 }\nexports.H = { bit: 2 }\n\nfunction fromString (string) {\n  if (typeof string !== 'string') {\n    throw new Error('Param is not a string')\n  }\n\n  const lcStr = string.toLowerCase()\n\n  switch (lcStr) {\n    case 'l':\n    case 'low':\n      return exports.L\n\n    case 'm':\n    case 'medium':\n      return exports.M\n\n    case 'q':\n    case 'quartile':\n      return exports.Q\n\n    case 'h':\n    case 'high':\n      return exports.H\n\n    default:\n      throw new Error('Unknown EC Level: ' + string)\n  }\n}\n\nexports.isValid = function isValid (level) {\n  return level && typeof level.bit !== 'undefined' &&\n    level.bit >= 0 && level.bit < 4\n}\n\nexports.from = function from (value, defaultValue) {\n  if (exports.isValid(value)) {\n    return value\n  }\n\n  try {\n    return fromString(value)\n  } catch (e) {\n    return defaultValue\n  }\n}\n","const getSymbolSize = require('./utils').getSymbolSize\nconst FINDER_PATTERN_SIZE = 7\n\n/**\n * Returns an array containing the positions of each finder pattern.\n * Each array's element represent the top-left point of the pattern as (x, y) coordinates\n *\n * @param  {Number} version QR Code version\n * @return {Array}          Array of coordinates\n */\nexports.getPositions = function getPositions (version) {\n  const size = getSymbolSize(version)\n\n  return [\n    // top-left\n    [0, 0],\n    // top-right\n    [size - FINDER_PATTERN_SIZE, 0],\n    // bottom-left\n    [0, size - FINDER_PATTERN_SIZE]\n  ]\n}\n","const Utils = require('./utils')\n\nconst G15 = (1 << 10) | (1 << 8) | (1 << 5) | (1 << 4) | (1 << 2) | (1 << 1) | (1 << 0)\nconst G15_MASK = (1 << 14) | (1 << 12) | (1 << 10) | (1 << 4) | (1 << 1)\nconst G15_BCH = Utils.getBCHDigit(G15)\n\n/**\n * Returns format information with relative error correction bits\n *\n * The format information is a 15-bit sequence containing 5 data bits,\n * with 10 error correction bits calculated using the (15, 5) BCH code.\n *\n * @param  {Number} errorCorrectionLevel Error correction level\n * @param  {Number} mask                 Mask pattern\n * @return {Number}                      Encoded format information bits\n */\nexports.getEncodedBits = function getEncodedBits (errorCorrectionLevel, mask) {\n  const data = ((errorCorrectionLevel.bit << 3) | mask)\n  let d = data << 10\n\n  while (Utils.getBCHDigit(d) - G15_BCH >= 0) {\n    d ^= (G15 << (Utils.getBCHDigit(d) - G15_BCH))\n  }\n\n  // xor final data with mask pattern in order to ensure that\n  // no combination of Error Correction Level and data mask pattern\n  // will result in an all-zero data string\n  return ((data << 10) | d) ^ G15_MASK\n}\n","const EXP_TABLE = new Uint8Array(512)\nconst LOG_TABLE = new Uint8Array(256)\n/**\n * Precompute the log and anti-log tables for faster computation later\n *\n * For each possible value in the galois field 2^8, we will pre-compute\n * the logarithm and anti-logarithm (exponential) of this value\n *\n * ref {@link https://en.wikiversity.org/wiki/Reed%E2%80%93Solomon_codes_for_coders#Introduction_to_mathematical_fields}\n */\n;(function initTables () {\n  let x = 1\n  for (let i = 0; i < 255; i++) {\n    EXP_TABLE[i] = x\n    LOG_TABLE[x] = i\n\n    x <<= 1 // multiply by 2\n\n    // The QR code specification says to use byte-wise modulo 100011101 arithmetic.\n    // This means that when a number is 256 or larger, it should be XORed with 0x11D.\n    if (x & 0x100) { // similar to x >= 256, but a lot faster (because 0x100 == 256)\n      x ^= 0x11D\n    }\n  }\n\n  // Optimization: double the size of the anti-log table so that we don't need to mod 255 to\n  // stay inside the bounds (because we will mainly use this table for the multiplication of\n  // two GF numbers, no more).\n  // @see {@link mul}\n  for (let i = 255; i < 512; i++) {\n    EXP_TABLE[i] = EXP_TABLE[i - 255]\n  }\n}())\n\n/**\n * Returns log value of n inside Galois Field\n *\n * @param  {Number} n\n * @return {Number}\n */\nexports.log = function log (n) {\n  if (n < 1) throw new Error('log(' + n + ')')\n  return LOG_TABLE[n]\n}\n\n/**\n * Returns anti-log value of n inside Galois Field\n *\n * @param  {Number} n\n * @return {Number}\n */\nexports.exp = function exp (n) {\n  return EXP_TABLE[n]\n}\n\n/**\n * Multiplies two number inside Galois Field\n *\n * @param  {Number} x\n * @param  {Number} y\n * @return {Number}\n */\nexports.mul = function mul (x, y) {\n  if (x === 0 || y === 0) return 0\n\n  // should be EXP_TABLE[(LOG_TABLE[x] + LOG_TABLE[y]) % 255] if EXP_TABLE wasn't oversized\n  // @see {@link initTables}\n  return EXP_TABLE[LOG_TABLE[x] + LOG_TABLE[y]]\n}\n","const Mode = require('./mode')\nconst Utils = require('./utils')\n\nfunction KanjiData (data) {\n  this.mode = Mode.KANJI\n  this.data = data\n}\n\nKanjiData.getBitsLength = function getBitsLength (length) {\n  return length * 13\n}\n\nKanjiData.prototype.getLength = function getLength () {\n  return this.data.length\n}\n\nKanjiData.prototype.getBitsLength = function getBitsLength () {\n  return KanjiData.getBitsLength(this.data.length)\n}\n\nKanjiData.prototype.write = function (bitBuffer) {\n  let i\n\n  // In the Shift JIS system, Kanji characters are represented by a two byte combination.\n  // These byte values are shifted from the JIS X 0208 values.\n  // JIS X 0208 gives details of the shift coded representation.\n  for (i = 0; i < this.data.length; i++) {\n    let value = Utils.toSJIS(this.data[i])\n\n    // For characters with Shift JIS values from 0x8140 to 0x9FFC:\n    if (value >= 0x8140 && value <= 0x9FFC) {\n      // Subtract 0x8140 from Shift JIS value\n      value -= 0x8140\n\n    // For characters with Shift JIS values from 0xE040 to 0xEBBF\n    } else if (value >= 0xE040 && value <= 0xEBBF) {\n      // Subtract 0xC140 from Shift JIS value\n      value -= 0xC140\n    } else {\n      throw new Error(\n        'Invalid SJIS character: ' + this.data[i] + '\\n' +\n        'Make sure your charset is UTF-8')\n    }\n\n    // Multiply most significant byte of result by 0xC0\n    // and add least significant byte to product\n    value = (((value >>> 8) & 0xff) * 0xC0) + (value & 0xff)\n\n    // Convert result to a 13-bit binary string\n    bitBuffer.put(value, 13)\n  }\n}\n\nmodule.exports = KanjiData\n","/**\n * Data mask pattern reference\n * @type {Object}\n */\nexports.Patterns = {\n  PATTERN000: 0,\n  PATTERN001: 1,\n  PATTERN010: 2,\n  PATTERN011: 3,\n  PATTERN100: 4,\n  PATTERN101: 5,\n  PATTERN110: 6,\n  PATTERN111: 7\n}\n\n/**\n * Weighted penalty scores for the undesirable features\n * @type {Object}\n */\nconst PenaltyScores = {\n  N1: 3,\n  N2: 3,\n  N3: 40,\n  N4: 10\n}\n\n/**\n * Check if mask pattern value is valid\n *\n * @param  {Number}  mask    Mask pattern\n * @return {Boolean}         true if valid, false otherwise\n */\nexports.isValid = function isValid (mask) {\n  return mask != null && mask !== '' && !isNaN(mask) && mask >= 0 && mask <= 7\n}\n\n/**\n * Returns mask pattern from a value.\n * If value is not valid, returns undefined\n *\n * @param  {Number|String} value        Mask pattern value\n * @return {Number}                     Valid mask pattern or undefined\n */\nexports.from = function from (value) {\n  return exports.isValid(value) ? parseInt(value, 10) : undefined\n}\n\n/**\n* Find adjacent modules in row/column with the same color\n* and assign a penalty value.\n*\n* Points: N1 + i\n* i is the amount by which the number of adjacent modules of the same color exceeds 5\n*/\nexports.getPenaltyN1 = function getPenaltyN1 (data) {\n  const size = data.size\n  let points = 0\n  let sameCountCol = 0\n  let sameCountRow = 0\n  let lastCol = null\n  let lastRow = null\n\n  for (let row = 0; row < size; row++) {\n    sameCountCol = sameCountRow = 0\n    lastCol = lastRow = null\n\n    for (let col = 0; col < size; col++) {\n      let module = data.get(row, col)\n      if (module === lastCol) {\n        sameCountCol++\n      } else {\n        if (sameCountCol >= 5) points += PenaltyScores.N1 + (sameCountCol - 5)\n        lastCol = module\n        sameCountCol = 1\n      }\n\n      module = data.get(col, row)\n      if (module === lastRow) {\n        sameCountRow++\n      } else {\n        if (sameCountRow >= 5) points += PenaltyScores.N1 + (sameCountRow - 5)\n        lastRow = module\n        sameCountRow = 1\n      }\n    }\n\n    if (sameCountCol >= 5) points += PenaltyScores.N1 + (sameCountCol - 5)\n    if (sameCountRow >= 5) points += PenaltyScores.N1 + (sameCountRow - 5)\n  }\n\n  return points\n}\n\n/**\n * Find 2x2 blocks with the same color and assign a penalty value\n *\n * Points: N2 * (m - 1) * (n - 1)\n */\nexports.getPenaltyN2 = function getPenaltyN2 (data) {\n  const size = data.size\n  let points = 0\n\n  for (let row = 0; row < size - 1; row++) {\n    for (let col = 0; col < size - 1; col++) {\n      const last = data.get(row, col) +\n        data.get(row, col + 1) +\n        data.get(row + 1, col) +\n        data.get(row + 1, col + 1)\n\n      if (last === 4 || last === 0) points++\n    }\n  }\n\n  return points * PenaltyScores.N2\n}\n\n/**\n * Find 1:1:3:1:1 ratio (dark:light:dark:light:dark) pattern in row/column,\n * preceded or followed by light area 4 modules wide\n *\n * Points: N3 * number of pattern found\n */\nexports.getPenaltyN3 = function getPenaltyN3 (data) {\n  const size = data.size\n  let points = 0\n  let bitsCol = 0\n  let bitsRow = 0\n\n  for (let row = 0; row < size; row++) {\n    bitsCol = bitsRow = 0\n    for (let col = 0; col < size; col++) {\n      bitsCol = ((bitsCol << 1) & 0x7FF) | data.get(row, col)\n      if (col >= 10 && (bitsCol === 0x5D0 || bitsCol === 0x05D)) points++\n\n      bitsRow = ((bitsRow << 1) & 0x7FF) | data.get(col, row)\n      if (col >= 10 && (bitsRow === 0x5D0 || bitsRow === 0x05D)) points++\n    }\n  }\n\n  return points * PenaltyScores.N3\n}\n\n/**\n * Calculate proportion of dark modules in entire symbol\n *\n * Points: N4 * k\n *\n * k is the rating of the deviation of the proportion of dark modules\n * in the symbol from 50% in steps of 5%\n */\nexports.getPenaltyN4 = function getPenaltyN4 (data) {\n  let darkCount = 0\n  const modulesCount = data.data.length\n\n  for (let i = 0; i < modulesCount; i++) darkCount += data.data[i]\n\n  const k = Math.abs(Math.ceil((darkCount * 100 / modulesCount) / 5) - 10)\n\n  return k * PenaltyScores.N4\n}\n\n/**\n * Return mask value at given position\n *\n * @param  {Number} maskPattern Pattern reference value\n * @param  {Number} i           Row\n * @param  {Number} j           Column\n * @return {Boolean}            Mask value\n */\nfunction getMaskAt (maskPattern, i, j) {\n  switch (maskPattern) {\n    case exports.Patterns.PATTERN000: return (i + j) % 2 === 0\n    case exports.Patterns.PATTERN001: return i % 2 === 0\n    case exports.Patterns.PATTERN010: return j % 3 === 0\n    case exports.Patterns.PATTERN011: return (i + j) % 3 === 0\n    case exports.Patterns.PATTERN100: return (Math.floor(i / 2) + Math.floor(j / 3)) % 2 === 0\n    case exports.Patterns.PATTERN101: return (i * j) % 2 + (i * j) % 3 === 0\n    case exports.Patterns.PATTERN110: return ((i * j) % 2 + (i * j) % 3) % 2 === 0\n    case exports.Patterns.PATTERN111: return ((i * j) % 3 + (i + j) % 2) % 2 === 0\n\n    default: throw new Error('bad maskPattern:' + maskPattern)\n  }\n}\n\n/**\n * Apply a mask pattern to a BitMatrix\n *\n * @param  {Number}    pattern Pattern reference number\n * @param  {BitMatrix} data    BitMatrix data\n */\nexports.applyMask = function applyMask (pattern, data) {\n  const size = data.size\n\n  for (let col = 0; col < size; col++) {\n    for (let row = 0; row < size; row++) {\n      if (data.isReserved(row, col)) continue\n      data.xor(row, col, getMaskAt(pattern, row, col))\n    }\n  }\n}\n\n/**\n * Returns the best mask pattern for data\n *\n * @param  {BitMatrix} data\n * @return {Number} Mask pattern reference number\n */\nexports.getBestMask = function getBestMask (data, setupFormatFunc) {\n  const numPatterns = Object.keys(exports.Patterns).length\n  let bestPattern = 0\n  let lowerPenalty = Infinity\n\n  for (let p = 0; p < numPatterns; p++) {\n    setupFormatFunc(p)\n    exports.applyMask(p, data)\n\n    // Calculate penalty\n    const penalty =\n      exports.getPenaltyN1(data) +\n      exports.getPenaltyN2(data) +\n      exports.getPenaltyN3(data) +\n      exports.getPenaltyN4(data)\n\n    // Undo previously applied mask\n    exports.applyMask(p, data)\n\n    if (penalty < lowerPenalty) {\n      lowerPenalty = penalty\n      bestPattern = p\n    }\n  }\n\n  return bestPattern\n}\n","const VersionCheck = require('./version-check')\nconst Regex = require('./regex')\n\n/**\n * Numeric mode encodes data from the decimal digit set (0 - 9)\n * (byte values 30HEX to 39HEX).\n * Normally, 3 data characters are represented by 10 bits.\n *\n * @type {Object}\n */\nexports.NUMERIC = {\n  id: 'Numeric',\n  bit: 1 << 0,\n  ccBits: [10, 12, 14]\n}\n\n/**\n * Alphanumeric mode encodes data from a set of 45 characters,\n * i.e. 10 numeric digits (0 - 9),\n *      26 alphabetic characters (A - Z),\n *   and 9 symbols (SP, $, %, *, +, -, ., /, :).\n * Normally, two input characters are represented by 11 bits.\n *\n * @type {Object}\n */\nexports.ALPHANUMERIC = {\n  id: 'Alphanumeric',\n  bit: 1 << 1,\n  ccBits: [9, 11, 13]\n}\n\n/**\n * In byte mode, data is encoded at 8 bits per character.\n *\n * @type {Object}\n */\nexports.BYTE = {\n  id: 'Byte',\n  bit: 1 << 2,\n  ccBits: [8, 16, 16]\n}\n\n/**\n * The Kanji mode efficiently encodes Kanji characters in accordance with\n * the Shift JIS system based on JIS X 0208.\n * The Shift JIS values are shifted from the JIS X 0208 values.\n * JIS X 0208 gives details of the shift coded representation.\n * Each two-byte character value is compacted to a 13-bit binary codeword.\n *\n * @type {Object}\n */\nexports.KANJI = {\n  id: 'Kanji',\n  bit: 1 << 3,\n  ccBits: [8, 10, 12]\n}\n\n/**\n * Mixed mode will contain a sequences of data in a combination of any of\n * the modes described above\n *\n * @type {Object}\n */\nexports.MIXED = {\n  bit: -1\n}\n\n/**\n * Returns the number of bits needed to store the data length\n * according to QR Code specifications.\n *\n * @param  {Mode}   mode    Data mode\n * @param  {Number} version QR Code version\n * @return {Number}         Number of bits\n */\nexports.getCharCountIndicator = function getCharCountIndicator (mode, version) {\n  if (!mode.ccBits) throw new Error('Invalid mode: ' + mode)\n\n  if (!VersionCheck.isValid(version)) {\n    throw new Error('Invalid version: ' + version)\n  }\n\n  if (version >= 1 && version < 10) return mode.ccBits[0]\n  else if (version < 27) return mode.ccBits[1]\n  return mode.ccBits[2]\n}\n\n/**\n * Returns the most efficient mode to store the specified data\n *\n * @param  {String} dataStr Input data string\n * @return {Mode}           Best mode\n */\nexports.getBestModeForData = function getBestModeForData (dataStr) {\n  if (Regex.testNumeric(dataStr)) return exports.NUMERIC\n  else if (Regex.testAlphanumeric(dataStr)) return exports.ALPHANUMERIC\n  else if (Regex.testKanji(dataStr)) return exports.KANJI\n  else return exports.BYTE\n}\n\n/**\n * Return mode name as string\n *\n * @param {Mode} mode Mode object\n * @returns {String}  Mode name\n */\nexports.toString = function toString (mode) {\n  if (mode && mode.id) return mode.id\n  throw new Error('Invalid mode')\n}\n\n/**\n * Check if input param is a valid mode object\n *\n * @param   {Mode}    mode Mode object\n * @returns {Boolean} True if valid mode, false otherwise\n */\nexports.isValid = function isValid (mode) {\n  return mode && mode.bit && mode.ccBits\n}\n\n/**\n * Get mode object from its name\n *\n * @param   {String} string Mode name\n * @returns {Mode}          Mode object\n */\nfunction fromString (string) {\n  if (typeof string !== 'string') {\n    throw new Error('Param is not a string')\n  }\n\n  const lcStr = string.toLowerCase()\n\n  switch (lcStr) {\n    case 'numeric':\n      return exports.NUMERIC\n    case 'alphanumeric':\n      return exports.ALPHANUMERIC\n    case 'kanji':\n      return exports.KANJI\n    case 'byte':\n      return exports.BYTE\n    default:\n      throw new Error('Unknown mode: ' + string)\n  }\n}\n\n/**\n * Returns mode from a value.\n * If value is not a valid mode, returns defaultValue\n *\n * @param  {Mode|String} value        Encoding mode\n * @param  {Mode}        defaultValue Fallback value\n * @return {Mode}                     Encoding mode\n */\nexports.from = function from (value, defaultValue) {\n  if (exports.isValid(value)) {\n    return value\n  }\n\n  try {\n    return fromString(value)\n  } catch (e) {\n    return defaultValue\n  }\n}\n","const Mode = require('./mode')\n\nfunction NumericData (data) {\n  this.mode = Mode.NUMERIC\n  this.data = data.toString()\n}\n\nNumericData.getBitsLength = function getBitsLength (length) {\n  return 10 * Math.floor(length / 3) + ((length % 3) ? ((length % 3) * 3 + 1) : 0)\n}\n\nNumericData.prototype.getLength = function getLength () {\n  return this.data.length\n}\n\nNumericData.prototype.getBitsLength = function getBitsLength () {\n  return NumericData.getBitsLength(this.data.length)\n}\n\nNumericData.prototype.write = function write (bitBuffer) {\n  let i, group, value\n\n  // The input data string is divided into groups of three digits,\n  // and each group is converted to its 10-bit binary equivalent.\n  for (i = 0; i + 3 <= this.data.length; i += 3) {\n    group = this.data.substr(i, 3)\n    value = parseInt(group, 10)\n\n    bitBuffer.put(value, 10)\n  }\n\n  // If the number of input digits is not an exact multiple of three,\n  // the final one or two digits are converted to 4 or 7 bits respectively.\n  const remainingNum = this.data.length - i\n  if (remainingNum > 0) {\n    group = this.data.substr(i)\n    value = parseInt(group, 10)\n\n    bitBuffer.put(value, remainingNum * 3 + 1)\n  }\n}\n\nmodule.exports = NumericData\n","const GF = require('./galois-field')\n\n/**\n * Multiplies two polynomials inside Galois Field\n *\n * @param  {Uint8Array} p1 Polynomial\n * @param  {Uint8Array} p2 Polynomial\n * @return {Uint8Array}    Product of p1 and p2\n */\nexports.mul = function mul (p1, p2) {\n  const coeff = new Uint8Array(p1.length + p2.length - 1)\n\n  for (let i = 0; i < p1.length; i++) {\n    for (let j = 0; j < p2.length; j++) {\n      coeff[i + j] ^= GF.mul(p1[i], p2[j])\n    }\n  }\n\n  return coeff\n}\n\n/**\n * Calculate the remainder of polynomials division\n *\n * @param  {Uint8Array} divident Polynomial\n * @param  {Uint8Array} divisor  Polynomial\n * @return {Uint8Array}          Remainder\n */\nexports.mod = function mod (divident, divisor) {\n  let result = new Uint8Array(divident)\n\n  while ((result.length - divisor.length) >= 0) {\n    const coeff = result[0]\n\n    for (let i = 0; i < divisor.length; i++) {\n      result[i] ^= GF.mul(divisor[i], coeff)\n    }\n\n    // remove all zeros from buffer head\n    let offset = 0\n    while (offset < result.length && result[offset] === 0) offset++\n    result = result.slice(offset)\n  }\n\n  return result\n}\n\n/**\n * Generate an irreducible generator polynomial of specified degree\n * (used by Reed-Solomon encoder)\n *\n * @param  {Number} degree Degree of the generator polynomial\n * @return {Uint8Array}    Buffer containing polynomial coefficients\n */\nexports.generateECPolynomial = function generateECPolynomial (degree) {\n  let poly = new Uint8Array([1])\n  for (let i = 0; i < degree; i++) {\n    poly = exports.mul(poly, new Uint8Array([1, GF.exp(i)]))\n  }\n\n  return poly\n}\n","const Utils = require('./utils')\nconst ECLevel = require('./error-correction-level')\nconst BitBuffer = require('./bit-buffer')\nconst BitMatrix = require('./bit-matrix')\nconst AlignmentPattern = require('./alignment-pattern')\nconst FinderPattern = require('./finder-pattern')\nconst MaskPattern = require('./mask-pattern')\nconst ECCode = require('./error-correction-code')\nconst ReedSolomonEncoder = require('./reed-solomon-encoder')\nconst Version = require('./version')\nconst FormatInfo = require('./format-info')\nconst Mode = require('./mode')\nconst Segments = require('./segments')\n\n/**\n * QRCode for JavaScript\n *\n * modified by Ryan Day for nodejs support\n * Copyright (c) 2011 Ryan Day\n *\n * Licensed under the MIT license:\n *   http://www.opensource.org/licenses/mit-license.php\n *\n//---------------------------------------------------------------------\n// QRCode for JavaScript\n//\n// Copyright (c) 2009 Kazuhiko Arase\n//\n// URL: http://www.d-project.com/\n//\n// Licensed under the MIT license:\n//   http://www.opensource.org/licenses/mit-license.php\n//\n// The word \"QR Code\" is registered trademark of\n// DENSO WAVE INCORPORATED\n//   http://www.denso-wave.com/qrcode/faqpatent-e.html\n//\n//---------------------------------------------------------------------\n*/\n\n/**\n * Add finder patterns bits to matrix\n *\n * @param  {BitMatrix} matrix  Modules matrix\n * @param  {Number}    version QR Code version\n */\nfunction setupFinderPattern (matrix, version) {\n  const size = matrix.size\n  const pos = FinderPattern.getPositions(version)\n\n  for (let i = 0; i < pos.length; i++) {\n    const row = pos[i][0]\n    const col = pos[i][1]\n\n    for (let r = -1; r <= 7; r++) {\n      if (row + r <= -1 || size <= row + r) continue\n\n      for (let c = -1; c <= 7; c++) {\n        if (col + c <= -1 || size <= col + c) continue\n\n        if ((r >= 0 && r <= 6 && (c === 0 || c === 6)) ||\n          (c >= 0 && c <= 6 && (r === 0 || r === 6)) ||\n          (r >= 2 && r <= 4 && c >= 2 && c <= 4)) {\n          matrix.set(row + r, col + c, true, true)\n        } else {\n          matrix.set(row + r, col + c, false, true)\n        }\n      }\n    }\n  }\n}\n\n/**\n * Add timing pattern bits to matrix\n *\n * Note: this function must be called before {@link setupAlignmentPattern}\n *\n * @param  {BitMatrix} matrix Modules matrix\n */\nfunction setupTimingPattern (matrix) {\n  const size = matrix.size\n\n  for (let r = 8; r < size - 8; r++) {\n    const value = r % 2 === 0\n    matrix.set(r, 6, value, true)\n    matrix.set(6, r, value, true)\n  }\n}\n\n/**\n * Add alignment patterns bits to matrix\n *\n * Note: this function must be called after {@link setupTimingPattern}\n *\n * @param  {BitMatrix} matrix  Modules matrix\n * @param  {Number}    version QR Code version\n */\nfunction setupAlignmentPattern (matrix, version) {\n  const pos = AlignmentPattern.getPositions(version)\n\n  for (let i = 0; i < pos.length; i++) {\n    const row = pos[i][0]\n    const col = pos[i][1]\n\n    for (let r = -2; r <= 2; r++) {\n      for (let c = -2; c <= 2; c++) {\n        if (r === -2 || r === 2 || c === -2 || c === 2 ||\n          (r === 0 && c === 0)) {\n          matrix.set(row + r, col + c, true, true)\n        } else {\n          matrix.set(row + r, col + c, false, true)\n        }\n      }\n    }\n  }\n}\n\n/**\n * Add version info bits to matrix\n *\n * @param  {BitMatrix} matrix  Modules matrix\n * @param  {Number}    version QR Code version\n */\nfunction setupVersionInfo (matrix, version) {\n  const size = matrix.size\n  const bits = Version.getEncodedBits(version)\n  let row, col, mod\n\n  for (let i = 0; i < 18; i++) {\n    row = Math.floor(i / 3)\n    col = i % 3 + size - 8 - 3\n    mod = ((bits >> i) & 1) === 1\n\n    matrix.set(row, col, mod, true)\n    matrix.set(col, row, mod, true)\n  }\n}\n\n/**\n * Add format info bits to matrix\n *\n * @param  {BitMatrix} matrix               Modules matrix\n * @param  {ErrorCorrectionLevel}    errorCorrectionLevel Error correction level\n * @param  {Number}    maskPattern          Mask pattern reference value\n */\nfunction setupFormatInfo (matrix, errorCorrectionLevel, maskPattern) {\n  const size = matrix.size\n  const bits = FormatInfo.getEncodedBits(errorCorrectionLevel, maskPattern)\n  let i, mod\n\n  for (i = 0; i < 15; i++) {\n    mod = ((bits >> i) & 1) === 1\n\n    // vertical\n    if (i < 6) {\n      matrix.set(i, 8, mod, true)\n    } else if (i < 8) {\n      matrix.set(i + 1, 8, mod, true)\n    } else {\n      matrix.set(size - 15 + i, 8, mod, true)\n    }\n\n    // horizontal\n    if (i < 8) {\n      matrix.set(8, size - i - 1, mod, true)\n    } else if (i < 9) {\n      matrix.set(8, 15 - i - 1 + 1, mod, true)\n    } else {\n      matrix.set(8, 15 - i - 1, mod, true)\n    }\n  }\n\n  // fixed module\n  matrix.set(size - 8, 8, 1, true)\n}\n\n/**\n * Add encoded data bits to matrix\n *\n * @param  {BitMatrix}  matrix Modules matrix\n * @param  {Uint8Array} data   Data codewords\n */\nfunction setupData (matrix, data) {\n  const size = matrix.size\n  let inc = -1\n  let row = size - 1\n  let bitIndex = 7\n  let byteIndex = 0\n\n  for (let col = size - 1; col > 0; col -= 2) {\n    if (col === 6) col--\n\n    while (true) {\n      for (let c = 0; c < 2; c++) {\n        if (!matrix.isReserved(row, col - c)) {\n          let dark = false\n\n          if (byteIndex < data.length) {\n            dark = (((data[byteIndex] >>> bitIndex) & 1) === 1)\n          }\n\n          matrix.set(row, col - c, dark)\n          bitIndex--\n\n          if (bitIndex === -1) {\n            byteIndex++\n            bitIndex = 7\n          }\n        }\n      }\n\n      row += inc\n\n      if (row < 0 || size <= row) {\n        row -= inc\n        inc = -inc\n        break\n      }\n    }\n  }\n}\n\n/**\n * Create encoded codewords from data input\n *\n * @param  {Number}   version              QR Code version\n * @param  {ErrorCorrectionLevel}   errorCorrectionLevel Error correction level\n * @param  {ByteData} data                 Data input\n * @return {Uint8Array}                    Buffer containing encoded codewords\n */\nfunction createData (version, errorCorrectionLevel, segments) {\n  // Prepare data buffer\n  const buffer = new BitBuffer()\n\n  segments.forEach(function (data) {\n    // prefix data with mode indicator (4 bits)\n    buffer.put(data.mode.bit, 4)\n\n    // Prefix data with character count indicator.\n    // The character count indicator is a string of bits that represents the\n    // number of characters that are being encoded.\n    // The character count indicator must be placed after the mode indicator\n    // and must be a certain number of bits long, depending on the QR version\n    // and data mode\n    // @see {@link Mode.getCharCountIndicator}.\n    buffer.put(data.getLength(), Mode.getCharCountIndicator(data.mode, version))\n\n    // add binary data sequence to buffer\n    data.write(buffer)\n  })\n\n  // Calculate required number of bits\n  const totalCodewords = Utils.getSymbolTotalCodewords(version)\n  const ecTotalCodewords = ECCode.getTotalCodewordsCount(version, errorCorrectionLevel)\n  const dataTotalCodewordsBits = (totalCodewords - ecTotalCodewords) * 8\n\n  // Add a terminator.\n  // If the bit string is shorter than the total number of required bits,\n  // a terminator of up to four 0s must be added to the right side of the string.\n  // If the bit string is more than four bits shorter than the required number of bits,\n  // add four 0s to the end.\n  if (buffer.getLengthInBits() + 4 <= dataTotalCodewordsBits) {\n    buffer.put(0, 4)\n  }\n\n  // If the bit string is fewer than four bits shorter, add only the number of 0s that\n  // are needed to reach the required number of bits.\n\n  // After adding the terminator, if the number of bits in the string is not a multiple of 8,\n  // pad the string on the right with 0s to make the string's length a multiple of 8.\n  while (buffer.getLengthInBits() % 8 !== 0) {\n    buffer.putBit(0)\n  }\n\n  // Add pad bytes if the string is still shorter than the total number of required bits.\n  // Extend the buffer to fill the data capacity of the symbol corresponding to\n  // the Version and Error Correction Level by adding the Pad Codewords 11101100 (0xEC)\n  // and 00010001 (0x11) alternately.\n  const remainingByte = (dataTotalCodewordsBits - buffer.getLengthInBits()) / 8\n  for (let i = 0; i < remainingByte; i++) {\n    buffer.put(i % 2 ? 0x11 : 0xEC, 8)\n  }\n\n  return createCodewords(buffer, version, errorCorrectionLevel)\n}\n\n/**\n * Encode input data with Reed-Solomon and return codewords with\n * relative error correction bits\n *\n * @param  {BitBuffer} bitBuffer            Data to encode\n * @param  {Number}    version              QR Code version\n * @param  {ErrorCorrectionLevel} errorCorrectionLevel Error correction level\n * @return {Uint8Array}                     Buffer containing encoded codewords\n */\nfunction createCodewords (bitBuffer, version, errorCorrectionLevel) {\n  // Total codewords for this QR code version (Data + Error correction)\n  const totalCodewords = Utils.getSymbolTotalCodewords(version)\n\n  // Total number of error correction codewords\n  const ecTotalCodewords = ECCode.getTotalCodewordsCount(version, errorCorrectionLevel)\n\n  // Total number of data codewords\n  const dataTotalCodewords = totalCodewords - ecTotalCodewords\n\n  // Total number of blocks\n  const ecTotalBlocks = ECCode.getBlocksCount(version, errorCorrectionLevel)\n\n  // Calculate how many blocks each group should contain\n  const blocksInGroup2 = totalCodewords % ecTotalBlocks\n  const blocksInGroup1 = ecTotalBlocks - blocksInGroup2\n\n  const totalCodewordsInGroup1 = Math.floor(totalCodewords / ecTotalBlocks)\n\n  const dataCodewordsInGroup1 = Math.floor(dataTotalCodewords / ecTotalBlocks)\n  const dataCodewordsInGroup2 = dataCodewordsInGroup1 + 1\n\n  // Number of EC codewords is the same for both groups\n  const ecCount = totalCodewordsInGroup1 - dataCodewordsInGroup1\n\n  // Initialize a Reed-Solomon encoder with a generator polynomial of degree ecCount\n  const rs = new ReedSolomonEncoder(ecCount)\n\n  let offset = 0\n  const dcData = new Array(ecTotalBlocks)\n  const ecData = new Array(ecTotalBlocks)\n  let maxDataSize = 0\n  const buffer = new Uint8Array(bitBuffer.buffer)\n\n  // Divide the buffer into the required number of blocks\n  for (let b = 0; b < ecTotalBlocks; b++) {\n    const dataSize = b < blocksInGroup1 ? dataCodewordsInGroup1 : dataCodewordsInGroup2\n\n    // extract a block of data from buffer\n    dcData[b] = buffer.slice(offset, offset + dataSize)\n\n    // Calculate EC codewords for this data block\n    ecData[b] = rs.encode(dcData[b])\n\n    offset += dataSize\n    maxDataSize = Math.max(maxDataSize, dataSize)\n  }\n\n  // Create final data\n  // Interleave the data and error correction codewords from each block\n  const data = new Uint8Array(totalCodewords)\n  let index = 0\n  let i, r\n\n  // Add data codewords\n  for (i = 0; i < maxDataSize; i++) {\n    for (r = 0; r < ecTotalBlocks; r++) {\n      if (i < dcData[r].length) {\n        data[index++] = dcData[r][i]\n      }\n    }\n  }\n\n  // Apped EC codewords\n  for (i = 0; i < ecCount; i++) {\n    for (r = 0; r < ecTotalBlocks; r++) {\n      data[index++] = ecData[r][i]\n    }\n  }\n\n  return data\n}\n\n/**\n * Build QR Code symbol\n *\n * @param  {String} data                 Input string\n * @param  {Number} version              QR Code version\n * @param  {ErrorCorretionLevel} errorCorrectionLevel Error level\n * @param  {MaskPattern} maskPattern     Mask pattern\n * @return {Object}                      Object containing symbol data\n */\nfunction createSymbol (data, version, errorCorrectionLevel, maskPattern) {\n  let segments\n\n  if (Array.isArray(data)) {\n    segments = Segments.fromArray(data)\n  } else if (typeof data === 'string') {\n    let estimatedVersion = version\n\n    if (!estimatedVersion) {\n      const rawSegments = Segments.rawSplit(data)\n\n      // Estimate best version that can contain raw splitted segments\n      estimatedVersion = Version.getBestVersionForData(rawSegments, errorCorrectionLevel)\n    }\n\n    // Build optimized segments\n    // If estimated version is undefined, try with the highest version\n    segments = Segments.fromString(data, estimatedVersion || 40)\n  } else {\n    throw new Error('Invalid data')\n  }\n\n  // Get the min version that can contain data\n  const bestVersion = Version.getBestVersionForData(segments, errorCorrectionLevel)\n\n  // If no version is found, data cannot be stored\n  if (!bestVersion) {\n    throw new Error('The amount of data is too big to be stored in a QR Code')\n  }\n\n  // If not specified, use min version as default\n  if (!version) {\n    version = bestVersion\n\n  // Check if the specified version can contain the data\n  } else if (version < bestVersion) {\n    throw new Error('\\n' +\n      'The chosen QR Code version cannot contain this amount of data.\\n' +\n      'Minimum version required to store current data is: ' + bestVersion + '.\\n'\n    )\n  }\n\n  const dataBits = createData(version, errorCorrectionLevel, segments)\n\n  // Allocate matrix buffer\n  const moduleCount = Utils.getSymbolSize(version)\n  const modules = new BitMatrix(moduleCount)\n\n  // Add function modules\n  setupFinderPattern(modules, version)\n  setupTimingPattern(modules)\n  setupAlignmentPattern(modules, version)\n\n  // Add temporary dummy bits for format info just to set them as reserved.\n  // This is needed to prevent these bits from being masked by {@link MaskPattern.applyMask}\n  // since the masking operation must be performed only on the encoding region.\n  // These blocks will be replaced with correct values later in code.\n  setupFormatInfo(modules, errorCorrectionLevel, 0)\n\n  if (version >= 7) {\n    setupVersionInfo(modules, version)\n  }\n\n  // Add data codewords\n  setupData(modules, dataBits)\n\n  if (isNaN(maskPattern)) {\n    // Find best mask pattern\n    maskPattern = MaskPattern.getBestMask(modules,\n      setupFormatInfo.bind(null, modules, errorCorrectionLevel))\n  }\n\n  // Apply mask pattern\n  MaskPattern.applyMask(maskPattern, modules)\n\n  // Replace format info bits with correct values\n  setupFormatInfo(modules, errorCorrectionLevel, maskPattern)\n\n  return {\n    modules: modules,\n    version: version,\n    errorCorrectionLevel: errorCorrectionLevel,\n    maskPattern: maskPattern,\n    segments: segments\n  }\n}\n\n/**\n * QR Code\n *\n * @param {String | Array} data                 Input data\n * @param {Object} options                      Optional configurations\n * @param {Number} options.version              QR Code version\n * @param {String} options.errorCorrectionLevel Error correction level\n * @param {Function} options.toSJISFunc         Helper func to convert utf8 to sjis\n */\nexports.create = function create (data, options) {\n  if (typeof data === 'undefined' || data === '') {\n    throw new Error('No input text')\n  }\n\n  let errorCorrectionLevel = ECLevel.M\n  let version\n  let mask\n\n  if (typeof options !== 'undefined') {\n    // Use higher error correction level as default\n    errorCorrectionLevel = ECLevel.from(options.errorCorrectionLevel, ECLevel.M)\n    version = Version.from(options.version)\n    mask = MaskPattern.from(options.maskPattern)\n\n    if (options.toSJISFunc) {\n      Utils.setToSJISFunction(options.toSJISFunc)\n    }\n  }\n\n  return createSymbol(data, version, errorCorrectionLevel, mask)\n}\n","const Polynomial = require('./polynomial')\n\nfunction ReedSolomonEncoder (degree) {\n  this.genPoly = undefined\n  this.degree = degree\n\n  if (this.degree) this.initialize(this.degree)\n}\n\n/**\n * Initialize the encoder.\n * The input param should correspond to the number of error correction codewords.\n *\n * @param  {Number} degree\n */\nReedSolomonEncoder.prototype.initialize = function initialize (degree) {\n  // create an irreducible generator polynomial\n  this.degree = degree\n  this.genPoly = Polynomial.generateECPolynomial(this.degree)\n}\n\n/**\n * Encodes a chunk of data\n *\n * @param  {Uint8Array} data Buffer containing input data\n * @return {Uint8Array}      Buffer containing encoded data\n */\nReedSolomonEncoder.prototype.encode = function encode (data) {\n  if (!this.genPoly) {\n    throw new Error('Encoder not initialized')\n  }\n\n  // Calculate EC for this data block\n  // extends data size to data+genPoly size\n  const paddedData = new Uint8Array(data.length + this.degree)\n  paddedData.set(data)\n\n  // The error correction codewords are the remainder after dividing the data codewords\n  // by a generator polynomial\n  const remainder = Polynomial.mod(paddedData, this.genPoly)\n\n  // return EC data blocks (last n byte, where n is the degree of genPoly)\n  // If coefficients number in remainder are less than genPoly degree,\n  // pad with 0s to the left to reach the needed number of coefficients\n  const start = this.degree - remainder.length\n  if (start > 0) {\n    const buff = new Uint8Array(this.degree)\n    buff.set(remainder, start)\n\n    return buff\n  }\n\n  return remainder\n}\n\nmodule.exports = ReedSolomonEncoder\n","const numeric = '[0-9]+'\nconst alphanumeric = '[A-Z $%*+\\\\-./:]+'\nlet kanji = '(?:[u3000-u303F]|[u3040-u309F]|[u30A0-u30FF]|' +\n  '[uFF00-uFFEF]|[u4E00-u9FAF]|[u2605-u2606]|[u2190-u2195]|u203B|' +\n  '[u2010u2015u2018u2019u2025u2026u201Cu201Du2225u2260]|' +\n  '[u0391-u0451]|[u00A7u00A8u00B1u00B4u00D7u00F7])+'\nkanji = kanji.replace(/u/g, '\\\\u')\n\nconst byte = '(?:(?![A-Z0-9 $%*+\\\\-./:]|' + kanji + ')(?:.|[\\r\\n]))+'\n\nexports.KANJI = new RegExp(kanji, 'g')\nexports.BYTE_KANJI = new RegExp('[^A-Z0-9 $%*+\\\\-./:]+', 'g')\nexports.BYTE = new RegExp(byte, 'g')\nexports.NUMERIC = new RegExp(numeric, 'g')\nexports.ALPHANUMERIC = new RegExp(alphanumeric, 'g')\n\nconst TEST_KANJI = new RegExp('^' + kanji + '$')\nconst TEST_NUMERIC = new RegExp('^' + numeric + '$')\nconst TEST_ALPHANUMERIC = new RegExp('^[A-Z0-9 $%*+\\\\-./:]+$')\n\nexports.testKanji = function testKanji (str) {\n  return TEST_KANJI.test(str)\n}\n\nexports.testNumeric = function testNumeric (str) {\n  return TEST_NUMERIC.test(str)\n}\n\nexports.testAlphanumeric = function testAlphanumeric (str) {\n  return TEST_ALPHANUMERIC.test(str)\n}\n","const Mode = require('./mode')\nconst NumericData = require('./numeric-data')\nconst AlphanumericData = require('./alphanumeric-data')\nconst ByteData = require('./byte-data')\nconst KanjiData = require('./kanji-data')\nconst Regex = require('./regex')\nconst Utils = require('./utils')\nconst dijkstra = require('dijkstrajs')\n\n/**\n * Returns UTF8 byte length\n *\n * @param  {String} str Input string\n * @return {Number}     Number of byte\n */\nfunction getStringByteLength (str) {\n  return unescape(encodeURIComponent(str)).length\n}\n\n/**\n * Get a list of segments of the specified mode\n * from a string\n *\n * @param  {Mode}   mode Segment mode\n * @param  {String} str  String to process\n * @return {Array}       Array of object with segments data\n */\nfunction getSegments (regex, mode, str) {\n  const segments = []\n  let result\n\n  while ((result = regex.exec(str)) !== null) {\n    segments.push({\n      data: result[0],\n      index: result.index,\n      mode: mode,\n      length: result[0].length\n    })\n  }\n\n  return segments\n}\n\n/**\n * Extracts a series of segments with the appropriate\n * modes from a string\n *\n * @param  {String} dataStr Input string\n * @return {Array}          Array of object with segments data\n */\nfunction getSegmentsFromString (dataStr) {\n  const numSegs = getSegments(Regex.NUMERIC, Mode.NUMERIC, dataStr)\n  const alphaNumSegs = getSegments(Regex.ALPHANUMERIC, Mode.ALPHANUMERIC, dataStr)\n  let byteSegs\n  let kanjiSegs\n\n  if (Utils.isKanjiModeEnabled()) {\n    byteSegs = getSegments(Regex.BYTE, Mode.BYTE, dataStr)\n    kanjiSegs = getSegments(Regex.KANJI, Mode.KANJI, dataStr)\n  } else {\n    byteSegs = getSegments(Regex.BYTE_KANJI, Mode.BYTE, dataStr)\n    kanjiSegs = []\n  }\n\n  const segs = numSegs.concat(alphaNumSegs, byteSegs, kanjiSegs)\n\n  return segs\n    .sort(function (s1, s2) {\n      return s1.index - s2.index\n    })\n    .map(function (obj) {\n      return {\n        data: obj.data,\n        mode: obj.mode,\n        length: obj.length\n      }\n    })\n}\n\n/**\n * Returns how many bits are needed to encode a string of\n * specified length with the specified mode\n *\n * @param  {Number} length String length\n * @param  {Mode} mode     Segment mode\n * @return {Number}        Bit length\n */\nfunction getSegmentBitsLength (length, mode) {\n  switch (mode) {\n    case Mode.NUMERIC:\n      return NumericData.getBitsLength(length)\n    case Mode.ALPHANUMERIC:\n      return AlphanumericData.getBitsLength(length)\n    case Mode.KANJI:\n      return KanjiData.getBitsLength(length)\n    case Mode.BYTE:\n      return ByteData.getBitsLength(length)\n  }\n}\n\n/**\n * Merges adjacent segments which have the same mode\n *\n * @param  {Array} segs Array of object with segments data\n * @return {Array}      Array of object with segments data\n */\nfunction mergeSegments (segs) {\n  return segs.reduce(function (acc, curr) {\n    const prevSeg = acc.length - 1 >= 0 ? acc[acc.length - 1] : null\n    if (prevSeg && prevSeg.mode === curr.mode) {\n      acc[acc.length - 1].data += curr.data\n      return acc\n    }\n\n    acc.push(curr)\n    return acc\n  }, [])\n}\n\n/**\n * Generates a list of all possible nodes combination which\n * will be used to build a segments graph.\n *\n * Nodes are divided by groups. Each group will contain a list of all the modes\n * in which is possible to encode the given text.\n *\n * For example the text '12345' can be encoded as Numeric, Alphanumeric or Byte.\n * The group for '12345' will contain then 3 objects, one for each\n * possible encoding mode.\n *\n * Each node represents a possible segment.\n *\n * @param  {Array} segs Array of object with segments data\n * @return {Array}      Array of object with segments data\n */\nfunction buildNodes (segs) {\n  const nodes = []\n  for (let i = 0; i < segs.length; i++) {\n    const seg = segs[i]\n\n    switch (seg.mode) {\n      case Mode.NUMERIC:\n        nodes.push([seg,\n          { data: seg.data, mode: Mode.ALPHANUMERIC, length: seg.length },\n          { data: seg.data, mode: Mode.BYTE, length: seg.length }\n        ])\n        break\n      case Mode.ALPHANUMERIC:\n        nodes.push([seg,\n          { data: seg.data, mode: Mode.BYTE, length: seg.length }\n        ])\n        break\n      case Mode.KANJI:\n        nodes.push([seg,\n          { data: seg.data, mode: Mode.BYTE, length: getStringByteLength(seg.data) }\n        ])\n        break\n      case Mode.BYTE:\n        nodes.push([\n          { data: seg.data, mode: Mode.BYTE, length: getStringByteLength(seg.data) }\n        ])\n    }\n  }\n\n  return nodes\n}\n\n/**\n * Builds a graph from a list of nodes.\n * All segments in each node group will be connected with all the segments of\n * the next group and so on.\n *\n * At each connection will be assigned a weight depending on the\n * segment's byte length.\n *\n * @param  {Array} nodes    Array of object with segments data\n * @param  {Number} version QR Code version\n * @return {Object}         Graph of all possible segments\n */\nfunction buildGraph (nodes, version) {\n  const table = {}\n  const graph = { start: {} }\n  let prevNodeIds = ['start']\n\n  for (let i = 0; i < nodes.length; i++) {\n    const nodeGroup = nodes[i]\n    const currentNodeIds = []\n\n    for (let j = 0; j < nodeGroup.length; j++) {\n      const node = nodeGroup[j]\n      const key = '' + i + j\n\n      currentNodeIds.push(key)\n      table[key] = { node: node, lastCount: 0 }\n      graph[key] = {}\n\n      for (let n = 0; n < prevNodeIds.length; n++) {\n        const prevNodeId = prevNodeIds[n]\n\n        if (table[prevNodeId] && table[prevNodeId].node.mode === node.mode) {\n          graph[prevNodeId][key] =\n            getSegmentBitsLength(table[prevNodeId].lastCount + node.length, node.mode) -\n            getSegmentBitsLength(table[prevNodeId].lastCount, node.mode)\n\n          table[prevNodeId].lastCount += node.length\n        } else {\n          if (table[prevNodeId]) table[prevNodeId].lastCount = node.length\n\n          graph[prevNodeId][key] = getSegmentBitsLength(node.length, node.mode) +\n            4 + Mode.getCharCountIndicator(node.mode, version) // switch cost\n        }\n      }\n    }\n\n    prevNodeIds = currentNodeIds\n  }\n\n  for (let n = 0; n < prevNodeIds.length; n++) {\n    graph[prevNodeIds[n]].end = 0\n  }\n\n  return { map: graph, table: table }\n}\n\n/**\n * Builds a segment from a specified data and mode.\n * If a mode is not specified, the more suitable will be used.\n *\n * @param  {String} data             Input data\n * @param  {Mode | String} modesHint Data mode\n * @return {Segment}                 Segment\n */\nfunction buildSingleSegment (data, modesHint) {\n  let mode\n  const bestMode = Mode.getBestModeForData(data)\n\n  mode = Mode.from(modesHint, bestMode)\n\n  // Make sure data can be encoded\n  if (mode !== Mode.BYTE && mode.bit < bestMode.bit) {\n    throw new Error('\"' + data + '\"' +\n      ' cannot be encoded with mode ' + Mode.toString(mode) +\n      '.\\n Suggested mode is: ' + Mode.toString(bestMode))\n  }\n\n  // Use Mode.BYTE if Kanji support is disabled\n  if (mode === Mode.KANJI && !Utils.isKanjiModeEnabled()) {\n    mode = Mode.BYTE\n  }\n\n  switch (mode) {\n    case Mode.NUMERIC:\n      return new NumericData(data)\n\n    case Mode.ALPHANUMERIC:\n      return new AlphanumericData(data)\n\n    case Mode.KANJI:\n      return new KanjiData(data)\n\n    case Mode.BYTE:\n      return new ByteData(data)\n  }\n}\n\n/**\n * Builds a list of segments from an array.\n * Array can contain Strings or Objects with segment's info.\n *\n * For each item which is a string, will be generated a segment with the given\n * string and the more appropriate encoding mode.\n *\n * For each item which is an object, will be generated a segment with the given\n * data and mode.\n * Objects must contain at least the property \"data\".\n * If property \"mode\" is not present, the more suitable mode will be used.\n *\n * @param  {Array} array Array of objects with segments data\n * @return {Array}       Array of Segments\n */\nexports.fromArray = function fromArray (array) {\n  return array.reduce(function (acc, seg) {\n    if (typeof seg === 'string') {\n      acc.push(buildSingleSegment(seg, null))\n    } else if (seg.data) {\n      acc.push(buildSingleSegment(seg.data, seg.mode))\n    }\n\n    return acc\n  }, [])\n}\n\n/**\n * Builds an optimized sequence of segments from a string,\n * which will produce the shortest possible bitstream.\n *\n * @param  {String} data    Input string\n * @param  {Number} version QR Code version\n * @return {Array}          Array of segments\n */\nexports.fromString = function fromString (data, version) {\n  const segs = getSegmentsFromString(data, Utils.isKanjiModeEnabled())\n\n  const nodes = buildNodes(segs)\n  const graph = buildGraph(nodes, version)\n  const path = dijkstra.find_path(graph.map, 'start', 'end')\n\n  const optimizedSegs = []\n  for (let i = 1; i < path.length - 1; i++) {\n    optimizedSegs.push(graph.table[path[i]].node)\n  }\n\n  return exports.fromArray(mergeSegments(optimizedSegs))\n}\n\n/**\n * Splits a string in various segments with the modes which\n * best represent their content.\n * The produced segments are far from being optimized.\n * The output of this function is only used to estimate a QR Code version\n * which may contain the data.\n *\n * @param  {string} data Input string\n * @return {Array}       Array of segments\n */\nexports.rawSplit = function rawSplit (data) {\n  return exports.fromArray(\n    getSegmentsFromString(data, Utils.isKanjiModeEnabled())\n  )\n}\n","let toSJISFunction\nconst CODEWORDS_COUNT = [\n  0, // Not used\n  26, 44, 70, 100, 134, 172, 196, 242, 292, 346,\n  404, 466, 532, 581, 655, 733, 815, 901, 991, 1085,\n  1156, 1258, 1364, 1474, 1588, 1706, 1828, 1921, 2051, 2185,\n  2323, 2465, 2611, 2761, 2876, 3034, 3196, 3362, 3532, 3706\n]\n\n/**\n * Returns the QR Code size for the specified version\n *\n * @param  {Number} version QR Code version\n * @return {Number}         size of QR code\n */\nexports.getSymbolSize = function getSymbolSize (version) {\n  if (!version) throw new Error('\"version\" cannot be null or undefined')\n  if (version < 1 || version > 40) throw new Error('\"version\" should be in range from 1 to 40')\n  return version * 4 + 17\n}\n\n/**\n * Returns the total number of codewords used to store data and EC information.\n *\n * @param  {Number} version QR Code version\n * @return {Number}         Data length in bits\n */\nexports.getSymbolTotalCodewords = function getSymbolTotalCodewords (version) {\n  return CODEWORDS_COUNT[version]\n}\n\n/**\n * Encode data with Bose-Chaudhuri-Hocquenghem\n *\n * @param  {Number} data Value to encode\n * @return {Number}      Encoded value\n */\nexports.getBCHDigit = function (data) {\n  let digit = 0\n\n  while (data !== 0) {\n    digit++\n    data >>>= 1\n  }\n\n  return digit\n}\n\nexports.setToSJISFunction = function setToSJISFunction (f) {\n  if (typeof f !== 'function') {\n    throw new Error('\"toSJISFunc\" is not a valid function.')\n  }\n\n  toSJISFunction = f\n}\n\nexports.isKanjiModeEnabled = function () {\n  return typeof toSJISFunction !== 'undefined'\n}\n\nexports.toSJIS = function toSJIS (kanji) {\n  return toSJISFunction(kanji)\n}\n","/**\n * Check if QR Code version is valid\n *\n * @param  {Number}  version QR Code version\n * @return {Boolean}         true if valid version, false otherwise\n */\nexports.isValid = function isValid (version) {\n  return !isNaN(version) && version >= 1 && version <= 40\n}\n","const Utils = require('./utils')\nconst ECCode = require('./error-correction-code')\nconst ECLevel = require('./error-correction-level')\nconst Mode = require('./mode')\nconst VersionCheck = require('./version-check')\n\n// Generator polynomial used to encode version information\nconst G18 = (1 << 12) | (1 << 11) | (1 << 10) | (1 << 9) | (1 << 8) | (1 << 5) | (1 << 2) | (1 << 0)\nconst G18_BCH = Utils.getBCHDigit(G18)\n\nfunction getBestVersionForDataLength (mode, length, errorCorrectionLevel) {\n  for (let currentVersion = 1; currentVersion <= 40; currentVersion++) {\n    if (length <= exports.getCapacity(currentVersion, errorCorrectionLevel, mode)) {\n      return currentVersion\n    }\n  }\n\n  return undefined\n}\n\nfunction getReservedBitsCount (mode, version) {\n  // Character count indicator + mode indicator bits\n  return Mode.getCharCountIndicator(mode, version) + 4\n}\n\nfunction getTotalBitsFromDataArray (segments, version) {\n  let totalBits = 0\n\n  segments.forEach(function (data) {\n    const reservedBits = getReservedBitsCount(data.mode, version)\n    totalBits += reservedBits + data.getBitsLength()\n  })\n\n  return totalBits\n}\n\nfunction getBestVersionForMixedData (segments, errorCorrectionLevel) {\n  for (let currentVersion = 1; currentVersion <= 40; currentVersion++) {\n    const length = getTotalBitsFromDataArray(segments, currentVersion)\n    if (length <= exports.getCapacity(currentVersion, errorCorrectionLevel, Mode.MIXED)) {\n      return currentVersion\n    }\n  }\n\n  return undefined\n}\n\n/**\n * Returns version number from a value.\n * If value is not a valid version, returns defaultValue\n *\n * @param  {Number|String} value        QR Code version\n * @param  {Number}        defaultValue Fallback value\n * @return {Number}                     QR Code version number\n */\nexports.from = function from (value, defaultValue) {\n  if (VersionCheck.isValid(value)) {\n    return parseInt(value, 10)\n  }\n\n  return defaultValue\n}\n\n/**\n * Returns how much data can be stored with the specified QR code version\n * and error correction level\n *\n * @param  {Number} version              QR Code version (1-40)\n * @param  {Number} errorCorrectionLevel Error correction level\n * @param  {Mode}   mode                 Data mode\n * @return {Number}                      Quantity of storable data\n */\nexports.getCapacity = function getCapacity (version, errorCorrectionLevel, mode) {\n  if (!VersionCheck.isValid(version)) {\n    throw new Error('Invalid QR Code version')\n  }\n\n  // Use Byte mode as default\n  if (typeof mode === 'undefined') mode = Mode.BYTE\n\n  // Total codewords for this QR code version (Data + Error correction)\n  const totalCodewords = Utils.getSymbolTotalCodewords(version)\n\n  // Total number of error correction codewords\n  const ecTotalCodewords = ECCode.getTotalCodewordsCount(version, errorCorrectionLevel)\n\n  // Total number of data codewords\n  const dataTotalCodewordsBits = (totalCodewords - ecTotalCodewords) * 8\n\n  if (mode === Mode.MIXED) return dataTotalCodewordsBits\n\n  const usableBits = dataTotalCodewordsBits - getReservedBitsCount(mode, version)\n\n  // Return max number of storable codewords\n  switch (mode) {\n    case Mode.NUMERIC:\n      return Math.floor((usableBits / 10) * 3)\n\n    case Mode.ALPHANUMERIC:\n      return Math.floor((usableBits / 11) * 2)\n\n    case Mode.KANJI:\n      return Math.floor(usableBits / 13)\n\n    case Mode.BYTE:\n    default:\n      return Math.floor(usableBits / 8)\n  }\n}\n\n/**\n * Returns the minimum version needed to contain the amount of data\n *\n * @param  {Segment} data                    Segment of data\n * @param  {Number} [errorCorrectionLevel=H] Error correction level\n * @param  {Mode} mode                       Data mode\n * @return {Number}                          QR Code version\n */\nexports.getBestVersionForData = function getBestVersionForData (data, errorCorrectionLevel) {\n  let seg\n\n  const ecl = ECLevel.from(errorCorrectionLevel, ECLevel.M)\n\n  if (Array.isArray(data)) {\n    if (data.length > 1) {\n      return getBestVersionForMixedData(data, ecl)\n    }\n\n    if (data.length === 0) {\n      return 1\n    }\n\n    seg = data[0]\n  } else {\n    seg = data\n  }\n\n  return getBestVersionForDataLength(seg.mode, seg.getLength(), ecl)\n}\n\n/**\n * Returns version information with relative error correction bits\n *\n * The version information is included in QR Code symbols of version 7 or larger.\n * It consists of an 18-bit sequence containing 6 data bits,\n * with 12 error correction bits calculated using the (18, 6) Golay code.\n *\n * @param  {Number} version QR Code version\n * @return {Number}         Encoded version info bits\n */\nexports.getEncodedBits = function getEncodedBits (version) {\n  if (!VersionCheck.isValid(version) || version < 7) {\n    throw new Error('Invalid QR Code version')\n  }\n\n  let d = version << 12\n\n  while (Utils.getBCHDigit(d) - G18_BCH >= 0) {\n    d ^= (G18 << (Utils.getBCHDigit(d) - G18_BCH))\n  }\n\n  return (version << 12) | d\n}\n","const Utils = require('./utils')\n\nfunction clearCanvas (ctx, canvas, size) {\n  ctx.clearRect(0, 0, canvas.width, canvas.height)\n\n  if (!canvas.style) canvas.style = {}\n  canvas.height = size\n  canvas.width = size\n  canvas.style.height = size + 'px'\n  canvas.style.width = size + 'px'\n}\n\nfunction getCanvasElement () {\n  try {\n    return document.createElement('canvas')\n  } catch (e) {\n    throw new Error('You need to specify a canvas element')\n  }\n}\n\nexports.render = function render (qrData, canvas, options) {\n  let opts = options\n  let canvasEl = canvas\n\n  if (typeof opts === 'undefined' && (!canvas || !canvas.getContext)) {\n    opts = canvas\n    canvas = undefined\n  }\n\n  if (!canvas) {\n    canvasEl = getCanvasElement()\n  }\n\n  opts = Utils.getOptions(opts)\n  const size = Utils.getImageWidth(qrData.modules.size, opts)\n\n  const ctx = canvasEl.getContext('2d')\n  const image = ctx.createImageData(size, size)\n  Utils.qrToImageData(image.data, qrData, opts)\n\n  clearCanvas(ctx, canvasEl, size)\n  ctx.putImageData(image, 0, 0)\n\n  return canvasEl\n}\n\nexports.renderToDataURL = function renderToDataURL (qrData, canvas, options) {\n  let opts = options\n\n  if (typeof opts === 'undefined' && (!canvas || !canvas.getContext)) {\n    opts = canvas\n    canvas = undefined\n  }\n\n  if (!opts) opts = {}\n\n  const canvasEl = exports.render(qrData, canvas, opts)\n\n  const type = opts.type || 'image/png'\n  const rendererOpts = opts.rendererOpts || {}\n\n  return canvasEl.toDataURL(type, rendererOpts.quality)\n}\n","const Utils = require('./utils')\n\nfunction getColorAttrib (color, attrib) {\n  const alpha = color.a / 255\n  const str = attrib + '=\"' + color.hex + '\"'\n\n  return alpha < 1\n    ? str + ' ' + attrib + '-opacity=\"' + alpha.toFixed(2).slice(1) + '\"'\n    : str\n}\n\nfunction svgCmd (cmd, x, y) {\n  let str = cmd + x\n  if (typeof y !== 'undefined') str += ' ' + y\n\n  return str\n}\n\nfunction qrToPath (data, size, margin) {\n  let path = ''\n  let moveBy = 0\n  let newRow = false\n  let lineLength = 0\n\n  for (let i = 0; i < data.length; i++) {\n    const col = Math.floor(i % size)\n    const row = Math.floor(i / size)\n\n    if (!col && !newRow) newRow = true\n\n    if (data[i]) {\n      lineLength++\n\n      if (!(i > 0 && col > 0 && data[i - 1])) {\n        path += newRow\n          ? svgCmd('M', col + margin, 0.5 + row + margin)\n          : svgCmd('m', moveBy, 0)\n\n        moveBy = 0\n        newRow = false\n      }\n\n      if (!(col + 1 < size && data[i + 1])) {\n        path += svgCmd('h', lineLength)\n        lineLength = 0\n      }\n    } else {\n      moveBy++\n    }\n  }\n\n  return path\n}\n\nexports.render = function render (qrData, options, cb) {\n  const opts = Utils.getOptions(options)\n  const size = qrData.modules.size\n  const data = qrData.modules.data\n  const qrcodesize = size + opts.margin * 2\n\n  const bg = !opts.color.light.a\n    ? ''\n    : '<path ' + getColorAttrib(opts.color.light, 'fill') +\n      ' d=\"M0 0h' + qrcodesize + 'v' + qrcodesize + 'H0z\"/>'\n\n  const path =\n    '<path ' + getColorAttrib(opts.color.dark, 'stroke') +\n    ' d=\"' + qrToPath(data, size, opts.margin) + '\"/>'\n\n  const viewBox = 'viewBox=\"' + '0 0 ' + qrcodesize + ' ' + qrcodesize + '\"'\n\n  const width = !opts.width ? '' : 'width=\"' + opts.width + '\" height=\"' + opts.width + '\" '\n\n  const svgTag = '<svg xmlns=\"http://www.w3.org/2000/svg\" ' + width + viewBox + ' shape-rendering=\"crispEdges\">' + bg + path + '</svg>\\n'\n\n  if (typeof cb === 'function') {\n    cb(null, svgTag)\n  }\n\n  return svgTag\n}\n","function hex2rgba (hex) {\n  if (typeof hex === 'number') {\n    hex = hex.toString()\n  }\n\n  if (typeof hex !== 'string') {\n    throw new Error('Color should be defined as hex string')\n  }\n\n  let hexCode = hex.slice().replace('#', '').split('')\n  if (hexCode.length < 3 || hexCode.length === 5 || hexCode.length > 8) {\n    throw new Error('Invalid hex color: ' + hex)\n  }\n\n  // Convert from short to long form (fff -> ffffff)\n  if (hexCode.length === 3 || hexCode.length === 4) {\n    hexCode = Array.prototype.concat.apply([], hexCode.map(function (c) {\n      return [c, c]\n    }))\n  }\n\n  // Add default alpha value\n  if (hexCode.length === 6) hexCode.push('F', 'F')\n\n  const hexValue = parseInt(hexCode.join(''), 16)\n\n  return {\n    r: (hexValue >> 24) & 255,\n    g: (hexValue >> 16) & 255,\n    b: (hexValue >> 8) & 255,\n    a: hexValue & 255,\n    hex: '#' + hexCode.slice(0, 6).join('')\n  }\n}\n\nexports.getOptions = function getOptions (options) {\n  if (!options) options = {}\n  if (!options.color) options.color = {}\n\n  const margin = typeof options.margin === 'undefined' ||\n    options.margin === null ||\n    options.margin < 0\n    ? 4\n    : options.margin\n\n  const width = options.width && options.width >= 21 ? options.width : undefined\n  const scale = options.scale || 4\n\n  return {\n    width: width,\n    scale: width ? 4 : scale,\n    margin: margin,\n    color: {\n      dark: hex2rgba(options.color.dark || '#000000ff'),\n      light: hex2rgba(options.color.light || '#ffffffff')\n    },\n    type: options.type,\n    rendererOpts: options.rendererOpts || {}\n  }\n}\n\nexports.getScale = function getScale (qrSize, opts) {\n  return opts.width && opts.width >= qrSize + opts.margin * 2\n    ? opts.width / (qrSize + opts.margin * 2)\n    : opts.scale\n}\n\nexports.getImageWidth = function getImageWidth (qrSize, opts) {\n  const scale = exports.getScale(qrSize, opts)\n  return Math.floor((qrSize + opts.margin * 2) * scale)\n}\n\nexports.qrToImageData = function qrToImageData (imgData, qr, opts) {\n  const size = qr.modules.size\n  const data = qr.modules.data\n  const scale = exports.getScale(size, opts)\n  const symbolSize = Math.floor((size + opts.margin * 2) * scale)\n  const scaledMargin = opts.margin * scale\n  const palette = [opts.color.light, opts.color.dark]\n\n  for (let i = 0; i < symbolSize; i++) {\n    for (let j = 0; j < symbolSize; j++) {\n      let posDst = (i * symbolSize + j) * 4\n      let pxColor = opts.color.light\n\n      if (i >= scaledMargin && j >= scaledMargin &&\n        i < symbolSize - scaledMargin && j < symbolSize - scaledMargin) {\n        const iSrc = Math.floor((i - scaledMargin) / scale)\n        const jSrc = Math.floor((j - scaledMargin) / scale)\n        pxColor = palette[data[iSrc * size + jSrc] ? 1 : 0]\n      }\n\n      imgData[posDst++] = pxColor.r\n      imgData[posDst++] = pxColor.g\n      imgData[posDst++] = pxColor.b\n      imgData[posDst] = pxColor.a\n    }\n  }\n}\n","'use strict'\n\n// JS treats subjects of bitwise operators as SIGNED 32 bit numbers,\n// which means the maximum amount of bits we can store inside each byte\n// is 7..\nconst BITS_PER_BYTE = 7\n\nmodule.exports = class SparseArray {\n  constructor () {\n    this._bitArrays = []\n    this._data = []\n    this._length = 0\n    this._changedLength = false\n    this._changedData = false\n  }\n\n  set (index, value) {\n    let pos = this._internalPositionFor(index, false)\n    if (value === undefined) {\n      // unsetting\n      if (pos !== -1) {\n        // remove item from bit array and array itself\n        this._unsetInternalPos(pos)\n        this._unsetBit(index)\n        this._changedLength = true\n        this._changedData = true\n      }\n    } else {\n      let needsSort = false\n      if (pos === -1) {\n        pos = this._data.length\n        this._setBit(index)\n        this._changedData = true\n      } else {\n        needsSort = true\n      }\n      this._setInternalPos(pos, index, value, needsSort)\n      this._changedLength = true\n    }\n  }\n\n  unset (index) {\n    this.set(index, undefined)\n  }\n\n  get (index) {\n    this._sortData()\n    const pos = this._internalPositionFor(index, true)\n    if (pos === -1) {\n      return undefined\n    }\n    return this._data[pos][1]\n  }\n\n  push (value) {\n    this.set(this.length, value)\n    return this.length\n  }\n\n  get length () {\n    this._sortData()\n    if (this._changedLength) {\n      const last = this._data[this._data.length - 1]\n      this._length = last ? last[0] + 1 : 0\n      this._changedLength = false\n    }\n    return this._length\n  }\n\n  forEach (iterator) {\n    let i = 0\n    while(i < this.length) {\n      iterator(this.get(i), i, this)\n      i++\n    }\n  }\n\n  map (iterator) {\n    let i = 0\n    let mapped = new Array(this.length)\n    while(i < this.length) {\n      mapped[i] = iterator(this.get(i), i, this)\n      i++\n    }\n    return mapped\n  }\n\n  reduce (reducer, initialValue) {\n    let i = 0\n    let acc = initialValue\n    while(i < this.length) {\n      const value = this.get(i)\n      acc = reducer(acc, value, i)\n      i++\n    }\n    return acc\n  }\n\n  find (finder) {\n    let i = 0, found, last\n    while ((i < this.length) && !found) {\n      last = this.get(i)\n      found = finder(last)\n      i++\n    }\n    return found ? last : undefined\n  }\n\n  _internalPositionFor (index, noCreate) {\n    const bytePos = this._bytePosFor(index, noCreate)\n    if (bytePos >= this._bitArrays.length) {\n      return -1\n    }\n    const byte = this._bitArrays[bytePos]\n    const bitPos = index - bytePos * BITS_PER_BYTE\n    const exists = (byte & (1 << bitPos)) > 0\n    if (!exists) {\n      return -1\n    }\n    const previousPopCount = this._bitArrays.slice(0, bytePos).reduce(popCountReduce, 0)\n\n    const mask = ~(0xffffffff << (bitPos + 1))\n    const bytePopCount = popCount(byte & mask)\n    const arrayPos = previousPopCount + bytePopCount - 1\n    return arrayPos\n  }\n\n  _bytePosFor (index, noCreate) {\n    const bytePos = Math.floor(index / BITS_PER_BYTE)\n    const targetLength = bytePos + 1\n    while (!noCreate && this._bitArrays.length < targetLength) {\n      this._bitArrays.push(0)\n    }\n    return bytePos\n  }\n\n  _setBit (index) {\n    const bytePos = this._bytePosFor(index, false)\n    this._bitArrays[bytePos] |= (1 << (index - (bytePos * BITS_PER_BYTE)))\n  }\n\n  _unsetBit(index) {\n    const bytePos = this._bytePosFor(index, false)\n    this._bitArrays[bytePos] &= ~(1 << (index - (bytePos * BITS_PER_BYTE)))\n  }\n\n  _setInternalPos(pos, index, value, needsSort) {\n    const data =this._data\n    const elem = [index, value]\n    if (needsSort) {\n      this._sortData()\n      data[pos] = elem\n    } else {\n      // new element. just shove it into the array\n      // but be nice about where we shove it\n      // in order to make sorting it later easier\n      if (data.length) {\n        if (data[data.length - 1][0] >= index) {\n          data.push(elem)\n        } else if (data[0][0] <= index) {\n          data.unshift(elem)\n        } else {\n          const randomIndex = Math.round(data.length / 2)\n          this._data = data.slice(0, randomIndex).concat(elem).concat(data.slice(randomIndex))\n        }\n      } else {\n        this._data.push(elem)\n      }\n      this._changedData = true\n      this._changedLength = true\n    }\n  }\n\n  _unsetInternalPos (pos) {\n    this._data.splice(pos, 1)\n  }\n\n  _sortData () {\n    if (this._changedData) {\n      this._data.sort(sortInternal)\n    }\n\n    this._changedData = false\n  }\n\n  bitField () {\n    const bytes = []\n    let pendingBitsForResultingByte = 8\n    let pendingBitsForNewByte = 0\n    let resultingByte = 0\n    let newByte\n    const pending = this._bitArrays.slice()\n    while (pending.length || pendingBitsForNewByte) {\n      if (pendingBitsForNewByte === 0) {\n        newByte = pending.shift()\n        pendingBitsForNewByte = 7\n      }\n\n      const usingBits = Math.min(pendingBitsForNewByte, pendingBitsForResultingByte)\n      const mask = ~(0b11111111 << usingBits)\n      const masked = newByte & mask\n      resultingByte |= masked << (8 - pendingBitsForResultingByte)\n      newByte = newByte >>> usingBits\n      pendingBitsForNewByte -= usingBits\n      pendingBitsForResultingByte -= usingBits\n\n      if (!pendingBitsForResultingByte || (!pendingBitsForNewByte && !pending.length)) {\n        bytes.push(resultingByte)\n        resultingByte = 0\n        pendingBitsForResultingByte = 8\n      }\n    }\n\n    // remove trailing zeroes\n    for(var i = bytes.length - 1; i > 0; i--) {\n      const value = bytes[i]\n      if (value === 0) {\n        bytes.pop()\n      } else {\n        break\n      }\n    }\n\n    return bytes\n  }\n\n  compactArray () {\n    this._sortData()\n    return this._data.map(valueOnly)\n  }\n}\n\nfunction popCountReduce (count, byte) {\n  return count + popCount(byte)\n}\n\nfunction popCount(_v) {\n  let v = _v\n  v = v - ((v >> 1) & 0x55555555)                    // reuse input as temporary\n  v = (v & 0x33333333) + ((v >> 2) & 0x33333333)     // temp\n  return ((v + (v >> 4) & 0xF0F0F0F) * 0x1010101) >> 24\n}\n\nfunction sortInternal (a, b) {\n  return a[0] - b[0]\n}\n\nfunction valueOnly (elem) {\n  return elem[1]\n}","module.exports = read\n\nvar MSB = 0x80\n  , REST = 0x7F\n\nfunction read(buf, offset) {\n  var res    = 0\n    , offset = offset || 0\n    , shift  = 0\n    , counter = offset\n    , b\n    , l = buf.length\n\n  do {\n    if (counter >= l || shift > 49) {\n      read.bytes = 0\n      throw new RangeError('Could not decode varint')\n    }\n    b = buf[counter++]\n    res += shift < 28\n      ? (b & REST) << shift\n      : (b & REST) * Math.pow(2, shift)\n    shift += 7\n  } while (b >= MSB)\n\n  read.bytes = counter - offset\n\n  return res\n}\n","module.exports = encode\n\nvar MSB = 0x80\n  , REST = 0x7F\n  , MSBALL = ~REST\n  , INT = Math.pow(2, 31)\n\nfunction encode(num, out, offset) {\n  if (Number.MAX_SAFE_INTEGER && num > Number.MAX_SAFE_INTEGER) {\n    encode.bytes = 0\n    throw new RangeError('Could not encode varint')\n  }\n  out = out || []\n  offset = offset || 0\n  var oldOffset = offset\n\n  while(num >= INT) {\n    out[offset++] = (num & 0xFF) | MSB\n    num /= 128\n  }\n  while(num & MSBALL) {\n    out[offset++] = (num & 0xFF) | MSB\n    num >>>= 7\n  }\n  out[offset] = num | 0\n  \n  encode.bytes = offset - oldOffset + 1\n  \n  return out\n}\n","module.exports = {\n    encode: require('./encode.js')\n  , decode: require('./decode.js')\n  , encodingLength: require('./length.js')\n}\n","\nvar N1 = Math.pow(2,  7)\nvar N2 = Math.pow(2, 14)\nvar N3 = Math.pow(2, 21)\nvar N4 = Math.pow(2, 28)\nvar N5 = Math.pow(2, 35)\nvar N6 = Math.pow(2, 42)\nvar N7 = Math.pow(2, 49)\nvar N8 = Math.pow(2, 56)\nvar N9 = Math.pow(2, 63)\n\nmodule.exports = function (value) {\n  return (\n    value < N1 ? 1\n  : value < N2 ? 2\n  : value < N3 ? 3\n  : value < N4 ? 4\n  : value < N5 ? 5\n  : value < N6 ? 6\n  : value < N7 ? 7\n  : value < N8 ? 8\n  : value < N9 ? 9\n  :              10\n  )\n}\n","var Timestamp=function(){\"undefined\"!=typeof module&&(module.exports=d);var l=86400,s=3200,T=146097*s/400,e=l*T,f=1e3*e,c=864e13,g=4294967296,h=1e6,u=\"000000000\",m=Math.trunc||function(n){var t=n-n%1;return 0==t&&(n<0||0===n&&1/n!=1/0)?-0:t},n=d.prototype,o=(d.fromDate=function(n){return new d(+n)},d.fromInt64BE=r(0,1,2,3,0,4),d.fromInt64LE=r(3,2,1,0,4,0),d.fromString=function(n){var e,r=new d,n=(n+=\"\").replace(/^\\s*[+\\-]?\\d+/,function(n){var n=+n,t=1970+(n-1970)%400;return r.year=n-t,t}).replace(/(?:Z|([+\\-]\\d{2}):?(\\d{2}))$/,function(n,t,r){return t<0&&(r*=-1),e=6e4*(60*+t+ +r),\"\"}).replace(/\\.\\d+$/,function(n){return r.nano=+(n+u).substr(1,9),\"\"}).split(/\\D+/);1<n.length?n[1]--:n[1]=0;if(r.time=e=Date.UTC.apply(Date,n)-(e||0),isNaN(e))throw new TypeError(\"Invalid Date\");return p(r)},d.fromTimeT=function(n){return y(n,0)},n.year=0,n.time=0,n.nano=0,n.addNano=function(n){return this.nano+=+n||0,this},n.getNano=function(){var n=p(this);return(n.time%1e3*h+ +n.nano+1e9)%1e9},n.getTimeT=function(){var n=p(this),t=Math.floor(n.time/1e3),n=n.year;n&&(t+=n*T*l/s);return t},n.getYear=function(){return this.toDate().getUTCFullYear()+this.year},n.toDate=function(){return M(p(this).time)},n.toJSON=function(){return this.toString().replace(/0{1,6}Z$/,\"Z\")},n.toString=function(n){var t=this,r=t.toDate(),u={H:function(){return C(r.getUTCHours())},L:function(){return D(r.getUTCMilliseconds(),3)},M:function(){return C(r.getUTCMinutes())},N:function(){return D(t.getNano(),9)},S:function(){return C(r.getUTCSeconds())},Y:function(){var n=t.getYear();return 999999<n?\"+\"+n:9999<n?\"+\"+D(n,6):0<=n?D(n,4):-999999<=n?\"-\"+D(-n,6):n},a:function(){return a[r.getUTCDay()]},b:function(){return i[r.getUTCMonth()]},d:function(){return C(r.getUTCDate())},e:function(){return function(n){return(9<n?\"\":\" \")+(0|n)}(r.getUTCDate())},m:function(){return C(r.getUTCMonth()+1)}};return function e(n){return n.replace(/%./g,function(n){var t=n[1],r=v[t],t=u[t];return r?e(r):t?t():n})}(n||o)},n.writeInt64BE=t(0,1,2,3,0,4),n.writeInt64LE=t(3,2,1,0,4,0),\"%Y-%m-%dT%H:%M:%S.%NZ\"),i=[\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"],a=[\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\"],v={\"%\":\"%\",F:\"%Y-%m-%d\",n:\"\\n\",R:\"%H:%M\",T:\"%H:%M:%S\",t:\"\\t\",X:\"%T\",Z:\"GMT\",z:\"+0000\"};return d;function d(n,t,r){var e=this;if(!(e instanceof d))return new d(n,t,r);e.time=+n||0,e.nano=+t||0,e.year=+r||0,p(e)}function p(n){var t,r,e,u=n.year,o=n.time,i=n.nano,a=((i<0||h<=i)&&(i-=(r=Math.floor(i/h))*h,o+=r,r=1),u%s);return(o<-c||c<o||a)&&((t=m(o/f))&&(u+=t*s,o-=t*f),(e=M(o)).setUTCFullYear(a+e.getUTCFullYear()),e=(o=+e)+(t=m((u-=a)/s))*f,t&&-c<=e&&e<=c&&(u-=t*s,o=e),r=1),r&&(n.year=u,n.time=o,n.nano=i),n}function M(n){var t=new Date(0);return t.setTime(n),t}function y(n,t){n=+n||0;var r=m((t=(t|0)*g)/e)+m(n/e),t=t%e+n%e,n=m(t/e);return n&&(r+=n,t-=n*e),new d(1e3*t,0,r*s)}function t(e,u,o,i,a,f){return function(n,t){var r=p(this);n=n||new Array(8);w(n,t|=0);var e=Math.floor(r.time/1e3),r=r.year*(T*l/s),u=m(r/g)+m(e/g),r=r%g+e%g,e=Math.floor(r/g);e&&(u+=e,r-=e*g);return c(n,t+a,u),c(n,t+f,r),n};function c(n,t,r){n[t+e]=r>>24&255,n[t+u]=r>>16&255,n[t+o]=r>>8&255,n[t+i]=255&r}}function r(r,e,u,o,i,a){return function(n,t){w(n,t|=0);var r=f(n,t+i);return y(f(n,t+a),r)};function f(n,t){return 16777216*n[t+r]+(n[t+e]<<16|n[t+u]<<8|n[t+o])}}function w(n,t){n=n&&n.length;if(null==n)throw new TypeError(\"Invalid Buffer\");if(n<t+8)throw new RangeError(\"Out of range\")}function C(n){return(9<n?\"\":\"0\")+(0|n)}function D(n,t){return(u+(0|n)).substr(-t)}}();","import {\n  useAccordionItemContext,\n  useAccordionStyles\n} from \"./chunk-JST25EWU.mjs\";\n\n// src/accordion-button.tsx\nimport {\n  chakra,\n  forwardRef\n} from \"@chakra-ui/system\";\nimport { cx } from \"@chakra-ui/shared-utils\";\nimport { jsx } from \"react/jsx-runtime\";\nvar AccordionButton = forwardRef(\n  function AccordionButton2(props, ref) {\n    const { getButtonProps } = useAccordionItemContext();\n    const buttonProps = getButtonProps(props, ref);\n    const styles = useAccordionStyles();\n    const buttonStyles = {\n      display: \"flex\",\n      alignItems: \"center\",\n      width: \"100%\",\n      outline: 0,\n      ...styles.button\n    };\n    return /* @__PURE__ */ jsx(\n      chakra.button,\n      {\n        ...buttonProps,\n        className: cx(\"chakra-accordion__button\", props.className),\n        __css: buttonStyles\n      }\n    );\n  }\n);\nAccordionButton.displayName = \"AccordionButton\";\n\nexport {\n  AccordionButton\n};\n","import {\n  useAccordionItem\n} from \"./chunk-JDQBKIKM.mjs\";\nimport {\n  AccordionItemProvider,\n  useAccordionStyles\n} from \"./chunk-JST25EWU.mjs\";\n\n// src/accordion-item.tsx\nimport {\n  chakra,\n  forwardRef\n} from \"@chakra-ui/system\";\nimport { cx } from \"@chakra-ui/shared-utils\";\nimport { useMemo } from \"react\";\nimport { jsx } from \"react/jsx-runtime\";\nvar AccordionItem = forwardRef(\n  function AccordionItem2(props, ref) {\n    const { children, className } = props;\n    const { htmlProps, ...context } = useAccordionItem(props);\n    const styles = useAccordionStyles();\n    const containerStyles = {\n      ...styles.container,\n      overflowAnchor: \"none\"\n    };\n    const ctx = useMemo(() => context, [context]);\n    return /* @__PURE__ */ jsx(AccordionItemProvider, { value: ctx, children: /* @__PURE__ */ jsx(\n      chakra.div,\n      {\n        ref,\n        ...htmlProps,\n        className: cx(\"chakra-accordion__item\", className),\n        __css: containerStyles,\n        children: typeof children === \"function\" ? children({\n          isExpanded: !!context.isOpen,\n          isDisabled: !!context.isDisabled\n        }) : children\n      }\n    ) });\n  }\n);\nAccordionItem.displayName = \"AccordionItem\";\n\nexport {\n  AccordionItem\n};\n","import {\n  useAccordionContext\n} from \"./chunk-JDQBKIKM.mjs\";\nimport {\n  useAccordionItemContext,\n  useAccordionStyles\n} from \"./chunk-JST25EWU.mjs\";\n\n// src/accordion-icon.tsx\nimport { Icon } from \"@chakra-ui/icon\";\nimport { cx } from \"@chakra-ui/shared-utils\";\nimport { jsx } from \"react/jsx-runtime\";\nfunction AccordionIcon(props) {\n  const { isOpen, isDisabled } = useAccordionItemContext();\n  const { reduceMotion } = useAccordionContext();\n  const _className = cx(\"chakra-accordion__icon\", props.className);\n  const styles = useAccordionStyles();\n  const iconStyles = {\n    opacity: isDisabled ? 0.4 : 1,\n    transform: isOpen ? \"rotate(-180deg)\" : void 0,\n    transition: reduceMotion ? void 0 : \"transform 0.2s\",\n    transformOrigin: \"center\",\n    ...styles.icon\n  };\n  return /* @__PURE__ */ jsx(\n    Icon,\n    {\n      viewBox: \"0 0 24 24\",\n      \"aria-hidden\": true,\n      className: _className,\n      __css: iconStyles,\n      ...props,\n      children: /* @__PURE__ */ jsx(\n        \"path\",\n        {\n          fill: \"currentColor\",\n          d: \"M16.59 8.59L12 13.17 7.41 8.59 6 10l6 6 6-6z\"\n        }\n      )\n    }\n  );\n}\nAccordionIcon.displayName = \"AccordionIcon\";\n\nexport {\n  AccordionIcon\n};\n","import {\n  TRANSITION_EASINGS,\n  withDelay\n} from \"./chunk-LB6CWFOC.mjs\";\n\n// src/collapse.tsx\nimport { cx, warn } from \"@chakra-ui/shared-utils\";\nimport {\n  AnimatePresence,\n  motion\n} from \"framer-motion\";\nimport { forwardRef, useEffect, useState } from \"react\";\nimport { jsx } from \"react/jsx-runtime\";\nvar isNumeric = (value) => value != null && parseInt(value.toString(), 10) > 0;\nvar defaultTransitions = {\n  exit: {\n    height: { duration: 0.2, ease: TRANSITION_EASINGS.ease },\n    opacity: { duration: 0.3, ease: TRANSITION_EASINGS.ease }\n  },\n  enter: {\n    height: { duration: 0.3, ease: TRANSITION_EASINGS.ease },\n    opacity: { duration: 0.4, ease: TRANSITION_EASINGS.ease }\n  }\n};\nvar variants = {\n  exit: ({\n    animateOpacity,\n    startingHeight,\n    transition,\n    transitionEnd,\n    delay\n  }) => {\n    var _a;\n    return {\n      ...animateOpacity && { opacity: isNumeric(startingHeight) ? 1 : 0 },\n      height: startingHeight,\n      transitionEnd: transitionEnd == null ? void 0 : transitionEnd.exit,\n      transition: (_a = transition == null ? void 0 : transition.exit) != null ? _a : withDelay.exit(defaultTransitions.exit, delay)\n    };\n  },\n  enter: ({\n    animateOpacity,\n    endingHeight,\n    transition,\n    transitionEnd,\n    delay\n  }) => {\n    var _a;\n    return {\n      ...animateOpacity && { opacity: 1 },\n      height: endingHeight,\n      transitionEnd: transitionEnd == null ? void 0 : transitionEnd.enter,\n      transition: (_a = transition == null ? void 0 : transition.enter) != null ? _a : withDelay.enter(defaultTransitions.enter, delay)\n    };\n  }\n};\nvar Collapse = forwardRef(\n  (props, ref) => {\n    const {\n      in: isOpen,\n      unmountOnExit,\n      animateOpacity = true,\n      startingHeight = 0,\n      endingHeight = \"auto\",\n      style,\n      className,\n      transition,\n      transitionEnd,\n      ...rest\n    } = props;\n    const [mounted, setMounted] = useState(false);\n    useEffect(() => {\n      const timeout = setTimeout(() => {\n        setMounted(true);\n      });\n      return () => clearTimeout(timeout);\n    }, []);\n    warn({\n      condition: Number(startingHeight) > 0 && !!unmountOnExit,\n      message: `startingHeight and unmountOnExit are mutually exclusive. You can't use them together`\n    });\n    const hasStartingHeight = parseFloat(startingHeight.toString()) > 0;\n    const custom = {\n      startingHeight,\n      endingHeight,\n      animateOpacity,\n      transition: !mounted ? { enter: { duration: 0 } } : transition,\n      transitionEnd: {\n        enter: transitionEnd == null ? void 0 : transitionEnd.enter,\n        exit: unmountOnExit ? transitionEnd == null ? void 0 : transitionEnd.exit : {\n          ...transitionEnd == null ? void 0 : transitionEnd.exit,\n          display: hasStartingHeight ? \"block\" : \"none\"\n        }\n      }\n    };\n    const show = unmountOnExit ? isOpen : true;\n    const animate = isOpen || unmountOnExit ? \"enter\" : \"exit\";\n    return /* @__PURE__ */ jsx(AnimatePresence, { initial: false, custom, children: show && /* @__PURE__ */ jsx(\n      motion.div,\n      {\n        ref,\n        ...rest,\n        className: cx(\"chakra-collapse\", className),\n        style: {\n          overflow: \"hidden\",\n          display: \"block\",\n          ...style\n        },\n        custom,\n        variants,\n        initial: unmountOnExit ? \"exit\" : false,\n        animate,\n        exit: \"exit\"\n      }\n    ) });\n  }\n);\nCollapse.displayName = \"Collapse\";\n\nexport {\n  Collapse\n};\n","import {\n  useAccordionContext\n} from \"./chunk-JDQBKIKM.mjs\";\nimport {\n  useAccordionItemContext,\n  useAccordionStyles\n} from \"./chunk-JST25EWU.mjs\";\n\n// src/accordion-panel.tsx\nimport { chakra, forwardRef } from \"@chakra-ui/system\";\nimport { Collapse } from \"@chakra-ui/transition\";\nimport { cx } from \"@chakra-ui/shared-utils\";\nimport { jsx } from \"react/jsx-runtime\";\nvar AccordionPanel = forwardRef(\n  function AccordionPanel2(props, ref) {\n    const { className, motionProps, ...rest } = props;\n    const { reduceMotion } = useAccordionContext();\n    const { getPanelProps, isOpen } = useAccordionItemContext();\n    const panelProps = getPanelProps(rest, ref);\n    const _className = cx(\"chakra-accordion__panel\", className);\n    const styles = useAccordionStyles();\n    if (!reduceMotion) {\n      delete panelProps.hidden;\n    }\n    const child = /* @__PURE__ */ jsx(chakra.div, { ...panelProps, __css: styles.panel, className: _className });\n    if (!reduceMotion) {\n      return /* @__PURE__ */ jsx(Collapse, { in: isOpen, ...motionProps, children: child });\n    }\n    return child;\n  }\n);\nAccordionPanel.displayName = \"AccordionPanel\";\n\nexport {\n  AccordionPanel\n};\n","// src/aspect-ratio.tsx\nimport {\n  chakra,\n  forwardRef\n} from \"@chakra-ui/system\";\nimport { mapResponsive } from \"@chakra-ui/breakpoint-utils\";\nimport { cx } from \"@chakra-ui/shared-utils\";\nimport { Children } from \"react\";\nimport { jsx } from \"react/jsx-runtime\";\nvar AspectRatio = forwardRef(function(props, ref) {\n  const { ratio = 4 / 3, children, className, ...rest } = props;\n  const child = Children.only(children);\n  const _className = cx(\"chakra-aspect-ratio\", className);\n  return /* @__PURE__ */ jsx(\n    chakra.div,\n    {\n      ref,\n      position: \"relative\",\n      className: _className,\n      _before: {\n        height: 0,\n        content: `\"\"`,\n        display: \"block\",\n        paddingBottom: mapResponsive(ratio, (r) => `${1 / r * 100}%`)\n      },\n      __css: {\n        \"& > *:not(style)\": {\n          overflow: \"hidden\",\n          position: \"absolute\",\n          top: \"0\",\n          right: \"0\",\n          bottom: \"0\",\n          left: \"0\",\n          display: \"flex\",\n          justifyContent: \"center\",\n          alignItems: \"center\",\n          width: \"100%\",\n          height: \"100%\"\n        },\n        \"& > img, & > video\": {\n          objectFit: \"cover\"\n        }\n      },\n      ...rest,\n      children: child\n    }\n  );\n});\nAspectRatio.displayName = \"AspectRatio\";\n\nexport {\n  AspectRatio\n};\n","// src/link-box.tsx\nimport { chakra, forwardRef } from \"@chakra-ui/system\";\nimport { cx } from \"@chakra-ui/shared-utils\";\nimport { jsx } from \"react/jsx-runtime\";\nvar LinkOverlay = forwardRef(\n  function LinkOverlay2(props, ref) {\n    const { isExternal, target, rel, className, ...rest } = props;\n    return /* @__PURE__ */ jsx(\n      chakra.a,\n      {\n        ...rest,\n        ref,\n        className: cx(\"chakra-linkbox__overlay\", className),\n        rel: isExternal ? \"noopener noreferrer\" : rel,\n        target: isExternal ? \"_blank\" : target,\n        __css: {\n          position: \"static\",\n          \"&::before\": {\n            content: \"''\",\n            cursor: \"inherit\",\n            display: \"block\",\n            position: \"absolute\",\n            top: 0,\n            left: 0,\n            zIndex: 0,\n            width: \"100%\",\n            height: \"100%\"\n          }\n        }\n      }\n    );\n  }\n);\nvar LinkBox = forwardRef(function LinkBox2(props, ref) {\n  const { className, ...rest } = props;\n  return /* @__PURE__ */ jsx(\n    chakra.div,\n    {\n      ref,\n      position: \"relative\",\n      ...rest,\n      className: cx(\"chakra-linkbox\", className),\n      __css: {\n        \"a[href]:not(.chakra-linkbox__overlay), abbr[title]\": {\n          position: \"relative\",\n          zIndex: 1\n        }\n      }\n    }\n  );\n});\n\nexport {\n  LinkOverlay,\n  LinkBox\n};\n","import {\n  useRadio\n} from \"./chunk-5XCGGO7V.mjs\";\nimport {\n  useRadioGroupContext\n} from \"./chunk-QUJ23J4G.mjs\";\n\n// src/radio.tsx\nimport {\n  chakra,\n  forwardRef,\n  layoutPropNames,\n  omitThemingProps,\n  useMultiStyleConfig\n} from \"@chakra-ui/system\";\nimport { callAll } from \"@chakra-ui/shared-utils\";\n\n// ../../utilities/object-utils/src/index.ts\nfunction split(object, keys) {\n  const picked = {};\n  const omitted = {};\n  for (const [key, value] of Object.entries(object)) {\n    if (keys.includes(key))\n      picked[key] = value;\n    else\n      omitted[key] = value;\n  }\n  return [picked, omitted];\n}\n\n// src/radio.tsx\nimport { jsx, jsxs } from \"react/jsx-runtime\";\nvar Radio = forwardRef((props, ref) => {\n  var _a;\n  const group = useRadioGroupContext();\n  const { onChange: onChangeProp, value: valueProp } = props;\n  const styles = useMultiStyleConfig(\"Radio\", { ...group, ...props });\n  const ownProps = omitThemingProps(props);\n  const {\n    spacing = \"0.5rem\",\n    children,\n    isDisabled = group == null ? void 0 : group.isDisabled,\n    isFocusable = group == null ? void 0 : group.isFocusable,\n    inputProps: htmlInputProps,\n    ...rest\n  } = ownProps;\n  let isChecked = props.isChecked;\n  if ((group == null ? void 0 : group.value) != null && valueProp != null) {\n    isChecked = group.value === valueProp;\n  }\n  let onChange = onChangeProp;\n  if ((group == null ? void 0 : group.onChange) && valueProp != null) {\n    onChange = callAll(group.onChange, onChangeProp);\n  }\n  const name = (_a = props == null ? void 0 : props.name) != null ? _a : group == null ? void 0 : group.name;\n  const {\n    getInputProps,\n    getCheckboxProps,\n    getLabelProps,\n    getRootProps,\n    htmlProps\n  } = useRadio({\n    ...rest,\n    isChecked,\n    isFocusable,\n    isDisabled,\n    onChange,\n    name\n  });\n  const [layoutProps, otherProps] = split(htmlProps, layoutPropNames);\n  const checkboxProps = getCheckboxProps(otherProps);\n  const inputProps = getInputProps(htmlInputProps, ref);\n  const labelProps = getLabelProps();\n  const rootProps = Object.assign({}, layoutProps, getRootProps());\n  const rootStyles = {\n    display: \"inline-flex\",\n    alignItems: \"center\",\n    verticalAlign: \"top\",\n    cursor: \"pointer\",\n    position: \"relative\",\n    ...styles.container\n  };\n  const checkboxStyles = {\n    display: \"inline-flex\",\n    alignItems: \"center\",\n    justifyContent: \"center\",\n    flexShrink: 0,\n    ...styles.control\n  };\n  const labelStyles = {\n    userSelect: \"none\",\n    marginStart: spacing,\n    ...styles.label\n  };\n  return /* @__PURE__ */ jsxs(chakra.label, { className: \"chakra-radio\", ...rootProps, __css: rootStyles, children: [\n    /* @__PURE__ */ jsx(\"input\", { className: \"chakra-radio__input\", ...inputProps }),\n    /* @__PURE__ */ jsx(\n      chakra.span,\n      {\n        className: \"chakra-radio__control\",\n        ...checkboxProps,\n        __css: checkboxStyles\n      }\n    ),\n    children && /* @__PURE__ */ jsx(\n      chakra.span,\n      {\n        className: \"chakra-radio__label\",\n        ...labelProps,\n        __css: labelStyles,\n        children\n      }\n    )\n  ] });\n});\nRadio.displayName = \"Radio\";\n\nexport {\n  Radio\n};\n","export const DEFAULT_SESSION_MIN_PROVIDERS = 1;\nexport const DEFAULT_SESSION_MAX_PROVIDERS = 5;\n//# sourceMappingURL=blocks.js.map","export class InsufficientProvidersError extends Error {\n    static name = 'InsufficientProvidersError';\n    constructor(message = 'Insufficient providers found') {\n        super(message);\n        this.name = 'InsufficientProvidersError';\n    }\n}\nexport class NoRoutersAvailableError extends Error {\n    static name = 'NoRoutersAvailableError';\n    constructor(message = 'No routers available') {\n        super(message);\n        this.name = 'NoRoutersAvailableError';\n    }\n}\nexport class UnknownHashAlgorithmError extends Error {\n    static name = 'UnknownHashAlgorithmError';\n    constructor(message = 'Unknown hash algorithm') {\n        super(message);\n        this.name = 'UnknownHashAlgorithmError';\n    }\n}\nexport class UnknownCodecError extends Error {\n    static name = 'UnknownCodecError';\n    constructor(message = 'Unknown codec') {\n        super(message);\n        this.name = 'UnknownCodecError';\n    }\n}\n//# sourceMappingURL=errors.js.map","/**\n * Noop for browser compatibility\n */\nexport function setMaxListeners() { }\n//# sourceMappingURL=events.browser.js.map","import { setMaxListeners as nodeSetMaxListeners } from 'events';\n/**\n * Create a setMaxListeners that doesn't break browser usage\n */\nexport const setMaxListeners = (n, ...eventTargets) => {\n    try {\n        nodeSetMaxListeners(n, ...eventTargets);\n    }\n    catch {\n        // swallow error, gulp\n    }\n};\n//# sourceMappingURL=events.js.map","import { setMaxListeners } from './events.js';\n/**\n * An implementation of a typed event target\n * etc\n */\nexport class TypedEventEmitter extends EventTarget {\n    #listeners = new Map();\n    constructor() {\n        super();\n        // silence MaxListenersExceededWarning warning on Node.js, this is a red\n        // herring almost all of the time\n        setMaxListeners(Infinity, this);\n    }\n    listenerCount(type) {\n        const listeners = this.#listeners.get(type);\n        if (listeners == null) {\n            return 0;\n        }\n        return listeners.length;\n    }\n    addEventListener(type, listener, options) {\n        super.addEventListener(type, listener, options);\n        let list = this.#listeners.get(type);\n        if (list == null) {\n            list = [];\n            this.#listeners.set(type, list);\n        }\n        list.push({\n            callback: listener,\n            once: (options !== true && options !== false && options?.once) ?? false\n        });\n    }\n    removeEventListener(type, listener, options) {\n        super.removeEventListener(type.toString(), listener ?? null, options);\n        let list = this.#listeners.get(type);\n        if (list == null) {\n            return;\n        }\n        list = list.filter(({ callback }) => callback !== listener);\n        this.#listeners.set(type, list);\n    }\n    dispatchEvent(event) {\n        const result = super.dispatchEvent(event);\n        let list = this.#listeners.get(event.type);\n        if (list == null) {\n            return result;\n        }\n        list = list.filter(({ once }) => !once);\n        this.#listeners.set(event.type, list);\n        return result;\n    }\n    safeDispatchEvent(type, detail = {}) {\n        return this.dispatchEvent(new CustomEvent(type, detail));\n    }\n}\n//# sourceMappingURL=event-target.js.map","export const empty = new Uint8Array(0);\nexport function toHex(d) {\n    return d.reduce((hex, byte) => hex + byte.toString(16).padStart(2, '0'), '');\n}\nexport function fromHex(hex) {\n    const hexes = hex.match(/../g);\n    return hexes != null ? new Uint8Array(hexes.map(b => parseInt(b, 16))) : empty;\n}\nexport function equals(aa, bb) {\n    if (aa === bb)\n        return true;\n    if (aa.byteLength !== bb.byteLength) {\n        return false;\n    }\n    for (let ii = 0; ii < aa.byteLength; ii++) {\n        if (aa[ii] !== bb[ii]) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function coerce(o) {\n    if (o instanceof Uint8Array && o.constructor.name === 'Uint8Array')\n        return o;\n    if (o instanceof ArrayBuffer)\n        return new Uint8Array(o);\n    if (ArrayBuffer.isView(o)) {\n        return new Uint8Array(o.buffer, o.byteOffset, o.byteLength);\n    }\n    throw new Error('Unknown type, must be binary type');\n}\nexport function isBinary(o) {\n    return o instanceof ArrayBuffer || ArrayBuffer.isView(o);\n}\nexport function fromString(str) {\n    return new TextEncoder().encode(str);\n}\nexport function toString(b) {\n    return new TextDecoder().decode(b);\n}\n//# sourceMappingURL=bytes.js.map","/* eslint-disable */\n// base-x encoding / decoding\n// Copyright (c) 2018 base-x contributors\n// Copyright (c) 2014-2018 The Bitcoin Core developers (base58.cpp)\n// Distributed under the MIT software license, see the accompanying\n// file LICENSE or http://www.opensource.org/licenses/mit-license.php.\n/**\n * @param {string} ALPHABET\n * @param {any} name\n */\nfunction base(ALPHABET, name) {\n    if (ALPHABET.length >= 255) {\n        throw new TypeError('Alphabet too long');\n    }\n    var BASE_MAP = new Uint8Array(256);\n    for (var j = 0; j < BASE_MAP.length; j++) {\n        BASE_MAP[j] = 255;\n    }\n    for (var i = 0; i < ALPHABET.length; i++) {\n        var x = ALPHABET.charAt(i);\n        var xc = x.charCodeAt(0);\n        if (BASE_MAP[xc] !== 255) {\n            throw new TypeError(x + ' is ambiguous');\n        }\n        BASE_MAP[xc] = i;\n    }\n    var BASE = ALPHABET.length;\n    var LEADER = ALPHABET.charAt(0);\n    var FACTOR = Math.log(BASE) / Math.log(256); // log(BASE) / log(256), rounded up\n    var iFACTOR = Math.log(256) / Math.log(BASE); // log(256) / log(BASE), rounded up\n    /**\n     * @param {any[] | Iterable<number>} source\n     */\n    function encode(source) {\n        // @ts-ignore\n        if (source instanceof Uint8Array)\n            ;\n        else if (ArrayBuffer.isView(source)) {\n            source = new Uint8Array(source.buffer, source.byteOffset, source.byteLength);\n        }\n        else if (Array.isArray(source)) {\n            source = Uint8Array.from(source);\n        }\n        if (!(source instanceof Uint8Array)) {\n            throw new TypeError('Expected Uint8Array');\n        }\n        if (source.length === 0) {\n            return '';\n        }\n        // Skip & count leading zeroes.\n        var zeroes = 0;\n        var length = 0;\n        var pbegin = 0;\n        var pend = source.length;\n        while (pbegin !== pend && source[pbegin] === 0) {\n            pbegin++;\n            zeroes++;\n        }\n        // Allocate enough space in big-endian base58 representation.\n        var size = ((pend - pbegin) * iFACTOR + 1) >>> 0;\n        var b58 = new Uint8Array(size);\n        // Process the bytes.\n        while (pbegin !== pend) {\n            var carry = source[pbegin];\n            // Apply \"b58 = b58 * 256 + ch\".\n            var i = 0;\n            for (var it1 = size - 1; (carry !== 0 || i < length) && (it1 !== -1); it1--, i++) {\n                carry += (256 * b58[it1]) >>> 0;\n                b58[it1] = (carry % BASE) >>> 0;\n                carry = (carry / BASE) >>> 0;\n            }\n            if (carry !== 0) {\n                throw new Error('Non-zero carry');\n            }\n            length = i;\n            pbegin++;\n        }\n        // Skip leading zeroes in base58 result.\n        var it2 = size - length;\n        while (it2 !== size && b58[it2] === 0) {\n            it2++;\n        }\n        // Translate the result into a string.\n        var str = LEADER.repeat(zeroes);\n        for (; it2 < size; ++it2) {\n            str += ALPHABET.charAt(b58[it2]);\n        }\n        return str;\n    }\n    /**\n     * @param {string | string[]} source\n     */\n    function decodeUnsafe(source) {\n        if (typeof source !== 'string') {\n            throw new TypeError('Expected String');\n        }\n        if (source.length === 0) {\n            return new Uint8Array();\n        }\n        var psz = 0;\n        // Skip leading spaces.\n        if (source[psz] === ' ') {\n            return;\n        }\n        // Skip and count leading '1's.\n        var zeroes = 0;\n        var length = 0;\n        while (source[psz] === LEADER) {\n            zeroes++;\n            psz++;\n        }\n        // Allocate enough space in big-endian base256 representation.\n        var size = (((source.length - psz) * FACTOR) + 1) >>> 0; // log(58) / log(256), rounded up.\n        var b256 = new Uint8Array(size);\n        // Process the characters.\n        while (source[psz]) {\n            // Decode character\n            var carry = BASE_MAP[source.charCodeAt(psz)];\n            // Invalid character\n            if (carry === 255) {\n                return;\n            }\n            var i = 0;\n            for (var it3 = size - 1; (carry !== 0 || i < length) && (it3 !== -1); it3--, i++) {\n                carry += (BASE * b256[it3]) >>> 0;\n                b256[it3] = (carry % 256) >>> 0;\n                carry = (carry / 256) >>> 0;\n            }\n            if (carry !== 0) {\n                throw new Error('Non-zero carry');\n            }\n            length = i;\n            psz++;\n        }\n        // Skip trailing spaces.\n        if (source[psz] === ' ') {\n            return;\n        }\n        // Skip leading zeroes in b256.\n        var it4 = size - length;\n        while (it4 !== size && b256[it4] === 0) {\n            it4++;\n        }\n        var vch = new Uint8Array(zeroes + (size - it4));\n        var j = zeroes;\n        while (it4 !== size) {\n            vch[j++] = b256[it4++];\n        }\n        return vch;\n    }\n    /**\n     * @param {string | string[]} string\n     */\n    function decode(string) {\n        var buffer = decodeUnsafe(string);\n        if (buffer) {\n            return buffer;\n        }\n        throw new Error(`Non-${name} character`);\n    }\n    return {\n        encode: encode,\n        decodeUnsafe: decodeUnsafe,\n        decode: decode\n    };\n}\nvar src = base;\nvar _brrp__multiformats_scope_baseX = src;\nexport default _brrp__multiformats_scope_baseX;\n//# sourceMappingURL=base-x.js.map","import { coerce } from '../bytes.js';\nimport basex from '../vendor/base-x.js';\n/**\n * Class represents both BaseEncoder and MultibaseEncoder meaning it\n * can be used to encode to multibase or base encode without multibase\n * prefix.\n */\nclass Encoder {\n    name;\n    prefix;\n    baseEncode;\n    constructor(name, prefix, baseEncode) {\n        this.name = name;\n        this.prefix = prefix;\n        this.baseEncode = baseEncode;\n    }\n    encode(bytes) {\n        if (bytes instanceof Uint8Array) {\n            return `${this.prefix}${this.baseEncode(bytes)}`;\n        }\n        else {\n            throw Error('Unknown type, must be binary type');\n        }\n    }\n}\n/**\n * Class represents both BaseDecoder and MultibaseDecoder so it could be used\n * to decode multibases (with matching prefix) or just base decode strings\n * with corresponding base encoding.\n */\nclass Decoder {\n    name;\n    prefix;\n    baseDecode;\n    prefixCodePoint;\n    constructor(name, prefix, baseDecode) {\n        this.name = name;\n        this.prefix = prefix;\n        const prefixCodePoint = prefix.codePointAt(0);\n        /* c8 ignore next 3 */\n        if (prefixCodePoint === undefined) {\n            throw new Error('Invalid prefix character');\n        }\n        this.prefixCodePoint = prefixCodePoint;\n        this.baseDecode = baseDecode;\n    }\n    decode(text) {\n        if (typeof text === 'string') {\n            if (text.codePointAt(0) !== this.prefixCodePoint) {\n                throw Error(`Unable to decode multibase string ${JSON.stringify(text)}, ${this.name} decoder only supports inputs prefixed with ${this.prefix}`);\n            }\n            return this.baseDecode(text.slice(this.prefix.length));\n        }\n        else {\n            throw Error('Can only multibase decode strings');\n        }\n    }\n    or(decoder) {\n        return or(this, decoder);\n    }\n}\nclass ComposedDecoder {\n    decoders;\n    constructor(decoders) {\n        this.decoders = decoders;\n    }\n    or(decoder) {\n        return or(this, decoder);\n    }\n    decode(input) {\n        const prefix = input[0];\n        const decoder = this.decoders[prefix];\n        if (decoder != null) {\n            return decoder.decode(input);\n        }\n        else {\n            throw RangeError(`Unable to decode multibase string ${JSON.stringify(input)}, only inputs prefixed with ${Object.keys(this.decoders)} are supported`);\n        }\n    }\n}\nexport function or(left, right) {\n    // eslint-disable-next-line @typescript-eslint/consistent-type-assertions\n    return new ComposedDecoder({\n        ...(left.decoders ?? { [left.prefix]: left }),\n        ...(right.decoders ?? { [right.prefix]: right })\n    });\n}\nexport class Codec {\n    name;\n    prefix;\n    baseEncode;\n    baseDecode;\n    encoder;\n    decoder;\n    constructor(name, prefix, baseEncode, baseDecode) {\n        this.name = name;\n        this.prefix = prefix;\n        this.baseEncode = baseEncode;\n        this.baseDecode = baseDecode;\n        this.encoder = new Encoder(name, prefix, baseEncode);\n        this.decoder = new Decoder(name, prefix, baseDecode);\n    }\n    encode(input) {\n        return this.encoder.encode(input);\n    }\n    decode(input) {\n        return this.decoder.decode(input);\n    }\n}\nexport function from({ name, prefix, encode, decode }) {\n    return new Codec(name, prefix, encode, decode);\n}\nexport function baseX({ name, prefix, alphabet }) {\n    const { encode, decode } = basex(alphabet, name);\n    return from({\n        prefix,\n        name,\n        encode,\n        decode: (text) => coerce(decode(text))\n    });\n}\nfunction decode(string, alphabet, bitsPerChar, name) {\n    // Build the character lookup table:\n    const codes = {};\n    for (let i = 0; i < alphabet.length; ++i) {\n        codes[alphabet[i]] = i;\n    }\n    // Count the padding bytes:\n    let end = string.length;\n    while (string[end - 1] === '=') {\n        --end;\n    }\n    // Allocate the output:\n    const out = new Uint8Array((end * bitsPerChar / 8) | 0);\n    // Parse the data:\n    let bits = 0; // Number of bits currently in the buffer\n    let buffer = 0; // Bits waiting to be written out, MSB first\n    let written = 0; // Next byte to write\n    for (let i = 0; i < end; ++i) {\n        // Read one character from the string:\n        const value = codes[string[i]];\n        if (value === undefined) {\n            throw new SyntaxError(`Non-${name} character`);\n        }\n        // Append the bits to the buffer:\n        buffer = (buffer << bitsPerChar) | value;\n        bits += bitsPerChar;\n        // Write out some bits if the buffer has a byte's worth:\n        if (bits >= 8) {\n            bits -= 8;\n            out[written++] = 0xff & (buffer >> bits);\n        }\n    }\n    // Verify that we have received just enough bits:\n    if (bits >= bitsPerChar || (0xff & (buffer << (8 - bits))) !== 0) {\n        throw new SyntaxError('Unexpected end of data');\n    }\n    return out;\n}\nfunction encode(data, alphabet, bitsPerChar) {\n    const pad = alphabet[alphabet.length - 1] === '=';\n    const mask = (1 << bitsPerChar) - 1;\n    let out = '';\n    let bits = 0; // Number of bits currently in the buffer\n    let buffer = 0; // Bits waiting to be written out, MSB first\n    for (let i = 0; i < data.length; ++i) {\n        // Slurp data into the buffer:\n        buffer = (buffer << 8) | data[i];\n        bits += 8;\n        // Write out as much as we can:\n        while (bits > bitsPerChar) {\n            bits -= bitsPerChar;\n            out += alphabet[mask & (buffer >> bits)];\n        }\n    }\n    // Partial character:\n    if (bits !== 0) {\n        out += alphabet[mask & (buffer << (bitsPerChar - bits))];\n    }\n    // Add padding characters until we hit a byte boundary:\n    if (pad) {\n        while (((out.length * bitsPerChar) & 7) !== 0) {\n            out += '=';\n        }\n    }\n    return out;\n}\n/**\n * RFC4648 Factory\n */\nexport function rfc4648({ name, prefix, bitsPerChar, alphabet }) {\n    return from({\n        prefix,\n        name,\n        encode(input) {\n            return encode(input, alphabet, bitsPerChar);\n        },\n        decode(input) {\n            return decode(input, alphabet, bitsPerChar, name);\n        }\n    });\n}\n//# sourceMappingURL=base.js.map","import { baseX } from './base.js';\nexport const base10 = baseX({\n    prefix: '9',\n    name: 'base10',\n    alphabet: '0123456789'\n});\n//# sourceMappingURL=base10.js.map","import { rfc4648 } from './base.js';\nexport const base16 = rfc4648({\n    prefix: 'f',\n    name: 'base16',\n    alphabet: '0123456789abcdef',\n    bitsPerChar: 4\n});\nexport const base16upper = rfc4648({\n    prefix: 'F',\n    name: 'base16upper',\n    alphabet: '0123456789ABCDEF',\n    bitsPerChar: 4\n});\n//# sourceMappingURL=base16.js.map","import { rfc4648 } from './base.js';\nexport const base2 = rfc4648({\n    prefix: '0',\n    name: 'base2',\n    alphabet: '01',\n    bitsPerChar: 1\n});\n//# sourceMappingURL=base2.js.map","import { from } from './base.js';\nconst alphabet = Array.from('');\nconst alphabetBytesToChars = (alphabet.reduce((p, c, i) => { p[i] = c; return p; }, ([])));\nconst alphabetCharsToBytes = (alphabet.reduce((p, c, i) => {\n    const codePoint = c.codePointAt(0);\n    if (codePoint == null) {\n        throw new Error(`Invalid character: ${c}`);\n    }\n    p[codePoint] = i;\n    return p;\n}, ([])));\nfunction encode(data) {\n    return data.reduce((p, c) => {\n        p += alphabetBytesToChars[c];\n        return p;\n    }, '');\n}\nfunction decode(str) {\n    const byts = [];\n    for (const char of str) {\n        const codePoint = char.codePointAt(0);\n        if (codePoint == null) {\n            throw new Error(`Invalid character: ${char}`);\n        }\n        const byt = alphabetCharsToBytes[codePoint];\n        if (byt == null) {\n            throw new Error(`Non-base256emoji character: ${char}`);\n        }\n        byts.push(byt);\n    }\n    return new Uint8Array(byts);\n}\nexport const base256emoji = from({\n    prefix: '',\n    name: 'base256emoji',\n    encode,\n    decode\n});\n//# sourceMappingURL=base256emoji.js.map","import { rfc4648 } from './base.js';\nexport const base32 = rfc4648({\n    prefix: 'b',\n    name: 'base32',\n    alphabet: 'abcdefghijklmnopqrstuvwxyz234567',\n    bitsPerChar: 5\n});\nexport const base32upper = rfc4648({\n    prefix: 'B',\n    name: 'base32upper',\n    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567',\n    bitsPerChar: 5\n});\nexport const base32pad = rfc4648({\n    prefix: 'c',\n    name: 'base32pad',\n    alphabet: 'abcdefghijklmnopqrstuvwxyz234567=',\n    bitsPerChar: 5\n});\nexport const base32padupper = rfc4648({\n    prefix: 'C',\n    name: 'base32padupper',\n    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567=',\n    bitsPerChar: 5\n});\nexport const base32hex = rfc4648({\n    prefix: 'v',\n    name: 'base32hex',\n    alphabet: '0123456789abcdefghijklmnopqrstuv',\n    bitsPerChar: 5\n});\nexport const base32hexupper = rfc4648({\n    prefix: 'V',\n    name: 'base32hexupper',\n    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV',\n    bitsPerChar: 5\n});\nexport const base32hexpad = rfc4648({\n    prefix: 't',\n    name: 'base32hexpad',\n    alphabet: '0123456789abcdefghijklmnopqrstuv=',\n    bitsPerChar: 5\n});\nexport const base32hexpadupper = rfc4648({\n    prefix: 'T',\n    name: 'base32hexpadupper',\n    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUV=',\n    bitsPerChar: 5\n});\nexport const base32z = rfc4648({\n    prefix: 'h',\n    name: 'base32z',\n    alphabet: 'ybndrfg8ejkmcpqxot1uwisza345h769',\n    bitsPerChar: 5\n});\n//# sourceMappingURL=base32.js.map","import { baseX } from './base.js';\nexport const base36 = baseX({\n    prefix: 'k',\n    name: 'base36',\n    alphabet: '0123456789abcdefghijklmnopqrstuvwxyz'\n});\nexport const base36upper = baseX({\n    prefix: 'K',\n    name: 'base36upper',\n    alphabet: '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n});\n//# sourceMappingURL=base36.js.map","import { baseX } from './base.js';\nexport const base58btc = baseX({\n    name: 'base58btc',\n    prefix: 'z',\n    alphabet: '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'\n});\nexport const base58flickr = baseX({\n    name: 'base58flickr',\n    prefix: 'Z',\n    alphabet: '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'\n});\n//# sourceMappingURL=base58.js.map","import { rfc4648 } from './base.js';\nexport const base64 = rfc4648({\n    prefix: 'm',\n    name: 'base64',\n    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/',\n    bitsPerChar: 6\n});\nexport const base64pad = rfc4648({\n    prefix: 'M',\n    name: 'base64pad',\n    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=',\n    bitsPerChar: 6\n});\nexport const base64url = rfc4648({\n    prefix: 'u',\n    name: 'base64url',\n    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_',\n    bitsPerChar: 6\n});\nexport const base64urlpad = rfc4648({\n    prefix: 'U',\n    name: 'base64urlpad',\n    alphabet: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=',\n    bitsPerChar: 6\n});\n//# sourceMappingURL=base64.js.map","import { rfc4648 } from './base.js';\nexport const base8 = rfc4648({\n    prefix: '7',\n    name: 'base8',\n    alphabet: '01234567',\n    bitsPerChar: 3\n});\n//# sourceMappingURL=base8.js.map","import { fromString, toString } from '../bytes.js';\nimport { from } from './base.js';\nexport const identity = from({\n    prefix: '\\x00',\n    name: 'identity',\n    encode: (buf) => toString(buf),\n    decode: (str) => fromString(str)\n});\n//# sourceMappingURL=identity.js.map","const textEncoder = new TextEncoder();\nconst textDecoder = new TextDecoder();\nexport const name = 'json';\nexport const code = 0x0200;\nexport function encode(node) {\n    return textEncoder.encode(JSON.stringify(node));\n}\nexport function decode(data) {\n    return JSON.parse(textDecoder.decode(data));\n}\n//# sourceMappingURL=json.js.map","import { coerce } from '../bytes.js';\nexport const name = 'raw';\nexport const code = 0x55;\nexport function encode(node) {\n    return coerce(node);\n}\nexport function decode(data) {\n    return coerce(data);\n}\n//# sourceMappingURL=raw.js.map","/* eslint-disable */\nvar encode_1 = encode;\nvar MSB = 0x80, REST = 0x7F, MSBALL = ~REST, INT = Math.pow(2, 31);\n/**\n * @param {number} num\n * @param {number[]} out\n * @param {number} offset\n */\nfunction encode(num, out, offset) {\n    out = out || [];\n    offset = offset || 0;\n    var oldOffset = offset;\n    while (num >= INT) {\n        out[offset++] = (num & 0xFF) | MSB;\n        num /= 128;\n    }\n    while (num & MSBALL) {\n        out[offset++] = (num & 0xFF) | MSB;\n        num >>>= 7;\n    }\n    out[offset] = num | 0;\n    // @ts-ignore\n    encode.bytes = offset - oldOffset + 1;\n    return out;\n}\nvar decode = read;\nvar MSB$1 = 0x80, REST$1 = 0x7F;\n/**\n * @param {string | any[]} buf\n * @param {number} offset\n */\nfunction read(buf, offset) {\n    var res = 0, offset = offset || 0, shift = 0, counter = offset, b, l = buf.length;\n    do {\n        if (counter >= l) {\n            // @ts-ignore\n            read.bytes = 0;\n            throw new RangeError('Could not decode varint');\n        }\n        b = buf[counter++];\n        res += shift < 28\n            ? (b & REST$1) << shift\n            : (b & REST$1) * Math.pow(2, shift);\n        shift += 7;\n    } while (b >= MSB$1);\n    // @ts-ignore\n    read.bytes = counter - offset;\n    return res;\n}\nvar N1 = Math.pow(2, 7);\nvar N2 = Math.pow(2, 14);\nvar N3 = Math.pow(2, 21);\nvar N4 = Math.pow(2, 28);\nvar N5 = Math.pow(2, 35);\nvar N6 = Math.pow(2, 42);\nvar N7 = Math.pow(2, 49);\nvar N8 = Math.pow(2, 56);\nvar N9 = Math.pow(2, 63);\nvar length = function (/** @type {number} */ value) {\n    return (value < N1 ? 1\n        : value < N2 ? 2\n            : value < N3 ? 3\n                : value < N4 ? 4\n                    : value < N5 ? 5\n                        : value < N6 ? 6\n                            : value < N7 ? 7\n                                : value < N8 ? 8\n                                    : value < N9 ? 9\n                                        : 10);\n};\nvar varint = {\n    encode: encode_1,\n    decode: decode,\n    encodingLength: length\n};\nvar _brrp_varint = varint;\nexport default _brrp_varint;\n//# sourceMappingURL=varint.js.map","import varint from './vendor/varint.js';\nexport function decode(data, offset = 0) {\n    const code = varint.decode(data, offset);\n    return [code, varint.decode.bytes];\n}\nexport function encodeTo(int, target, offset = 0) {\n    varint.encode(int, target, offset);\n    return target;\n}\nexport function encodingLength(int) {\n    return varint.encodingLength(int);\n}\n//# sourceMappingURL=varint.js.map","import { coerce, equals as equalBytes } from '../bytes.js';\nimport * as varint from '../varint.js';\n/**\n * Creates a multihash digest.\n */\nexport function create(code, digest) {\n    const size = digest.byteLength;\n    const sizeOffset = varint.encodingLength(code);\n    const digestOffset = sizeOffset + varint.encodingLength(size);\n    const bytes = new Uint8Array(digestOffset + size);\n    varint.encodeTo(code, bytes, 0);\n    varint.encodeTo(size, bytes, sizeOffset);\n    bytes.set(digest, digestOffset);\n    return new Digest(code, size, digest, bytes);\n}\n/**\n * Turns bytes representation of multihash digest into an instance.\n */\nexport function decode(multihash) {\n    const bytes = coerce(multihash);\n    const [code, sizeOffset] = varint.decode(bytes);\n    const [size, digestOffset] = varint.decode(bytes.subarray(sizeOffset));\n    const digest = bytes.subarray(sizeOffset + digestOffset);\n    if (digest.byteLength !== size) {\n        throw new Error('Incorrect length');\n    }\n    return new Digest(code, size, digest, bytes);\n}\nexport function equals(a, b) {\n    if (a === b) {\n        return true;\n    }\n    else {\n        const data = b;\n        return (a.code === data.code &&\n            a.size === data.size &&\n            data.bytes instanceof Uint8Array &&\n            equalBytes(a.bytes, data.bytes));\n    }\n}\n/**\n * Represents a multihash digest which carries information about the\n * hashing algorithm and an actual hash digest.\n */\nexport class Digest {\n    code;\n    size;\n    digest;\n    bytes;\n    /**\n     * Creates a multihash digest.\n     */\n    constructor(code, size, digest, bytes) {\n        this.code = code;\n        this.size = size;\n        this.digest = digest;\n        this.bytes = bytes;\n    }\n}\n/**\n * Used to check that the passed multihash has the passed code\n */\nexport function hasCode(digest, code) {\n    return digest.code === code;\n}\n//# sourceMappingURL=digest.js.map","import { coerce } from '../bytes.js';\nimport * as Digest from './digest.js';\nconst code = 0x0;\nconst name = 'identity';\nconst encode = coerce;\nfunction digest(input) {\n    return Digest.create(code, encode(input));\n}\nexport const identity = { code, name, encode, digest };\n//# sourceMappingURL=identity.js.map","import * as Digest from './digest.js';\nexport function from({ name, code, encode }) {\n    return new Hasher(name, code, encode);\n}\n/**\n * Hasher represents a hashing algorithm implementation that produces as\n * `MultihashDigest`.\n */\nexport class Hasher {\n    name;\n    code;\n    encode;\n    constructor(name, code, encode) {\n        this.name = name;\n        this.code = code;\n        this.encode = encode;\n    }\n    digest(input) {\n        if (input instanceof Uint8Array) {\n            const result = this.encode(input);\n            return result instanceof Uint8Array\n                ? Digest.create(this.code, result)\n                /* c8 ignore next 1 */\n                : result.then(digest => Digest.create(this.code, digest));\n        }\n        else {\n            throw Error('Unknown type, must be binary type');\n            /* c8 ignore next 1 */\n        }\n    }\n}\n//# sourceMappingURL=hasher.js.map","/* global crypto */\nimport { from } from './hasher.js';\nfunction sha(name) {\n    return async (data) => new Uint8Array(await crypto.subtle.digest(name, data));\n}\nexport const sha256 = from({\n    name: 'sha2-256',\n    code: 0x12,\n    encode: sha('SHA-256')\n});\nexport const sha512 = from({\n    name: 'sha2-512',\n    code: 0x13,\n    encode: sha('SHA-512')\n});\n//# sourceMappingURL=sha2-browser.js.map","import { base32 } from './bases/base32.js';\nimport { base36 } from './bases/base36.js';\nimport { base58btc } from './bases/base58.js';\nimport { coerce } from './bytes.js';\nimport * as Digest from './hashes/digest.js';\nimport * as varint from './varint.js';\n// This way TS will also expose all the types from module\nexport * from './link/interface.js';\nexport function format(link, base) {\n    const { bytes, version } = link;\n    switch (version) {\n        case 0:\n            return toStringV0(bytes, baseCache(link), base ?? base58btc.encoder);\n        default:\n            return toStringV1(bytes, baseCache(link), (base ?? base32.encoder));\n    }\n}\nexport function toJSON(link) {\n    return {\n        '/': format(link)\n    };\n}\nexport function fromJSON(json) {\n    return CID.parse(json['/']);\n}\nconst cache = new WeakMap();\nfunction baseCache(cid) {\n    const baseCache = cache.get(cid);\n    if (baseCache == null) {\n        const baseCache = new Map();\n        cache.set(cid, baseCache);\n        return baseCache;\n    }\n    return baseCache;\n}\nexport class CID {\n    code;\n    version;\n    multihash;\n    bytes;\n    '/';\n    /**\n     * @param version - Version of the CID\n     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv\n     * @param multihash - (Multi)hash of the of the content.\n     */\n    constructor(version, code, multihash, bytes) {\n        this.code = code;\n        this.version = version;\n        this.multihash = multihash;\n        this.bytes = bytes;\n        // flag to serializers that this is a CID and\n        // should be treated specially\n        this['/'] = bytes;\n    }\n    /**\n     * Signalling `cid.asCID === cid` has been replaced with `cid['/'] === cid.bytes`\n     * please either use `CID.asCID(cid)` or switch to new signalling mechanism\n     *\n     * @deprecated\n     */\n    get asCID() {\n        return this;\n    }\n    // ArrayBufferView\n    get byteOffset() {\n        return this.bytes.byteOffset;\n    }\n    // ArrayBufferView\n    get byteLength() {\n        return this.bytes.byteLength;\n    }\n    toV0() {\n        switch (this.version) {\n            case 0: {\n                return this;\n            }\n            case 1: {\n                const { code, multihash } = this;\n                if (code !== DAG_PB_CODE) {\n                    throw new Error('Cannot convert a non dag-pb CID to CIDv0');\n                }\n                // sha2-256\n                if (multihash.code !== SHA_256_CODE) {\n                    throw new Error('Cannot convert non sha2-256 multihash CID to CIDv0');\n                }\n                return (CID.createV0(multihash));\n            }\n            default: {\n                throw Error(`Can not convert CID version ${this.version} to version 0. This is a bug please report`);\n            }\n        }\n    }\n    toV1() {\n        switch (this.version) {\n            case 0: {\n                const { code, digest } = this.multihash;\n                const multihash = Digest.create(code, digest);\n                return (CID.createV1(this.code, multihash));\n            }\n            case 1: {\n                return this;\n            }\n            default: {\n                throw Error(`Can not convert CID version ${this.version} to version 1. This is a bug please report`);\n            }\n        }\n    }\n    equals(other) {\n        return CID.equals(this, other);\n    }\n    static equals(self, other) {\n        const unknown = other;\n        return (unknown != null &&\n            self.code === unknown.code &&\n            self.version === unknown.version &&\n            Digest.equals(self.multihash, unknown.multihash));\n    }\n    toString(base) {\n        return format(this, base);\n    }\n    toJSON() {\n        return { '/': format(this) };\n    }\n    link() {\n        return this;\n    }\n    [Symbol.toStringTag] = 'CID';\n    // Legacy\n    [Symbol.for('nodejs.util.inspect.custom')]() {\n        return `CID(${this.toString()})`;\n    }\n    /**\n     * Takes any input `value` and returns a `CID` instance if it was\n     * a `CID` otherwise returns `null`. If `value` is instanceof `CID`\n     * it will return value back. If `value` is not instance of this CID\n     * class, but is compatible CID it will return new instance of this\n     * `CID` class. Otherwise returns null.\n     *\n     * This allows two different incompatible versions of CID library to\n     * co-exist and interop as long as binary interface is compatible.\n     */\n    static asCID(input) {\n        if (input == null) {\n            return null;\n        }\n        const value = input;\n        if (value instanceof CID) {\n            // If value is instance of CID then we're all set.\n            return value;\n        }\n        else if ((value['/'] != null && value['/'] === value.bytes) || value.asCID === value) {\n            // If value isn't instance of this CID class but `this.asCID === this` or\n            // `value['/'] === value.bytes` is true it is CID instance coming from a\n            // different implementation (diff version or duplicate). In that case we\n            // rebase it to this `CID` implementation so caller is guaranteed to get\n            // instance with expected API.\n            const { version, code, multihash, bytes } = value;\n            return new CID(version, code, multihash, bytes ?? encodeCID(version, code, multihash.bytes));\n        }\n        else if (value[cidSymbol] === true) {\n            // If value is a CID from older implementation that used to be tagged via\n            // symbol we still rebase it to the this `CID` implementation by\n            // delegating that to a constructor.\n            const { version, multihash, code } = value;\n            const digest = Digest.decode(multihash);\n            return CID.create(version, code, digest);\n        }\n        else {\n            // Otherwise value is not a CID (or an incompatible version of it) in\n            // which case we return `null`.\n            return null;\n        }\n    }\n    /**\n     * @param version - Version of the CID\n     * @param code - Code of the codec content is encoded in, see https://github.com/multiformats/multicodec/blob/master/table.csv\n     * @param digest - (Multi)hash of the of the content.\n     */\n    static create(version, code, digest) {\n        if (typeof code !== 'number') {\n            throw new Error('String codecs are no longer supported');\n        }\n        if (!(digest.bytes instanceof Uint8Array)) {\n            throw new Error('Invalid digest');\n        }\n        switch (version) {\n            case 0: {\n                if (code !== DAG_PB_CODE) {\n                    throw new Error(`Version 0 CID must use dag-pb (code: ${DAG_PB_CODE}) block encoding`);\n                }\n                else {\n                    return new CID(version, code, digest, digest.bytes);\n                }\n            }\n            case 1: {\n                const bytes = encodeCID(version, code, digest.bytes);\n                return new CID(version, code, digest, bytes);\n            }\n            default: {\n                throw new Error('Invalid version');\n            }\n        }\n    }\n    /**\n     * Simplified version of `create` for CIDv0.\n     */\n    static createV0(digest) {\n        return CID.create(0, DAG_PB_CODE, digest);\n    }\n    /**\n     * Simplified version of `create` for CIDv1.\n     *\n     * @param code - Content encoding format code.\n     * @param digest - Multihash of the content.\n     */\n    static createV1(code, digest) {\n        return CID.create(1, code, digest);\n    }\n    /**\n     * Decoded a CID from its binary representation. The byte array must contain\n     * only the CID with no additional bytes.\n     *\n     * An error will be thrown if the bytes provided do not contain a valid\n     * binary representation of a CID.\n     */\n    static decode(bytes) {\n        const [cid, remainder] = CID.decodeFirst(bytes);\n        if (remainder.length !== 0) {\n            throw new Error('Incorrect length');\n        }\n        return cid;\n    }\n    /**\n     * Decoded a CID from its binary representation at the beginning of a byte\n     * array.\n     *\n     * Returns an array with the first element containing the CID and the second\n     * element containing the remainder of the original byte array. The remainder\n     * will be a zero-length byte array if the provided bytes only contained a\n     * binary CID representation.\n     */\n    static decodeFirst(bytes) {\n        const specs = CID.inspectBytes(bytes);\n        const prefixSize = specs.size - specs.multihashSize;\n        const multihashBytes = coerce(bytes.subarray(prefixSize, prefixSize + specs.multihashSize));\n        if (multihashBytes.byteLength !== specs.multihashSize) {\n            throw new Error('Incorrect length');\n        }\n        const digestBytes = multihashBytes.subarray(specs.multihashSize - specs.digestSize);\n        const digest = new Digest.Digest(specs.multihashCode, specs.digestSize, digestBytes, multihashBytes);\n        const cid = specs.version === 0\n            ? CID.createV0(digest)\n            : CID.createV1(specs.codec, digest);\n        return [cid, bytes.subarray(specs.size)];\n    }\n    /**\n     * Inspect the initial bytes of a CID to determine its properties.\n     *\n     * Involves decoding up to 4 varints. Typically this will require only 4 to 6\n     * bytes but for larger multicodec code values and larger multihash digest\n     * lengths these varints can be quite large. It is recommended that at least\n     * 10 bytes be made available in the `initialBytes` argument for a complete\n     * inspection.\n     */\n    static inspectBytes(initialBytes) {\n        let offset = 0;\n        const next = () => {\n            const [i, length] = varint.decode(initialBytes.subarray(offset));\n            offset += length;\n            return i;\n        };\n        let version = next();\n        let codec = DAG_PB_CODE;\n        if (version === 18) {\n            // CIDv0\n            version = 0;\n            offset = 0;\n        }\n        else {\n            codec = next();\n        }\n        if (version !== 0 && version !== 1) {\n            throw new RangeError(`Invalid CID version ${version}`);\n        }\n        const prefixSize = offset;\n        const multihashCode = next(); // multihash code\n        const digestSize = next(); // multihash length\n        const size = offset + digestSize;\n        const multihashSize = size - prefixSize;\n        return { version, codec, multihashCode, digestSize, multihashSize, size };\n    }\n    /**\n     * Takes cid in a string representation and creates an instance. If `base`\n     * decoder is not provided will use a default from the configuration. It will\n     * throw an error if encoding of the CID is not compatible with supplied (or\n     * a default decoder).\n     */\n    static parse(source, base) {\n        const [prefix, bytes] = parseCIDtoBytes(source, base);\n        const cid = CID.decode(bytes);\n        if (cid.version === 0 && source[0] !== 'Q') {\n            throw Error('Version 0 CID string must not include multibase prefix');\n        }\n        // Cache string representation to avoid computing it on `this.toString()`\n        baseCache(cid).set(prefix, source);\n        return cid;\n    }\n}\nfunction parseCIDtoBytes(source, base) {\n    switch (source[0]) {\n        // CIDv0 is parsed differently\n        case 'Q': {\n            const decoder = base ?? base58btc;\n            return [\n                base58btc.prefix,\n                decoder.decode(`${base58btc.prefix}${source}`)\n            ];\n        }\n        case base58btc.prefix: {\n            const decoder = base ?? base58btc;\n            return [base58btc.prefix, decoder.decode(source)];\n        }\n        case base32.prefix: {\n            const decoder = base ?? base32;\n            return [base32.prefix, decoder.decode(source)];\n        }\n        case base36.prefix: {\n            const decoder = base ?? base36;\n            return [base36.prefix, decoder.decode(source)];\n        }\n        default: {\n            if (base == null) {\n                throw Error('To parse non base32, base36 or base58btc encoded CID multibase decoder must be provided');\n            }\n            return [source[0], base.decode(source)];\n        }\n    }\n}\nfunction toStringV0(bytes, cache, base) {\n    const { prefix } = base;\n    if (prefix !== base58btc.prefix) {\n        throw Error(`Cannot string encode V0 in ${base.name} encoding`);\n    }\n    const cid = cache.get(prefix);\n    if (cid == null) {\n        const cid = base.encode(bytes).slice(1);\n        cache.set(prefix, cid);\n        return cid;\n    }\n    else {\n        return cid;\n    }\n}\nfunction toStringV1(bytes, cache, base) {\n    const { prefix } = base;\n    const cid = cache.get(prefix);\n    if (cid == null) {\n        const cid = base.encode(bytes);\n        cache.set(prefix, cid);\n        return cid;\n    }\n    else {\n        return cid;\n    }\n}\nconst DAG_PB_CODE = 0x70;\nconst SHA_256_CODE = 0x12;\nfunction encodeCID(version, code, multihash) {\n    const codeOffset = varint.encodingLength(version);\n    const hashOffset = codeOffset + varint.encodingLength(code);\n    const bytes = new Uint8Array(hashOffset + multihash.byteLength);\n    varint.encodeTo(version, bytes, 0);\n    varint.encodeTo(code, bytes, codeOffset);\n    bytes.set(multihash, hashOffset);\n    return bytes;\n}\nconst cidSymbol = Symbol.for('@ipld/js-cid/CID');\n//# sourceMappingURL=cid.js.map","/**\n * @packageDocumentation\n *\n * This library defines common interfaces and low level building blocks for various interrelated multiformat technologies (multicodec, multihash, multibase, and CID). They can be used to implement custom base encoders / decoders / codecs, codec encoders /decoders and multihash hashers that comply to the interface that layers above assume.\n *\n * This library provides implementations for most basics and many others can be found in linked repositories.\n *\n * ```TypeScript\n * import { CID } from 'multiformats/cid'\n * import * as json from 'multiformats/codecs/json'\n * import { sha256 } from 'multiformats/hashes/sha2'\n *\n * const bytes = json.encode({ hello: 'world' })\n *\n * const hash = await sha256.digest(bytes)\n * const cid = CID.create(1, json.code, hash)\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n * ```\n *\n * ## Creating Blocks\n *\n * ```TypeScript\n * import * as Block from 'multiformats/block'\n * import * as codec from '@ipld/dag-cbor'\n * import { sha256 as hasher } from 'multiformats/hashes/sha2'\n *\n * const value = { hello: 'world' }\n *\n * // encode a block\n * let block = await Block.encode({ value, codec, hasher })\n *\n * block.value // { hello: 'world' }\n * block.bytes // Uint8Array\n * block.cid   // CID() w/ sha2-256 hash address and dag-cbor codec\n *\n * // you can also decode blocks from their binary state\n * block = await Block.decode({ bytes: block.bytes, codec, hasher })\n *\n * // if you have the cid you can also verify the hash on decode\n * block = await Block.create({ bytes: block.bytes, cid: block.cid, codec, hasher })\n * ```\n *\n * ## Multibase Encoders / Decoders / Codecs\n *\n * CIDs can be serialized to string representation using multibase encoders that implement [`MultibaseEncoder`](https://github.com/multiformats/js-multiformats/blob/master/src/bases/interface.ts) interface. This library provides quite a few implementations that can be imported:\n *\n * ```TypeScript\n * import { base64 } from \"multiformats/bases/base64\"\n * cid.toString(base64.encoder)\n * //> 'mAYAEEiCTojlxqRTl6svwqNJRVM2jCcPBxy+7mRTUfGDzy2gViA'\n * ```\n *\n * Parsing CID string serialized CIDs requires multibase decoder that implements [`MultibaseDecoder`](https://github.com/multiformats/js-multiformats/blob/master/src/bases/interface.ts) interface. This library provides a decoder for every encoder it provides:\n *\n * ```TypeScript\n * CID.parse('mAYAEEiCTojlxqRTl6svwqNJRVM2jCcPBxy+7mRTUfGDzy2gViA', base64.decoder)\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n * ```\n *\n * Dual of multibase encoder & decoder is defined as multibase codec and it exposes\n * them as `encoder` and `decoder` properties. For added convenience codecs also\n * implement `MultibaseEncoder` and `MultibaseDecoder` interfaces so they could be\n * used as either or both:\n *\n * ```TypeScript\n * cid.toString(base64)\n * CID.parse(cid.toString(base64), base64)\n * ```\n *\n * **Note:** CID implementation comes bundled with `base32` and `base58btc`\n * multibase codecs so that CIDs can be base serialized to (version specific)\n * default base encoding and parsed without having to supply base encoders/decoders:\n *\n * ```TypeScript\n * const v1 = CID.parse('bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea')\n * v1.toString()\n * //> 'bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea'\n *\n * const v0 = CID.parse('QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n')\n * v0.toString()\n * //> 'QmdfTbBqBPQ7VNxZEYEj14VmRuZBkqFbiwReogJgS1zR1n'\n * v0.toV1().toString()\n * //> 'bafybeihdwdcefgh4dqkjv67uzcmw7ojee6xedzdetojuzjevtenxquvyku'\n * ```\n *\n * ## Multicodec Encoders / Decoders / Codecs\n *\n * This library defines [`BlockEncoder`, `BlockDecoder` and `BlockCodec` interfaces](https://github.com/multiformats/js-multiformats/blob/master/src/codecs/interface.ts).\n * Codec implementations should conform to the `BlockCodec` interface which implements both `BlockEncoder` and `BlockDecoder`.\n * Here is an example implementation of JSON `BlockCodec`.\n *\n * ```TypeScript\n * export const { name, code, encode, decode } = {\n *   name: 'json',\n *   code: 0x0200,\n *   encode: json => new TextEncoder().encode(JSON.stringify(json)),\n *   decode: bytes => JSON.parse(new TextDecoder().decode(bytes))\n * }\n * ```\n *\n * ## Multihash Hashers\n *\n * This library defines [`MultihashHasher` and `MultihashDigest` interfaces](https://github.com/multiformats/js-multiformats/blob/master/src/hashes/interface.ts) and convinient function for implementing them:\n *\n * ```TypeScript\n * import * as hasher from 'multiformats/hashes/hasher'\n *\n * const sha256 = hasher.from({\n *   // As per multiformats table\n *   // https://github.com/multiformats/multicodec/blob/master/table.csv#L9\n *   name: 'sha2-256',\n *   code: 0x12,\n *\n *   encode: (input) => new Uint8Array(crypto.createHash('sha256').update(input).digest())\n * })\n *\n * const hash = await sha256.digest(json.encode({ hello: 'world' }))\n * CID.create(1, json.code, hash)\n *\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n * ```\n *\n * ## Traversal\n *\n * This library contains higher-order functions for traversing graphs of data easily.\n *\n * `walk()` walks through the links in each block of a DAG calling a user-supplied loader function for each one, in depth-first order with no duplicate block visits. The loader should return a `Block` object and can be used to inspect and collect block ordering for a full DAG walk. The loader should `throw` on error, and return `null` if a block should be skipped by `walk()`.\n *\n * ```TypeScript\n * import { walk } from 'multiformats/traversal'\n * import * as Block from 'multiformats/block'\n * import * as codec from 'multiformats/codecs/json'\n * import { sha256 as hasher } from 'multiformats/hashes/sha2'\n *\n * // build a DAG (a single block for this simple example)\n * const value = { hello: 'world' }\n * const block = await Block.encode({ value, codec, hasher })\n * const { cid } = block\n * console.log(cid)\n * //> CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)\n *\n * // create a loader function that also collects CIDs of blocks in\n * // their traversal order\n * const load = (cid, blocks) => async (cid) => {\n *   // fetch a block using its cid\n *   // e.g.: const block = await fetchBlockByCID(cid)\n *   blocks.push(cid)\n *   return block\n * }\n *\n * // collect blocks in this DAG starting from the root `cid`\n * const blocks = []\n * await walk({ cid, load: load(cid, blocks) })\n *\n * console.log(blocks)\n * //> [CID(bagaaierasords4njcts6vs7qvdjfcvgnume4hqohf65zsfguprqphs3icwea)]\n * ```\n *\n * ## Legacy interface\n *\n * [`blockcodec-to-ipld-format`](https://github.com/ipld/js-blockcodec-to-ipld-format) converts a multiformats [`BlockCodec`](https://github.com/multiformats/js-multiformats/blob/master/src/codecs/interface.ts#L21) into an\n * [`interface-ipld-format`](https://github.com/ipld/interface-ipld-format) for use with the [`ipld`](https://github.com/ipld/ipld) package. This can help bridge IPLD codecs implemented using the structure and interfaces defined here to existing code that assumes, or requires `interface-ipld-format`. This bridge also includes the relevant TypeScript definitions.\n *\n * ## Implementations\n *\n * By default, no base encodings (other than base32 & base58btc), hash functions,\n * or codec implementations are exposed by `multiformats`, you need to\n * import the ones you need yourself.\n *\n * ### Multibase codecs\n *\n * | bases                                                         | import                      | repo                                                                                              |\n * | ------------------------------------------------------------- | --------------------------- | ------------------------------------------------------------------------------------------------- |\n * | `base16`                                                      | `multiformats/bases/base16` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n * | `base32`, `base32pad`, `base32hex`, `base32hexpad`, `base32z` | `multiformats/bases/base32` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n * | `base64`, `base64pad`, `base64url`, `base64urlpad`            | `multiformats/bases/base64` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n * | `base58btc`, `base58flick4`                                   | `multiformats/bases/base58` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) |\n *\n * Other (less useful) bases implemented in [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/bases) include: `base2`, `base8`, `base10`, `base36` and `base256emoji`.\n *\n * ### Multihash hashers\n *\n * | hashes                                                                                                                          | import                         | repo                                                                                                               |\n * | ------------------------------------------------------------------------------------------------------------------------------- | ------------------------------ | ------------------------------------------------------------------------------------------------------------------ |\n * | `sha2-256`, `sha2-512`                                                                                                          | `multiformats/hashes/sha2`     | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/hashes)             |\n * | `sha3-224`, `sha3-256`, `sha3-384`,`sha3-512`, `shake-128`, `shake-256`, `keccak-224`, `keccak-256`, `keccak-384`, `keccak-512` | `@multiformats/sha3`           | [multiformats/js-sha3](https://github.com/multiformats/js-sha3)                                                    |\n * | `identity`                                                                                                                      | `multiformats/hashes/identity` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/hashes/identity.js) |\n * | `murmur3-128`, `murmur3-32`                                                                                                     | `@multiformats/murmur3`        | [multiformats/js-murmur3](https://github.com/multiformats/js-murmur3)                                              |\n * | `blake2b-*`, `blake2s-*`                                                                                                        | `@multiformats/blake2`         | [multiformats/js-blake2](https://github.com/multiformats/js-blake2)                                                |\n *\n * ### IPLD codecs (multicodec)\n *\n * | codec      | import                     | repo                                                                                                   |\n * | ---------- | -------------------------- | ------------------------------------------------------------------------------------------------------ |\n * | `raw`      | `multiformats/codecs/raw`  | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/codecs) |\n * | `json`     | `multiformats/codecs/json` | [multiformats/js-multiformats](https://github.com/multiformats/js-multiformats/tree/master/src/codecs) |\n * | `dag-cbor` | `@ipld/dag-cbor`           | [ipld/js-dag-cbor](https://github.com/ipld/js-dag-cbor)                                                |\n * | `dag-json` | `@ipld/dag-json`           | [ipld/js-dag-json](https://github.com/ipld/js-dag-json)                                                |\n * | `dag-pb`   | `@ipld/dag-pb`             | [ipld/js-dag-pb](https://github.com/ipld/js-dag-pb)                                                    |\n * | `dag-jose` | `dag-jose`                 | [ceramicnetwork/js-dag-jose](https://github.com/ceramicnetwork/js-dag-jose)                            |\n */\nimport * as bytes from './bytes.js';\nimport { CID } from './cid.js';\nimport * as digest from './hashes/digest.js';\nimport * as hasher from './hashes/hasher.js';\nimport * as varint from './varint.js';\n// This way TS will also expose all the types from module\nexport * from './interface.js';\nexport { CID, hasher, digest, varint, bytes };\n//# sourceMappingURL=index.js.map","import * as base10 from './bases/base10.js';\nimport * as base16 from './bases/base16.js';\nimport * as base2 from './bases/base2.js';\nimport * as base256emoji from './bases/base256emoji.js';\nimport * as base32 from './bases/base32.js';\nimport * as base36 from './bases/base36.js';\nimport * as base58 from './bases/base58.js';\nimport * as base64 from './bases/base64.js';\nimport * as base8 from './bases/base8.js';\nimport * as identityBase from './bases/identity.js';\nimport * as json from './codecs/json.js';\nimport * as raw from './codecs/raw.js';\nimport * as identity from './hashes/identity.js';\nimport * as sha2 from './hashes/sha2.js';\nimport { CID, hasher, digest, varint, bytes } from './index.js';\nexport const bases = { ...identityBase, ...base2, ...base8, ...base10, ...base16, ...base32, ...base36, ...base58, ...base64, ...base256emoji };\nexport const hashes = { ...sha2, ...identity };\nexport const codecs = { raw, json };\nexport { CID, hasher, digest, varint, bytes };\n//# sourceMappingURL=basics.js.map","/**\n * Returns a `Uint8Array` of the requested size. Referenced memory will\n * be initialized to 0.\n */\nexport function alloc(size = 0) {\n    return new Uint8Array(size);\n}\n/**\n * Where possible returns a Uint8Array of the requested size that references\n * uninitialized memory. Only use if you are certain you will immediately\n * overwrite every value in the returned `Uint8Array`.\n */\nexport function allocUnsafe(size = 0) {\n    return new Uint8Array(size);\n}\n//# sourceMappingURL=alloc.js.map","import { bases } from 'multiformats/basics';\nimport { allocUnsafe } from '#alloc';\nfunction createCodec(name, prefix, encode, decode) {\n    return {\n        name,\n        prefix,\n        encoder: {\n            name,\n            prefix,\n            encode\n        },\n        decoder: {\n            decode\n        }\n    };\n}\nconst string = createCodec('utf8', 'u', (buf) => {\n    const decoder = new TextDecoder('utf8');\n    return 'u' + decoder.decode(buf);\n}, (str) => {\n    const encoder = new TextEncoder();\n    return encoder.encode(str.substring(1));\n});\nconst ascii = createCodec('ascii', 'a', (buf) => {\n    let string = 'a';\n    for (let i = 0; i < buf.length; i++) {\n        string += String.fromCharCode(buf[i]);\n    }\n    return string;\n}, (str) => {\n    str = str.substring(1);\n    const buf = allocUnsafe(str.length);\n    for (let i = 0; i < str.length; i++) {\n        buf[i] = str.charCodeAt(i);\n    }\n    return buf;\n});\nconst BASES = {\n    utf8: string,\n    'utf-8': string,\n    hex: bases.base16,\n    latin1: ascii,\n    ascii,\n    binary: ascii,\n    ...bases\n};\nexport default BASES;\n//# sourceMappingURL=bases.js.map","import bases, {} from './util/bases.js';\n/**\n * Create a `Uint8Array` from the passed string\n *\n * Supports `utf8`, `utf-8`, `hex`, and any encoding supported by the multiformats module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n */\nexport function fromString(string, encoding = 'utf8') {\n    const base = bases[encoding];\n    if (base == null) {\n        throw new Error(`Unsupported encoding \"${encoding}\"`);\n    }\n    // add multibase prefix\n    return base.decoder.decode(`${base.prefix}${string}`); // eslint-disable-line @typescript-eslint/restrict-template-expressions\n}\n//# sourceMappingURL=from-string.js.map","/**\n * Returns true if the two passed Uint8Arrays have the same content\n */\nexport function equals(a, b) {\n    if (a === b) {\n        return true;\n    }\n    if (a.byteLength !== b.byteLength) {\n        return false;\n    }\n    for (let i = 0; i < a.byteLength; i++) {\n        if (a[i] !== b[i]) {\n            return false;\n        }\n    }\n    return true;\n}\n//# sourceMappingURL=equals.js.map","import { alloc as uint8ArrayAlloc } from 'uint8arrays/alloc';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nexport const MAX_FINGERPRINT_SIZE = 64;\nexport class Fingerprint {\n    fp;\n    h;\n    seed;\n    constructor(buf, hash, seed, fingerprintSize = 2) {\n        if (fingerprintSize > MAX_FINGERPRINT_SIZE) {\n            throw new TypeError('Invalid Fingerprint Size');\n        }\n        const fnv = hash.hashV(buf, seed);\n        const fp = uint8ArrayAlloc(fingerprintSize);\n        for (let i = 0; i < fp.length; i++) {\n            fp[i] = fnv[i];\n        }\n        if (fp.length === 0) {\n            fp[0] = 7;\n        }\n        this.fp = fp;\n        this.h = hash;\n        this.seed = seed;\n    }\n    hash() {\n        return this.h.hash(this.fp, this.seed);\n    }\n    equals(other) {\n        if (!(other?.fp instanceof Uint8Array)) {\n            return false;\n        }\n        return uint8ArrayEquals(this.fp, other.fp);\n    }\n}\n//# sourceMappingURL=fingerprint.js.map","export function getRandomInt(min, max) {\n    return Math.floor(Math.random() * (max - min)) + min;\n}\n//# sourceMappingURL=utils.js.map","import { Fingerprint } from './fingerprint.js';\nimport { getRandomInt } from './utils.js';\nexport class Bucket {\n    contents;\n    constructor(size) {\n        this.contents = new Array(size).fill(null);\n    }\n    has(fingerprint) {\n        if (!(fingerprint instanceof Fingerprint)) {\n            throw new TypeError('Invalid Fingerprint');\n        }\n        return this.contents.some((fp) => {\n            return fingerprint.equals(fp);\n        });\n    }\n    add(fingerprint) {\n        if (!(fingerprint instanceof Fingerprint)) {\n            throw new TypeError('Invalid Fingerprint');\n        }\n        for (let i = 0; i < this.contents.length; i++) {\n            if (this.contents[i] == null) {\n                this.contents[i] = fingerprint;\n                return true;\n            }\n        }\n        return true;\n    }\n    swap(fingerprint) {\n        if (!(fingerprint instanceof Fingerprint)) {\n            throw new TypeError('Invalid Fingerprint');\n        }\n        const i = getRandomInt(0, this.contents.length - 1);\n        const current = this.contents[i];\n        this.contents[i] = fingerprint;\n        return current;\n    }\n    remove(fingerprint) {\n        if (!(fingerprint instanceof Fingerprint)) {\n            throw new TypeError('Invalid Fingerprint');\n        }\n        const found = this.contents.findIndex((fp) => {\n            return fingerprint.equals(fp);\n        });\n        if (found > -1) {\n            this.contents[found] = null;\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n}\n//# sourceMappingURL=bucket.js.map","// FNV_PRIMES and FNV_OFFSETS from\n// http://www.isthe.com/chongo/tech/comp/fnv/index.html#FNV-param\n\nconst FNV_PRIMES = {\n\t32: 16_777_619n,\n\t64: 1_099_511_628_211n,\n\t128: 309_485_009_821_345_068_724_781_371n,\n\t256: 374_144_419_156_711_147_060_143_317_175_368_453_031_918_731_002_211n,\n\t512: 35_835_915_874_844_867_368_919_076_489_095_108_449_946_327_955_754_392_558_399_825_615_420_669_938_882_575_126_094_039_892_345_713_852_759n,\n\t1024: 5_016_456_510_113_118_655_434_598_811_035_278_955_030_765_345_404_790_744_303_017_523_831_112_055_108_147_451_509_157_692_220_295_382_716_162_651_878_526_895_249_385_292_291_816_524_375_083_746_691_371_804_094_271_873_160_484_737_966_720_260_389_217_684_476_157_468_082_573n,\n};\n\nconst FNV_OFFSETS = {\n\t32: 2_166_136_261n,\n\t64: 14_695_981_039_346_656_037n,\n\t128: 144_066_263_297_769_815_596_495_629_667_062_367_629n,\n\t256: 100_029_257_958_052_580_907_070_968_620_625_704_837_092_796_014_241_193_945_225_284_501_741_471_925_557n,\n\t512: 9_659_303_129_496_669_498_009_435_400_716_310_466_090_418_745_672_637_896_108_374_329_434_462_657_994_582_932_197_716_438_449_813_051_892_206_539_805_784_495_328_239_340_083_876_191_928_701_583_869_517_785n,\n\t1024: 14_197_795_064_947_621_068_722_070_641_403_218_320_880_622_795_441_933_960_878_474_914_617_582_723_252_296_732_303_717_722_150_864_096_521_202_355_549_365_628_174_669_108_571_814_760_471_015_076_148_029_755_969_804_077_320_157_692_458_563_003_215_304_957_150_157_403_644_460_363_550_505_412_711_285_966_361_610_267_868_082_893_823_963_790_439_336_411_086_884_584_107_735_010_676_915n,\n};\n\nconst cachedEncoder = new globalThis.TextEncoder();\n\nfunction fnv1aUint8Array(uint8Array, size) {\n\tconst fnvPrime = FNV_PRIMES[size];\n\tlet hash = FNV_OFFSETS[size];\n\n\t// eslint-disable-next-line unicorn/no-for-loop -- This is a performance-sensitive loop\n\tfor (let index = 0; index < uint8Array.length; index++) {\n\t\thash ^= BigInt(uint8Array[index]);\n\t\thash = BigInt.asUintN(size, hash * fnvPrime);\n\t}\n\n\treturn hash;\n}\n\nfunction fnv1aEncodeInto(string, size, utf8Buffer) {\n\tif (utf8Buffer.length === 0) {\n\t\tthrow new Error('The `utf8Buffer` option must have a length greater than zero');\n\t}\n\n\tconst fnvPrime = FNV_PRIMES[size];\n\tlet hash = FNV_OFFSETS[size];\n\tlet remaining = string;\n\n\twhile (remaining.length > 0) {\n\t\tconst result = cachedEncoder.encodeInto(remaining, utf8Buffer);\n\t\tremaining = remaining.slice(result.read);\n\t\tfor (let index = 0; index < result.written; index++) {\n\t\t\thash ^= BigInt(utf8Buffer[index]);\n\t\t\thash = BigInt.asUintN(size, hash * fnvPrime);\n\t\t}\n\t}\n\n\treturn hash;\n}\n\nexport default function fnv1a(value, {size = 32, utf8Buffer} = {}) {\n\tif (!FNV_PRIMES[size]) {\n\t\tthrow new Error('The `size` option must be one of 32, 64, 128, 256, 512, or 1024');\n\t}\n\n\tif (typeof value === 'string') {\n\t\tif (utf8Buffer) {\n\t\t\treturn fnv1aEncodeInto(value, size, utf8Buffer);\n\t\t}\n\n\t\tvalue = cachedEncoder.encode(value);\n\t}\n\n\treturn fnv1aUint8Array(value, size);\n}\n","import fnv1aHash from '@sindresorhus/fnv1a';\nimport mur from 'murmurhash3js-revisited';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nexport const murmur3 = {\n    hash: (input, seed) => {\n        return mur.x86.hash32(input, seed);\n    },\n    hashV: (input, seed) => {\n        return numberToBuffer(murmur3.hash(input, seed));\n    }\n};\nexport const fnv1a = {\n    hash: (input) => {\n        return Number(fnv1aHash(input, {\n            size: 32\n        }));\n    },\n    hashV: (input, seed) => {\n        return numberToBuffer(fnv1a.hash(input, seed));\n    }\n};\nexport function numberToBuffer(num) {\n    let hex = num.toString(16);\n    if (hex.length % 2 === 1) {\n        hex = `0${hex}`;\n    }\n    return uint8ArrayFromString(hex, 'base16');\n}\n//# sourceMappingURL=hashes.js.map","import { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { Bucket } from './bucket.js';\nimport { Fingerprint, MAX_FINGERPRINT_SIZE } from './fingerprint.js';\nimport { fnv1a } from './hashes.js';\nimport { getRandomInt } from './utils.js';\nconst maxCuckooCount = 500;\nexport class CuckooFilter {\n    bucketSize;\n    filterSize;\n    fingerprintSize;\n    buckets;\n    count;\n    hash;\n    seed;\n    constructor(init) {\n        this.filterSize = init.filterSize;\n        this.bucketSize = init.bucketSize ?? 4;\n        this.fingerprintSize = init.fingerprintSize ?? 2;\n        this.count = 0;\n        this.buckets = [];\n        this.hash = init.hash ?? fnv1a;\n        this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));\n    }\n    add(item) {\n        if (typeof item === 'string') {\n            item = uint8ArrayFromString(item);\n        }\n        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);\n        const j = this.hash.hash(item, this.seed) % this.filterSize;\n        const k = (j ^ fingerprint.hash()) % this.filterSize;\n        if (this.buckets[j] == null) {\n            this.buckets[j] = new Bucket(this.bucketSize);\n        }\n        if (this.buckets[k] == null) {\n            this.buckets[k] = new Bucket(this.bucketSize);\n        }\n        if (this.buckets[j].add(fingerprint) || this.buckets[k].add(fingerprint)) {\n            this.count++;\n            return true;\n        }\n        const rand = [j, k];\n        let i = rand[getRandomInt(0, rand.length - 1)];\n        if (this.buckets[i] == null) {\n            this.buckets[i] = new Bucket(this.bucketSize);\n        }\n        for (let n = 0; n < maxCuckooCount; n++) {\n            const swapped = this.buckets[i].swap(fingerprint);\n            if (swapped == null) {\n                continue;\n            }\n            i = (i ^ swapped.hash()) % this.filterSize;\n            if (this.buckets[i] == null) {\n                this.buckets[i] = new Bucket(this.bucketSize);\n            }\n            if (this.buckets[i].add(swapped)) {\n                this.count++;\n                return true;\n            }\n            else {\n                continue;\n            }\n        }\n        return false;\n    }\n    has(item) {\n        if (typeof item === 'string') {\n            item = uint8ArrayFromString(item);\n        }\n        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);\n        const j = this.hash.hash(item, this.seed) % this.filterSize;\n        const inJ = this.buckets[j]?.has(fingerprint) ?? false;\n        if (inJ) {\n            return inJ;\n        }\n        const k = (j ^ fingerprint.hash()) % this.filterSize;\n        return this.buckets[k]?.has(fingerprint) ?? false;\n    }\n    remove(item) {\n        if (typeof item === 'string') {\n            item = uint8ArrayFromString(item);\n        }\n        const fingerprint = new Fingerprint(item, this.hash, this.seed, this.fingerprintSize);\n        const j = this.hash.hash(item, this.seed) % this.filterSize;\n        const inJ = this.buckets[j]?.remove(fingerprint) ?? false;\n        if (inJ) {\n            this.count--;\n            return inJ;\n        }\n        const k = (j ^ fingerprint.hash()) % this.filterSize;\n        const inK = this.buckets[k]?.remove(fingerprint) ?? false;\n        if (inK) {\n            this.count--;\n        }\n        return inK;\n    }\n    get reliable() {\n        return Math.floor(100 * (this.count / this.filterSize)) <= 90;\n    }\n}\n// max load constants, defined in the cuckoo paper\nconst MAX_LOAD = {\n    1: 0.5,\n    2: 0.84,\n    4: 0.95,\n    8: 0.98\n};\nfunction calculateBucketSize(errorRate = 0.001) {\n    if (errorRate > 0.002) {\n        return 2;\n    }\n    if (errorRate > 0.00001) {\n        return 4;\n    }\n    return 8;\n}\nexport function optimize(maxItems, errorRate = 0.001) {\n    // https://www.eecs.harvard.edu/~michaelm/postscripts/cuckoo-conext2014.pdf\n    // Section 5.1 Optimal Bucket Size\n    const bucketSize = calculateBucketSize(errorRate);\n    const load = MAX_LOAD[bucketSize];\n    // https://stackoverflow.com/questions/57555236/how-to-size-a-cuckoo-filter/57617208#57617208\n    const filterSize = Math.round(maxItems / load);\n    const fingerprintSize = Math.min(Math.ceil(Math.log2(1 / errorRate) + Math.log2(2 * bucketSize)), MAX_FINGERPRINT_SIZE);\n    return {\n        filterSize,\n        bucketSize,\n        fingerprintSize\n    };\n}\nexport function createCuckooFilter(maxItems, errorRate = 0.005) {\n    const opts = optimize(maxItems, errorRate);\n    return new CuckooFilter(opts);\n}\n//# sourceMappingURL=cuckoo-filter.js.map","import { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { CuckooFilter, optimize } from './cuckoo-filter.js';\nimport { fnv1a } from './hashes.js';\nimport { getRandomInt } from './utils.js';\nexport class ScalableCuckooFilter {\n    filterSize;\n    bucketSize;\n    fingerprintSize;\n    scale;\n    filterSeries;\n    hash;\n    seed;\n    constructor(init) {\n        this.bucketSize = init.bucketSize ?? 4;\n        this.filterSize = init.filterSize ?? (1 << 18) / this.bucketSize;\n        this.fingerprintSize = init.fingerprintSize ?? 2;\n        this.scale = init.scale ?? 2;\n        this.hash = init.hash ?? fnv1a;\n        this.seed = init.seed ?? getRandomInt(0, Math.pow(2, 10));\n        this.filterSeries = [\n            new CuckooFilter({\n                filterSize: this.filterSize,\n                bucketSize: this.bucketSize,\n                fingerprintSize: this.fingerprintSize,\n                hash: this.hash,\n                seed: this.seed\n            })\n        ];\n    }\n    add(item) {\n        if (typeof item === 'string') {\n            item = uint8ArrayFromString(item);\n        }\n        if (this.has(item)) {\n            return true;\n        }\n        let current = this.filterSeries.find((cuckoo) => {\n            return cuckoo.reliable;\n        });\n        if (current == null) {\n            const curSize = this.filterSize * Math.pow(this.scale, this.filterSeries.length);\n            current = new CuckooFilter({\n                filterSize: curSize,\n                bucketSize: this.bucketSize,\n                fingerprintSize: this.fingerprintSize,\n                hash: this.hash,\n                seed: this.seed\n            });\n            this.filterSeries.push(current);\n        }\n        return current.add(item);\n    }\n    has(item) {\n        if (typeof item === 'string') {\n            item = uint8ArrayFromString(item);\n        }\n        for (let i = 0; i < this.filterSeries.length; i++) {\n            if (this.filterSeries[i].has(item)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    remove(item) {\n        if (typeof item === 'string') {\n            item = uint8ArrayFromString(item);\n        }\n        for (let i = 0; i < this.filterSeries.length; i++) {\n            if (this.filterSeries[i].remove(item)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    get count() {\n        return this.filterSeries.reduce((acc, curr) => {\n            return acc + curr.count;\n        }, 0);\n    }\n}\nexport function createScalableCuckooFilter(maxItems, errorRate = 0.001, options) {\n    return new ScalableCuckooFilter({\n        ...optimize(maxItems, errorRate),\n        ...(options ?? {})\n    });\n}\n//# sourceMappingURL=scalable-cuckoo-filter.js.map","/**\n * When this error is thrown it means an operation was aborted,\n * usually in response to the `abort` event being emitted by an\n * AbortSignal.\n */\nexport class AbortError extends Error {\n    static name = 'AbortError';\n    constructor(message = 'The operation was aborted') {\n        super(message);\n        this.name = 'AbortError';\n    }\n}\n/**\n * Thrown when a remote Peer ID does not match the expected one\n */\nexport class UnexpectedPeerError extends Error {\n    static name = 'UnexpectedPeerError';\n    constructor(message = 'Unexpected Peer') {\n        super(message);\n        this.name = 'UnexpectedPeerError';\n    }\n}\n/**\n * Thrown when a crypto exchange fails\n */\nexport class InvalidCryptoExchangeError extends Error {\n    static name = 'InvalidCryptoExchangeError';\n    constructor(message = 'Invalid crypto exchange') {\n        super(message);\n        this.name = 'InvalidCryptoExchangeError';\n    }\n}\n/**\n * Thrown when invalid parameters are passed to a function or method call\n */\nexport class InvalidParametersError extends Error {\n    static name = 'InvalidParametersError';\n    constructor(message = 'Invalid parameters') {\n        super(message);\n        this.name = 'InvalidParametersError';\n    }\n}\n/**\n * Thrown when a public key is invalid\n */\nexport class InvalidPublicKeyError extends Error {\n    static name = 'InvalidPublicKeyError';\n    constructor(message = 'Invalid public key') {\n        super(message);\n        this.name = 'InvalidPublicKeyError';\n    }\n}\n/**\n * Thrown when a private key is invalid\n */\nexport class InvalidPrivateKeyError extends Error {\n    static name = 'InvalidPrivateKeyError';\n    constructor(message = 'Invalid private key') {\n        super(message);\n        this.name = 'InvalidPrivateKeyError';\n    }\n}\n/**\n * Thrown when a operation is unsupported\n */\nexport class UnsupportedOperationError extends Error {\n    static name = 'UnsupportedOperationError';\n    constructor(message = 'Unsupported operation') {\n        super(message);\n        this.name = 'UnsupportedOperationError';\n    }\n}\n/**\n * Thrown when a connection is closing\n */\nexport class ConnectionClosingError extends Error {\n    static name = 'ConnectionClosingError';\n    constructor(message = 'The connection is closing') {\n        super(message);\n        this.name = 'ConnectionClosingError';\n    }\n}\n/**\n * Thrown when a connection is closed\n */\nexport class ConnectionClosedError extends Error {\n    static name = 'ConnectionClosedError';\n    constructor(message = 'The connection is closed') {\n        super(message);\n        this.name = 'ConnectionClosedError';\n    }\n}\n/**\n * Thrown when a connection fails\n */\nexport class ConnectionFailedError extends Error {\n    static name = 'ConnectionFailedError';\n    constructor(message = 'Connection failed') {\n        super(message);\n        this.name = 'ConnectionFailedError';\n    }\n}\n/**\n * Thrown when the muxer is closed and an attempt to open a stream occurs\n */\nexport class MuxerClosedError extends Error {\n    static name = 'MuxerClosedError';\n    constructor(message = 'The muxer is closed') {\n        super(message);\n        this.name = 'MuxerClosedError';\n    }\n}\n/**\n * Thrown when a protocol stream is reset by the remote muxer\n */\nexport class StreamResetError extends Error {\n    static name = 'StreamResetError';\n    constructor(message = 'The stream has been reset') {\n        super(message);\n        this.name = 'StreamResetError';\n    }\n}\n/**\n * Thrown when a stream is in an invalid state\n */\nexport class StreamStateError extends Error {\n    static name = 'StreamStateError';\n    constructor(message = 'The stream is in an invalid state') {\n        super(message);\n        this.name = 'StreamStateError';\n    }\n}\n/**\n * Thrown when a value could not be found\n */\nexport class NotFoundError extends Error {\n    static name = 'NotFoundError';\n    constructor(message = 'Not found') {\n        super(message);\n        this.name = 'NotFoundError';\n    }\n}\n/**\n * Thrown when an invalid peer ID is encountered\n */\nexport class InvalidPeerIdError extends Error {\n    static name = 'InvalidPeerIdError';\n    constructor(message = 'Invalid PeerID') {\n        super(message);\n        this.name = 'InvalidPeerIdError';\n    }\n}\n/**\n * Thrown when an invalid multiaddr is encountered\n */\nexport class InvalidMultiaddrError extends Error {\n    static name = 'InvalidMultiaddrError';\n    constructor(message = 'Invalid multiaddr') {\n        super(message);\n        this.name = 'InvalidMultiaddrError';\n    }\n}\n/**\n * Thrown when an invalid CID is encountered\n */\nexport class InvalidCIDError extends Error {\n    static name = 'InvalidCIDError';\n    constructor(message = 'Invalid CID') {\n        super(message);\n        this.name = 'InvalidCIDError';\n    }\n}\n/**\n * Thrown when an invalid multihash is encountered\n */\nexport class InvalidMultihashError extends Error {\n    static name = 'InvalidMultihashError';\n    constructor(message = 'Invalid Multihash') {\n        super(message);\n        this.name = 'InvalidMultihashError';\n    }\n}\n/**\n * Thrown when a protocol is not supported\n */\nexport class UnsupportedProtocolError extends Error {\n    static name = 'UnsupportedProtocolError';\n    constructor(message = 'Unsupported protocol error') {\n        super(message);\n        this.name = 'UnsupportedProtocolError';\n    }\n}\n/**\n * An invalid or malformed message was encountered during a protocol exchange\n */\nexport class InvalidMessageError extends Error {\n    static name = 'InvalidMessageError';\n    constructor(message = 'Invalid message') {\n        super(message);\n        this.name = 'InvalidMessageError';\n    }\n}\n/**\n * Thrown when a remote peer sends a structurally valid message that does not\n * comply with the protocol\n */\nexport class ProtocolError extends Error {\n    static name = 'ProtocolError';\n    constructor(message = 'Protocol error') {\n        super(message);\n        this.name = 'ProtocolError';\n    }\n}\n/**\n * Throw when an operation times out\n */\nexport class TimeoutError extends Error {\n    static name = 'TimeoutError';\n    constructor(message = 'Timed out') {\n        super(message);\n        this.name = 'TimeoutError';\n    }\n}\n/**\n * Thrown when a startable component is interacted with but it has not been\n * started yet\n */\nexport class NotStartedError extends Error {\n    static name = 'NotStartedError';\n    constructor(message = 'Not started') {\n        super(message);\n        this.name = 'NotStartedError';\n    }\n}\n/**\n * Thrown when a component is started that has already been started\n */\nexport class AlreadyStartedError extends Error {\n    static name = 'AlreadyStartedError';\n    constructor(message = 'Already started') {\n        super(message);\n        this.name = 'AlreadyStartedError';\n    }\n}\n/**\n * Thrown when dialing an address failed\n */\nexport class DialError extends Error {\n    static name = 'DialError';\n    constructor(message = 'Dial error') {\n        super(message);\n        this.name = 'DialError';\n    }\n}\n/**\n * Thrown when listening on an address failed\n */\nexport class ListenError extends Error {\n    static name = 'ListenError';\n    constructor(message = 'Listen error') {\n        super(message);\n        this.name = 'ListenError';\n    }\n}\n/**\n * This error is thrown when a limited connection is encountered, i.e. if the\n * user tried to open a stream on a connection for a protocol that is not\n * configured to run over limited connections.\n */\nexport class LimitedConnectionError extends Error {\n    static name = 'LimitedConnectionError';\n    constructor(message = 'Limited connection') {\n        super(message);\n        this.name = 'LimitedConnectionError';\n    }\n}\n/**\n * This error is thrown where there are too many inbound protocols streams open\n */\nexport class TooManyInboundProtocolStreamsError extends Error {\n    static name = 'TooManyInboundProtocolStreamsError';\n    constructor(message = 'Too many inbound protocol streams') {\n        super(message);\n        this.name = 'TooManyInboundProtocolStreamsError';\n    }\n}\n/**\n * This error is thrown where there are too many outbound protocols streams open\n */\nexport class TooManyOutboundProtocolStreamsError extends Error {\n    static name = 'TooManyOutboundProtocolStreamsError';\n    constructor(message = 'Too many outbound protocol streams') {\n        super(message);\n        this.name = 'TooManyOutboundProtocolStreamsError';\n    }\n}\n/**\n * Thrown when and attempt to operate on an unsupported key was made\n */\nexport class UnsupportedKeyTypeError extends Error {\n    static name = 'UnsupportedKeyTypeError';\n    constructor(message = 'Unsupported key type') {\n        super(message);\n        this.name = 'UnsupportedKeyTypeError';\n    }\n}\n//# sourceMappingURL=errors.js.map","export default function pDefer() {\n\tconst deferred = {};\n\n\tdeferred.promise = new Promise((resolve, reject) => {\n\t\tdeferred.resolve = resolve;\n\t\tdeferred.reject = reject;\n\t});\n\n\treturn deferred;\n}\n","// ported from https://www.npmjs.com/package/fast-fifo\nclass FixedFIFO {\n    buffer;\n    mask;\n    top;\n    btm;\n    next;\n    constructor(hwm) {\n        if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) {\n            throw new Error('Max size for a FixedFIFO should be a power of two');\n        }\n        this.buffer = new Array(hwm);\n        this.mask = hwm - 1;\n        this.top = 0;\n        this.btm = 0;\n        this.next = null;\n    }\n    push(data) {\n        if (this.buffer[this.top] !== undefined) {\n            return false;\n        }\n        this.buffer[this.top] = data;\n        this.top = (this.top + 1) & this.mask;\n        return true;\n    }\n    shift() {\n        const last = this.buffer[this.btm];\n        if (last === undefined) {\n            return undefined;\n        }\n        this.buffer[this.btm] = undefined;\n        this.btm = (this.btm + 1) & this.mask;\n        return last;\n    }\n    isEmpty() {\n        return this.buffer[this.btm] === undefined;\n    }\n}\nexport class FIFO {\n    size;\n    hwm;\n    head;\n    tail;\n    constructor(options = {}) {\n        this.hwm = options.splitLimit ?? 16;\n        this.head = new FixedFIFO(this.hwm);\n        this.tail = this.head;\n        this.size = 0;\n    }\n    calculateSize(obj) {\n        if (obj?.byteLength != null) {\n            return obj.byteLength;\n        }\n        return 1;\n    }\n    push(val) {\n        if (val?.value != null) {\n            this.size += this.calculateSize(val.value);\n        }\n        if (!this.head.push(val)) {\n            const prev = this.head;\n            this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length);\n            this.head.push(val);\n        }\n    }\n    shift() {\n        let val = this.tail.shift();\n        if (val === undefined && (this.tail.next != null)) {\n            const next = this.tail.next;\n            this.tail.next = null;\n            this.tail = next;\n            val = this.tail.shift();\n        }\n        if (val?.value != null) {\n            this.size -= this.calculateSize(val.value);\n        }\n        return val;\n    }\n    isEmpty() {\n        return this.head.isEmpty();\n    }\n}\n//# sourceMappingURL=fifo.js.map","/**\n * @packageDocumentation\n *\n * An iterable that you can push values into.\n *\n * @example\n *\n * ```js\n * import { pushable } from 'it-pushable'\n *\n * const source = pushable()\n *\n * setTimeout(() => source.push('hello'), 100)\n * setTimeout(() => source.push('world'), 200)\n * setTimeout(() => source.end(), 300)\n *\n * const start = Date.now()\n *\n * for await (const value of source) {\n *   console.log(`got \"${value}\" after ${Date.now() - start}ms`)\n * }\n * console.log(`done after ${Date.now() - start}ms`)\n *\n * // Output:\n * // got \"hello\" after 105ms\n * // got \"world\" after 207ms\n * // done after 309ms\n * ```\n *\n * @example\n *\n * ```js\n * import { pushableV } from 'it-pushable'\n * import all from 'it-all'\n *\n * const source = pushableV()\n *\n * source.push(1)\n * source.push(2)\n * source.push(3)\n * source.end()\n *\n * console.info(await all(source))\n *\n * // Output:\n * // [ [1, 2, 3] ]\n * ```\n */\nimport deferred from 'p-defer';\nimport { FIFO } from './fifo.js';\nexport class AbortError extends Error {\n    type;\n    code;\n    constructor(message, code) {\n        super(message ?? 'The operation was aborted');\n        this.type = 'aborted';\n        this.code = code ?? 'ABORT_ERR';\n    }\n}\nexport function pushable(options = {}) {\n    const getNext = (buffer) => {\n        const next = buffer.shift();\n        if (next == null) {\n            return { done: true };\n        }\n        if (next.error != null) {\n            throw next.error;\n        }\n        return {\n            done: next.done === true,\n            // @ts-expect-error if done is false, value will be present\n            value: next.value\n        };\n    };\n    return _pushable(getNext, options);\n}\nexport function pushableV(options = {}) {\n    const getNext = (buffer) => {\n        let next;\n        const values = [];\n        while (!buffer.isEmpty()) {\n            next = buffer.shift();\n            if (next == null) {\n                break;\n            }\n            if (next.error != null) {\n                throw next.error;\n            }\n            if (next.done === false) {\n                // @ts-expect-error if done is false value should be pushed\n                values.push(next.value);\n            }\n        }\n        if (next == null) {\n            return { done: true };\n        }\n        return {\n            done: next.done === true,\n            value: values\n        };\n    };\n    return _pushable(getNext, options);\n}\nfunction _pushable(getNext, options) {\n    options = options ?? {};\n    let onEnd = options.onEnd;\n    let buffer = new FIFO();\n    let pushable;\n    let onNext;\n    let ended;\n    let drain = deferred();\n    const waitNext = async () => {\n        try {\n            if (!buffer.isEmpty()) {\n                return getNext(buffer);\n            }\n            if (ended) {\n                return { done: true };\n            }\n            return await new Promise((resolve, reject) => {\n                onNext = (next) => {\n                    onNext = null;\n                    buffer.push(next);\n                    try {\n                        resolve(getNext(buffer));\n                    }\n                    catch (err) {\n                        reject(err);\n                    }\n                    return pushable;\n                };\n            });\n        }\n        finally {\n            if (buffer.isEmpty()) {\n                // settle promise in the microtask queue to give consumers a chance to\n                // await after calling .push\n                queueMicrotask(() => {\n                    drain.resolve();\n                    drain = deferred();\n                });\n            }\n        }\n    };\n    const bufferNext = (next) => {\n        if (onNext != null) {\n            return onNext(next);\n        }\n        buffer.push(next);\n        return pushable;\n    };\n    const bufferError = (err) => {\n        buffer = new FIFO();\n        if (onNext != null) {\n            return onNext({ error: err });\n        }\n        buffer.push({ error: err });\n        return pushable;\n    };\n    const push = (value) => {\n        if (ended) {\n            return pushable;\n        }\n        // @ts-expect-error `byteLength` is not declared on PushType\n        if (options?.objectMode !== true && value?.byteLength == null) {\n            throw new Error('objectMode was not true but tried to push non-Uint8Array value');\n        }\n        return bufferNext({ done: false, value });\n    };\n    const end = (err) => {\n        if (ended)\n            return pushable;\n        ended = true;\n        return (err != null) ? bufferError(err) : bufferNext({ done: true });\n    };\n    const _return = () => {\n        buffer = new FIFO();\n        end();\n        return { done: true };\n    };\n    const _throw = (err) => {\n        end(err);\n        return { done: true };\n    };\n    pushable = {\n        [Symbol.asyncIterator]() { return this; },\n        next: waitNext,\n        return: _return,\n        throw: _throw,\n        push,\n        end,\n        get readableLength() {\n            return buffer.size;\n        },\n        onEmpty: async (options) => {\n            const signal = options?.signal;\n            signal?.throwIfAborted();\n            if (buffer.isEmpty()) {\n                return;\n            }\n            let cancel;\n            let listener;\n            if (signal != null) {\n                cancel = new Promise((resolve, reject) => {\n                    listener = () => {\n                        reject(new AbortError());\n                    };\n                    signal.addEventListener('abort', listener);\n                });\n            }\n            try {\n                await Promise.race([\n                    drain.promise,\n                    cancel\n                ]);\n            }\n            finally {\n                if (listener != null && signal != null) {\n                    signal?.removeEventListener('abort', listener);\n                }\n            }\n        }\n    };\n    if (onEnd == null) {\n        return pushable;\n    }\n    const _pushable = pushable;\n    pushable = {\n        [Symbol.asyncIterator]() { return this; },\n        next() {\n            return _pushable.next();\n        },\n        throw(err) {\n            _pushable.throw(err);\n            if (onEnd != null) {\n                onEnd(err);\n                onEnd = undefined;\n            }\n            return { done: true };\n        },\n        return() {\n            _pushable.return();\n            if (onEnd != null) {\n                onEnd();\n                onEnd = undefined;\n            }\n            return { done: true };\n        },\n        push,\n        end(err) {\n            _pushable.end(err);\n            if (onEnd != null) {\n                onEnd(err);\n                onEnd = undefined;\n            }\n            return pushable;\n        },\n        get readableLength() {\n            return _pushable.readableLength;\n        },\n        onEmpty: (opts) => {\n            return _pushable.onEmpty(opts);\n        }\n    };\n    return pushable;\n}\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Race an event against an AbortSignal, taking care to remove any event\n * listeners that were added.\n *\n * @example Getting started\n *\n * ```TypeScript\n * import { raceEvent } from 'race-event'\n *\n * const controller = new AbortController()\n * const emitter = new EventTarget()\n *\n * setTimeout(() => {\n *   controller.abort()\n * }, 500)\n *\n * setTimeout(() => {\n *   // too late\n *   emitter.dispatchEvent(new CustomEvent('event'))\n * }, 1000)\n *\n * // throws an AbortError\n * const resolve = await raceEvent(emitter, 'event', controller.signal)\n * ```\n *\n * @example Aborting the promise with an error event\n *\n * ```TypeScript\n * import { raceEvent } from 'race-event'\n *\n * const emitter = new EventTarget()\n *\n * setTimeout(() => {\n *   emitter.dispatchEvent(new CustomEvent('failure', {\n *     detail: new Error('Oh no!')\n *   }))\n * }, 1000)\n *\n * // throws 'Oh no!' error\n * const resolve = await raceEvent(emitter, 'success', AbortSignal.timeout(5000), {\n *   errorEvent: 'failure'\n * })\n * ```\n *\n * @example Customising the thrown AbortError\n *\n * The error message and `.code` property of the thrown `AbortError` can be\n * specified by passing options:\n *\n * ```TypeScript\n * import { raceEvent } from 'race-event'\n *\n * const controller = new AbortController()\n * const emitter = new EventTarget()\n *\n * setTimeout(() => {\n *   controller.abort()\n * }, 500)\n *\n * // throws a Error: Oh no!\n * const resolve = await raceEvent(emitter, 'event', controller.signal, {\n *   errorMessage: 'Oh no!',\n *   errorCode: 'ERR_OH_NO'\n * })\n * ```\n *\n * @example Only resolving on specific events\n *\n * Where multiple events with the same type are emitted, a `filter` function can\n * be passed to only resolve on one of them:\n *\n * ```TypeScript\n * import { raceEvent } from 'race-event'\n *\n * const controller = new AbortController()\n * const emitter = new EventTarget()\n *\n * // throws a Error: Oh no!\n * const resolve = await raceEvent(emitter, 'event', controller.signal, {\n *   filter: (evt: Event) => {\n *     return evt.detail.foo === 'bar'\n *   }\n * })\n * ```\n *\n * @example Terminating early by throwing from the filter\n *\n * You can cause listening for the event to cease and all event listeners to be\n * removed by throwing from the filter:\n *\n * ```TypeScript\n * import { raceEvent } from 'race-event'\n *\n * const controller = new AbortController()\n * const emitter = new EventTarget()\n *\n * // throws Error: Cannot continue\n * const resolve = await raceEvent(emitter, 'event', controller.signal, {\n *   filter: (evt) => {\n *     if (...reasons) {\n *       throw new Error('Cannot continue')\n *     }\n *\n *     return true\n *   }\n * })\n * ```\n */\n/**\n * An abort error class that extends error\n */\nexport class AbortError extends Error {\n    type;\n    code;\n    constructor(message, code) {\n        super(message ?? 'The operation was aborted');\n        this.type = 'aborted';\n        this.name = 'AbortError';\n        this.code = code ?? 'ABORT_ERR';\n    }\n}\n/**\n * Race a promise against an abort signal\n */\nexport async function raceEvent(emitter, eventName, signal, opts) {\n    // create the error here so we have more context in the stack trace\n    const error = new AbortError(opts?.errorMessage, opts?.errorCode);\n    if (signal?.aborted === true) {\n        return Promise.reject(error);\n    }\n    return new Promise((resolve, reject) => {\n        function removeListeners() {\n            signal?.removeEventListener('abort', abortListener);\n            emitter.removeEventListener(eventName, eventListener);\n            if (opts?.errorEvent != null) {\n                emitter.removeEventListener(opts.errorEvent, errorEventListener);\n            }\n        }\n        const eventListener = (evt) => {\n            try {\n                if (opts?.filter?.(evt) === false) {\n                    return;\n                }\n            }\n            catch (err) {\n                removeListeners();\n                reject(err);\n                return;\n            }\n            removeListeners();\n            resolve(evt);\n        };\n        const errorEventListener = (evt) => {\n            removeListeners();\n            reject(evt.detail);\n        };\n        const abortListener = () => {\n            removeListeners();\n            reject(error);\n        };\n        signal?.addEventListener('abort', abortListener);\n        emitter.addEventListener(eventName, eventListener);\n        if (opts?.errorEvent != null) {\n            emitter.addEventListener(opts.errorEvent, errorEventListener);\n        }\n    });\n}\n//# sourceMappingURL=index.js.map","/**\n * A rate limit was hit\n */\nexport class RateLimitError extends Error {\n    remainingPoints;\n    msBeforeNext;\n    consumedPoints;\n    isFirstInDuration;\n    constructor(message = 'Rate limit exceeded', props) {\n        super(message);\n        this.name = 'RateLimitError';\n        this.remainingPoints = props.remainingPoints;\n        this.msBeforeNext = props.msBeforeNext;\n        this.consumedPoints = props.consumedPoints;\n        this.isFirstInDuration = props.isFirstInDuration;\n    }\n}\nexport class QueueFullError extends Error {\n    static name = 'QueueFullError';\n    constructor(message = 'The queue was full') {\n        super(message);\n        this.name = 'QueueFullError';\n    }\n}\n//# sourceMappingURL=errors.js.map","/**\n * An abort error class that extends error\n */\nexport class AbortError extends Error {\n    type;\n    code;\n    constructor(message, code, name) {\n        super(message ?? 'The operation was aborted');\n        this.type = 'aborted';\n        this.name = name ?? 'AbortError';\n        this.code = code ?? 'ABORT_ERR';\n    }\n}\n/**\n * Race a promise against an abort signal\n */\nexport async function raceSignal(promise, signal, opts) {\n    if (signal == null) {\n        return promise;\n    }\n    if (signal.aborted) {\n        return Promise.reject(new AbortError(opts?.errorMessage, opts?.errorCode, opts?.errorName));\n    }\n    let listener;\n    // create the error here so we have more context in the stack trace\n    const error = new AbortError(opts?.errorMessage, opts?.errorCode, opts?.errorName);\n    try {\n        return await Promise.race([\n            promise,\n            new Promise((resolve, reject) => {\n                listener = () => {\n                    reject(error);\n                };\n                signal.addEventListener('abort', listener);\n            })\n        ]);\n    }\n    finally {\n        if (listener != null) {\n            signal.removeEventListener('abort', listener);\n        }\n    }\n}\n//# sourceMappingURL=index.js.map","import { AbortError } from '@libp2p/interface';\nimport pDefer from 'p-defer';\nexport class JobRecipient {\n    deferred;\n    signal;\n    constructor(signal) {\n        this.signal = signal;\n        this.deferred = pDefer();\n        this.onAbort = this.onAbort.bind(this);\n        this.signal?.addEventListener('abort', this.onAbort);\n    }\n    onAbort() {\n        this.deferred.reject(this.signal?.reason ?? new AbortError());\n    }\n    cleanup() {\n        this.signal?.removeEventListener('abort', this.onAbort);\n    }\n}\n//# sourceMappingURL=recipient.js.map","import { AbortError, setMaxListeners } from '@libp2p/interface';\nimport { raceSignal } from 'race-signal';\nimport { JobRecipient } from './recipient.js';\n/**\n * Returns a random string\n */\nfunction randomId() {\n    return `${(parseInt(String(Math.random() * 1e9), 10)).toString()}${Date.now()}`;\n}\nexport class Job {\n    id;\n    fn;\n    options;\n    recipients;\n    status;\n    timeline;\n    controller;\n    constructor(fn, options) {\n        this.id = randomId();\n        this.status = 'queued';\n        this.fn = fn;\n        this.options = options;\n        this.recipients = [];\n        this.timeline = {\n            created: Date.now()\n        };\n        this.controller = new AbortController();\n        setMaxListeners(Infinity, this.controller.signal);\n        this.onAbort = this.onAbort.bind(this);\n    }\n    abort(err) {\n        this.controller.abort(err);\n    }\n    onAbort() {\n        const allAborted = this.recipients.reduce((acc, curr) => {\n            return acc && (curr.signal?.aborted === true);\n        }, true);\n        // if all recipients have aborted the job, actually abort the job\n        if (allAborted) {\n            this.controller.abort(new AbortError());\n            this.cleanup();\n        }\n    }\n    async join(options = {}) {\n        const recipient = new JobRecipient(options.signal);\n        this.recipients.push(recipient);\n        options.signal?.addEventListener('abort', this.onAbort);\n        return recipient.deferred.promise;\n    }\n    async run() {\n        this.status = 'running';\n        this.timeline.started = Date.now();\n        try {\n            this.controller.signal.throwIfAborted();\n            const result = await raceSignal(this.fn({\n                ...(this.options ?? {}),\n                signal: this.controller.signal\n            }), this.controller.signal);\n            this.recipients.forEach(recipient => {\n                recipient.deferred.resolve(result);\n            });\n            this.status = 'complete';\n        }\n        catch (err) {\n            this.recipients.forEach(recipient => {\n                recipient.deferred.reject(err);\n            });\n            this.status = 'errored';\n        }\n        finally {\n            this.timeline.finished = Date.now();\n            this.cleanup();\n        }\n    }\n    cleanup() {\n        this.recipients.forEach(recipient => {\n            recipient.cleanup();\n            recipient.signal?.removeEventListener('abort', this.onAbort);\n        });\n    }\n}\n//# sourceMappingURL=job.js.map","import { AbortError, TypedEventEmitter } from '@libp2p/interface';\nimport { pushable } from 'it-pushable';\nimport { raceEvent } from 'race-event';\nimport { QueueFullError } from '../errors.js';\nimport { Job } from './job.js';\n/**\n * Heavily influence by `p-queue` with the following differences:\n *\n * 1. Items remain at the head of the queue while they are running so `queue.size` includes `queue.pending` items - this is so interested parties can join the results of a queue item while it is running\n * 2. The options for a job are stored separately to the job in order for them to be modified while they are still in the queue\n */\nexport class Queue extends TypedEventEmitter {\n    concurrency;\n    maxSize;\n    queue;\n    pending;\n    sort;\n    constructor(init = {}) {\n        super();\n        this.concurrency = init.concurrency ?? Number.POSITIVE_INFINITY;\n        this.maxSize = init.maxSize ?? Number.POSITIVE_INFINITY;\n        this.pending = 0;\n        if (init.metricName != null) {\n            init.metrics?.registerMetricGroup(init.metricName, {\n                calculate: () => {\n                    return {\n                        size: this.queue.length,\n                        running: this.pending,\n                        queued: this.queue.length - this.pending\n                    };\n                }\n            });\n        }\n        this.sort = init.sort;\n        this.queue = [];\n    }\n    tryToStartAnother() {\n        if (this.size === 0) {\n            // do this in the microtask queue so all job recipients receive the\n            // result before the \"empty\" event fires\n            queueMicrotask(() => {\n                this.safeDispatchEvent('empty');\n            });\n            if (this.running === 0) {\n                // do this in the microtask queue so all job recipients receive the\n                // result before the \"idle\" event fires\n                queueMicrotask(() => {\n                    this.safeDispatchEvent('idle');\n                });\n            }\n            return false;\n        }\n        if (this.pending < this.concurrency) {\n            let job;\n            for (const j of this.queue) {\n                if (j.status === 'queued') {\n                    job = j;\n                    break;\n                }\n            }\n            if (job == null) {\n                return false;\n            }\n            this.safeDispatchEvent('active');\n            this.pending++;\n            void job.run()\n                .finally(() => {\n                // remove the job from the queue\n                for (let i = 0; i < this.queue.length; i++) {\n                    if (this.queue[i] === job) {\n                        this.queue.splice(i, 1);\n                        break;\n                    }\n                }\n                this.pending--;\n                this.tryToStartAnother();\n                this.safeDispatchEvent('next');\n            });\n            return true;\n        }\n        return false;\n    }\n    enqueue(job) {\n        this.queue.push(job);\n        if (this.sort != null) {\n            this.queue.sort(this.sort);\n        }\n    }\n    /**\n     * Adds a sync or async task to the queue. Always returns a promise.\n     */\n    async add(fn, options) {\n        options?.signal?.throwIfAborted();\n        if (this.size === this.maxSize) {\n            throw new QueueFullError();\n        }\n        const job = new Job(fn, options);\n        this.enqueue(job);\n        this.safeDispatchEvent('add');\n        this.tryToStartAnother();\n        return job.join(options)\n            .then(result => {\n            this.safeDispatchEvent('completed', { detail: result });\n            this.safeDispatchEvent('success', { detail: { job, result } });\n            return result;\n        })\n            .catch(err => {\n            if (job.status === 'queued') {\n                // job was aborted before it started - remove the job from the queue\n                for (let i = 0; i < this.queue.length; i++) {\n                    if (this.queue[i] === job) {\n                        this.queue.splice(i, 1);\n                        break;\n                    }\n                }\n            }\n            this.safeDispatchEvent('error', { detail: err });\n            this.safeDispatchEvent('failure', { detail: { job, error: err } });\n            throw err;\n        });\n    }\n    /**\n     * Clear the queue\n     */\n    clear() {\n        this.queue.splice(0, this.queue.length);\n    }\n    /**\n     * Abort all jobs in the queue and clear it\n     */\n    abort() {\n        this.queue.forEach(job => {\n            job.abort(new AbortError());\n        });\n        this.clear();\n    }\n    /**\n     * Can be called multiple times. Useful if you for example add additional items at a later time.\n     *\n     * @returns A promise that settles when the queue becomes empty.\n     */\n    async onEmpty(options) {\n        // Instantly resolve if the queue is empty\n        if (this.size === 0) {\n            return;\n        }\n        await raceEvent(this, 'empty', options?.signal);\n    }\n    /**\n     * @returns A promise that settles when the queue size is less than the given\n     * limit: `queue.size < limit`.\n     *\n     * If you want to avoid having the queue grow beyond a certain size you can\n     * `await queue.onSizeLessThan()` before adding a new item.\n     *\n     * Note that this only limits the number of items waiting to start. There\n     * could still be up to `concurrency` jobs already running that this call does\n     * not include in its calculation.\n     */\n    async onSizeLessThan(limit, options) {\n        // Instantly resolve if the queue is empty.\n        if (this.size < limit) {\n            return;\n        }\n        await raceEvent(this, 'next', options?.signal, {\n            filter: () => this.size < limit\n        });\n    }\n    /**\n     * The difference with `.onEmpty` is that `.onIdle` guarantees that all work\n     * from the queue has finished. `.onEmpty` merely signals that the queue is\n     * empty, but it could mean that some promises haven't completed yet.\n     *\n     * @returns A promise that settles when the queue becomes empty, and all\n     * promises have completed; `queue.size === 0 && queue.pending === 0`.\n     */\n    async onIdle(options) {\n        // Instantly resolve if none pending and if nothing else is queued\n        if (this.pending === 0 && this.size === 0) {\n            return;\n        }\n        await raceEvent(this, 'idle', options?.signal);\n    }\n    /**\n     * Size of the queue including running items\n     */\n    get size() {\n        return this.queue.length;\n    }\n    /**\n     * The number of queued items waiting to run.\n     */\n    get queued() {\n        return this.queue.length - this.pending;\n    }\n    /**\n     * The number of items currently running.\n     */\n    get running() {\n        return this.pending;\n    }\n    /**\n     * Returns an async generator that makes it easy to iterate over the results\n     * of jobs added to the queue.\n     *\n     * The generator will end when the queue becomes idle, that is there are no\n     * jobs running and no jobs that have yet to run.\n     *\n     * If you need to keep the queue open indefinitely, consider using it-pushable\n     * instead.\n     */\n    async *toGenerator(options) {\n        options?.signal?.throwIfAborted();\n        const stream = pushable({\n            objectMode: true\n        });\n        const cleanup = (err) => {\n            if (err != null) {\n                this.abort();\n            }\n            else {\n                this.clear();\n            }\n            stream.end(err);\n        };\n        const onQueueJobComplete = (evt) => {\n            if (evt.detail != null) {\n                stream.push(evt.detail);\n            }\n        };\n        const onQueueError = (evt) => {\n            cleanup(evt.detail);\n        };\n        const onQueueIdle = () => {\n            cleanup();\n        };\n        // clear the queue and throw if the query is aborted\n        const onSignalAbort = () => {\n            cleanup(new AbortError('Queue aborted'));\n        };\n        // add listeners\n        this.addEventListener('completed', onQueueJobComplete);\n        this.addEventListener('error', onQueueError);\n        this.addEventListener('idle', onQueueIdle);\n        options?.signal?.addEventListener('abort', onSignalAbort);\n        try {\n            yield* stream;\n        }\n        finally {\n            // remove listeners\n            this.removeEventListener('completed', onQueueJobComplete);\n            this.removeEventListener('error', onQueueError);\n            this.removeEventListener('idle', onQueueIdle);\n            options?.signal?.removeEventListener('abort', onSignalAbort);\n            // empty the queue for when the user has broken out of a loop early\n            cleanup();\n        }\n    }\n}\n//# sourceMappingURL=index.js.map","import { DEFAULT_SESSION_MIN_PROVIDERS, DEFAULT_SESSION_MAX_PROVIDERS, InsufficientProvidersError } from '@helia/interface';\nimport { TypedEventEmitter, setMaxListeners } from '@libp2p/interface';\nimport { createScalableCuckooFilter } from '@libp2p/utils/filters';\nimport { Queue } from '@libp2p/utils/queue';\nimport { base64 } from 'multiformats/bases/base64';\nimport pDefer from 'p-defer';\nexport class AbstractSession extends TypedEventEmitter {\n    intialPeerSearchComplete;\n    requests;\n    name;\n    log;\n    logger;\n    minProviders;\n    maxProviders;\n    providers;\n    evictionFilter;\n    constructor(components, init) {\n        super();\n        setMaxListeners(Infinity, this);\n        this.name = init.name;\n        this.logger = components.logger;\n        this.log = components.logger.forComponent(this.name);\n        this.requests = new Map();\n        this.minProviders = init.minProviders ?? DEFAULT_SESSION_MIN_PROVIDERS;\n        this.maxProviders = init.maxProviders ?? DEFAULT_SESSION_MAX_PROVIDERS;\n        this.providers = [];\n        this.evictionFilter = createScalableCuckooFilter(this.maxProviders);\n    }\n    async retrieve(cid, options = {}) {\n        // see if we are already requesting this CID in this session\n        const cidStr = base64.encode(cid.multihash.bytes);\n        const existingJob = this.requests.get(cidStr);\n        if (existingJob != null) {\n            this.log('join existing request for %c', cid);\n            return existingJob;\n        }\n        const deferred = pDefer();\n        this.requests.set(cidStr, deferred.promise);\n        if (this.providers.length === 0) {\n            let first = false;\n            if (this.intialPeerSearchComplete == null) {\n                first = true;\n                this.log = this.logger.forComponent(`${this.name}:${cid}`);\n                this.intialPeerSearchComplete = this.findProviders(cid, this.minProviders, options);\n            }\n            await this.intialPeerSearchComplete;\n            if (first) {\n                this.log('found initial session peers for %c', cid);\n            }\n        }\n        let foundBlock = false;\n        // this queue manages outgoing requests - as new peers are added to the\n        // session they will be added to the queue so we can request the current\n        // block from multiple peers as they are discovered\n        const queue = new Queue({\n            concurrency: this.maxProviders\n        });\n        queue.addEventListener('error', () => { });\n        queue.addEventListener('failure', (evt) => {\n            this.log.error('error querying provider %o, evicting from session', evt.detail.job.options.provider, evt.detail.error);\n            this.evict(evt.detail.job.options.provider);\n        });\n        queue.addEventListener('success', (evt) => {\n            // peer has sent block, return it to the caller\n            foundBlock = true;\n            deferred.resolve(evt.detail.result);\n        });\n        queue.addEventListener('idle', () => {\n            if (foundBlock || options.signal?.aborted === true) {\n                // we either found the block or the user gave up\n                return;\n            }\n            // find more session peers and retry\n            Promise.resolve()\n                .then(async () => {\n                this.log('no session peers had block for for %c, finding new providers', cid);\n                // evict this.minProviders random providers to make room for more\n                for (let i = 0; i < this.minProviders; i++) {\n                    if (this.providers.length === 0) {\n                        break;\n                    }\n                    const provider = this.providers[Math.floor(Math.random() * this.providers.length)];\n                    this.evict(provider);\n                }\n                // find new providers for the CID\n                await this.findProviders(cid, this.minProviders, options);\n                // keep trying until the abort signal fires\n                this.log('found new providers re-retrieving %c', cid);\n                this.requests.delete(cidStr);\n                deferred.resolve(await this.retrieve(cid, options));\n            })\n                .catch(err => {\n                this.log.error('could not find new providers for %c', cid, err);\n                deferred.reject(err);\n            });\n        });\n        const peerAddedToSessionListener = (event) => {\n            queue.add(async () => {\n                return this.queryProvider(cid, event.detail, options);\n            }, {\n                provider: event.detail\n            })\n                .catch(err => {\n                if (options.signal?.aborted === true) {\n                    // skip logging error if signal was aborted because abort can happen\n                    // on success (e.g. another session found the block)\n                    return;\n                }\n                this.log.error('error retrieving session block for %c', cid, err);\n            });\n        };\n        // add new session peers to query as they are discovered\n        this.addEventListener('provider', peerAddedToSessionListener);\n        // query each session peer directly\n        Promise.all([...this.providers].map(async (provider) => {\n            return queue.add(async () => {\n                return this.queryProvider(cid, provider, options);\n            }, {\n                provider\n            });\n        }))\n            .catch(err => {\n            if (options.signal?.aborted === true) {\n                // skip logging error if signal was aborted because abort can happen\n                // on success (e.g. another session found the block)\n                return;\n            }\n            this.log.error('error retrieving session block for %c', cid, err);\n        });\n        try {\n            return await deferred.promise;\n        }\n        finally {\n            this.removeEventListener('provider', peerAddedToSessionListener);\n            queue.clear();\n            this.requests.delete(cidStr);\n        }\n    }\n    evict(provider) {\n        this.evictionFilter.add(this.toEvictionKey(provider));\n        const index = this.providers.findIndex(prov => this.equals(prov, provider));\n        if (index === -1) {\n            return;\n        }\n        this.providers.splice(index, 1);\n    }\n    isEvicted(provider) {\n        return this.evictionFilter.has(this.toEvictionKey(provider));\n    }\n    hasProvider(provider) {\n        // dedupe existing gateways\n        if (this.providers.find(prov => this.equals(prov, provider)) != null) {\n            return true;\n        }\n        // dedupe failed session peers\n        if (this.isEvicted(provider)) {\n            return true;\n        }\n        return false;\n    }\n    async findProviders(cid, count, options) {\n        const deferred = pDefer();\n        let found = 0;\n        // run async to resolve the deferred promise when `count` providers are\n        // found but continue util this.providers reaches this.maxProviders\n        void Promise.resolve()\n            .then(async () => {\n            this.log('finding %d-%d new provider(s) for %c', count, this.maxProviders, cid);\n            for await (const provider of this.findNewProviders(cid, options)) {\n                if (found === this.maxProviders || options.signal?.aborted === true) {\n                    break;\n                }\n                if (this.hasProvider(provider)) {\n                    continue;\n                }\n                this.log('found %d/%d new providers', found, this.maxProviders);\n                this.providers.push(provider);\n                // let the new peer join current queries\n                this.safeDispatchEvent('provider', {\n                    detail: provider\n                });\n                found++;\n                if (found === count) {\n                    this.log('session is ready');\n                    deferred.resolve();\n                    // continue finding peers until we reach this.maxProviders\n                }\n                if (this.providers.length === this.maxProviders) {\n                    this.log('found max session peers', found);\n                    break;\n                }\n            }\n            this.log('found %d/%d new session peers', found, this.maxProviders);\n            if (found < count) {\n                throw new InsufficientProvidersError(`Found ${found} of ${count} ${this.name} providers for ${cid}`);\n            }\n        })\n            .catch(err => {\n            this.log.error('error searching routing for potential session peers for %c', cid, err.errors ?? err);\n            deferred.reject(err);\n        });\n        return deferred.promise;\n    }\n}\n//# sourceMappingURL=abstract-session.js.map","/* eslint-disable @typescript-eslint/no-unsafe-return */\nexport class Parser {\n    index = 0;\n    input = \"\";\n    new(input) {\n        this.index = 0;\n        this.input = input;\n        return this;\n    }\n    /** Run a parser, and restore the pre-parse state if it fails. */\n    readAtomically(fn) {\n        const index = this.index;\n        const result = fn();\n        if (result === undefined) {\n            this.index = index;\n        }\n        return result;\n    }\n    /** Run a parser, but fail if the entire input wasn't consumed. Doesn't run atomically. */\n    parseWith(fn) {\n        const result = fn();\n        if (this.index !== this.input.length) {\n            return undefined;\n        }\n        return result;\n    }\n    /** Peek the next character from the input */\n    peekChar() {\n        if (this.index >= this.input.length) {\n            return undefined;\n        }\n        return this.input[this.index];\n    }\n    /** Read the next character from the input */\n    readChar() {\n        if (this.index >= this.input.length) {\n            return undefined;\n        }\n        return this.input[this.index++];\n    }\n    /** Read the next character from the input if it matches the target. */\n    readGivenChar(target) {\n        return this.readAtomically(() => {\n            const char = this.readChar();\n            if (char !== target) {\n                return undefined;\n            }\n            return char;\n        });\n    }\n    /**\n     * Helper for reading separators in an indexed loop. Reads the separator\n     * character iff index > 0, then runs the parser. When used in a loop,\n     * the separator character will only be read on index > 0 (see\n     * readIPv4Addr for an example)\n     */\n    readSeparator(sep, index, inner) {\n        return this.readAtomically(() => {\n            if (index > 0) {\n                if (this.readGivenChar(sep) === undefined) {\n                    return undefined;\n                }\n            }\n            return inner();\n        });\n    }\n    /**\n     * Read a number off the front of the input in the given radix, stopping\n     * at the first non-digit character or eof. Fails if the number has more\n     * digits than max_digits or if there is no number.\n     */\n    readNumber(radix, maxDigits, allowZeroPrefix, maxBytes) {\n        return this.readAtomically(() => {\n            let result = 0;\n            let digitCount = 0;\n            const leadingChar = this.peekChar();\n            if (leadingChar === undefined) {\n                return undefined;\n            }\n            const hasLeadingZero = leadingChar === \"0\";\n            const maxValue = 2 ** (8 * maxBytes) - 1;\n            // eslint-disable-next-line no-constant-condition\n            while (true) {\n                const digit = this.readAtomically(() => {\n                    const char = this.readChar();\n                    if (char === undefined) {\n                        return undefined;\n                    }\n                    const num = Number.parseInt(char, radix);\n                    if (Number.isNaN(num)) {\n                        return undefined;\n                    }\n                    return num;\n                });\n                if (digit === undefined) {\n                    break;\n                }\n                result *= radix;\n                result += digit;\n                if (result > maxValue) {\n                    return undefined;\n                }\n                digitCount += 1;\n                if (maxDigits !== undefined) {\n                    if (digitCount > maxDigits) {\n                        return undefined;\n                    }\n                }\n            }\n            if (digitCount === 0) {\n                return undefined;\n            }\n            else if (!allowZeroPrefix && hasLeadingZero && digitCount > 1) {\n                return undefined;\n            }\n            else {\n                return result;\n            }\n        });\n    }\n    /** Read an IPv4 address. */\n    readIPv4Addr() {\n        return this.readAtomically(() => {\n            const out = new Uint8Array(4);\n            for (let i = 0; i < out.length; i++) {\n                const ix = this.readSeparator(\".\", i, () => this.readNumber(10, 3, false, 1));\n                if (ix === undefined) {\n                    return undefined;\n                }\n                out[i] = ix;\n            }\n            return out;\n        });\n    }\n    /** Read an IPv6 Address. */\n    readIPv6Addr() {\n        /**\n         * Read a chunk of an IPv6 address into `groups`. Returns the number\n         * of groups read, along with a bool indicating if an embedded\n         * trailing IPv4 address was read. Specifically, read a series of\n         * colon-separated IPv6 groups (0x0000 - 0xFFFF), with an optional\n         * trailing embedded IPv4 address.\n         */\n        const readGroups = (groups) => {\n            for (let i = 0; i < groups.length / 2; i++) {\n                const ix = i * 2;\n                // Try to read a trailing embedded IPv4 address. There must be at least 4 groups left.\n                if (i < groups.length - 3) {\n                    const ipv4 = this.readSeparator(\":\", i, () => this.readIPv4Addr());\n                    if (ipv4 !== undefined) {\n                        groups[ix] = ipv4[0];\n                        groups[ix + 1] = ipv4[1];\n                        groups[ix + 2] = ipv4[2];\n                        groups[ix + 3] = ipv4[3];\n                        return [ix + 4, true];\n                    }\n                }\n                const group = this.readSeparator(\":\", i, () => this.readNumber(16, 4, true, 2));\n                if (group === undefined) {\n                    return [ix, false];\n                }\n                groups[ix] = group >> 8;\n                groups[ix + 1] = group & 255;\n            }\n            return [groups.length, false];\n        };\n        return this.readAtomically(() => {\n            // Read the front part of the address; either the whole thing, or up to the first ::\n            const head = new Uint8Array(16);\n            const [headSize, headIp4] = readGroups(head);\n            if (headSize === 16) {\n                return head;\n            }\n            // IPv4 part is not allowed before `::`\n            if (headIp4) {\n                return undefined;\n            }\n            // Read `::` if previous code parsed less than 8 groups.\n            // `::` indicates one or more groups of 16 bits of zeros.\n            if (this.readGivenChar(\":\") === undefined) {\n                return undefined;\n            }\n            if (this.readGivenChar(\":\") === undefined) {\n                return undefined;\n            }\n            // Read the back part of the address. The :: must contain at least one\n            // set of zeroes, so our max length is 7.\n            const tail = new Uint8Array(14);\n            const limit = 16 - (headSize + 2);\n            const [tailSize] = readGroups(tail.subarray(0, limit));\n            // Concat the head and tail of the IP address\n            head.set(tail.subarray(0, tailSize), 16 - tailSize);\n            return head;\n        });\n    }\n    /** Read an IP Address, either IPv4 or IPv6. */\n    readIPAddr() {\n        return this.readIPv4Addr() ?? this.readIPv6Addr();\n    }\n}\n//# sourceMappingURL=parser.js.map","import { Parser } from \"./parser.js\";\n// See https://stackoverflow.com/questions/166132/maximum-length-of-the-textual-representation-of-an-ipv6-address\nconst MAX_IPV6_LENGTH = 45;\nconst MAX_IPV4_LENGTH = 15;\nconst parser = new Parser();\n/** Parse `input` into IPv4 bytes. */\nexport function parseIPv4(input) {\n    if (input.length > MAX_IPV4_LENGTH) {\n        return undefined;\n    }\n    return parser.new(input).parseWith(() => parser.readIPv4Addr());\n}\n/** Parse `input` into IPv6 bytes. */\nexport function parseIPv6(input) {\n    // strip zone index if it is present\n    if (input.includes(\"%\")) {\n        input = input.split(\"%\")[0];\n    }\n    if (input.length > MAX_IPV6_LENGTH) {\n        return undefined;\n    }\n    return parser.new(input).parseWith(() => parser.readIPv6Addr());\n}\n/** Parse `input` into IPv4 or IPv6 bytes. */\nexport function parseIP(input) {\n    // strip zone index if it is present\n    if (input.includes(\"%\")) {\n        input = input.split(\"%\")[0];\n    }\n    if (input.length > MAX_IPV6_LENGTH) {\n        return undefined;\n    }\n    return parser.new(input).parseWith(() => parser.readIPAddr());\n}\n//# sourceMappingURL=parse.js.map","import { parseIP, parseIPv4, parseIPv6 } from \"./parse.js\";\n/** Check if `input` is IPv4. */\nexport function isIPv4(input) {\n    return Boolean(parseIPv4(input));\n}\n/** Check if `input` is IPv6. */\nexport function isIPv6(input) {\n    return Boolean(parseIPv6(input));\n}\n/** Check if `input` is IPv4 or IPv6. */\nexport function isIP(input) {\n    return Boolean(parseIP(input));\n}\n/**\n * @returns `6` if `input` is IPv6, `4` if `input` is IPv4, or `undefined` if `input` is neither.\n */\nexport function ipVersion(input) {\n    if (isIPv4(input)) {\n        return 4;\n    }\n    else if (isIPv6(input)) {\n        return 6;\n    }\n    else {\n        return undefined;\n    }\n}\n//# sourceMappingURL=is-ip.js.map","import { isIPv4, isIPv6 } from '@chainsafe/is-ip';\nimport { Netmask } from 'netmask';\nconst PRIVATE_IP_RANGES = [\n    '0.0.0.0/8',\n    '10.0.0.0/8',\n    '100.64.0.0/10',\n    '127.0.0.0/8',\n    '169.254.0.0/16',\n    '172.16.0.0/12',\n    '192.0.0.0/24',\n    '192.0.0.0/29',\n    '192.0.0.8/32',\n    '192.0.0.9/32',\n    '192.0.0.10/32',\n    '192.0.0.170/32',\n    '192.0.0.171/32',\n    '192.0.2.0/24',\n    '192.31.196.0/24',\n    '192.52.193.0/24',\n    '192.88.99.0/24',\n    '192.168.0.0/16',\n    '192.175.48.0/24',\n    '198.18.0.0/15',\n    '198.51.100.0/24',\n    '203.0.113.0/24',\n    '240.0.0.0/4',\n    '255.255.255.255/32'\n];\nconst NETMASK_RANGES = PRIVATE_IP_RANGES.map(ipRange => new Netmask(ipRange));\nfunction ipv4Check(ipAddr) {\n    for (const r of NETMASK_RANGES) {\n        if (r.contains(ipAddr))\n            return true;\n    }\n    return false;\n}\nfunction isIpv4MappedIpv6(ipAddr) {\n    return /^::ffff:([0-9a-fA-F]{1,4}):([0-9a-fA-F]{1,4})$/.test(ipAddr);\n}\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc4291#section-2.5.5.2\n */\nfunction ipv4MappedIpv6Check(ipAddr) {\n    const parts = ipAddr.split(':');\n    if (parts.length < 2) {\n        return false;\n    }\n    const octet34 = parts[parts.length - 1].padStart(4, '0');\n    const octet12 = parts[parts.length - 2].padStart(4, '0');\n    const ip4 = `${parseInt(octet12.substring(0, 2), 16)}.${parseInt(octet12.substring(2), 16)}.${parseInt(octet34.substring(0, 2), 16)}.${parseInt(octet34.substring(2), 16)}`;\n    return ipv4Check(ip4);\n}\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc4291#section-2.2 example 3\n */\nfunction isIpv4EmbeddedIpv6(ipAddr) {\n    return /^::ffff:([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})$/.test(ipAddr);\n}\nfunction ipv4EmbeddedIpv6Check(ipAddr) {\n    const parts = ipAddr.split(':');\n    const ip4 = parts[parts.length - 1];\n    return ipv4Check(ip4);\n}\nfunction ipv6Check(ipAddr) {\n    return /^::$/.test(ipAddr) ||\n        /^::1$/.test(ipAddr) ||\n        /^64:ff9b::([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})\\.([0-9]{1,3})$/.test(ipAddr) ||\n        /^100::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||\n        /^2001::([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||\n        /^2001:2[0-9a-fA-F]:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||\n        /^2001:db8:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||\n        /^2002:([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4}):?([0-9a-fA-F]{0,4})$/.test(ipAddr) ||\n        /^f[c-d]([0-9a-fA-F]{2,2}):/i.test(ipAddr) ||\n        /^fe[8-9a-bA-B][0-9a-fA-F]:/i.test(ipAddr) ||\n        /^ff([0-9a-fA-F]{2,2}):/i.test(ipAddr);\n}\nexport function isPrivateIp(ip) {\n    if (isIPv4(ip))\n        return ipv4Check(ip);\n    else if (isIpv4MappedIpv6(ip))\n        return ipv4MappedIpv6Check(ip);\n    else if (isIpv4EmbeddedIpv6(ip))\n        return ipv4EmbeddedIpv6Check(ip);\n    else if (isIPv6(ip))\n        return ipv6Check(ip);\n    else\n        return undefined;\n}\n//# sourceMappingURL=private-ip.js.map","import { base58btc } from 'multiformats/bases/base58';\nimport { base64url } from 'multiformats/bases/base64';\n/**\n * Split a multiaddr into path components\n */\nconst toParts = (ma) => {\n    return ma.toString().split('/').slice(1);\n};\nexport const func = (fn) => {\n    return {\n        match: (vals) => {\n            if (vals.length < 1) {\n                return false;\n            }\n            if (fn(vals[0])) {\n                return vals.slice(1);\n            }\n            return false;\n        },\n        pattern: 'fn'\n    };\n};\nexport const literal = (str) => {\n    return {\n        match: (vals) => func((val) => val === str).match(vals),\n        pattern: str\n    };\n};\nexport const string = () => {\n    return {\n        match: (vals) => func((val) => typeof val === 'string').match(vals),\n        pattern: '{string}'\n    };\n};\nexport const number = () => {\n    return {\n        match: (vals) => func((val) => !isNaN(parseInt(val))).match(vals),\n        pattern: '{number}'\n    };\n};\nexport const peerId = () => {\n    return {\n        match: (vals) => {\n            if (vals.length < 2) {\n                return false;\n            }\n            if (vals[0] !== 'p2p' && vals[0] !== 'ipfs') {\n                return false;\n            }\n            // Q is RSA, 1 is Ed25519 or Secp256k1\n            if (vals[1].startsWith('Q') || vals[1].startsWith('1')) {\n                try {\n                    base58btc.decode(`z${vals[1]}`);\n                }\n                catch (err) {\n                    return false;\n                }\n            }\n            else {\n                return false;\n            }\n            return vals.slice(2);\n        },\n        pattern: '/p2p/{peerid}'\n    };\n};\nexport const certhash = () => {\n    return {\n        match: (vals) => {\n            if (vals.length < 2) {\n                return false;\n            }\n            if (vals[0] !== 'certhash') {\n                return false;\n            }\n            try {\n                base64url.decode(vals[1]);\n            }\n            catch {\n                return false;\n            }\n            return vals.slice(2);\n        },\n        pattern: '/certhash/{certhash}'\n    };\n};\nexport const optional = (matcher) => {\n    return {\n        match: (vals) => {\n            const result = matcher.match(vals);\n            if (result === false) {\n                return vals;\n            }\n            return result;\n        },\n        pattern: `optional(${matcher.pattern})`\n    };\n};\nexport const or = (...matchers) => {\n    return {\n        match: (vals) => {\n            let matches;\n            for (const matcher of matchers) {\n                const result = matcher.match(vals);\n                // no match\n                if (result === false) {\n                    continue;\n                }\n                // choose greediest matcher\n                if (matches == null || result.length < matches.length) {\n                    matches = result;\n                }\n            }\n            if (matches == null) {\n                return false;\n            }\n            return matches;\n        },\n        pattern: `or(${matchers.map(m => m.pattern).join(', ')})`\n    };\n};\nexport const and = (...matchers) => {\n    return {\n        match: (vals) => {\n            for (const matcher of matchers) {\n                // pass what's left of the array\n                const result = matcher.match(vals);\n                // no match\n                if (result === false) {\n                    return false;\n                }\n                vals = result;\n            }\n            return vals;\n        },\n        pattern: `and(${matchers.map(m => m.pattern).join(', ')})`\n    };\n};\nexport function fmt(...matchers) {\n    function match(ma) {\n        let parts = toParts(ma);\n        for (const matcher of matchers) {\n            const result = matcher.match(parts);\n            if (result === false) {\n                return false;\n            }\n            parts = result;\n        }\n        return parts;\n    }\n    function matches(ma) {\n        const result = match(ma);\n        return result !== false;\n    }\n    function exactMatch(ma) {\n        const result = match(ma);\n        if (result === false) {\n            return false;\n        }\n        return result.length === 0;\n    }\n    return {\n        matchers,\n        matches,\n        exactMatch\n    };\n}\n//# sourceMappingURL=utils.js.map","/**\n * @packageDocumentation\n *\n * This module exports various matchers that can be used to infer the type of a\n * passed multiaddr.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { DNS } from '@multiformats/multiaddr-matcher'\n *\n * const ma = multiaddr('/dnsaddr/example.org')\n *\n * DNS.matches(ma) // true - this is a multiaddr with a DNS address at the start\n * ```\n *\n * @example\n *\n * The default matching behaviour ignores any subsequent tuples in the multiaddr.\n * If you want stricter matching you can use `.exactMatch`:\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { DNS, Circuit } from '@multiformats/multiaddr-matcher'\n *\n * const ma = multiaddr('/dnsaddr/example.org/p2p/QmFoo/p2p-circuit/p2p/QmBar')\n *\n * DNS.exactMatch(ma) // false - this address has extra tuples after the DNS component\n * Circuit.matches(ma) // true\n * Circuit.exactMatch(ma) // true - the extra tuples are circuit relay related\n * ```\n */\nimport { isIPv4, isIPv6 } from '@chainsafe/is-ip';\nimport { and, or, literal, string, peerId, optional, fmt, func, number, certhash } from './utils.js';\n/**\n * DNS matchers\n */\nconst _DNS4 = and(literal('dns4'), string());\nconst _DNS6 = and(literal('dns6'), string());\nconst _DNSADDR = and(literal('dnsaddr'), string());\nconst _DNS = and(literal('dns'), string());\n/**\n * Matches dns4 addresses.\n *\n * Use {@link DNS DNS} instead to match any type of DNS address.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { DNS4 } from '@multiformats/multiaddr-matcher'\n *\n * DNS4.matches(multiaddr('/dns4/example.org')) // true\n * ```\n */\nexport const DNS4 = fmt(_DNS4, optional(peerId()));\n/**\n * Matches dns6 addresses.\n *\n * Use {@link DNS DNS} instead to match any type of DNS address.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { DNS6 } from '@multiformats/multiaddr-matcher'\n *\n * DNS6.matches(multiaddr('/dns6/example.org')) // true\n * ```\n */\nexport const DNS6 = fmt(_DNS6, optional(peerId()));\n/**\n * Matches dnsaddr addresses.\n *\n * Use {@link DNS DNS} instead to match any type of DNS address.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { DNSADDR } from '@multiformats/multiaddr-matcher'\n *\n * DNSADDR.matches(multiaddr('/dnsaddr/example.org')) // true\n * DNSADDR.matches(multiaddr('/dnsaddr/example.org/p2p/Qmfoo')) // true\n * ```\n */\nexport const DNSADDR = fmt(_DNSADDR, optional(peerId()));\n/**\n * Matches any dns address.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { DNS } from '@multiformats/multiaddr-matcher'\n *\n * DNS.matches(multiaddr('/dnsaddr/example.org')) // true\n * DNS.matches(multiaddr('/dns4/example.org')) // true\n * DNS.matches(multiaddr('/dns6/example.org')) // true\n * DNS.matches(multiaddr('/dns6/example.org/p2p/Qmfoo')) // true\n * ```\n */\nexport const DNS = fmt(or(_DNS, _DNSADDR, _DNS4, _DNS6), optional(peerId()));\nconst _IP4 = and(literal('ip4'), func(isIPv4));\nconst _IP6 = and(literal('ip6'), func(isIPv6));\nconst _IP = or(_IP4, _IP6);\nconst _IP_OR_DOMAIN = or(_IP, _DNS, _DNS4, _DNS6, _DNSADDR);\n/**\n * A matcher for addresses that start with IP or DNS tuples.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { IP_OR_DOMAIN } from '@multiformats/multiaddr-matcher'\n *\n * IP_OR_DOMAIN.matches(multiaddr('/ip4/123.123.123.123')) // true\n * IP_OR_DOMAIN.matches(multiaddr('/ip4/123.123.123.123/p2p/QmFoo')) // true\n * IP_OR_DOMAIN.matches(multiaddr('/dns/example.com/p2p/QmFoo')) // true\n * IP_OR_DOMAIN.matches(multiaddr('/p2p/QmFoo')) // false\n * ```\n */\nexport const IP_OR_DOMAIN = fmt(or(_IP, and(or(_DNS, _DNSADDR, _DNS4, _DNS6), optional(peerId()))));\n/**\n * Matches ip4 addresses.\n *\n * Use {@link IP IP} instead to match any ip4/ip6 address.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { IP4 } from '@multiformats/multiaddr-matcher'\n *\n * const ma = multiaddr('/ip4/123.123.123.123')\n *\n * IP4.matches(ma) // true\n * ```\n */\nexport const IP4 = fmt(_IP4);\n/**\n * Matches ip6 addresses.\n *\n * Use {@link IP IP} instead to match any ip4/ip6 address.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { IP6 } from '@multiformats/multiaddr-matcher'\n *\n * const ma = multiaddr('/ip6/fe80::1cc1:a3b8:322f:cf22')\n *\n * IP6.matches(ma) // true\n * ```\n */\nexport const IP6 = fmt(_IP6);\n/**\n * Matches ip4 or ip6 addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { IP } from '@multiformats/multiaddr-matcher'\n *\n * IP.matches(multiaddr('/ip4/123.123.123.123')) // true\n * IP.matches(multiaddr('/ip6/fe80::1cc1:a3b8:322f:cf22')) // true\n * ```\n */\nexport const IP = fmt(_IP);\nconst _TCP = and(_IP_OR_DOMAIN, literal('tcp'), number());\nconst _UDP = and(_IP_OR_DOMAIN, literal('udp'), number());\n/**\n * Matches TCP addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { TCP } from '@multiformats/multiaddr-matcher'\n *\n * TCP.matches(multiaddr('/ip4/123.123.123.123/tcp/1234')) // true\n * ```\n */\nexport const TCP = fmt(and(_TCP, optional(peerId())));\n/**\n * Matches UDP addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { UDP } from '@multiformats/multiaddr-matcher'\n *\n * UDP.matches(multiaddr('/ip4/123.123.123.123/udp/1234')) // true\n * ```\n */\nexport const UDP = fmt(_UDP);\nconst _QUIC = and(_UDP, literal('quic'));\nconst _QUICV1 = and(_UDP, literal('quic-v1'));\nconst QUIC_V0_OR_V1 = or(_QUIC, _QUICV1);\n/**\n * Matches QUIC addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { QUIC } from '@multiformats/multiaddr-matcher'\n *\n * QUIC.matches(multiaddr('/ip4/123.123.123.123/udp/1234/quic')) // true\n * ```\n */\nexport const QUIC = fmt(_QUIC);\n/**\n * Matches QUICv1 addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { QUICV1 } from '@multiformats/multiaddr-matcher'\n *\n * QUICV1.matches(multiaddr('/ip4/123.123.123.123/udp/1234/quic-v1')) // true\n * ```\n */\nexport const QUICV1 = fmt(_QUICV1);\nconst _WEB = or(_IP_OR_DOMAIN, _TCP, _UDP, _QUIC, _QUICV1);\nconst _WebSockets = or(and(_WEB, literal('ws'), optional(peerId())));\n/**\n * Matches WebSocket addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { WebSockets } from '@multiformats/multiaddr-matcher'\n *\n * WebSockets.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/ws')) // true\n * ```\n */\nexport const WebSockets = fmt(_WebSockets);\nconst _WebSocketsSecure = or(and(_WEB, literal('wss'), optional(peerId())), and(_WEB, literal('tls'), optional(and(literal('sni'), string())), literal('ws'), optional(peerId())));\n/**\n * Matches secure WebSocket addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { WebSocketsSecure } from '@multiformats/multiaddr-matcher'\n *\n * WebSocketsSecure.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/wss')) // true\n * ```\n */\nexport const WebSocketsSecure = fmt(_WebSocketsSecure);\nconst _WebRTCDirect = and(_UDP, literal('webrtc-direct'), optional(certhash()), optional(certhash()), optional(peerId()));\n/**\n * Matches WebRTC-direct addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { WebRTCDirect } from '@multiformats/multiaddr-matcher'\n *\n * WebRTCDirect.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmFoo/webrtc-direct/certhash/u....')) // true\n * ```\n */\nexport const WebRTCDirect = fmt(_WebRTCDirect);\nconst _WebTransport = and(_QUICV1, literal('webtransport'), optional(certhash()), optional(certhash()), optional(peerId()));\n/**\n * Matches WebTransport addresses.\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { WebRTCDirect } from '@multiformats/multiaddr-matcher'\n *\n * WebRTCDirect.matches(multiaddr('/ip4/123.123.123.123/udp/1234/quic-v1/webtransport/certhash/u..../certhash/u..../p2p/QmFoo')) // true\n * ```\n */\nexport const WebTransport = fmt(_WebTransport);\nconst _P2P = or(_WebSockets, _WebSocketsSecure, and(_TCP, optional(peerId())), and(QUIC_V0_OR_V1, optional(peerId())), and(_IP_OR_DOMAIN, optional(peerId())), _WebRTCDirect, _WebTransport, peerId());\n/**\n * Matches peer addresses\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { P2P } from '@multiformats/multiaddr-matcher'\n *\n * P2P.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmFoo')) // true\n * ```\n */\nexport const P2P = fmt(_P2P);\nconst _Circuit = and(_P2P, literal('p2p-circuit'), peerId());\n/**\n * Matches circuit relay addresses\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { Circuit } from '@multiformats/multiaddr-matcher'\n *\n * Circuit.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmRelay/p2p-circuit/p2p/QmTarget')) // true\n * ```\n */\nexport const Circuit = fmt(_Circuit);\nconst _WebRTC = or(and(_P2P, literal('p2p-circuit'), literal('webrtc'), optional(peerId())), and(_P2P, literal('webrtc'), optional(peerId())), literal('webrtc'));\n/**\n * Matches WebRTC addresses\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { WebRTC } from '@multiformats/multiaddr-matcher'\n *\n * WebRTC.matches(multiaddr('/ip4/123.123.123.123/tcp/1234/p2p/QmRelay/p2p-circuit/webrtc/p2p/QmTarget')) // true\n * ```\n */\nexport const WebRTC = fmt(_WebRTC);\nconst _HTTP = or(and(_IP_OR_DOMAIN, literal('tcp'), number(), literal('http'), optional(peerId())), and(_IP_OR_DOMAIN, literal('http'), optional(peerId())));\n/**\n * Matches HTTP addresses\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { HTTP } from '@multiformats/multiaddr-matcher'\n *\n * HTTP.matches(multiaddr('/dns/example.org/http')) // true\n * ```\n */\nexport const HTTP = fmt(_HTTP);\nconst _HTTPS = or(and(_IP_OR_DOMAIN, literal('tcp'), or(and(literal('443'), literal('http')), and(number(), literal('https'))), optional(peerId())), and(_IP_OR_DOMAIN, literal('tls'), literal('http'), optional(peerId())), and(_IP_OR_DOMAIN, literal('https'), optional(peerId())));\n/**\n * Matches HTTPS addresses\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { HTTP } from '@multiformats/multiaddr-matcher'\n *\n * HTTP.matches(multiaddr('/dns/example.org/tls/http')) // true\n * ```\n */\nexport const HTTPS = fmt(_HTTPS);\nconst _Memory = or(and(literal('memory'), string(), optional(peerId())));\n/**\n * Matches Memory addresses\n *\n * @example\n *\n * ```ts\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { Memory } from '@multiformats/multiaddr-matcher'\n *\n * Memory.matches(multiaddr('/memory/0xDEADBEEF')) // true\n * ```\n */\nexport const Memory = fmt(_Memory);\n//# sourceMappingURL=index.js.map","import bases, {} from './util/bases.js';\n/**\n * Turns a `Uint8Array` into a string.\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n */\nexport function toString(array, encoding = 'utf8') {\n    const base = bases[encoding];\n    if (base == null) {\n        throw new Error(`Unsupported encoding \"${encoding}\"`);\n    }\n    // strip multibase prefix\n    return base.encoder.encode(array).substring(1);\n}\n//# sourceMappingURL=to-string.js.map","/* eslint-disable no-fallthrough */\nimport { allocUnsafe } from 'uint8arrays/alloc';\nconst N1 = Math.pow(2, 7);\nconst N2 = Math.pow(2, 14);\nconst N3 = Math.pow(2, 21);\nconst N4 = Math.pow(2, 28);\nconst N5 = Math.pow(2, 35);\nconst N6 = Math.pow(2, 42);\nconst N7 = Math.pow(2, 49);\n/** Most significant bit of a byte */\nconst MSB = 0x80;\n/** Rest of the bits in a byte */\nconst REST = 0x7f;\nexport function encodingLength(value) {\n    if (value < N1) {\n        return 1;\n    }\n    if (value < N2) {\n        return 2;\n    }\n    if (value < N3) {\n        return 3;\n    }\n    if (value < N4) {\n        return 4;\n    }\n    if (value < N5) {\n        return 5;\n    }\n    if (value < N6) {\n        return 6;\n    }\n    if (value < N7) {\n        return 7;\n    }\n    if (Number.MAX_SAFE_INTEGER != null && value > Number.MAX_SAFE_INTEGER) {\n        throw new RangeError('Could not encode varint');\n    }\n    return 8;\n}\nexport function encodeUint8Array(value, buf, offset = 0) {\n    switch (encodingLength(value)) {\n        case 8: {\n            buf[offset++] = (value & 0xFF) | MSB;\n            value /= 128;\n        }\n        case 7: {\n            buf[offset++] = (value & 0xFF) | MSB;\n            value /= 128;\n        }\n        case 6: {\n            buf[offset++] = (value & 0xFF) | MSB;\n            value /= 128;\n        }\n        case 5: {\n            buf[offset++] = (value & 0xFF) | MSB;\n            value /= 128;\n        }\n        case 4: {\n            buf[offset++] = (value & 0xFF) | MSB;\n            value >>>= 7;\n        }\n        case 3: {\n            buf[offset++] = (value & 0xFF) | MSB;\n            value >>>= 7;\n        }\n        case 2: {\n            buf[offset++] = (value & 0xFF) | MSB;\n            value >>>= 7;\n        }\n        case 1: {\n            buf[offset++] = (value & 0xFF);\n            value >>>= 7;\n            break;\n        }\n        default: throw new Error('unreachable');\n    }\n    return buf;\n}\nexport function encodeUint8ArrayList(value, buf, offset = 0) {\n    switch (encodingLength(value)) {\n        case 8: {\n            buf.set(offset++, (value & 0xFF) | MSB);\n            value /= 128;\n        }\n        case 7: {\n            buf.set(offset++, (value & 0xFF) | MSB);\n            value /= 128;\n        }\n        case 6: {\n            buf.set(offset++, (value & 0xFF) | MSB);\n            value /= 128;\n        }\n        case 5: {\n            buf.set(offset++, (value & 0xFF) | MSB);\n            value /= 128;\n        }\n        case 4: {\n            buf.set(offset++, (value & 0xFF) | MSB);\n            value >>>= 7;\n        }\n        case 3: {\n            buf.set(offset++, (value & 0xFF) | MSB);\n            value >>>= 7;\n        }\n        case 2: {\n            buf.set(offset++, (value & 0xFF) | MSB);\n            value >>>= 7;\n        }\n        case 1: {\n            buf.set(offset++, (value & 0xFF));\n            value >>>= 7;\n            break;\n        }\n        default: throw new Error('unreachable');\n    }\n    return buf;\n}\nexport function decodeUint8Array(buf, offset) {\n    let b = buf[offset];\n    let res = 0;\n    res += b & REST;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf[offset + 1];\n    res += (b & REST) << 7;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf[offset + 2];\n    res += (b & REST) << 14;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf[offset + 3];\n    res += (b & REST) << 21;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf[offset + 4];\n    res += (b & REST) * N4;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf[offset + 5];\n    res += (b & REST) * N5;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf[offset + 6];\n    res += (b & REST) * N6;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf[offset + 7];\n    res += (b & REST) * N7;\n    if (b < MSB) {\n        return res;\n    }\n    throw new RangeError('Could not decode varint');\n}\nexport function decodeUint8ArrayList(buf, offset) {\n    let b = buf.get(offset);\n    let res = 0;\n    res += b & REST;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf.get(offset + 1);\n    res += (b & REST) << 7;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf.get(offset + 2);\n    res += (b & REST) << 14;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf.get(offset + 3);\n    res += (b & REST) << 21;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf.get(offset + 4);\n    res += (b & REST) * N4;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf.get(offset + 5);\n    res += (b & REST) * N5;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf.get(offset + 6);\n    res += (b & REST) * N6;\n    if (b < MSB) {\n        return res;\n    }\n    b = buf.get(offset + 7);\n    res += (b & REST) * N7;\n    if (b < MSB) {\n        return res;\n    }\n    throw new RangeError('Could not decode varint');\n}\nexport function encode(value, buf, offset = 0) {\n    if (buf == null) {\n        buf = allocUnsafe(encodingLength(value));\n    }\n    if (buf instanceof Uint8Array) {\n        return encodeUint8Array(value, buf, offset);\n    }\n    else {\n        return encodeUint8ArrayList(value, buf, offset);\n    }\n}\nexport function decode(buf, offset = 0) {\n    if (buf instanceof Uint8Array) {\n        return decodeUint8Array(buf, offset);\n    }\n    else {\n        return decodeUint8ArrayList(buf, offset);\n    }\n}\n//# sourceMappingURL=index.js.map","/**\n * To guarantee Uint8Array semantics, convert nodejs Buffers\n * into vanilla Uint8Arrays\n */\nexport function asUint8Array(buf) {\n    return buf;\n}\n//# sourceMappingURL=as-uint8array.js.map","import { allocUnsafe } from '#alloc';\nimport { asUint8Array } from '#util/as-uint8array';\n/**\n * Returns a new Uint8Array created by concatenating the passed Uint8Arrays\n */\nexport function concat(arrays, length) {\n    if (length == null) {\n        length = arrays.reduce((acc, curr) => acc + curr.length, 0);\n    }\n    const output = allocUnsafe(length);\n    let offset = 0;\n    for (const arr of arrays) {\n        output.set(arr, offset);\n        offset += arr.length;\n    }\n    return asUint8Array(output);\n}\n//# sourceMappingURL=concat.js.map","import { IPv4Len, IPv6Len } from \"./ip.js\";\nexport function allFF(a, from, to) {\n    let i = 0;\n    for (const e of a) {\n        if (i < from)\n            continue;\n        if (i > to)\n            break;\n        if (e !== 0xff)\n            return false;\n        i++;\n    }\n    return true;\n}\nexport function deepEqual(a, b, from, to) {\n    let i = 0;\n    for (const e of a) {\n        if (i < from)\n            continue;\n        if (i > to)\n            break;\n        if (e !== b[i])\n            return false;\n        i++;\n    }\n    return true;\n}\n/***\n * Returns long ip format\n */\nexport function ipToString(ip) {\n    switch (ip.length) {\n        case IPv4Len: {\n            return ip.join(\".\");\n        }\n        case IPv6Len: {\n            const result = [];\n            for (let i = 0; i < ip.length; i++) {\n                if (i % 2 === 0) {\n                    result.push(ip[i].toString(16).padStart(2, \"0\") +\n                        ip[i + 1].toString(16).padStart(2, \"0\"));\n                }\n            }\n            return result.join(\":\");\n        }\n        default: {\n            throw new Error(\"Invalid ip length\");\n        }\n    }\n}\n/**\n * If mask is a sequence of 1 bits followed by 0 bits, return number of 1 bits else -1\n */\nexport function simpleMaskLength(mask) {\n    let ones = 0;\n    // eslint-disable-next-line prefer-const\n    for (let [index, byte] of mask.entries()) {\n        if (byte === 0xff) {\n            ones += 8;\n            continue;\n        }\n        while ((byte & 0x80) != 0) {\n            ones++;\n            byte = byte << 1;\n        }\n        if ((byte & 0x80) != 0) {\n            return -1;\n        }\n        for (let i = index + 1; i < mask.length; i++) {\n            if (mask[i] != 0) {\n                return -1;\n            }\n        }\n        break;\n    }\n    return ones;\n}\nexport function maskToHex(mask) {\n    let hex = \"0x\";\n    for (const byte of mask) {\n        hex += (byte >> 4).toString(16) + (byte & 0x0f).toString(16);\n    }\n    return hex;\n}\n//# sourceMappingURL=util.js.map","import { parseIP } from \"@chainsafe/is-ip/parse\";\nimport { allFF, deepEqual } from \"./util.js\";\nexport const IPv4Len = 4;\nexport const IPv6Len = 16;\nexport const maxIPv6Octet = parseInt(\"0xFFFF\", 16);\nexport const ipv4Prefix = new Uint8Array([\n    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255,\n]);\nexport function maskIp(ip, mask) {\n    if (mask.length === IPv6Len && ip.length === IPv4Len && allFF(mask, 0, 11)) {\n        mask = mask.slice(12);\n    }\n    if (mask.length === IPv4Len &&\n        ip.length === IPv6Len &&\n        deepEqual(ip, ipv4Prefix, 0, 11)) {\n        ip = ip.slice(12);\n    }\n    const n = ip.length;\n    if (n != mask.length) {\n        throw new Error(\"Failed to mask ip\");\n    }\n    const out = new Uint8Array(n);\n    for (let i = 0; i < n; i++) {\n        out[i] = ip[i] & mask[i];\n    }\n    return out;\n}\nexport function containsIp(net, ip) {\n    if (typeof ip === \"string\") {\n        ip = parseIP(ip);\n    }\n    if (ip == null)\n        throw new Error(\"Invalid ip\");\n    if (ip.length !== net.network.length) {\n        return false;\n    }\n    for (let i = 0; i < ip.length; i++) {\n        if ((net.network[i] & net.mask[i]) !== (ip[i] & net.mask[i])) {\n            return false;\n        }\n    }\n    return true;\n}\nexport function iPv4FromIPv6(ip) {\n    if (!isIPv4mappedIPv6(ip)) {\n        throw new Error(\"Must have 0xffff prefix\");\n    }\n    return ip.slice(12);\n}\nexport function isIPv4mappedIPv6(ip) {\n    return deepEqual(ip, ipv4Prefix, 0, 11);\n}\n//# sourceMappingURL=ip.js.map","import { parseIPv4, parseIPv6 } from \"@chainsafe/is-ip/parse\";\nimport { IPv4Len, IPv6Len, maskIp } from \"./ip.js\";\nexport function parseCidr(s) {\n    const [address, maskString] = s.split(\"/\");\n    if (!address || !maskString)\n        throw new Error(\"Failed to parse given CIDR: \" + s);\n    let ipLength = IPv4Len;\n    let ip = parseIPv4(address);\n    if (ip == null) {\n        ipLength = IPv6Len;\n        ip = parseIPv6(address);\n        if (ip == null)\n            throw new Error(\"Failed to parse given CIDR: \" + s);\n    }\n    const m = parseInt(maskString, 10);\n    if (Number.isNaN(m) ||\n        String(m).length !== maskString.length ||\n        m < 0 ||\n        m > ipLength * 8) {\n        throw new Error(\"Failed to parse given CIDR: \" + s);\n    }\n    const mask = cidrMask(m, 8 * ipLength);\n    return {\n        network: maskIp(ip, mask),\n        mask,\n    };\n}\nexport function cidrMask(ones, bits) {\n    if (bits !== 8 * IPv4Len && bits !== 8 * IPv6Len)\n        throw new Error(\"Invalid CIDR mask\");\n    if (ones < 0 || ones > bits)\n        throw new Error(\"Invalid CIDR mask\");\n    const l = bits / 8;\n    const m = new Uint8Array(l);\n    for (let i = 0; i < l; i++) {\n        if (ones >= 8) {\n            m[i] = 0xff;\n            ones -= 8;\n            continue;\n        }\n        m[i] = 255 - (0xff >> ones);\n        ones = 0;\n    }\n    return m;\n}\n//# sourceMappingURL=cidr.js.map","import { parseIP } from \"@chainsafe/is-ip/parse\";\nimport { cidrMask, parseCidr } from \"./cidr.js\";\nimport { containsIp, maskIp } from \"./ip.js\";\nimport { ipToString, maskToHex, simpleMaskLength } from \"./util.js\";\nexport class IpNet {\n    /**\n     *\n     * @param ipOrCidr either network ip or full cidr address\n     * @param mask in case ipOrCidr is network this can be either mask in decimal format or as ip address\n     */\n    constructor(ipOrCidr, mask) {\n        if (mask == null) {\n            ({ network: this.network, mask: this.mask } = parseCidr(ipOrCidr));\n        }\n        else {\n            const ipResult = parseIP(ipOrCidr);\n            if (ipResult == null) {\n                throw new Error(\"Failed to parse network\");\n            }\n            mask = String(mask);\n            const m = parseInt(mask, 10);\n            if (Number.isNaN(m) ||\n                String(m).length !== mask.length ||\n                m < 0 ||\n                m > ipResult.length * 8) {\n                const maskResult = parseIP(mask);\n                if (maskResult == null) {\n                    throw new Error(\"Failed to parse mask\");\n                }\n                this.mask = maskResult;\n            }\n            else {\n                this.mask = cidrMask(m, 8 * ipResult.length);\n            }\n            this.network = maskIp(ipResult, this.mask);\n        }\n    }\n    /**\n     * Checks if netmask contains ip address\n     * @param ip\n     * @returns\n     */\n    contains(ip) {\n        return containsIp({ network: this.network, mask: this.mask }, ip);\n    }\n    /**Serializes back to string format */\n    toString() {\n        const l = simpleMaskLength(this.mask);\n        const mask = l !== -1 ? String(l) : maskToHex(this.mask);\n        return ipToString(this.network) + \"/\" + mask;\n    }\n}\n//# sourceMappingURL=ipnet.js.map","import { IpNet } from \"./ipnet.js\";\nexport { ipToString } from \"./util.js\";\nexport { maskIp, iPv4FromIPv6, isIPv4mappedIPv6 } from \"./ip.js\";\nexport { IpNet } from \"./ipnet.js\";\nexport { parseCidr } from \"./cidr.js\";\n/**\n * Checks if cidr block contains ip address\n * @param cidr ipv4 or ipv6 formatted cidr . Example 198.51.100.14/24 or 2001:db8::/48\n * @param ip ipv4 or ipv6 address Example 198.51.100.14 or 2001:db8::\n *\n */\nexport function cidrContains(cidr, ip) {\n    const ipnet = new IpNet(cidr);\n    return ipnet.contains(ip);\n}\n//# sourceMappingURL=index.js.map","import { isIPv4, isIPv6 } from '@chainsafe/is-ip';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nexport { isIP } from '@chainsafe/is-ip';\nexport const isV4 = isIPv4;\nexport const isV6 = isIPv6;\n// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L7\n// but with buf/offset args removed because we don't use them\nexport const toBytes = function (ip) {\n    let offset = 0;\n    ip = ip.toString().trim();\n    if (isV4(ip)) {\n        const bytes = new Uint8Array(offset + 4);\n        ip.split(/\\./g).forEach((byte) => {\n            bytes[offset++] = parseInt(byte, 10) & 0xff;\n        });\n        return bytes;\n    }\n    if (isV6(ip)) {\n        const sections = ip.split(':', 8);\n        let i;\n        for (i = 0; i < sections.length; i++) {\n            const isv4 = isV4(sections[i]);\n            let v4Buffer;\n            if (isv4) {\n                v4Buffer = toBytes(sections[i]);\n                sections[i] = uint8ArrayToString(v4Buffer.slice(0, 2), 'base16');\n            }\n            if (v4Buffer != null && ++i < 8) {\n                sections.splice(i, 0, uint8ArrayToString(v4Buffer.slice(2, 4), 'base16'));\n            }\n        }\n        if (sections[0] === '') {\n            while (sections.length < 8)\n                sections.unshift('0');\n        }\n        else if (sections[sections.length - 1] === '') {\n            while (sections.length < 8)\n                sections.push('0');\n        }\n        else if (sections.length < 8) {\n            for (i = 0; i < sections.length && sections[i] !== ''; i++)\n                ;\n            const argv = [i, 1];\n            for (i = 9 - sections.length; i > 0; i--) {\n                argv.push('0');\n            }\n            sections.splice.apply(sections, argv);\n        }\n        const bytes = new Uint8Array(offset + 16);\n        for (i = 0; i < sections.length; i++) {\n            const word = parseInt(sections[i], 16);\n            bytes[offset++] = (word >> 8) & 0xff;\n            bytes[offset++] = word & 0xff;\n        }\n        return bytes;\n    }\n    throw new Error('invalid ip address');\n};\n// Copied from https://github.com/indutny/node-ip/blob/master/lib/ip.js#L63\nexport const toString = function (buf, offset = 0, length) {\n    offset = ~~offset;\n    length = length ?? (buf.length - offset);\n    const view = new DataView(buf.buffer);\n    if (length === 4) {\n        const result = [];\n        // IPv4\n        for (let i = 0; i < length; i++) {\n            result.push(buf[offset + i]);\n        }\n        return result.join('.');\n    }\n    if (length === 16) {\n        const result = [];\n        // IPv6\n        for (let i = 0; i < length; i += 2) {\n            result.push(view.getUint16(offset + i).toString(16));\n        }\n        return result.join(':')\n            .replace(/(^|:)0(:0)*:0(:|$)/, '$1::$3')\n            .replace(/:{3,4}/, '::');\n    }\n    return '';\n};\n//# sourceMappingURL=ip.js.map","const V = -1;\nexport const names = {};\nexport const codes = {};\nexport const table = [\n    [4, 32, 'ip4'],\n    [6, 16, 'tcp'],\n    [33, 16, 'dccp'],\n    [41, 128, 'ip6'],\n    [42, V, 'ip6zone'],\n    [43, 8, 'ipcidr'],\n    [53, V, 'dns', true],\n    [54, V, 'dns4', true],\n    [55, V, 'dns6', true],\n    [56, V, 'dnsaddr', true],\n    [132, 16, 'sctp'],\n    [273, 16, 'udp'],\n    [275, 0, 'p2p-webrtc-star'],\n    [276, 0, 'p2p-webrtc-direct'],\n    [277, 0, 'p2p-stardust'],\n    [280, 0, 'webrtc-direct'],\n    [281, 0, 'webrtc'],\n    [290, 0, 'p2p-circuit'],\n    [301, 0, 'udt'],\n    [302, 0, 'utp'],\n    [400, V, 'unix', false, true],\n    // `ipfs` is added before `p2p` for legacy support.\n    // All text representations will default to `p2p`, but `ipfs` will\n    // still be supported\n    [421, V, 'ipfs'],\n    // `p2p` is the preferred name for 421, and is now the default\n    [421, V, 'p2p'],\n    [443, 0, 'https'],\n    [444, 96, 'onion'],\n    [445, 296, 'onion3'],\n    [446, V, 'garlic64'],\n    [448, 0, 'tls'],\n    [449, V, 'sni'],\n    [460, 0, 'quic'],\n    [461, 0, 'quic-v1'],\n    [465, 0, 'webtransport'],\n    [466, V, 'certhash'],\n    [477, 0, 'ws'],\n    [478, 0, 'wss'],\n    [479, 0, 'p2p-websocket-star'],\n    [480, 0, 'http'],\n    [481, V, 'http-path'],\n    [777, V, 'memory']\n];\n// populate tables\ntable.forEach(row => {\n    const proto = createProtocol(...row);\n    codes[proto.code] = proto;\n    names[proto.name] = proto;\n});\nexport function createProtocol(code, size, name, resolvable, path) {\n    return {\n        code,\n        size,\n        name,\n        resolvable: Boolean(resolvable),\n        path: Boolean(path)\n    };\n}\n/**\n * For the passed proto string or number, return a {@link Protocol}\n *\n * @example\n *\n * ```js\n * import { protocol } from '@multiformats/multiaddr'\n *\n * console.info(protocol(4))\n * // { code: 4, size: 32, name: 'ip4', resolvable: false, path: false }\n * ```\n */\nexport function getProtocol(proto) {\n    if (typeof proto === 'number') {\n        if (codes[proto] != null) {\n            return codes[proto];\n        }\n        throw new Error(`no protocol with code: ${proto}`);\n    }\n    else if (typeof proto === 'string') {\n        if (names[proto] != null) {\n            return names[proto];\n        }\n        throw new Error(`no protocol with name: ${proto}`);\n    }\n    throw new Error(`invalid protocol id type: ${typeof proto}`);\n}\n//# sourceMappingURL=protocols-table.js.map","/**\n * @packageDocumentation\n *\n * Provides methods for converting\n */\nimport { IpNet } from '@chainsafe/netmask';\nimport { base32 } from 'multiformats/bases/base32';\nimport { base58btc } from 'multiformats/bases/base58';\nimport { bases } from 'multiformats/basics';\nimport { CID } from 'multiformats/cid';\nimport * as Digest from 'multiformats/hashes/digest';\nimport * as varint from 'uint8-varint';\nimport { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport * as ip from './ip.js';\nimport { getProtocol } from './protocols-table.js';\nconst ip4Protocol = getProtocol('ip4');\nconst ip6Protocol = getProtocol('ip6');\nconst ipcidrProtocol = getProtocol('ipcidr');\nexport function convert(proto, a) {\n    if (a instanceof Uint8Array) {\n        return convertToString(proto, a);\n    }\n    else {\n        return convertToBytes(proto, a);\n    }\n}\n/**\n * Convert [code,Uint8Array] to string\n */\nexport function convertToString(proto, buf) {\n    const protocol = getProtocol(proto);\n    switch (protocol.code) {\n        case 4: // ipv4\n        case 41: // ipv6\n            return bytes2ip(buf);\n        case 42: // ipv6zone\n            return bytes2str(buf);\n        case 6: // tcp\n        case 273: // udp\n        case 33: // dccp\n        case 132: // sctp\n            return bytes2port(buf).toString();\n        case 53: // dns\n        case 54: // dns4\n        case 55: // dns6\n        case 56: // dnsaddr\n        case 400: // unix\n        case 449: // sni\n        case 777: // memory\n            return bytes2str(buf);\n        case 421: // ipfs\n            return bytes2mh(buf);\n        case 444: // onion\n            return bytes2onion(buf);\n        case 445: // onion3\n            return bytes2onion(buf);\n        case 466: // certhash\n            return bytes2mb(buf);\n        case 481: // http-path\n            return globalThis.encodeURIComponent(bytes2str(buf));\n        default:\n            return uint8ArrayToString(buf, 'base16'); // no clue. convert to hex\n    }\n}\nexport function convertToBytes(proto, str) {\n    const protocol = getProtocol(proto);\n    switch (protocol.code) {\n        case 4: // ipv4\n            return ip2bytes(str);\n        case 41: // ipv6\n            return ip2bytes(str);\n        case 42: // ipv6zone\n            return str2bytes(str);\n        case 6: // tcp\n        case 273: // udp\n        case 33: // dccp\n        case 132: // sctp\n            return port2bytes(parseInt(str, 10));\n        case 53: // dns\n        case 54: // dns4\n        case 55: // dns6\n        case 56: // dnsaddr\n        case 400: // unix\n        case 449: // sni\n        case 777: // memory\n            return str2bytes(str);\n        case 421: // ipfs\n            return mh2bytes(str);\n        case 444: // onion\n            return onion2bytes(str);\n        case 445: // onion3\n            return onion32bytes(str);\n        case 466: // certhash\n            return mb2bytes(str);\n        case 481: // http-path\n            return str2bytes(globalThis.decodeURIComponent(str));\n        default:\n            return uint8ArrayFromString(str, 'base16'); // no clue. convert from hex\n    }\n}\nexport function convertToIpNet(multiaddr) {\n    let mask;\n    let addr;\n    multiaddr.stringTuples().forEach(([code, value]) => {\n        if (code === ip4Protocol.code || code === ip6Protocol.code) {\n            addr = value;\n        }\n        if (code === ipcidrProtocol.code) {\n            mask = value;\n        }\n    });\n    if (mask == null || addr == null) {\n        throw new Error('Invalid multiaddr');\n    }\n    return new IpNet(addr, mask);\n}\nconst decoders = Object.values(bases).map((c) => c.decoder);\nconst anybaseDecoder = (function () {\n    let acc = decoders[0].or(decoders[1]);\n    decoders.slice(2).forEach((d) => (acc = acc.or(d)));\n    return acc;\n})();\nfunction ip2bytes(ipString) {\n    if (!ip.isIP(ipString)) {\n        throw new Error('invalid ip address');\n    }\n    return ip.toBytes(ipString);\n}\nfunction bytes2ip(ipBuff) {\n    const ipString = ip.toString(ipBuff, 0, ipBuff.length);\n    if (ipString == null) {\n        throw new Error('ipBuff is required');\n    }\n    if (!ip.isIP(ipString)) {\n        throw new Error('invalid ip address');\n    }\n    return ipString;\n}\nfunction port2bytes(port) {\n    const buf = new ArrayBuffer(2);\n    const view = new DataView(buf);\n    view.setUint16(0, port);\n    return new Uint8Array(buf);\n}\nfunction bytes2port(buf) {\n    const view = new DataView(buf.buffer);\n    return view.getUint16(buf.byteOffset);\n}\nfunction str2bytes(str) {\n    const buf = uint8ArrayFromString(str);\n    const size = Uint8Array.from(varint.encode(buf.length));\n    return uint8ArrayConcat([size, buf], size.length + buf.length);\n}\nfunction bytes2str(buf) {\n    const size = varint.decode(buf);\n    buf = buf.slice(varint.encodingLength(size));\n    if (buf.length !== size) {\n        throw new Error('inconsistent lengths');\n    }\n    return uint8ArrayToString(buf);\n}\nfunction mh2bytes(hash) {\n    let mh;\n    if (hash[0] === 'Q' || hash[0] === '1') {\n        mh = Digest.decode(base58btc.decode(`z${hash}`)).bytes;\n    }\n    else {\n        mh = CID.parse(hash).multihash.bytes;\n    }\n    // the address is a varint prefixed multihash string representation\n    const size = Uint8Array.from(varint.encode(mh.length));\n    return uint8ArrayConcat([size, mh], size.length + mh.length);\n}\nfunction mb2bytes(mbstr) {\n    const mb = anybaseDecoder.decode(mbstr);\n    const size = Uint8Array.from(varint.encode(mb.length));\n    return uint8ArrayConcat([size, mb], size.length + mb.length);\n}\nfunction bytes2mb(buf) {\n    const size = varint.decode(buf);\n    const hash = buf.slice(varint.encodingLength(size));\n    if (hash.length !== size) {\n        throw new Error('inconsistent lengths');\n    }\n    return 'u' + uint8ArrayToString(hash, 'base64url');\n}\n/**\n * Converts bytes to bas58btc string\n */\nfunction bytes2mh(buf) {\n    const size = varint.decode(buf);\n    const address = buf.slice(varint.encodingLength(size));\n    if (address.length !== size) {\n        throw new Error('inconsistent lengths');\n    }\n    return uint8ArrayToString(address, 'base58btc');\n}\nfunction onion2bytes(str) {\n    const addr = str.split(':');\n    if (addr.length !== 2) {\n        throw new Error(`failed to parse onion addr: [\"'${addr.join('\", \"')}'\"]' does not contain a port number`);\n    }\n    if (addr[0].length !== 16) {\n        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion address.`);\n    }\n    // onion addresses do not include the multibase prefix, add it before decoding\n    const buf = base32.decode('b' + addr[0]);\n    // onion port number\n    const port = parseInt(addr[1], 10);\n    if (port < 1 || port > 65536) {\n        throw new Error('Port number is not in range(1, 65536)');\n    }\n    const portBuf = port2bytes(port);\n    return uint8ArrayConcat([buf, portBuf], buf.length + portBuf.length);\n}\nfunction onion32bytes(str) {\n    const addr = str.split(':');\n    if (addr.length !== 2) {\n        throw new Error(`failed to parse onion addr: [\"'${addr.join('\", \"')}'\"]' does not contain a port number`);\n    }\n    if (addr[0].length !== 56) {\n        throw new Error(`failed to parse onion addr: ${addr[0]} not a Tor onion3 address.`);\n    }\n    // onion addresses do not include the multibase prefix, add it before decoding\n    const buf = base32.decode(`b${addr[0]}`);\n    // onion port number\n    const port = parseInt(addr[1], 10);\n    if (port < 1 || port > 65536) {\n        throw new Error('Port number is not in range(1, 65536)');\n    }\n    const portBuf = port2bytes(port);\n    return uint8ArrayConcat([buf, portBuf], buf.length + portBuf.length);\n}\nfunction bytes2onion(buf) {\n    const addrBytes = buf.slice(0, buf.length - 2);\n    const portBytes = buf.slice(buf.length - 2);\n    const addr = uint8ArrayToString(addrBytes, 'base32');\n    const port = bytes2port(portBytes);\n    return `${addr}:${port}`;\n}\n//# sourceMappingURL=convert.js.map","import * as varint from 'uint8-varint';\nimport { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport { convertToBytes, convertToString } from './convert.js';\nimport { getProtocol } from './protocols-table.js';\nexport function stringToMultiaddrParts(str) {\n    str = cleanPath(str);\n    const tuples = [];\n    const stringTuples = [];\n    let path = null;\n    const parts = str.split('/').slice(1);\n    if (parts.length === 1 && parts[0] === '') {\n        return {\n            bytes: new Uint8Array(),\n            string: '/',\n            tuples: [],\n            stringTuples: [],\n            path: null\n        };\n    }\n    for (let p = 0; p < parts.length; p++) {\n        const part = parts[p];\n        const proto = getProtocol(part);\n        if (proto.size === 0) {\n            tuples.push([proto.code]);\n            stringTuples.push([proto.code]);\n            // eslint-disable-next-line no-continue\n            continue;\n        }\n        p++; // advance addr part\n        if (p >= parts.length) {\n            throw ParseError('invalid address: ' + str);\n        }\n        // if it's a path proto, take the rest\n        if (proto.path === true) {\n            // should we need to check each path part to see if it's a proto?\n            // This would allow for other protocols to be added after a unix path,\n            // however it would have issues if the path had a protocol name in the path\n            path = cleanPath(parts.slice(p).join('/'));\n            tuples.push([proto.code, convertToBytes(proto.code, path)]);\n            stringTuples.push([proto.code, path]);\n            break;\n        }\n        const bytes = convertToBytes(proto.code, parts[p]);\n        tuples.push([proto.code, bytes]);\n        stringTuples.push([proto.code, convertToString(proto.code, bytes)]);\n    }\n    return {\n        string: stringTuplesToString(stringTuples),\n        bytes: tuplesToBytes(tuples),\n        tuples,\n        stringTuples,\n        path\n    };\n}\nexport function bytesToMultiaddrParts(bytes) {\n    const tuples = [];\n    const stringTuples = [];\n    let path = null;\n    let i = 0;\n    while (i < bytes.length) {\n        const code = varint.decode(bytes, i);\n        const n = varint.encodingLength(code);\n        const p = getProtocol(code);\n        const size = sizeForAddr(p, bytes.slice(i + n));\n        if (size === 0) {\n            tuples.push([code]);\n            stringTuples.push([code]);\n            i += n;\n            // eslint-disable-next-line no-continue\n            continue;\n        }\n        const addr = bytes.slice(i + n, i + n + size);\n        i += (size + n);\n        if (i > bytes.length) { // did not end _exactly_ at buffer.length\n            throw ParseError('Invalid address Uint8Array: ' + uint8ArrayToString(bytes, 'base16'));\n        }\n        // ok, tuple seems good.\n        tuples.push([code, addr]);\n        const stringAddr = convertToString(code, addr);\n        stringTuples.push([code, stringAddr]);\n        if (p.path === true) {\n            // should we need to check each path part to see if it's a proto?\n            // This would allow for other protocols to be added after a unix path,\n            // however it would have issues if the path had a protocol name in the path\n            path = stringAddr;\n            break;\n        }\n    }\n    return {\n        bytes: Uint8Array.from(bytes),\n        string: stringTuplesToString(stringTuples),\n        tuples,\n        stringTuples,\n        path\n    };\n}\n/**\n * [[str name, str addr]... ] -> string\n */\nfunction stringTuplesToString(tuples) {\n    const parts = [];\n    tuples.map((tup) => {\n        const proto = getProtocol(tup[0]);\n        parts.push(proto.name);\n        if (tup.length > 1 && tup[1] != null) {\n            parts.push(tup[1]);\n        }\n        return null;\n    });\n    return cleanPath(parts.join('/'));\n}\n/**\n * [[int code, Uint8Array ]... ] -> Uint8Array\n */\nexport function tuplesToBytes(tuples) {\n    return uint8ArrayConcat(tuples.map((tup) => {\n        const proto = getProtocol(tup[0]);\n        let buf = Uint8Array.from(varint.encode(proto.code));\n        if (tup.length > 1 && tup[1] != null) {\n            buf = uint8ArrayConcat([buf, tup[1]]); // add address buffer\n        }\n        return buf;\n    }));\n}\n/**\n * For the passed address, return the serialized size\n */\nfunction sizeForAddr(p, addr) {\n    if (p.size > 0) {\n        return p.size / 8;\n    }\n    else if (p.size === 0) {\n        return 0;\n    }\n    else {\n        const size = varint.decode(addr instanceof Uint8Array ? addr : Uint8Array.from(addr));\n        return size + varint.encodingLength(size);\n    }\n}\nexport function bytesToTuples(buf) {\n    const tuples = [];\n    let i = 0;\n    while (i < buf.length) {\n        const code = varint.decode(buf, i);\n        const n = varint.encodingLength(code);\n        const p = getProtocol(code);\n        const size = sizeForAddr(p, buf.slice(i + n));\n        if (size === 0) {\n            tuples.push([code]);\n            i += n;\n            // eslint-disable-next-line no-continue\n            continue;\n        }\n        const addr = buf.slice(i + n, i + n + size);\n        i += (size + n);\n        if (i > buf.length) { // did not end _exactly_ at buffer.length\n            throw ParseError('Invalid address Uint8Array: ' + uint8ArrayToString(buf, 'base16'));\n        }\n        // ok, tuple seems good.\n        tuples.push([code, addr]);\n    }\n    return tuples;\n}\nexport function cleanPath(str) {\n    return '/' + str.trim().split('/').filter((a) => a).join('/');\n}\nexport function ParseError(str) {\n    return new Error('Error parsing address: ' + str);\n}\n//# sourceMappingURL=codec.js.map","/**\n * @packageDocumentation\n *\n * An implementation of a Multiaddr in JavaScript\n *\n * @example\n *\n * ```js\n * import { multiaddr } from '@multiformats/multiaddr'\n *\n * const ma = multiaddr('/ip4/127.0.0.1/tcp/1234')\n * ```\n */\nimport { base58btc } from 'multiformats/bases/base58';\nimport { CID } from 'multiformats/cid';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport { bytesToMultiaddrParts, stringToMultiaddrParts, tuplesToBytes } from './codec.js';\nimport { getProtocol, names } from './protocols-table.js';\nimport { isMultiaddr, multiaddr, resolvers } from './index.js';\nconst inspect = Symbol.for('nodejs.util.inspect.custom');\nexport const symbol = Symbol.for('@multiformats/js-multiaddr/multiaddr');\nconst DNS_CODES = [\n    getProtocol('dns').code,\n    getProtocol('dns4').code,\n    getProtocol('dns6').code,\n    getProtocol('dnsaddr').code\n];\nclass NoAvailableResolverError extends Error {\n    constructor(message = 'No available resolver') {\n        super(message);\n        this.name = 'NoAvailableResolverError';\n    }\n}\n/**\n * Creates a {@link Multiaddr} from a {@link MultiaddrInput}\n */\nexport class Multiaddr {\n    bytes;\n    #string;\n    #tuples;\n    #stringTuples;\n    #path;\n    [symbol] = true;\n    constructor(addr) {\n        // default\n        if (addr == null) {\n            addr = '';\n        }\n        let parts;\n        if (addr instanceof Uint8Array) {\n            parts = bytesToMultiaddrParts(addr);\n        }\n        else if (typeof addr === 'string') {\n            if (addr.length > 0 && addr.charAt(0) !== '/') {\n                throw new Error(`multiaddr \"${addr}\" must start with a \"/\"`);\n            }\n            parts = stringToMultiaddrParts(addr);\n        }\n        else if (isMultiaddr(addr)) { // Multiaddr\n            parts = bytesToMultiaddrParts(addr.bytes);\n        }\n        else {\n            throw new Error('addr must be a string, Buffer, or another Multiaddr');\n        }\n        this.bytes = parts.bytes;\n        this.#string = parts.string;\n        this.#tuples = parts.tuples;\n        this.#stringTuples = parts.stringTuples;\n        this.#path = parts.path;\n    }\n    toString() {\n        return this.#string;\n    }\n    toJSON() {\n        return this.toString();\n    }\n    toOptions() {\n        let family;\n        let transport;\n        let host;\n        let port;\n        let zone = '';\n        const tcp = getProtocol('tcp');\n        const udp = getProtocol('udp');\n        const ip4 = getProtocol('ip4');\n        const ip6 = getProtocol('ip6');\n        const dns6 = getProtocol('dns6');\n        const ip6zone = getProtocol('ip6zone');\n        for (const [code, value] of this.stringTuples()) {\n            if (code === ip6zone.code) {\n                zone = `%${value ?? ''}`;\n            }\n            // default to https when protocol & port are omitted from DNS addrs\n            if (DNS_CODES.includes(code)) {\n                transport = tcp.name;\n                port = 443;\n                host = `${value ?? ''}${zone}`;\n                family = code === dns6.code ? 6 : 4;\n            }\n            if (code === tcp.code || code === udp.code) {\n                transport = getProtocol(code).name;\n                port = parseInt(value ?? '');\n            }\n            if (code === ip4.code || code === ip6.code) {\n                transport = getProtocol(code).name;\n                host = `${value ?? ''}${zone}`;\n                family = code === ip6.code ? 6 : 4;\n            }\n        }\n        if (family == null || transport == null || host == null || port == null) {\n            throw new Error('multiaddr must have a valid format: \"/{ip4, ip6, dns4, dns6, dnsaddr}/{address}/{tcp, udp}/{port}\".');\n        }\n        const opts = {\n            family,\n            host,\n            transport,\n            port\n        };\n        return opts;\n    }\n    protos() {\n        return this.#tuples.map(([code]) => Object.assign({}, getProtocol(code)));\n    }\n    protoCodes() {\n        return this.#tuples.map(([code]) => code);\n    }\n    protoNames() {\n        return this.#tuples.map(([code]) => getProtocol(code).name);\n    }\n    tuples() {\n        return this.#tuples;\n    }\n    stringTuples() {\n        return this.#stringTuples;\n    }\n    encapsulate(addr) {\n        addr = new Multiaddr(addr);\n        return new Multiaddr(this.toString() + addr.toString());\n    }\n    decapsulate(addr) {\n        const addrString = addr.toString();\n        const s = this.toString();\n        const i = s.lastIndexOf(addrString);\n        if (i < 0) {\n            throw new Error(`Address ${this.toString()} does not contain subaddress: ${addr.toString()}`);\n        }\n        return new Multiaddr(s.slice(0, i));\n    }\n    decapsulateCode(code) {\n        const tuples = this.tuples();\n        for (let i = tuples.length - 1; i >= 0; i--) {\n            if (tuples[i][0] === code) {\n                return new Multiaddr(tuplesToBytes(tuples.slice(0, i)));\n            }\n        }\n        return this;\n    }\n    getPeerId() {\n        try {\n            let tuples = [];\n            this.stringTuples().forEach(([code, name]) => {\n                if (code === names.p2p.code) {\n                    tuples.push([code, name]);\n                }\n                // if this is a p2p-circuit address, return the target peer id if present\n                // not the peer id of the relay\n                if (code === names['p2p-circuit'].code) {\n                    tuples = [];\n                }\n            });\n            // Get the last ipfs tuple ['p2p', 'peerid string']\n            const tuple = tuples.pop();\n            if (tuple?.[1] != null) {\n                const peerIdStr = tuple[1];\n                // peer id is base58btc encoded string but not multibase encoded so add the `z`\n                // prefix so we can validate that it is correctly encoded\n                if (peerIdStr[0] === 'Q' || peerIdStr[0] === '1') {\n                    return uint8ArrayToString(base58btc.decode(`z${peerIdStr}`), 'base58btc');\n                }\n                // try to parse peer id as CID\n                return uint8ArrayToString(CID.parse(peerIdStr).multihash.bytes, 'base58btc');\n            }\n            return null;\n        }\n        catch (e) {\n            return null;\n        }\n    }\n    getPath() {\n        return this.#path;\n    }\n    equals(addr) {\n        return uint8ArrayEquals(this.bytes, addr.bytes);\n    }\n    async resolve(options) {\n        const resolvableProto = this.protos().find((p) => p.resolvable);\n        // Multiaddr is not resolvable?\n        if (resolvableProto == null) {\n            return [this];\n        }\n        const resolver = resolvers.get(resolvableProto.name);\n        if (resolver == null) {\n            throw new NoAvailableResolverError(`no available resolver for ${resolvableProto.name}`);\n        }\n        const result = await resolver(this, options);\n        return result.map(str => multiaddr(str));\n    }\n    nodeAddress() {\n        const options = this.toOptions();\n        if (options.transport !== 'tcp' && options.transport !== 'udp') {\n            throw new Error(`multiaddr must have a valid format - no protocol with name: \"${options.transport}\". Must have a valid transport protocol: \"{tcp, udp}\"`);\n        }\n        return {\n            family: options.family,\n            address: options.host,\n            port: options.port\n        };\n    }\n    isThinWaistAddress(addr) {\n        const protos = (addr ?? this).protos();\n        if (protos.length !== 2) {\n            return false;\n        }\n        if (protos[0].code !== 4 && protos[0].code !== 41) {\n            return false;\n        }\n        if (protos[1].code !== 6 && protos[1].code !== 273) {\n            return false;\n        }\n        return true;\n    }\n    /**\n     * Returns Multiaddr as a human-readable string\n     * https://nodejs.org/api/util.html#utilinspectcustom\n     *\n     * @example\n     * ```js\n     * import { multiaddr } from '@multiformats/multiaddr'\n     *\n     * console.info(multiaddr('/ip4/127.0.0.1/tcp/4001'))\n     * // 'Multiaddr(/ip4/127.0.0.1/tcp/4001)'\n     * ```\n     */\n    [inspect]() {\n        return `Multiaddr(${this.#string})`;\n    }\n}\n//# sourceMappingURL=multiaddr.js.map","import { convertToIpNet } from '../convert.js';\nimport { multiaddr } from '../index.js';\n/**\n * A utility class to determine if a Multiaddr contains another\n * multiaddr.\n *\n * This can be used with ipcidr ranges to determine if a given\n * multiaddr is in a ipcidr range.\n *\n * @example\n *\n * ```js\n * import { multiaddr, MultiaddrFilter } from '@multiformats/multiaddr'\n *\n * const range = multiaddr('/ip4/192.168.10.10/ipcidr/24')\n * const filter = new MultiaddrFilter(range)\n *\n * const input = multiaddr('/ip4/192.168.10.2/udp/60')\n * console.info(filter.contains(input)) // true\n * ```\n */\nexport class MultiaddrFilter {\n    multiaddr;\n    netmask;\n    constructor(input) {\n        this.multiaddr = multiaddr(input);\n        this.netmask = convertToIpNet(this.multiaddr);\n    }\n    contains(input) {\n        if (input == null)\n            return false;\n        const m = multiaddr(input);\n        let ip;\n        for (const [code, value] of m.stringTuples()) {\n            if (code === 4 || code === 41) {\n                ip = value;\n                break;\n            }\n        }\n        if (ip === undefined)\n            return false;\n        return this.netmask.contains(ip);\n    }\n}\n//# sourceMappingURL=multiaddr-filter.js.map","/**\n * @packageDocumentation\n *\n * A standard way to represent addresses that\n *\n * - support any standard network protocol\n * - are self-describing\n * - have a binary packed format\n * - have a nice string representation\n * - encapsulate well\n *\n * @example\n *\n * ```TypeScript\n * import { multiaddr } from '@multiformats/multiaddr'\n * const addr =  multiaddr(\"/ip4/127.0.0.1/udp/1234\")\n * // Multiaddr(/ip4/127.0.0.1/udp/1234)\n *\n * const addr = multiaddr(\"/ip4/127.0.0.1/udp/1234\")\n * // Multiaddr(/ip4/127.0.0.1/udp/1234)\n *\n * addr.bytes\n * // <Uint8Array 04 7f 00 00 01 11 04 d2>\n *\n * addr.toString()\n * // '/ip4/127.0.0.1/udp/1234'\n *\n * addr.protos()\n * // [\n * //   {code: 4, name: 'ip4', size: 32},\n * //   {code: 273, name: 'udp', size: 16}\n * // ]\n *\n * // gives you an object that is friendly with what Node.js core modules expect for addresses\n * addr.nodeAddress()\n * // {\n * //   family: 4,\n * //   port: 1234,\n * //   address: \"127.0.0.1\"\n * // }\n *\n * addr.encapsulate('/sctp/5678')\n * // Multiaddr(/ip4/127.0.0.1/udp/1234/sctp/5678)\n * ```\n *\n * ## Resolving DNSADDR addresses\n *\n * [DNSADDR](https://github.com/multiformats/multiaddr/blob/master/protocols/DNSADDR.md) is a spec that allows storing a TXT DNS record that contains a Multiaddr.\n *\n * To resolve DNSADDR addresses, call the `.resolve()` function the multiaddr, optionally passing a `DNS` resolver.\n *\n * DNSADDR addresses can resolve to multiple multiaddrs, since there is no limit to the number of TXT records that can be stored.\n *\n * @example Resolving DNSADDR Multiaddrs\n *\n * ```TypeScript\n * import { multiaddr, resolvers } from '@multiformats/multiaddr'\n * import { dnsaddr } from '@multiformats/multiaddr/resolvers'\n *\n * resolvers.set('dnsaddr', dnsaddr)\n *\n * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')\n *\n * // resolve with a 5s timeout\n * const resolved = await ma.resolve({\n *   signal: AbortSignal.timeout(5000)\n * })\n *\n * console.info(await ma.resolve(resolved)\n * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]\n * ```\n *\n * @example Using a custom DNS resolver to resolve DNSADDR Multiaddrs\n *\n * See the docs for [@multiformats/dns](https://www.npmjs.com/package/@multiformats/dns) for a full breakdown of how to specify multiple resolvers or resolvers that can be used for specific TLDs.\n *\n * ```TypeScript\n * import { multiaddr } from '@multiformats/multiaddr'\n * import { dns } from '@multiformats/dns'\n * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'\n *\n * const resolver = dns({\n *   '.': dnsJsonOverHttps('https://cloudflare-dns.com/dns-query')\n * })\n *\n * const ma = multiaddr('/dnsaddr/bootstrap.libp2p.io')\n * const resolved = await ma.resolve({\n *  dns: resolver\n * })\n *\n * console.info(resolved)\n * // [Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...'), Multiaddr('/ip4/147.75...')...]\n * ```\n */\nimport { Multiaddr as MultiaddrClass, symbol } from './multiaddr.js';\nimport { getProtocol } from './protocols-table.js';\n/**\n * All configured {@link Resolver}s\n */\nexport const resolvers = new Map();\nexport { MultiaddrFilter } from './filter/multiaddr-filter.js';\n/**\n * Creates a Multiaddr from a node-friendly address object\n *\n * @example\n * ```js\n * import { fromNodeAddress } from '@multiformats/multiaddr'\n *\n * fromNodeAddress({address: '127.0.0.1', port: '4001'}, 'tcp')\n * // Multiaddr(/ip4/127.0.0.1/tcp/4001)\n * ```\n */\nexport function fromNodeAddress(addr, transport) {\n    if (addr == null) {\n        throw new Error('requires node address object');\n    }\n    if (transport == null) {\n        throw new Error('requires transport protocol');\n    }\n    let ip;\n    let host = addr.address;\n    switch (addr.family) {\n        case 4:\n            ip = 'ip4';\n            break;\n        case 6:\n            ip = 'ip6';\n            if (host.includes('%')) {\n                const parts = host.split('%');\n                if (parts.length !== 2) {\n                    throw Error('Multiple ip6 zones in multiaddr');\n                }\n                host = parts[0];\n                const zone = parts[1];\n                ip = `/ip6zone/${zone}/ip6`;\n            }\n            break;\n        default:\n            throw Error('Invalid addr family, should be 4 or 6.');\n    }\n    return new MultiaddrClass('/' + [ip, host, transport, addr.port].join('/'));\n}\n/**\n * Returns if something is a {@link Multiaddr} that is a resolvable name\n *\n * @example\n *\n * ```js\n * import { isName, multiaddr } from '@multiformats/multiaddr'\n *\n * isName(multiaddr('/ip4/127.0.0.1'))\n * // false\n * isName(multiaddr('/dns/ipfs.io'))\n * // true\n * ```\n */\nexport function isName(addr) {\n    if (!isMultiaddr(addr)) {\n        return false;\n    }\n    // if a part of the multiaddr is resolvable, then return true\n    return addr.protos().some((proto) => proto.resolvable);\n}\n/**\n * Check if object is a {@link Multiaddr} instance\n *\n * @example\n *\n * ```js\n * import { isMultiaddr, multiaddr } from '@multiformats/multiaddr'\n *\n * isMultiaddr(5)\n * // false\n * isMultiaddr(multiaddr('/ip4/127.0.0.1'))\n * // true\n * ```\n */\nexport function isMultiaddr(value) {\n    return Boolean(value?.[symbol]);\n}\n/**\n * A function that takes a {@link MultiaddrInput} and returns a {@link Multiaddr}\n *\n * @example\n * ```js\n * import { multiaddr } from '@libp2p/multiaddr'\n *\n * multiaddr('/ip4/127.0.0.1/tcp/4001')\n * // Multiaddr(/ip4/127.0.0.1/tcp/4001)\n * ```\n *\n * @param {MultiaddrInput} [addr] - If String or Uint8Array, needs to adhere to the address format of a [multiaddr](https://github.com/multiformats/multiaddr#string-format)\n */\nexport function multiaddr(addr) {\n    return new MultiaddrClass(addr);\n}\nexport { getProtocol as protocols };\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * This module allows easy conversion of Multiaddrs to string URIs.\n *\n * @example Converting multiaddrs to string URIs\n *\n * ```js\n * import { multiaddrToUri } from '@multiformats/multiaddr-to-uri'\n *\n * console.log(multiaddrToUri('/dnsaddr/protocol.ai/https'))\n * // -> https://protocol.ai\n *\n * console.log(multiaddrToUri('/ip4/127.0.0.1/tcp/8080'))\n * // -> http://127.0.0.1:8080\n *\n * console.log(multiaddrToUri('/ip4/127.0.0.1/tcp/8080', { assumeHttp: false }))\n * // -> tcp://127.0.0.1:8080\n * ```\n *\n * Note:\n *\n * - When `/tcp` is the last (terminating) protocol HTTP is assumed by default (implicit `assumeHttp: true`)\n *   - this means produced URIs will start with `http://` instead of `tcp://`\n *   - passing `{ assumeHttp: false }` disables this behavior\n * - Might be lossy - e.g. a DNSv6 multiaddr\n * - Can throw if the passed multiaddr:\n *   - is not a valid multiaddr\n *   - is not supported as a URI e.g. circuit\n */\nimport { multiaddr, protocols } from '@multiformats/multiaddr';\nconst ASSUME_HTTP_CODES = [\n    protocols('tcp').code,\n    protocols('dns').code,\n    protocols('dnsaddr').code,\n    protocols('dns4').code,\n    protocols('dns6').code\n];\nfunction extractSNI(ma) {\n    return extractTuple('sni', ma)?.[1];\n}\nfunction extractPort(ma) {\n    const port = extractTuple('tcp', ma)?.[1];\n    if (port == null) {\n        return '';\n    }\n    return `:${port}`;\n}\nfunction extractTuple(name, ma) {\n    let code;\n    try {\n        code = protocols(name).code;\n    }\n    catch (e) {\n        // No support for protocol in multiaddr\n        return;\n    }\n    for (const [proto, value] of ma) {\n        if (proto === code && value != null) {\n            return [proto, value];\n        }\n    }\n}\nfunction hasTLS(ma) {\n    return ma.some(([proto, _]) => proto === protocols('tls').code);\n}\nfunction interpretNext(headProtoCode, headProtoVal, restMa) {\n    const interpreter = interpreters[protocols(headProtoCode).name];\n    if (interpreter == null) {\n        throw new Error(`Can't interpret protocol ${protocols(headProtoCode).name}`);\n    }\n    const restVal = interpreter(headProtoVal, restMa);\n    if (headProtoCode === protocols('ip6').code) {\n        return `[${restVal}]`;\n    }\n    return restVal;\n}\nconst interpreters = {\n    ip4: (value, restMa) => value,\n    ip6: (value, restMa) => {\n        if (restMa.length === 0) {\n            return value;\n        }\n        return `[${value}]`;\n    },\n    tcp: (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return `tcp://${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}:${value}`;\n    },\n    udp: (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return `udp://${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}:${value}`;\n    },\n    dnsaddr: (value, restMa) => value,\n    dns4: (value, restMa) => value,\n    dns6: (value, restMa) => value,\n    dns: (value, restMa) => value,\n    ipfs: (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/ipfs/${value}`;\n    },\n    p2p: (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p/${value}`;\n    },\n    http: (value, restMa) => {\n        const maHasTLS = hasTLS(restMa);\n        const sni = extractSNI(restMa);\n        const port = extractPort(restMa);\n        if (maHasTLS && sni != null) {\n            return `https://${sni}${port}`;\n        }\n        const protocol = maHasTLS ? 'https://' : 'http://';\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);\n        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there\n        baseVal = baseVal.replace('tcp://', '');\n        return `${protocol}${baseVal}`;\n    },\n    'http-path': (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        const baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);\n        const decodedValue = decodeURIComponent(value);\n        return `${baseVal}/${decodedValue}`;\n    },\n    tls: (value, restMa) => {\n        // Noop, the parent context knows that it's tls. We don't need to do\n        // anything here\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return interpretNext(tailProto[0], tailProto[1] ?? '', restMa);\n    },\n    sni: (value, restMa) => {\n        // Noop, the parent context uses the sni information, we don't need to do\n        // anything here\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return interpretNext(tailProto[0], tailProto[1] ?? '', restMa);\n    },\n    https: (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);\n        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there\n        baseVal = baseVal.replace('tcp://', '');\n        return `https://${baseVal}`;\n    },\n    ws: (value, restMa) => {\n        const maHasTLS = hasTLS(restMa);\n        const sni = extractSNI(restMa);\n        const port = extractPort(restMa);\n        if (maHasTLS && sni != null) {\n            return `wss://${sni}${port}`;\n        }\n        const protocol = maHasTLS ? 'wss://' : 'ws://';\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);\n        // We are reinterpreting the base, so we need to remove the tcp:// if it's there\n        baseVal = baseVal.replace('tcp://', '');\n        return `${protocol}${baseVal}`;\n    },\n    wss: (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        let baseVal = interpretNext(tailProto[0], tailProto[1] ?? '', restMa);\n        // We are reinterpreting the base as http, so we need to remove the tcp:// if it's there\n        baseVal = baseVal.replace('tcp://', '');\n        return `wss://${baseVal}`;\n    },\n    'p2p-websocket-star': (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p-websocket-star`;\n    },\n    'p2p-webrtc-star': (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p-webrtc-star`;\n    },\n    'p2p-webrtc-direct': (value, restMa) => {\n        const tailProto = restMa.pop();\n        if (tailProto == null) {\n            throw new Error('Unexpected end of multiaddr');\n        }\n        return `${interpretNext(tailProto[0], tailProto[1] ?? '', restMa)}/p2p-webrtc-direct`;\n    }\n};\nexport function multiaddrToUri(input, opts) {\n    const ma = multiaddr(input);\n    const parts = ma.stringTuples();\n    const head = parts.pop();\n    if (head == null) {\n        throw new Error('Unexpected end of multiaddr');\n    }\n    const protocol = protocols(head[0]);\n    const interpreter = interpreters[protocol.name];\n    if (interpreter == null) {\n        throw new Error(`No interpreter found for ${protocol.name}`);\n    }\n    let uri = interpreter(head[1] ?? '', parts);\n    if (opts?.assumeHttp !== false && ASSUME_HTTP_CODES.includes(head[0])) {\n        // strip any declared protocol\n        uri = uri.replace(/^.*:\\/\\//, '');\n        if (head[1] === '443') {\n            uri = `https://${uri}`;\n        }\n        else {\n            uri = `http://${uri}`;\n        }\n    }\n    if (uri.startsWith('http://') || uri.startsWith('https://') || uri.startsWith('ws://') || uri.startsWith('wss://')) {\n        // this will strip default ports while keeping paths intact\n        uri = new URL(uri).toString();\n        // strip trailing slash, e.g. http://127.0.0.1/ -> http://127.0.0.1\n        if (uri.endsWith('/')) {\n            uri = uri.substring(0, uri.length - 1);\n        }\n    }\n    return uri;\n}\n//# sourceMappingURL=index.js.map","import { base64 } from 'multiformats/bases/base64';\n/**\n * A `TrustlessGateway` keeps track of the number of attempts, errors, and\n * successes for a given gateway url so that we can prioritize gateways that\n * have been more reliable in the past, and ensure that requests are distributed\n * across all gateways within a given `TrustlessGatewayBlockBroker` instance.\n */\nexport class TrustlessGateway {\n    url;\n    /**\n     * The number of times this gateway has been attempted to be used to fetch a\n     * block. This includes successful, errored, and aborted attempts. By counting\n     * even aborted attempts, slow gateways that are out-raced by others will be\n     * considered less reliable.\n     */\n    #attempts = 0;\n    /**\n     * The number of times this gateway has errored while attempting to fetch a\n     * block. This includes `response.ok === false` and any other errors that\n     * throw while attempting to fetch a block. This does not include aborted\n     * attempts.\n     */\n    #errors = 0;\n    /**\n     * The number of times this gateway has returned an invalid block. A gateway\n     * that returns the wrong blocks for a CID should be considered for removal\n     * from the list of gateways to fetch blocks from.\n     */\n    #invalidBlocks = 0;\n    /**\n     * The number of times this gateway has successfully fetched a block.\n     */\n    #successes = 0;\n    /**\n     * A map of pending responses for this gateway. This is used to ensure that\n     * only one request per CID is made to a given gateway at a time, and that we\n     * don't make multiple in-flight requests for the same CID to the same gateway.\n     */\n    #pendingResponses = new Map();\n    log;\n    constructor(url, logger) {\n        this.url = url instanceof URL ? url : new URL(url);\n        this.log = logger.forComponent(`helia:trustless-gateway-block-broker:${this.url.hostname}`);\n    }\n    /**\n     * This function returns a unique string for the multihash.bytes of the CID.\n     *\n     * Some useful resources for why this is needed can be found using the links below:\n     *\n     * - https://github.com/ipfs/helia/pull/503#discussion_r1572451331\n     * - https://github.com/ipfs/kubo/issues/6815\n     * - https://www.notion.so/pl-strflt/Handling-ambiguity-around-CIDs-9d5e14f6516f438980b01ef188efe15d#d9d45cd1ed8b4d349b96285de4aed5ab\n     */\n    #uniqueBlockId(cid) {\n        const multihashBytes = cid.multihash.bytes;\n        return base64.encode(multihashBytes);\n    }\n    /**\n     * Fetch a raw block from `this.url` following the specification defined at\n     * https://specs.ipfs.tech/http-gateways/trustless-gateway/\n     */\n    async getRawBlock(cid, signal) {\n        const gwUrl = new URL(this.url.toString());\n        gwUrl.pathname = `/ipfs/${cid.toString()}`;\n        // necessary as not every gateway supports dag-cbor, but every should support\n        // sending raw block as-is\n        gwUrl.search = '?format=raw';\n        if (signal?.aborted === true) {\n            throw new Error(`Signal to fetch raw block for CID ${cid} from gateway ${this.url} was aborted prior to fetch`);\n        }\n        const blockId = this.#uniqueBlockId(cid);\n        // workaround for https://github.com/nodejs/node/issues/52635\n        const innerController = new AbortController();\n        const abortInnerSignal = () => {\n            innerController.abort();\n        };\n        signal?.addEventListener('abort', abortInnerSignal);\n        try {\n            let pendingResponse = this.#pendingResponses.get(blockId);\n            if (pendingResponse == null) {\n                this.#attempts++;\n                pendingResponse = fetch(gwUrl.toString(), {\n                    signal: innerController.signal,\n                    headers: {\n                        Accept: 'application/vnd.ipld.raw'\n                    },\n                    cache: 'force-cache'\n                }).then(async (res) => {\n                    this.log('GET %s %d', gwUrl, res.status);\n                    if (!res.ok) {\n                        this.#errors++;\n                        throw new Error(`unable to fetch raw block for CID ${cid} from gateway ${this.url}`);\n                    }\n                    this.#successes++;\n                    return new Uint8Array(await res.arrayBuffer());\n                });\n                this.#pendingResponses.set(blockId, pendingResponse);\n            }\n            return await pendingResponse;\n        }\n        catch (cause) {\n            // @ts-expect-error - TS thinks signal?.aborted can only be false now\n            // because it was checked for true above.\n            if (signal?.aborted === true) {\n                throw new Error(`fetching raw block for CID ${cid} from gateway ${this.url} was aborted`);\n            }\n            this.#errors++;\n            throw new Error(`unable to fetch raw block for CID ${cid}`);\n        }\n        finally {\n            signal?.removeEventListener('abort', abortInnerSignal);\n            this.#pendingResponses.delete(blockId);\n        }\n    }\n    /**\n     * Encapsulate the logic for determining whether a gateway is considered\n     * reliable, for prioritization. This is based on the number of successful attempts made\n     * and the number of errors encountered.\n     *\n     * Unused gateways have 100% reliability; They will be prioritized over\n     * gateways with a 100% success rate to ensure that we attempt all gateways.\n     */\n    reliability() {\n        /**\n         * if we have never tried to use this gateway, it is considered the most\n         * reliable until we determine otherwise (prioritize unused gateways)\n         */\n        if (this.#attempts === 0) {\n            return 1;\n        }\n        if (this.#invalidBlocks > 0) {\n            // this gateway may not be trustworthy..\n            return -Infinity;\n        }\n        /**\n         * We have attempted the gateway, so we need to calculate the reliability\n         * based on the number of attempts, errors, and successes. Gateways that\n         * return a single error should drop their reliability score more than a\n         * single success increases it.\n         *\n         * Play around with the below reliability function at https://www.desmos.com/calculator/d6hfhf5ukm\n         */\n        return this.#successes / (this.#attempts + (this.#errors * 3));\n    }\n    /**\n     * Increment the number of invalid blocks returned by this gateway.\n     */\n    incrementInvalidBlocks() {\n        this.#invalidBlocks++;\n    }\n    getStats() {\n        return {\n            attempts: this.#attempts,\n            errors: this.#errors,\n            invalidBlocks: this.#invalidBlocks,\n            successes: this.#successes,\n            pendingResponses: this.#pendingResponses.size\n        };\n    }\n}\n//# sourceMappingURL=trustless-gateway.js.map","import { isPrivateIp } from '@libp2p/utils/private-ip';\nimport { DNS, HTTP, HTTPS } from '@multiformats/multiaddr-matcher';\nimport { multiaddrToUri } from '@multiformats/multiaddr-to-uri';\nimport { TrustlessGateway } from './trustless-gateway.js';\nexport function filterNonHTTPMultiaddrs(multiaddrs, allowInsecure, allowLocal) {\n    return multiaddrs.filter(ma => {\n        if (HTTPS.matches(ma) || (allowInsecure && HTTP.matches(ma))) {\n            if (allowLocal) {\n                return true;\n            }\n            if (DNS.matches(ma)) {\n                return true;\n            }\n            return isPrivateIp(ma.toOptions().host) === false;\n        }\n        // When allowInsecure is false and allowLocal is true, allow multiaddrs with \"127.0.0.1\", \"localhost\", or any subdomain ending with \".localhost\"\n        if (!allowInsecure && allowLocal) {\n            const { host } = ma.toOptions();\n            if (host === '127.0.0.1' || host === 'localhost' || host.endsWith('.localhost')) {\n                return true;\n            }\n        }\n        return false;\n    });\n}\nexport async function* findHttpGatewayProviders(cid, routing, logger, allowInsecure, allowLocal, options) {\n    for await (const provider of routing.findProviders(cid, options)) {\n        // require http(s) addresses\n        const httpAddresses = filterNonHTTPMultiaddrs(provider.multiaddrs, allowInsecure, allowLocal);\n        if (httpAddresses.length === 0) {\n            continue;\n        }\n        // take first address?\n        // /ip4/x.x.x.x/tcp/31337/http\n        // /ip4/x.x.x.x/tcp/31337/https\n        // etc\n        const uri = multiaddrToUri(httpAddresses[0]);\n        yield new TrustlessGateway(uri, logger);\n    }\n}\n//# sourceMappingURL=utils.js.map","import { AbstractSession } from '@helia/utils';\nimport { findHttpGatewayProviders } from './utils.js';\nimport { DEFAULT_ALLOW_INSECURE, DEFAULT_ALLOW_LOCAL } from './index.js';\nclass TrustlessGatewaySession extends AbstractSession {\n    routing;\n    allowInsecure;\n    allowLocal;\n    constructor(components, init) {\n        super(components, {\n            ...init,\n            name: 'helia:trustless-gateway:session'\n        });\n        this.routing = components.routing;\n        this.allowInsecure = init.allowInsecure ?? DEFAULT_ALLOW_INSECURE;\n        this.allowLocal = init.allowLocal ?? DEFAULT_ALLOW_LOCAL;\n    }\n    async queryProvider(cid, provider, options) {\n        this.log('fetching BLOCK for %c from %s', cid, provider.url);\n        const block = await provider.getRawBlock(cid, options.signal);\n        this.log.trace('got block for %c from %s', cid, provider.url);\n        await options.validateFn?.(block);\n        return block;\n    }\n    async *findNewProviders(cid, options = {}) {\n        yield* findHttpGatewayProviders(cid, this.routing, this.logger, this.allowInsecure, this.allowLocal, options);\n    }\n    toEvictionKey(provider) {\n        return provider.url.toString();\n    }\n    equals(providerA, providerB) {\n        return providerA.url.toString() === providerB.url.toString();\n    }\n}\nexport function createTrustlessGatewaySession(components, init) {\n    return new TrustlessGatewaySession(components, init);\n}\n//# sourceMappingURL=session.js.map","import { createTrustlessGatewaySession } from './session.js';\nimport { findHttpGatewayProviders } from './utils.js';\nimport { DEFAULT_ALLOW_INSECURE, DEFAULT_ALLOW_LOCAL } from './index.js';\n/**\n * A class that accepts a list of trustless gateways that are queried\n * for blocks.\n */\nexport class TrustlessGatewayBlockBroker {\n    allowInsecure;\n    allowLocal;\n    routing;\n    log;\n    logger;\n    constructor(components, init = {}) {\n        this.log = components.logger.forComponent('helia:trustless-gateway-block-broker');\n        this.logger = components.logger;\n        this.routing = components.routing;\n        this.allowInsecure = init.allowInsecure ?? DEFAULT_ALLOW_INSECURE;\n        this.allowLocal = init.allowLocal ?? DEFAULT_ALLOW_LOCAL;\n    }\n    async retrieve(cid, options = {}) {\n        const aggregateErrors = [];\n        for await (const gateway of findHttpGatewayProviders(cid, this.routing, this.logger, this.allowInsecure, this.allowLocal, options)) {\n            this.log('getting block for %c from %s', cid, gateway.url);\n            try {\n                const block = await gateway.getRawBlock(cid, options.signal);\n                this.log.trace('got block for %c from %s', cid, gateway.url);\n                try {\n                    await options.validateFn?.(block);\n                }\n                catch (err) {\n                    this.log.error('failed to validate block for %c from %s', cid, gateway.url, err);\n                    // try another gateway\n                    continue;\n                }\n                return block;\n            }\n            catch (err) {\n                this.log.error('failed to get block for %c from %s', cid, gateway.url, err);\n                if (err instanceof Error) {\n                    aggregateErrors.push(err);\n                }\n                else {\n                    aggregateErrors.push(new Error(`Unable to fetch raw block for CID ${cid} from gateway ${gateway.url}`));\n                }\n                // if signal was aborted, exit the loop\n                if (options.signal?.aborted === true) {\n                    this.log.trace('request aborted while fetching raw block for CID %c from gateway %s', cid, gateway.url);\n                    break;\n                }\n            }\n        }\n        if (aggregateErrors.length > 0) {\n            throw new AggregateError(aggregateErrors, `Unable to fetch raw block for CID ${cid} from any gateway`);\n        }\n        else {\n            throw new Error(`Unable to fetch raw block for CID ${cid} from any gateway`);\n        }\n    }\n    createSession(options = {}) {\n        return createTrustlessGatewaySession({\n            logger: this.logger,\n            routing: this.routing\n        }, {\n            ...options,\n            allowLocal: this.allowLocal,\n            allowInsecure: this.allowInsecure\n        });\n    }\n}\n//# sourceMappingURL=broker.js.map","import { TrustlessGatewayBlockBroker } from './broker.js';\nexport const DEFAULT_ALLOW_INSECURE = false;\nexport const DEFAULT_ALLOW_LOCAL = false;\nexport function trustlessGateway(init = {}) {\n    return (components) => new TrustlessGatewayBlockBroker(components, init);\n}\n//# sourceMappingURL=index.js.map","export { bitswap } from './bitswap.js';\nexport { trustlessGateway } from './trustless-gateway/index.js';\n//# sourceMappingURL=index.js.map","/**\n * Any object that implements this Symbol as a property should return a\n * ContentRouting instance as the property value, similar to how\n * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.\n *\n * @example\n *\n * ```TypeScript\n * import { contentRoutingSymbol, ContentRouting } from '@libp2p/content-routing'\n *\n * class MyContentRouter implements ContentRouting {\n *   get [contentRoutingSymbol] () {\n *     return this\n *   }\n *\n *   // ...other methods\n * }\n * ```\n */\nexport const contentRoutingSymbol = Symbol.for('@libp2p/content-routing');\n//# sourceMappingURL=index.js.map","/**\n * Any object that implements this Symbol as a property should return a\n * PeerRouting instance as the property value, similar to how\n * `Symbol.Iterable` can be used to return an `Iterable` from an `Iterator`.\n *\n * @example\n *\n * ```TypeScript\n * import { peerRouting, PeerRouting } from '@libp2p/peer-routing'\n *\n * class MyPeerRouter implements PeerRouting {\n *   get [peerRouting] () {\n *     return this\n *   }\n *\n *   // ...other methods\n * }\n * ```\n */\nexport const peerRoutingSymbol = Symbol.for('@libp2p/peer-routing');\n//# sourceMappingURL=index.js.map","// Helpers.\nconst s = 1000;\nconst m = s * 60;\nconst h = m * 60;\nconst d = h * 24;\nconst w = d * 7;\nconst y = d * 365.25;\nfunction ms(value, options) {\n    try {\n        if (typeof value === 'string' && value.length > 0) {\n            return parse(value);\n        }\n        else if (typeof value === 'number' && isFinite(value)) {\n            return options?.long ? fmtLong(value) : fmtShort(value);\n        }\n        throw new Error('Value is not a string or number.');\n    }\n    catch (error) {\n        const message = isError(error)\n            ? `${error.message}. value=${JSON.stringify(value)}`\n            : 'An unknown error has occured.';\n        throw new Error(message);\n    }\n}\n/**\n * Parse the given `str` and return milliseconds.\n */\nfunction parse(str) {\n    str = String(str);\n    if (str.length > 100) {\n        throw new Error('Value exceeds the maximum length of 100 characters.');\n    }\n    const match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(str);\n    if (!match) {\n        return NaN;\n    }\n    const n = parseFloat(match[1]);\n    const type = (match[2] || 'ms').toLowerCase();\n    switch (type) {\n        case 'years':\n        case 'year':\n        case 'yrs':\n        case 'yr':\n        case 'y':\n            return n * y;\n        case 'weeks':\n        case 'week':\n        case 'w':\n            return n * w;\n        case 'days':\n        case 'day':\n        case 'd':\n            return n * d;\n        case 'hours':\n        case 'hour':\n        case 'hrs':\n        case 'hr':\n        case 'h':\n            return n * h;\n        case 'minutes':\n        case 'minute':\n        case 'mins':\n        case 'min':\n        case 'm':\n            return n * m;\n        case 'seconds':\n        case 'second':\n        case 'secs':\n        case 'sec':\n        case 's':\n            return n * s;\n        case 'milliseconds':\n        case 'millisecond':\n        case 'msecs':\n        case 'msec':\n        case 'ms':\n            return n;\n        default:\n            // This should never occur.\n            throw new Error(`The unit ${type} was matched, but no matching case exists.`);\n    }\n}\nexport default ms;\n/**\n * Short format for `ms`.\n */\nfunction fmtShort(ms) {\n    const msAbs = Math.abs(ms);\n    if (msAbs >= d) {\n        return `${Math.round(ms / d)}d`;\n    }\n    if (msAbs >= h) {\n        return `${Math.round(ms / h)}h`;\n    }\n    if (msAbs >= m) {\n        return `${Math.round(ms / m)}m`;\n    }\n    if (msAbs >= s) {\n        return `${Math.round(ms / s)}s`;\n    }\n    return `${ms}ms`;\n}\n/**\n * Long format for `ms`.\n */\nfunction fmtLong(ms) {\n    const msAbs = Math.abs(ms);\n    if (msAbs >= d) {\n        return plural(ms, msAbs, d, 'day');\n    }\n    if (msAbs >= h) {\n        return plural(ms, msAbs, h, 'hour');\n    }\n    if (msAbs >= m) {\n        return plural(ms, msAbs, m, 'minute');\n    }\n    if (msAbs >= s) {\n        return plural(ms, msAbs, s, 'second');\n    }\n    return `${ms} ms`;\n}\n/**\n * Pluralization helper.\n */\nfunction plural(ms, msAbs, n, name) {\n    const isPlural = msAbs >= n * 1.5;\n    return `${Math.round(ms / n)} ${name}${isPlural ? 's' : ''}`;\n}\n/**\n * A type guard for errors.\n */\nfunction isError(error) {\n    return typeof error === 'object' && error !== null && 'message' in error;\n}\n","/* eslint-disable no-console */\n/* eslint-disable @typescript-eslint/strict-boolean-expressions */\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\nimport humanize from 'ms';\nexport default function setup(env) {\n    createDebug.debug = createDebug;\n    createDebug.default = createDebug;\n    createDebug.coerce = coerce;\n    createDebug.disable = disable;\n    createDebug.enable = enable;\n    createDebug.enabled = enabled;\n    createDebug.humanize = humanize;\n    createDebug.destroy = destroy;\n    Object.keys(env).forEach(key => {\n        // @ts-expect-error cannot use string to index type\n        createDebug[key] = env[key];\n    });\n    /**\n     * The currently active debug mode names, and names to skip.\n     */\n    createDebug.names = [];\n    createDebug.skips = [];\n    /**\n     * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n     *\n     * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n     */\n    createDebug.formatters = {};\n    /**\n     * Selects a color for a debug namespace\n     *\n     * @param {string} namespace - The namespace string for the debug instance to be colored\n     * @returns {number | string} An ANSI color code for the given namespace\n     */\n    function selectColor(namespace) {\n        let hash = 0;\n        for (let i = 0; i < namespace.length; i++) {\n            hash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n            hash |= 0; // Convert to 32bit integer\n        }\n        // @ts-expect-error colors is not in the types\n        return createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n    }\n    createDebug.selectColor = selectColor;\n    /**\n     * Create a debugger with the given `namespace`.\n     *\n     * @param {string} namespace\n     * @returns {Function}\n     */\n    function createDebug(namespace) {\n        let prevTime;\n        let enableOverride = null;\n        let namespacesCache;\n        let enabledCache;\n        function debug(...args) {\n            // Disabled?\n            // @ts-expect-error enabled is not in the types\n            if (!debug.enabled) {\n                return;\n            }\n            const self = debug;\n            // Set `diff` timestamp\n            const curr = Number(new Date());\n            const ms = curr - (prevTime || curr);\n            self.diff = ms;\n            self.prev = prevTime;\n            self.curr = curr;\n            prevTime = curr;\n            args[0] = createDebug.coerce(args[0]);\n            if (typeof args[0] !== 'string') {\n                // Anything else let's inspect with %O\n                args.unshift('%O');\n            }\n            // Apply any `formatters` transformations\n            let index = 0;\n            args[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n                // If we encounter an escaped % then don't increase the array index\n                if (match === '%%') {\n                    return '%';\n                }\n                index++;\n                // @ts-expect-error formatters is not in the types\n                const formatter = createDebug.formatters[format];\n                if (typeof formatter === 'function') {\n                    const val = args[index];\n                    match = formatter.call(self, val);\n                    // Now we need to remove `args[index]` since it's inlined in the `format`\n                    args.splice(index, 1);\n                    index--;\n                }\n                return match;\n            });\n            // Apply env-specific formatting (colors, etc.)\n            // @ts-expect-error formatArgs is not in the types\n            createDebug.formatArgs.call(self, args);\n            // @ts-expect-error log is not in the types\n            const logFn = self.log || createDebug.log;\n            logFn.apply(self, args);\n        }\n        debug.namespace = namespace;\n        // @ts-expect-error useColors is not in the types\n        debug.useColors = createDebug.useColors();\n        debug.color = createDebug.selectColor(namespace);\n        debug.extend = extend;\n        debug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n        Object.defineProperty(debug, 'enabled', {\n            enumerable: true,\n            configurable: false,\n            get: () => {\n                if (enableOverride !== null) {\n                    return enableOverride;\n                }\n                // @ts-expect-error namespaces is not in the types\n                if (namespacesCache !== createDebug.namespaces) {\n                    // @ts-expect-error namespaces is not in the types\n                    namespacesCache = createDebug.namespaces;\n                    enabledCache = createDebug.enabled(namespace);\n                }\n                return enabledCache;\n            },\n            set: v => {\n                enableOverride = v;\n            }\n        });\n        // Env-specific initialization logic for debug instances\n        // @ts-expect-error init is not in the types\n        if (typeof createDebug.init === 'function') {\n            // @ts-expect-error init is not in the types\n            createDebug.init(debug);\n        }\n        // @ts-expect-error some properties are added dynamically\n        return debug;\n    }\n    function extend(namespace, delimiter) {\n        const newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n        newDebug.log = this.log;\n        return newDebug;\n    }\n    /**\n     * Enables a debug mode by namespaces. This can include modes\n     * separated by a colon and wildcards.\n     *\n     * @param {string} namespaces\n     */\n    function enable(namespaces) {\n        // @ts-expect-error save is not in the types\n        createDebug.save(namespaces);\n        // @ts-expect-error namespaces is not in the types\n        createDebug.namespaces = namespaces;\n        createDebug.names = [];\n        createDebug.skips = [];\n        let i;\n        const split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n        const len = split.length;\n        for (i = 0; i < len; i++) {\n            if (!split[i]) {\n                // ignore empty strings\n                continue;\n            }\n            namespaces = split[i].replace(/\\*/g, '.*?');\n            if (namespaces[0] === '-') {\n                createDebug.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n            }\n            else {\n                createDebug.names.push(new RegExp('^' + namespaces + '$'));\n            }\n        }\n    }\n    /**\n     * Disable debug output.\n     *\n     * @returns {string} namespaces\n     */\n    function disable() {\n        const namespaces = [\n            ...createDebug.names.map(toNamespace),\n            ...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n        ].join(',');\n        createDebug.enable('');\n        return namespaces;\n    }\n    /**\n     * Returns true if the given mode name is enabled, false otherwise.\n     *\n     * @param {string} name\n     * @returns {boolean}\n     */\n    function enabled(name) {\n        if (name[name.length - 1] === '*') {\n            return true;\n        }\n        let i;\n        let len;\n        for (i = 0, len = createDebug.skips.length; i < len; i++) {\n            if (createDebug.skips[i].test(name)) {\n                return false;\n            }\n        }\n        for (i = 0, len = createDebug.names.length; i < len; i++) {\n            if (createDebug.names[i].test(name)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Convert regexp to namespace\n     */\n    function toNamespace(regexp) {\n        return regexp.toString()\n            .substring(2, regexp.toString().length - 2)\n            .replace(/\\.\\*\\?$/, '*');\n    }\n    /**\n     * Coerce `val`.\n     */\n    function coerce(val) {\n        if (val instanceof Error) {\n            return val.stack ?? val.message;\n        }\n        return val;\n    }\n    /**\n     * XXX DO NOT USE. This is a temporary stub function.\n     * XXX It WILL be removed in the next major release.\n     */\n    function destroy() {\n        console.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n    }\n    // @ts-expect-error setupFormatters is not in the types\n    createDebug.setupFormatters(createDebug.formatters);\n    // @ts-expect-error load is not in the types\n    createDebug.enable(createDebug.load());\n    // @ts-expect-error some properties are added dynamically\n    return createDebug;\n}\n//# sourceMappingURL=common.js.map","/* eslint-disable no-console */\n/* eslint-disable @typescript-eslint/restrict-plus-operands */\n/* eslint-disable @typescript-eslint/strict-boolean-expressions */\n/* eslint-env browser */\n/**\n * This is the web browser implementation of `debug()`.\n */\nimport humanize from 'ms';\nimport setup from './common.js';\nconst storage = localstorage();\n/**\n * Colors.\n */\nconst colors = [\n    '#0000CC',\n    '#0000FF',\n    '#0033CC',\n    '#0033FF',\n    '#0066CC',\n    '#0066FF',\n    '#0099CC',\n    '#0099FF',\n    '#00CC00',\n    '#00CC33',\n    '#00CC66',\n    '#00CC99',\n    '#00CCCC',\n    '#00CCFF',\n    '#3300CC',\n    '#3300FF',\n    '#3333CC',\n    '#3333FF',\n    '#3366CC',\n    '#3366FF',\n    '#3399CC',\n    '#3399FF',\n    '#33CC00',\n    '#33CC33',\n    '#33CC66',\n    '#33CC99',\n    '#33CCCC',\n    '#33CCFF',\n    '#6600CC',\n    '#6600FF',\n    '#6633CC',\n    '#6633FF',\n    '#66CC00',\n    '#66CC33',\n    '#9900CC',\n    '#9900FF',\n    '#9933CC',\n    '#9933FF',\n    '#99CC00',\n    '#99CC33',\n    '#CC0000',\n    '#CC0033',\n    '#CC0066',\n    '#CC0099',\n    '#CC00CC',\n    '#CC00FF',\n    '#CC3300',\n    '#CC3333',\n    '#CC3366',\n    '#CC3399',\n    '#CC33CC',\n    '#CC33FF',\n    '#CC6600',\n    '#CC6633',\n    '#CC9900',\n    '#CC9933',\n    '#CCCC00',\n    '#CCCC33',\n    '#FF0000',\n    '#FF0033',\n    '#FF0066',\n    '#FF0099',\n    '#FF00CC',\n    '#FF00FF',\n    '#FF3300',\n    '#FF3333',\n    '#FF3366',\n    '#FF3399',\n    '#FF33CC',\n    '#FF33FF',\n    '#FF6600',\n    '#FF6633',\n    '#FF9900',\n    '#FF9933',\n    '#FFCC00',\n    '#FFCC33'\n];\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n// eslint-disable-next-line complexity\nfunction useColors() {\n    // NB: In an Electron preload script, document will be defined but not fully\n    // initialized. Since we know we're in Chrome, we'll just detect this case\n    // explicitly\n    // @ts-expect-error window.process.type and window.process.__nwjs are not in the types\n    if (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n        return true;\n    }\n    // Internet Explorer and Edge do not support colors.\n    if (typeof navigator !== 'undefined' && (navigator.userAgent?.toLowerCase().match(/(edge|trident)\\/(\\d+)/) != null)) {\n        return false;\n    }\n    // Is webkit? http://stackoverflow.com/a/16459606/376773\n    // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n    // @ts-expect-error document.documentElement.style.WebkitAppearance is not in the types\n    return (typeof document !== 'undefined' && document.documentElement?.style?.WebkitAppearance) ||\n        // Is firebug? http://stackoverflow.com/a/398120/376773\n        // @ts-expect-error window.console.firebug and window.console.exception are not in the types\n        (typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n        // Is firefox >= v31?\n        // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n        (typeof navigator !== 'undefined' && (navigator.userAgent?.toLowerCase().match(/firefox\\/(\\d+)/) != null) && parseInt(RegExp.$1, 10) >= 31) ||\n        // Double check webkit in userAgent just in case we are in a worker\n        (typeof navigator !== 'undefined' && navigator.userAgent?.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n/**\n * Colorize log arguments if enabled.\n */\nfunction formatArgs(args) {\n    args[0] = (this.useColors ? '%c' : '') +\n        this.namespace +\n        (this.useColors ? ' %c' : ' ') +\n        args[0] +\n        (this.useColors ? '%c ' : ' ') +\n        '+' + humanize(this.diff);\n    if (!this.useColors) {\n        return;\n    }\n    const c = 'color: ' + this.color;\n    args.splice(1, 0, c, 'color: inherit');\n    // The final \"%c\" is somewhat tricky, because there could be other\n    // arguments passed either before or after the %c, so we need to\n    // figure out the correct index to insert the CSS into\n    let index = 0;\n    let lastC = 0;\n    args[0].replace(/%[a-zA-Z%]/g, (match) => {\n        if (match === '%%') {\n            return;\n        }\n        index++;\n        if (match === '%c') {\n            // We only are interested in the *last* %c\n            // (the user may have provided their own)\n            lastC = index;\n        }\n    });\n    args.splice(lastC, 0, c);\n}\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a \"function\".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n */\nconst log = console.debug ?? console.log ?? (() => { });\n/**\n * Save `namespaces`.\n *\n * @param {string} namespaces\n */\nfunction save(namespaces) {\n    try {\n        if (namespaces) {\n            storage?.setItem('debug', namespaces);\n        }\n        else {\n            storage?.removeItem('debug');\n        }\n    }\n    catch (error) {\n        // Swallow\n        // XXX (@Qix-) should we be logging these?\n    }\n}\n/**\n * Load `namespaces`.\n *\n * @returns {string} returns the previously persisted debug modes\n */\nfunction load() {\n    let r;\n    try {\n        r = storage?.getItem('debug');\n    }\n    catch (error) {\n        // Swallow\n        // XXX (@Qix-) should we be logging these?\n    }\n    // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n    if (!r && typeof globalThis.process !== 'undefined' && 'env' in globalThis.process) {\n        r = globalThis.process.env.DEBUG;\n    }\n    return r;\n}\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n */\nfunction localstorage() {\n    try {\n        // TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n        // The Browser also has localStorage in the global context.\n        return localStorage;\n    }\n    catch (error) {\n        // Swallow\n        // XXX (@Qix-) should we be logging these?\n    }\n}\nfunction setupFormatters(formatters) {\n    /**\n     * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n     */\n    formatters.j = function (v) {\n        try {\n            return JSON.stringify(v);\n        }\n        catch (error) {\n            return '[UnexpectedJSONParseError]: ' + error.message;\n        }\n    };\n}\nexport default setup({ formatArgs, save, load, useColors, setupFormatters, colors, storage, log });\n//# sourceMappingURL=browser.js.map","/**\n * @packageDocumentation\n *\n * This module is a fork of the [debug](https://www.npmjs.com/package/debug) module. It has been converted to TypeScript and the output is ESM.\n *\n * It is API compatible with no extra features or bug fixes, it should only be used if you want a 100% ESM application.\n *\n * ESM should be arriving in `debug@5.x.x` so this module can be retired after that.\n *\n * Please see [debug](https://www.npmjs.com/package/debug) for API details.\n */\n/**\n * Module dependencies.\n */\nimport weald from './node.js';\nexport default weald;\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * A logger for libp2p based on [weald](https://www.npmjs.com/package/weald), a TypeScript port of the venerable [debug](https://www.npmjs.com/package/debug) module.\n *\n * @example\n *\n * ```TypeScript\n * import { logger } from '@libp2p/logger'\n *\n * const log = logger('libp2p:my:component:name')\n *\n * try {\n *   // an operation\n *   log('something happened: %s', 'it was ok')\n * } catch (err) {\n *   log.error('something bad happened: %o', err)\n * }\n *\n * log('with this peer: %p', {})\n * log('and this base58btc: %b', Uint8Array.from([0, 1, 2, 3]))\n * log('and this base32: %t', Uint8Array.from([4, 5, 6, 7]))\n * ```\n *\n * ```console\n * $ DEBUG=libp2p:* node index.js\n * something happened: it was ok\n * something bad happened: <stack trace>\n * with this peer: 12D3Foo\n * with this base58btc: Qmfoo\n * with this base32: bafyfoo\n * ```\n */\nimport { base32 } from 'multiformats/bases/base32';\nimport { base58btc } from 'multiformats/bases/base58';\nimport { base64 } from 'multiformats/bases/base64';\nimport debug from 'weald';\nimport { truncatePeerId } from './utils.js';\n// Add a formatter for converting to a base58 string\ndebug.formatters.b = (v) => {\n    return v == null ? 'undefined' : base58btc.baseEncode(v);\n};\n// Add a formatter for converting to a base32 string\ndebug.formatters.t = (v) => {\n    return v == null ? 'undefined' : base32.baseEncode(v);\n};\n// Add a formatter for converting to a base64 string\ndebug.formatters.m = (v) => {\n    return v == null ? 'undefined' : base64.baseEncode(v);\n};\n// Add a formatter for stringifying peer ids\ndebug.formatters.p = (v) => {\n    return v == null ? 'undefined' : v.toString();\n};\n// Add a formatter for stringifying CIDs\ndebug.formatters.c = (v) => {\n    return v == null ? 'undefined' : v.toString();\n};\n// Add a formatter for stringifying Datastore keys\ndebug.formatters.k = (v) => {\n    return v == null ? 'undefined' : v.toString();\n};\n// Add a formatter for stringifying Multiaddrs\ndebug.formatters.a = (v) => {\n    return v == null ? 'undefined' : v.toString();\n};\n// Add a formatter for stringifying Errors\ndebug.formatters.e = (v) => {\n    return v == null ? 'undefined' : notEmpty(v.stack) ?? notEmpty(v.message) ?? v.toString();\n};\nfunction createDisabledLogger(namespace) {\n    const logger = () => { };\n    logger.enabled = false;\n    logger.color = '';\n    logger.diff = 0;\n    logger.log = () => { };\n    logger.namespace = namespace;\n    logger.destroy = () => true;\n    logger.extend = () => logger;\n    return logger;\n}\n/**\n * Create a component logger that will prefix any log messages with a truncated\n * peer id.\n *\n * @example\n *\n * ```TypeScript\n * import { peerLogger } from '@libp2p/logger'\n * import { peerIdFromString } from '@libp2p/peer-id'\n *\n * const peerId = peerIdFromString('12D3FooBar')\n * const logger = peerLogger(peerId)\n *\n * const log = logger.forComponent('my-component')\n * log.info('hello world')\n * // logs \"12oBar:my-component hello world\"\n * ```\n */\nexport function peerLogger(peerId, options = {}) {\n    return prefixLogger(truncatePeerId(peerId, options));\n}\n/**\n * Create a component logger that will prefix any log messages with the passed\n * string.\n *\n * @example\n *\n * ```TypeScript\n * import { prefixLogger } from '@libp2p/logger'\n *\n * const logger = prefixLogger('my-node')\n *\n * const log = logger.forComponent('my-component')\n * log.info('hello world')\n * // logs \"my-node:my-component hello world\"\n * ```\n */\nexport function prefixLogger(prefix) {\n    return {\n        forComponent(name) {\n            return logger(`${prefix}:${name}`);\n        }\n    };\n}\n/**\n * Create a component logger\n *\n * @example\n *\n * ```TypeScript\n * import { defaultLogger } from '@libp2p/logger'\n * import { peerIdFromString } from '@libp2p/peer-id'\n *\n * const logger = defaultLogger()\n *\n * const log = logger.forComponent('my-component')\n * log.info('hello world')\n * // logs \"my-component hello world\"\n * ```\n */\nexport function defaultLogger() {\n    return {\n        forComponent(name) {\n            return logger(name);\n        }\n    };\n}\n/**\n * Creates a logger for the passed component name.\n *\n * @example\n *\n * ```TypeScript\n * import { logger } from '@libp2p/logger'\n *\n * const log = logger('my-component')\n * log.info('hello world')\n * // logs \"my-component hello world\"\n * ```\n */\nexport function logger(name) {\n    // trace logging is a no-op by default\n    let trace = createDisabledLogger(`${name}:trace`);\n    // look at all the debug names and see if trace logging has explicitly been enabled\n    if (debug.enabled(`${name}:trace`) && debug.names.map((r) => r.toString()).find((n) => n.includes(':trace')) != null) {\n        trace = debug(`${name}:trace`);\n    }\n    return Object.assign(debug(name), {\n        error: debug(`${name}:error`),\n        trace\n    });\n}\nexport function disable() {\n    debug.disable();\n}\nexport function enable(namespaces) {\n    debug.enable(namespaces);\n}\nexport function enabled(namespaces) {\n    return debug.enabled(namespaces);\n}\nfunction notEmpty(str) {\n    if (str == null) {\n        return;\n    }\n    str = str.trim();\n    if (str.length === 0) {\n        return;\n    }\n    return str;\n}\n//# sourceMappingURL=index.js.map","import { HashMD } from './_md.js';\nimport u64 from './_u64.js';\nimport { wrapConstructor } from './utils.js';\n// Round contants (first 32 bits of the fractional parts of the cube roots of the first 80 primes 2..409):\n// prettier-ignore\nconst [SHA512_Kh, SHA512_Kl] = /* @__PURE__ */ (() => u64.split([\n    '0x428a2f98d728ae22', '0x7137449123ef65cd', '0xb5c0fbcfec4d3b2f', '0xe9b5dba58189dbbc',\n    '0x3956c25bf348b538', '0x59f111f1b605d019', '0x923f82a4af194f9b', '0xab1c5ed5da6d8118',\n    '0xd807aa98a3030242', '0x12835b0145706fbe', '0x243185be4ee4b28c', '0x550c7dc3d5ffb4e2',\n    '0x72be5d74f27b896f', '0x80deb1fe3b1696b1', '0x9bdc06a725c71235', '0xc19bf174cf692694',\n    '0xe49b69c19ef14ad2', '0xefbe4786384f25e3', '0x0fc19dc68b8cd5b5', '0x240ca1cc77ac9c65',\n    '0x2de92c6f592b0275', '0x4a7484aa6ea6e483', '0x5cb0a9dcbd41fbd4', '0x76f988da831153b5',\n    '0x983e5152ee66dfab', '0xa831c66d2db43210', '0xb00327c898fb213f', '0xbf597fc7beef0ee4',\n    '0xc6e00bf33da88fc2', '0xd5a79147930aa725', '0x06ca6351e003826f', '0x142929670a0e6e70',\n    '0x27b70a8546d22ffc', '0x2e1b21385c26c926', '0x4d2c6dfc5ac42aed', '0x53380d139d95b3df',\n    '0x650a73548baf63de', '0x766a0abb3c77b2a8', '0x81c2c92e47edaee6', '0x92722c851482353b',\n    '0xa2bfe8a14cf10364', '0xa81a664bbc423001', '0xc24b8b70d0f89791', '0xc76c51a30654be30',\n    '0xd192e819d6ef5218', '0xd69906245565a910', '0xf40e35855771202a', '0x106aa07032bbd1b8',\n    '0x19a4c116b8d2d0c8', '0x1e376c085141ab53', '0x2748774cdf8eeb99', '0x34b0bcb5e19b48a8',\n    '0x391c0cb3c5c95a63', '0x4ed8aa4ae3418acb', '0x5b9cca4f7763e373', '0x682e6ff3d6b2b8a3',\n    '0x748f82ee5defb2fc', '0x78a5636f43172f60', '0x84c87814a1f0ab72', '0x8cc702081a6439ec',\n    '0x90befffa23631e28', '0xa4506cebde82bde9', '0xbef9a3f7b2c67915', '0xc67178f2e372532b',\n    '0xca273eceea26619c', '0xd186b8c721c0c207', '0xeada7dd6cde0eb1e', '0xf57d4f7fee6ed178',\n    '0x06f067aa72176fba', '0x0a637dc5a2c898a6', '0x113f9804bef90dae', '0x1b710b35131c471b',\n    '0x28db77f523047d84', '0x32caab7b40c72493', '0x3c9ebe0a15c9bebc', '0x431d67c49c100d4c',\n    '0x4cc5d4becb3e42b6', '0x597f299cfc657e2a', '0x5fcb6fab3ad6faec', '0x6c44198c4a475817'\n].map(n => BigInt(n))))();\n// Temporary buffer, not used to store anything between runs\nconst SHA512_W_H = /* @__PURE__ */ new Uint32Array(80);\nconst SHA512_W_L = /* @__PURE__ */ new Uint32Array(80);\nexport class SHA512 extends HashMD {\n    constructor() {\n        super(128, 64, 16, false);\n        // We cannot use array here since array allows indexing by variable which means optimizer/compiler cannot use registers.\n        // Also looks cleaner and easier to verify with spec.\n        // Initial state (first 32 bits of the fractional parts of the square roots of the first 8 primes 2..19):\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0x6a09e667 | 0;\n        this.Al = 0xf3bcc908 | 0;\n        this.Bh = 0xbb67ae85 | 0;\n        this.Bl = 0x84caa73b | 0;\n        this.Ch = 0x3c6ef372 | 0;\n        this.Cl = 0xfe94f82b | 0;\n        this.Dh = 0xa54ff53a | 0;\n        this.Dl = 0x5f1d36f1 | 0;\n        this.Eh = 0x510e527f | 0;\n        this.El = 0xade682d1 | 0;\n        this.Fh = 0x9b05688c | 0;\n        this.Fl = 0x2b3e6c1f | 0;\n        this.Gh = 0x1f83d9ab | 0;\n        this.Gl = 0xfb41bd6b | 0;\n        this.Hh = 0x5be0cd19 | 0;\n        this.Hl = 0x137e2179 | 0;\n    }\n    // prettier-ignore\n    get() {\n        const { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n        return [Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl];\n    }\n    // prettier-ignore\n    set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl) {\n        this.Ah = Ah | 0;\n        this.Al = Al | 0;\n        this.Bh = Bh | 0;\n        this.Bl = Bl | 0;\n        this.Ch = Ch | 0;\n        this.Cl = Cl | 0;\n        this.Dh = Dh | 0;\n        this.Dl = Dl | 0;\n        this.Eh = Eh | 0;\n        this.El = El | 0;\n        this.Fh = Fh | 0;\n        this.Fl = Fl | 0;\n        this.Gh = Gh | 0;\n        this.Gl = Gl | 0;\n        this.Hh = Hh | 0;\n        this.Hl = Hl | 0;\n    }\n    process(view, offset) {\n        // Extend the first 16 words into the remaining 64 words w[16..79] of the message schedule array\n        for (let i = 0; i < 16; i++, offset += 4) {\n            SHA512_W_H[i] = view.getUint32(offset);\n            SHA512_W_L[i] = view.getUint32((offset += 4));\n        }\n        for (let i = 16; i < 80; i++) {\n            // s0 := (w[i-15] rightrotate 1) xor (w[i-15] rightrotate 8) xor (w[i-15] rightshift 7)\n            const W15h = SHA512_W_H[i - 15] | 0;\n            const W15l = SHA512_W_L[i - 15] | 0;\n            const s0h = u64.rotrSH(W15h, W15l, 1) ^ u64.rotrSH(W15h, W15l, 8) ^ u64.shrSH(W15h, W15l, 7);\n            const s0l = u64.rotrSL(W15h, W15l, 1) ^ u64.rotrSL(W15h, W15l, 8) ^ u64.shrSL(W15h, W15l, 7);\n            // s1 := (w[i-2] rightrotate 19) xor (w[i-2] rightrotate 61) xor (w[i-2] rightshift 6)\n            const W2h = SHA512_W_H[i - 2] | 0;\n            const W2l = SHA512_W_L[i - 2] | 0;\n            const s1h = u64.rotrSH(W2h, W2l, 19) ^ u64.rotrBH(W2h, W2l, 61) ^ u64.shrSH(W2h, W2l, 6);\n            const s1l = u64.rotrSL(W2h, W2l, 19) ^ u64.rotrBL(W2h, W2l, 61) ^ u64.shrSL(W2h, W2l, 6);\n            // SHA256_W[i] = s0 + s1 + SHA256_W[i - 7] + SHA256_W[i - 16];\n            const SUMl = u64.add4L(s0l, s1l, SHA512_W_L[i - 7], SHA512_W_L[i - 16]);\n            const SUMh = u64.add4H(SUMl, s0h, s1h, SHA512_W_H[i - 7], SHA512_W_H[i - 16]);\n            SHA512_W_H[i] = SUMh | 0;\n            SHA512_W_L[i] = SUMl | 0;\n        }\n        let { Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl } = this;\n        // Compression function main loop, 80 rounds\n        for (let i = 0; i < 80; i++) {\n            // S1 := (e rightrotate 14) xor (e rightrotate 18) xor (e rightrotate 41)\n            const sigma1h = u64.rotrSH(Eh, El, 14) ^ u64.rotrSH(Eh, El, 18) ^ u64.rotrBH(Eh, El, 41);\n            const sigma1l = u64.rotrSL(Eh, El, 14) ^ u64.rotrSL(Eh, El, 18) ^ u64.rotrBL(Eh, El, 41);\n            //const T1 = (H + sigma1 + Chi(E, F, G) + SHA256_K[i] + SHA256_W[i]) | 0;\n            const CHIh = (Eh & Fh) ^ (~Eh & Gh);\n            const CHIl = (El & Fl) ^ (~El & Gl);\n            // T1 = H + sigma1 + Chi(E, F, G) + SHA512_K[i] + SHA512_W[i]\n            // prettier-ignore\n            const T1ll = u64.add5L(Hl, sigma1l, CHIl, SHA512_Kl[i], SHA512_W_L[i]);\n            const T1h = u64.add5H(T1ll, Hh, sigma1h, CHIh, SHA512_Kh[i], SHA512_W_H[i]);\n            const T1l = T1ll | 0;\n            // S0 := (a rightrotate 28) xor (a rightrotate 34) xor (a rightrotate 39)\n            const sigma0h = u64.rotrSH(Ah, Al, 28) ^ u64.rotrBH(Ah, Al, 34) ^ u64.rotrBH(Ah, Al, 39);\n            const sigma0l = u64.rotrSL(Ah, Al, 28) ^ u64.rotrBL(Ah, Al, 34) ^ u64.rotrBL(Ah, Al, 39);\n            const MAJh = (Ah & Bh) ^ (Ah & Ch) ^ (Bh & Ch);\n            const MAJl = (Al & Bl) ^ (Al & Cl) ^ (Bl & Cl);\n            Hh = Gh | 0;\n            Hl = Gl | 0;\n            Gh = Fh | 0;\n            Gl = Fl | 0;\n            Fh = Eh | 0;\n            Fl = El | 0;\n            ({ h: Eh, l: El } = u64.add(Dh | 0, Dl | 0, T1h | 0, T1l | 0));\n            Dh = Ch | 0;\n            Dl = Cl | 0;\n            Ch = Bh | 0;\n            Cl = Bl | 0;\n            Bh = Ah | 0;\n            Bl = Al | 0;\n            const All = u64.add3L(T1l, sigma0l, MAJl);\n            Ah = u64.add3H(All, T1h, sigma0h, MAJh);\n            Al = All | 0;\n        }\n        // Add the compressed chunk to the current hash value\n        ({ h: Ah, l: Al } = u64.add(this.Ah | 0, this.Al | 0, Ah | 0, Al | 0));\n        ({ h: Bh, l: Bl } = u64.add(this.Bh | 0, this.Bl | 0, Bh | 0, Bl | 0));\n        ({ h: Ch, l: Cl } = u64.add(this.Ch | 0, this.Cl | 0, Ch | 0, Cl | 0));\n        ({ h: Dh, l: Dl } = u64.add(this.Dh | 0, this.Dl | 0, Dh | 0, Dl | 0));\n        ({ h: Eh, l: El } = u64.add(this.Eh | 0, this.El | 0, Eh | 0, El | 0));\n        ({ h: Fh, l: Fl } = u64.add(this.Fh | 0, this.Fl | 0, Fh | 0, Fl | 0));\n        ({ h: Gh, l: Gl } = u64.add(this.Gh | 0, this.Gl | 0, Gh | 0, Gl | 0));\n        ({ h: Hh, l: Hl } = u64.add(this.Hh | 0, this.Hl | 0, Hh | 0, Hl | 0));\n        this.set(Ah, Al, Bh, Bl, Ch, Cl, Dh, Dl, Eh, El, Fh, Fl, Gh, Gl, Hh, Hl);\n    }\n    roundClean() {\n        SHA512_W_H.fill(0);\n        SHA512_W_L.fill(0);\n    }\n    destroy() {\n        this.buffer.fill(0);\n        this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    }\n}\nexport class SHA512_224 extends SHA512 {\n    constructor() {\n        super();\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0x8c3d37c8 | 0;\n        this.Al = 0x19544da2 | 0;\n        this.Bh = 0x73e19966 | 0;\n        this.Bl = 0x89dcd4d6 | 0;\n        this.Ch = 0x1dfab7ae | 0;\n        this.Cl = 0x32ff9c82 | 0;\n        this.Dh = 0x679dd514 | 0;\n        this.Dl = 0x582f9fcf | 0;\n        this.Eh = 0x0f6d2b69 | 0;\n        this.El = 0x7bd44da8 | 0;\n        this.Fh = 0x77e36f73 | 0;\n        this.Fl = 0x04c48942 | 0;\n        this.Gh = 0x3f9d85a8 | 0;\n        this.Gl = 0x6a1d36c8 | 0;\n        this.Hh = 0x1112e6ad | 0;\n        this.Hl = 0x91d692a1 | 0;\n        this.outputLen = 28;\n    }\n}\nexport class SHA512_256 extends SHA512 {\n    constructor() {\n        super();\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0x22312194 | 0;\n        this.Al = 0xfc2bf72c | 0;\n        this.Bh = 0x9f555fa3 | 0;\n        this.Bl = 0xc84c64c2 | 0;\n        this.Ch = 0x2393b86b | 0;\n        this.Cl = 0x6f53b151 | 0;\n        this.Dh = 0x96387719 | 0;\n        this.Dl = 0x5940eabd | 0;\n        this.Eh = 0x96283ee2 | 0;\n        this.El = 0xa88effe3 | 0;\n        this.Fh = 0xbe5e1e25 | 0;\n        this.Fl = 0x53863992 | 0;\n        this.Gh = 0x2b0199fc | 0;\n        this.Gl = 0x2c85b8aa | 0;\n        this.Hh = 0x0eb72ddc | 0;\n        this.Hl = 0x81c52ca2 | 0;\n        this.outputLen = 32;\n    }\n}\nexport class SHA384 extends SHA512 {\n    constructor() {\n        super();\n        // h -- high 32 bits, l -- low 32 bits\n        this.Ah = 0xcbbb9d5d | 0;\n        this.Al = 0xc1059ed8 | 0;\n        this.Bh = 0x629a292a | 0;\n        this.Bl = 0x367cd507 | 0;\n        this.Ch = 0x9159015a | 0;\n        this.Cl = 0x3070dd17 | 0;\n        this.Dh = 0x152fecd8 | 0;\n        this.Dl = 0xf70e5939 | 0;\n        this.Eh = 0x67332667 | 0;\n        this.El = 0xffc00b31 | 0;\n        this.Fh = 0x8eb44a87 | 0;\n        this.Fl = 0x68581511 | 0;\n        this.Gh = 0xdb0c2e0d | 0;\n        this.Gl = 0x64f98fa7 | 0;\n        this.Hh = 0x47b5481d | 0;\n        this.Hl = 0xbefa4fa4 | 0;\n        this.outputLen = 48;\n    }\n}\nexport const sha512 = /* @__PURE__ */ wrapConstructor(() => new SHA512());\nexport const sha512_224 = /* @__PURE__ */ wrapConstructor(() => new SHA512_224());\nexport const sha512_256 = /* @__PURE__ */ wrapConstructor(() => new SHA512_256());\nexport const sha384 = /* @__PURE__ */ wrapConstructor(() => new SHA384());\n//# sourceMappingURL=sha512.js.map","/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// Utilities for modular arithmetics and finite fields\nimport { bitMask, bytesToNumberBE, bytesToNumberLE, ensureBytes, numberToBytesBE, numberToBytesLE, validateObject, } from './utils.js';\n// prettier-ignore\nconst _0n = BigInt(0), _1n = BigInt(1), _2n = BigInt(2), _3n = BigInt(3);\n// prettier-ignore\nconst _4n = BigInt(4), _5n = BigInt(5), _8n = BigInt(8);\n// prettier-ignore\nconst _9n = BigInt(9), _16n = BigInt(16);\n// Calculates a modulo b\nexport function mod(a, b) {\n    const result = a % b;\n    return result >= _0n ? result : b + result;\n}\n/**\n * Efficiently raise num to power and do modular division.\n * Unsafe in some contexts: uses ladder, so can expose bigint bits.\n * @example\n * pow(2n, 6n, 11n) // 64n % 11n == 9n\n */\n// TODO: use field version && remove\nexport function pow(num, power, modulo) {\n    if (modulo <= _0n || power < _0n)\n        throw new Error('Expected power/modulo > 0');\n    if (modulo === _1n)\n        return _0n;\n    let res = _1n;\n    while (power > _0n) {\n        if (power & _1n)\n            res = (res * num) % modulo;\n        num = (num * num) % modulo;\n        power >>= _1n;\n    }\n    return res;\n}\n// Does x ^ (2 ^ power) mod p. pow2(30, 4) == 30 ^ (2 ^ 4)\nexport function pow2(x, power, modulo) {\n    let res = x;\n    while (power-- > _0n) {\n        res *= res;\n        res %= modulo;\n    }\n    return res;\n}\n// Inverses number over modulo\nexport function invert(number, modulo) {\n    if (number === _0n || modulo <= _0n) {\n        throw new Error(`invert: expected positive integers, got n=${number} mod=${modulo}`);\n    }\n    // Euclidean GCD https://brilliant.org/wiki/extended-euclidean-algorithm/\n    // Fermat's little theorem \"CT-like\" version inv(n) = n^(m-2) mod m is 30x slower.\n    let a = mod(number, modulo);\n    let b = modulo;\n    // prettier-ignore\n    let x = _0n, y = _1n, u = _1n, v = _0n;\n    while (a !== _0n) {\n        // JIT applies optimization if those two lines follow each other\n        const q = b / a;\n        const r = b % a;\n        const m = x - u * q;\n        const n = y - v * q;\n        // prettier-ignore\n        b = a, a = r, x = u, y = v, u = m, v = n;\n    }\n    const gcd = b;\n    if (gcd !== _1n)\n        throw new Error('invert: does not exist');\n    return mod(x, modulo);\n}\n/**\n * Tonelli-Shanks square root search algorithm.\n * 1. https://eprint.iacr.org/2012/685.pdf (page 12)\n * 2. Square Roots from 1; 24, 51, 10 to Dan Shanks\n * Will start an infinite loop if field order P is not prime.\n * @param P field order\n * @returns function that takes field Fp (created from P) and number n\n */\nexport function tonelliShanks(P) {\n    // Legendre constant: used to calculate Legendre symbol (a | p),\n    // which denotes the value of a^((p-1)/2) (mod p).\n    // (a | p)  1    if a is a square (mod p)\n    // (a | p)  -1   if a is not a square (mod p)\n    // (a | p)  0    if a  0 (mod p)\n    const legendreC = (P - _1n) / _2n;\n    let Q, S, Z;\n    // Step 1: By factoring out powers of 2 from p - 1,\n    // find q and s such that p - 1 = q*(2^s) with q odd\n    for (Q = P - _1n, S = 0; Q % _2n === _0n; Q /= _2n, S++)\n        ;\n    // Step 2: Select a non-square z such that (z | p)  -1 and set c  zq\n    for (Z = _2n; Z < P && pow(Z, legendreC, P) !== P - _1n; Z++)\n        ;\n    // Fast-path\n    if (S === 1) {\n        const p1div4 = (P + _1n) / _4n;\n        return function tonelliFast(Fp, n) {\n            const root = Fp.pow(n, p1div4);\n            if (!Fp.eql(Fp.sqr(root), n))\n                throw new Error('Cannot find square root');\n            return root;\n        };\n    }\n    // Slow-path\n    const Q1div2 = (Q + _1n) / _2n;\n    return function tonelliSlow(Fp, n) {\n        // Step 0: Check that n is indeed a square: (n | p) should not be  -1\n        if (Fp.pow(n, legendreC) === Fp.neg(Fp.ONE))\n            throw new Error('Cannot find square root');\n        let r = S;\n        // TODO: will fail at Fp2/etc\n        let g = Fp.pow(Fp.mul(Fp.ONE, Z), Q); // will update both x and b\n        let x = Fp.pow(n, Q1div2); // first guess at the square root\n        let b = Fp.pow(n, Q); // first guess at the fudge factor\n        while (!Fp.eql(b, Fp.ONE)) {\n            if (Fp.eql(b, Fp.ZERO))\n                return Fp.ZERO; // https://en.wikipedia.org/wiki/Tonelli%E2%80%93Shanks_algorithm (4. If t = 0, return r = 0)\n            // Find m such b^(2^m)==1\n            let m = 1;\n            for (let t2 = Fp.sqr(b); m < r; m++) {\n                if (Fp.eql(t2, Fp.ONE))\n                    break;\n                t2 = Fp.sqr(t2); // t2 *= t2\n            }\n            // NOTE: r-m-1 can be bigger than 32, need to convert to bigint before shift, otherwise there will be overflow\n            const ge = Fp.pow(g, _1n << BigInt(r - m - 1)); // ge = 2^(r-m-1)\n            g = Fp.sqr(ge); // g = ge * ge\n            x = Fp.mul(x, ge); // x *= ge\n            b = Fp.mul(b, g); // b *= g\n            r = m;\n        }\n        return x;\n    };\n}\nexport function FpSqrt(P) {\n    // NOTE: different algorithms can give different roots, it is up to user to decide which one they want.\n    // For example there is FpSqrtOdd/FpSqrtEven to choice root based on oddness (used for hash-to-curve).\n    // P  3 (mod 4)\n    // n = n^((P+1)/4)\n    if (P % _4n === _3n) {\n        // Not all roots possible!\n        // const ORDER =\n        //   0x1a0111ea397fe69a4b1ba7b6434bacd764774b84f38512bf6730d2a0f6b0f6241eabfffeb153ffffb9feffffffffaaabn;\n        // const NUM = 72057594037927816n;\n        const p1div4 = (P + _1n) / _4n;\n        return function sqrt3mod4(Fp, n) {\n            const root = Fp.pow(n, p1div4);\n            // Throw if root**2 != n\n            if (!Fp.eql(Fp.sqr(root), n))\n                throw new Error('Cannot find square root');\n            return root;\n        };\n    }\n    // Atkin algorithm for q  5 (mod 8), https://eprint.iacr.org/2012/685.pdf (page 10)\n    if (P % _8n === _5n) {\n        const c1 = (P - _5n) / _8n;\n        return function sqrt5mod8(Fp, n) {\n            const n2 = Fp.mul(n, _2n);\n            const v = Fp.pow(n2, c1);\n            const nv = Fp.mul(n, v);\n            const i = Fp.mul(Fp.mul(nv, _2n), v);\n            const root = Fp.mul(nv, Fp.sub(i, Fp.ONE));\n            if (!Fp.eql(Fp.sqr(root), n))\n                throw new Error('Cannot find square root');\n            return root;\n        };\n    }\n    // P  9 (mod 16)\n    if (P % _16n === _9n) {\n        // NOTE: tonelli is too slow for bls-Fp2 calculations even on start\n        // Means we cannot use sqrt for constants at all!\n        //\n        // const c1 = Fp.sqrt(Fp.negate(Fp.ONE)); //  1. c1 = sqrt(-1) in F, i.e., (c1^2) == -1 in F\n        // const c2 = Fp.sqrt(c1);                //  2. c2 = sqrt(c1) in F, i.e., (c2^2) == c1 in F\n        // const c3 = Fp.sqrt(Fp.negate(c1));     //  3. c3 = sqrt(-c1) in F, i.e., (c3^2) == -c1 in F\n        // const c4 = (P + _7n) / _16n;           //  4. c4 = (q + 7) / 16        # Integer arithmetic\n        // sqrt = (x) => {\n        //   let tv1 = Fp.pow(x, c4);             //  1. tv1 = x^c4\n        //   let tv2 = Fp.mul(c1, tv1);           //  2. tv2 = c1 * tv1\n        //   const tv3 = Fp.mul(c2, tv1);         //  3. tv3 = c2 * tv1\n        //   let tv4 = Fp.mul(c3, tv1);           //  4. tv4 = c3 * tv1\n        //   const e1 = Fp.equals(Fp.square(tv2), x); //  5.  e1 = (tv2^2) == x\n        //   const e2 = Fp.equals(Fp.square(tv3), x); //  6.  e2 = (tv3^2) == x\n        //   tv1 = Fp.cmov(tv1, tv2, e1); //  7. tv1 = CMOV(tv1, tv2, e1)  # Select tv2 if (tv2^2) == x\n        //   tv2 = Fp.cmov(tv4, tv3, e2); //  8. tv2 = CMOV(tv4, tv3, e2)  # Select tv3 if (tv3^2) == x\n        //   const e3 = Fp.equals(Fp.square(tv2), x); //  9.  e3 = (tv2^2) == x\n        //   return Fp.cmov(tv1, tv2, e3); //  10.  z = CMOV(tv1, tv2, e3)  # Select the sqrt from tv1 and tv2\n        // }\n    }\n    // Other cases: Tonelli-Shanks algorithm\n    return tonelliShanks(P);\n}\n// Little-endian check for first LE bit (last BE bit);\nexport const isNegativeLE = (num, modulo) => (mod(num, modulo) & _1n) === _1n;\n// prettier-ignore\nconst FIELD_FIELDS = [\n    'create', 'isValid', 'is0', 'neg', 'inv', 'sqrt', 'sqr',\n    'eql', 'add', 'sub', 'mul', 'pow', 'div',\n    'addN', 'subN', 'mulN', 'sqrN'\n];\nexport function validateField(field) {\n    const initial = {\n        ORDER: 'bigint',\n        MASK: 'bigint',\n        BYTES: 'isSafeInteger',\n        BITS: 'isSafeInteger',\n    };\n    const opts = FIELD_FIELDS.reduce((map, val) => {\n        map[val] = 'function';\n        return map;\n    }, initial);\n    return validateObject(field, opts);\n}\n// Generic field functions\n/**\n * Same as `pow` but for Fp: non-constant-time.\n * Unsafe in some contexts: uses ladder, so can expose bigint bits.\n */\nexport function FpPow(f, num, power) {\n    // Should have same speed as pow for bigints\n    // TODO: benchmark!\n    if (power < _0n)\n        throw new Error('Expected power > 0');\n    if (power === _0n)\n        return f.ONE;\n    if (power === _1n)\n        return num;\n    let p = f.ONE;\n    let d = num;\n    while (power > _0n) {\n        if (power & _1n)\n            p = f.mul(p, d);\n        d = f.sqr(d);\n        power >>= _1n;\n    }\n    return p;\n}\n/**\n * Efficiently invert an array of Field elements.\n * `inv(0)` will return `undefined` here: make sure to throw an error.\n */\nexport function FpInvertBatch(f, nums) {\n    const tmp = new Array(nums.length);\n    // Walk from first to last, multiply them by each other MOD p\n    const lastMultiplied = nums.reduce((acc, num, i) => {\n        if (f.is0(num))\n            return acc;\n        tmp[i] = acc;\n        return f.mul(acc, num);\n    }, f.ONE);\n    // Invert last element\n    const inverted = f.inv(lastMultiplied);\n    // Walk from last to first, multiply them by inverted each other MOD p\n    nums.reduceRight((acc, num, i) => {\n        if (f.is0(num))\n            return acc;\n        tmp[i] = f.mul(acc, tmp[i]);\n        return f.mul(acc, num);\n    }, inverted);\n    return tmp;\n}\nexport function FpDiv(f, lhs, rhs) {\n    return f.mul(lhs, typeof rhs === 'bigint' ? invert(rhs, f.ORDER) : f.inv(rhs));\n}\nexport function FpLegendre(order) {\n    // (a | p)  1    if a is a square (mod p), quadratic residue\n    // (a | p)  -1   if a is not a square (mod p), quadratic non residue\n    // (a | p)  0    if a  0 (mod p)\n    const legendreConst = (order - _1n) / _2n; // Integer arithmetic\n    return (f, x) => f.pow(x, legendreConst);\n}\n// This function returns True whenever the value x is a square in the field F.\nexport function FpIsSquare(f) {\n    const legendre = FpLegendre(f.ORDER);\n    return (x) => {\n        const p = legendre(f, x);\n        return f.eql(p, f.ZERO) || f.eql(p, f.ONE);\n    };\n}\n// CURVE.n lengths\nexport function nLength(n, nBitLength) {\n    // Bit size, byte size of CURVE.n\n    const _nBitLength = nBitLength !== undefined ? nBitLength : n.toString(2).length;\n    const nByteLength = Math.ceil(_nBitLength / 8);\n    return { nBitLength: _nBitLength, nByteLength };\n}\n/**\n * Initializes a finite field over prime. **Non-primes are not supported.**\n * Do not init in loop: slow. Very fragile: always run a benchmark on a change.\n * Major performance optimizations:\n * * a) denormalized operations like mulN instead of mul\n * * b) same object shape: never add or remove keys\n * * c) Object.freeze\n * NOTE: operations don't check 'isValid' for all elements for performance reasons,\n * it is caller responsibility to check this.\n * This is low-level code, please make sure you know what you doing.\n * @param ORDER prime positive bigint\n * @param bitLen how many bits the field consumes\n * @param isLE (def: false) if encoding / decoding should be in little-endian\n * @param redef optional faster redefinitions of sqrt and other methods\n */\nexport function Field(ORDER, bitLen, isLE = false, redef = {}) {\n    if (ORDER <= _0n)\n        throw new Error(`Expected Field ORDER > 0, got ${ORDER}`);\n    const { nBitLength: BITS, nByteLength: BYTES } = nLength(ORDER, bitLen);\n    if (BYTES > 2048)\n        throw new Error('Field lengths over 2048 bytes are not supported');\n    const sqrtP = FpSqrt(ORDER);\n    const f = Object.freeze({\n        ORDER,\n        BITS,\n        BYTES,\n        MASK: bitMask(BITS),\n        ZERO: _0n,\n        ONE: _1n,\n        create: (num) => mod(num, ORDER),\n        isValid: (num) => {\n            if (typeof num !== 'bigint')\n                throw new Error(`Invalid field element: expected bigint, got ${typeof num}`);\n            return _0n <= num && num < ORDER; // 0 is valid element, but it's not invertible\n        },\n        is0: (num) => num === _0n,\n        isOdd: (num) => (num & _1n) === _1n,\n        neg: (num) => mod(-num, ORDER),\n        eql: (lhs, rhs) => lhs === rhs,\n        sqr: (num) => mod(num * num, ORDER),\n        add: (lhs, rhs) => mod(lhs + rhs, ORDER),\n        sub: (lhs, rhs) => mod(lhs - rhs, ORDER),\n        mul: (lhs, rhs) => mod(lhs * rhs, ORDER),\n        pow: (num, power) => FpPow(f, num, power),\n        div: (lhs, rhs) => mod(lhs * invert(rhs, ORDER), ORDER),\n        // Same as above, but doesn't normalize\n        sqrN: (num) => num * num,\n        addN: (lhs, rhs) => lhs + rhs,\n        subN: (lhs, rhs) => lhs - rhs,\n        mulN: (lhs, rhs) => lhs * rhs,\n        inv: (num) => invert(num, ORDER),\n        sqrt: redef.sqrt || ((n) => sqrtP(f, n)),\n        invertBatch: (lst) => FpInvertBatch(f, lst),\n        // TODO: do we really need constant cmov?\n        // We don't have const-time bigints anyway, so probably will be not very useful\n        cmov: (a, b, c) => (c ? b : a),\n        toBytes: (num) => (isLE ? numberToBytesLE(num, BYTES) : numberToBytesBE(num, BYTES)),\n        fromBytes: (bytes) => {\n            if (bytes.length !== BYTES)\n                throw new Error(`Fp.fromBytes: expected ${BYTES}, got ${bytes.length}`);\n            return isLE ? bytesToNumberLE(bytes) : bytesToNumberBE(bytes);\n        },\n    });\n    return Object.freeze(f);\n}\nexport function FpSqrtOdd(Fp, elm) {\n    if (!Fp.isOdd)\n        throw new Error(`Field doesn't have isOdd`);\n    const root = Fp.sqrt(elm);\n    return Fp.isOdd(root) ? root : Fp.neg(root);\n}\nexport function FpSqrtEven(Fp, elm) {\n    if (!Fp.isOdd)\n        throw new Error(`Field doesn't have isOdd`);\n    const root = Fp.sqrt(elm);\n    return Fp.isOdd(root) ? Fp.neg(root) : root;\n}\n/**\n * \"Constant-time\" private key generation utility.\n * Same as mapKeyToField, but accepts less bytes (40 instead of 48 for 32-byte field).\n * Which makes it slightly more biased, less secure.\n * @deprecated use mapKeyToField instead\n */\nexport function hashToPrivateScalar(hash, groupOrder, isLE = false) {\n    hash = ensureBytes('privateHash', hash);\n    const hashLen = hash.length;\n    const minLen = nLength(groupOrder).nByteLength + 8;\n    if (minLen < 24 || hashLen < minLen || hashLen > 1024)\n        throw new Error(`hashToPrivateScalar: expected ${minLen}-1024 bytes of input, got ${hashLen}`);\n    const num = isLE ? bytesToNumberLE(hash) : bytesToNumberBE(hash);\n    return mod(num, groupOrder - _1n) + _1n;\n}\n/**\n * Returns total number of bytes consumed by the field element.\n * For example, 32 bytes for usual 256-bit weierstrass curve.\n * @param fieldOrder number of field elements, usually CURVE.n\n * @returns byte length of field\n */\nexport function getFieldBytesLength(fieldOrder) {\n    if (typeof fieldOrder !== 'bigint')\n        throw new Error('field order must be bigint');\n    const bitLength = fieldOrder.toString(2).length;\n    return Math.ceil(bitLength / 8);\n}\n/**\n * Returns minimal amount of bytes that can be safely reduced\n * by field order.\n * Should be 2^-128 for 128-bit curve such as P256.\n * @param fieldOrder number of field elements, usually CURVE.n\n * @returns byte length of target hash\n */\nexport function getMinHashLength(fieldOrder) {\n    const length = getFieldBytesLength(fieldOrder);\n    return length + Math.ceil(length / 2);\n}\n/**\n * \"Constant-time\" private key generation utility.\n * Can take (n + n/2) or more bytes of uniform input e.g. from CSPRNG or KDF\n * and convert them into private scalar, with the modulo bias being negligible.\n * Needs at least 48 bytes of input for 32-byte private key.\n * https://research.kudelskisecurity.com/2020/07/28/the-definitive-guide-to-modulo-bias-and-how-to-avoid-it/\n * FIPS 186-5, A.2 https://csrc.nist.gov/publications/detail/fips/186/5/final\n * RFC 9380, https://www.rfc-editor.org/rfc/rfc9380#section-5\n * @param hash hash output from SHA3 or a similar function\n * @param groupOrder size of subgroup - (e.g. secp256k1.CURVE.n)\n * @param isLE interpret hash bytes as LE num\n * @returns valid private scalar\n */\nexport function mapHashToField(key, fieldOrder, isLE = false) {\n    const len = key.length;\n    const fieldLen = getFieldBytesLength(fieldOrder);\n    const minLen = getMinHashLength(fieldOrder);\n    // No small numbers: need to understand bias story. No huge numbers: easier to detect JS timings.\n    if (len < 16 || len < minLen || len > 1024)\n        throw new Error(`expected ${minLen}-1024 bytes of input, got ${len}`);\n    const num = isLE ? bytesToNumberBE(key) : bytesToNumberLE(key);\n    // `mod(x, 11)` can sometimes produce 0. `mod(x, 10) + 1` is the same, but no 0\n    const reduced = mod(num, fieldOrder - _1n) + _1n;\n    return isLE ? numberToBytesLE(reduced, fieldLen) : numberToBytesBE(reduced, fieldLen);\n}\n//# sourceMappingURL=modular.js.map","/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// Abelian group utilities\nimport { validateField, nLength } from './modular.js';\nimport { validateObject, bitLen } from './utils.js';\nconst _0n = BigInt(0);\nconst _1n = BigInt(1);\n// Since points in different groups cannot be equal (different object constructor),\n// we can have single place to store precomputes\nconst pointPrecomputes = new WeakMap();\nconst pointWindowSizes = new WeakMap(); // This allows use make points immutable (nothing changes inside)\n// Elliptic curve multiplication of Point by scalar. Fragile.\n// Scalars should always be less than curve order: this should be checked inside of a curve itself.\n// Creates precomputation tables for fast multiplication:\n// - private scalar is split by fixed size windows of W bits\n// - every window point is collected from window's table & added to accumulator\n// - since windows are different, same point inside tables won't be accessed more than once per calc\n// - each multiplication is 'Math.ceil(CURVE_ORDER / ) + 1' point additions (fixed for any scalar)\n// - +1 window is neccessary for wNAF\n// - wNAF reduces table size: 2x less memory + 2x faster generation, but 10% slower multiplication\n// TODO: Research returning 2d JS array of windows, instead of a single window. This would allow\n// windows to be in different memory locations\nexport function wNAF(c, bits) {\n    const constTimeNegate = (condition, item) => {\n        const neg = item.negate();\n        return condition ? neg : item;\n    };\n    const validateW = (W) => {\n        if (!Number.isSafeInteger(W) || W <= 0 || W > bits)\n            throw new Error(`Wrong window size=${W}, should be [1..${bits}]`);\n    };\n    const opts = (W) => {\n        validateW(W);\n        const windows = Math.ceil(bits / W) + 1; // +1, because\n        const windowSize = 2 ** (W - 1); // -1 because we skip zero\n        return { windows, windowSize };\n    };\n    return {\n        constTimeNegate,\n        // non-const time multiplication ladder\n        unsafeLadder(elm, n) {\n            let p = c.ZERO;\n            let d = elm;\n            while (n > _0n) {\n                if (n & _1n)\n                    p = p.add(d);\n                d = d.double();\n                n >>= _1n;\n            }\n            return p;\n        },\n        /**\n         * Creates a wNAF precomputation window. Used for caching.\n         * Default window size is set by `utils.precompute()` and is equal to 8.\n         * Number of precomputed points depends on the curve size:\n         * 2^(1) * (Math.ceil( / ) + 1), where:\n         * -  is the window size\n         * -  is the bitlength of the curve order.\n         * For a 256-bit curve and window size 8, the number of precomputed points is 128 * 33 = 4224.\n         * @returns precomputed point tables flattened to a single array\n         */\n        precomputeWindow(elm, W) {\n            const { windows, windowSize } = opts(W);\n            const points = [];\n            let p = elm;\n            let base = p;\n            for (let window = 0; window < windows; window++) {\n                base = p;\n                points.push(base);\n                // =1, because we skip zero\n                for (let i = 1; i < windowSize; i++) {\n                    base = base.add(p);\n                    points.push(base);\n                }\n                p = base.double();\n            }\n            return points;\n        },\n        /**\n         * Implements ec multiplication using precomputed tables and w-ary non-adjacent form.\n         * @param W window size\n         * @param precomputes precomputed tables\n         * @param n scalar (we don't check here, but should be less than curve order)\n         * @returns real and fake (for const-time) points\n         */\n        wNAF(W, precomputes, n) {\n            // TODO: maybe check that scalar is less than group order? wNAF behavious is undefined otherwise\n            // But need to carefully remove other checks before wNAF. ORDER == bits here\n            const { windows, windowSize } = opts(W);\n            let p = c.ZERO;\n            let f = c.BASE;\n            const mask = BigInt(2 ** W - 1); // Create mask with W ones: 0b1111 for W=4 etc.\n            const maxNumber = 2 ** W;\n            const shiftBy = BigInt(W);\n            for (let window = 0; window < windows; window++) {\n                const offset = window * windowSize;\n                // Extract W bits.\n                let wbits = Number(n & mask);\n                // Shift number by W bits.\n                n >>= shiftBy;\n                // If the bits are bigger than max size, we'll split those.\n                // +224 => 256 - 32\n                if (wbits > windowSize) {\n                    wbits -= maxNumber;\n                    n += _1n;\n                }\n                // This code was first written with assumption that 'f' and 'p' will never be infinity point:\n                // since each addition is multiplied by 2 ** W, it cannot cancel each other. However,\n                // there is negate now: it is possible that negated element from low value\n                // would be the same as high element, which will create carry into next window.\n                // It's not obvious how this can fail, but still worth investigating later.\n                // Check if we're onto Zero point.\n                // Add random point inside current window to f.\n                const offset1 = offset;\n                const offset2 = offset + Math.abs(wbits) - 1; // -1 because we skip zero\n                const cond1 = window % 2 !== 0;\n                const cond2 = wbits < 0;\n                if (wbits === 0) {\n                    // The most important part for const-time getPublicKey\n                    f = f.add(constTimeNegate(cond1, precomputes[offset1]));\n                }\n                else {\n                    p = p.add(constTimeNegate(cond2, precomputes[offset2]));\n                }\n            }\n            // JIT-compiler should not eliminate f here, since it will later be used in normalizeZ()\n            // Even if the variable is still unused, there are some checks which will\n            // throw an exception, so compiler needs to prove they won't happen, which is hard.\n            // At this point there is a way to F be infinity-point even if p is not,\n            // which makes it less const-time: around 1 bigint multiply.\n            return { p, f };\n        },\n        wNAFCached(P, n, transform) {\n            const W = pointWindowSizes.get(P) || 1;\n            // Calculate precomputes on a first run, reuse them after\n            let comp = pointPrecomputes.get(P);\n            if (!comp) {\n                comp = this.precomputeWindow(P, W);\n                if (W !== 1)\n                    pointPrecomputes.set(P, transform(comp));\n            }\n            return this.wNAF(W, comp, n);\n        },\n        // We calculate precomputes for elliptic curve point multiplication\n        // using windowed method. This specifies window size and\n        // stores precomputed values. Usually only base point would be precomputed.\n        setWindowSize(P, W) {\n            validateW(W);\n            pointWindowSizes.set(P, W);\n            pointPrecomputes.delete(P);\n        },\n    };\n}\n/**\n * Pippenger algorithm for multi-scalar multiplication (MSM).\n * MSM is basically (Pa + Qb + Rc + ...).\n * 30x faster vs naive addition on L=4096, 10x faster with precomputes.\n * For N=254bit, L=1, it does: 1024 ADD + 254 DBL. For L=5: 1536 ADD + 254 DBL.\n * Algorithmically constant-time (for same L), even when 1 point + scalar, or when scalar = 0.\n * @param c Curve Point constructor\n * @param field field over CURVE.N - important that it's not over CURVE.P\n * @param points array of L curve points\n * @param scalars array of L scalars (aka private keys / bigints)\n */\nexport function pippenger(c, field, points, scalars) {\n    // If we split scalars by some window (let's say 8 bits), every chunk will only\n    // take 256 buckets even if there are 4096 scalars, also re-uses double.\n    // TODO:\n    // - https://eprint.iacr.org/2024/750.pdf\n    // - https://tches.iacr.org/index.php/TCHES/article/view/10287\n    // 0 is accepted in scalars\n    if (!Array.isArray(points) || !Array.isArray(scalars) || scalars.length !== points.length)\n        throw new Error('arrays of points and scalars must have equal length');\n    scalars.forEach((s, i) => {\n        if (!field.isValid(s))\n            throw new Error(`wrong scalar at index ${i}`);\n    });\n    points.forEach((p, i) => {\n        if (!(p instanceof c))\n            throw new Error(`wrong point at index ${i}`);\n    });\n    const wbits = bitLen(BigInt(points.length));\n    const windowSize = wbits > 12 ? wbits - 3 : wbits > 4 ? wbits - 2 : wbits ? 2 : 1; // in bits\n    const MASK = (1 << windowSize) - 1;\n    const buckets = new Array(MASK + 1).fill(c.ZERO); // +1 for zero array\n    const lastBits = Math.floor((field.BITS - 1) / windowSize) * windowSize;\n    let sum = c.ZERO;\n    for (let i = lastBits; i >= 0; i -= windowSize) {\n        buckets.fill(c.ZERO);\n        for (let j = 0; j < scalars.length; j++) {\n            const scalar = scalars[j];\n            const wbits = Number((scalar >> BigInt(i)) & BigInt(MASK));\n            buckets[wbits] = buckets[wbits].add(points[j]);\n        }\n        let resI = c.ZERO; // not using this will do small speed-up, but will lose ct\n        // Skip first bucket, because it is zero\n        for (let j = buckets.length - 1, sumI = c.ZERO; j > 0; j--) {\n            sumI = sumI.add(buckets[j]);\n            resI = resI.add(sumI);\n        }\n        sum = sum.add(resI);\n        if (i !== 0)\n            for (let j = 0; j < windowSize; j++)\n                sum = sum.double();\n    }\n    return sum;\n}\nexport function validateBasic(curve) {\n    validateField(curve.Fp);\n    validateObject(curve, {\n        n: 'bigint',\n        h: 'bigint',\n        Gx: 'field',\n        Gy: 'field',\n    }, {\n        nBitLength: 'isSafeInteger',\n        nByteLength: 'isSafeInteger',\n    });\n    // Set defaults\n    return Object.freeze({\n        ...nLength(curve.n, curve.nBitLength),\n        ...curve,\n        ...{ p: curve.Fp.ORDER },\n    });\n}\n//# sourceMappingURL=curve.js.map","/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// Twisted Edwards curve. The formula is: ax + y = 1 + dxy\nimport { validateBasic, wNAF, pippenger, } from './curve.js';\nimport { mod, Field } from './modular.js';\nimport * as ut from './utils.js';\nimport { ensureBytes, memoized, abool } from './utils.js';\n// Be friendly to bad ECMAScript parsers by not using bigint literals\n// prettier-ignore\nconst _0n = BigInt(0), _1n = BigInt(1), _2n = BigInt(2), _8n = BigInt(8);\n// verification rule is either zip215 or rfc8032 / nist186-5. Consult fromHex:\nconst VERIFY_DEFAULT = { zip215: true };\nfunction validateOpts(curve) {\n    const opts = validateBasic(curve);\n    ut.validateObject(curve, {\n        hash: 'function',\n        a: 'bigint',\n        d: 'bigint',\n        randomBytes: 'function',\n    }, {\n        adjustScalarBytes: 'function',\n        domain: 'function',\n        uvRatio: 'function',\n        mapToCurve: 'function',\n    });\n    // Set defaults\n    return Object.freeze({ ...opts });\n}\n/**\n * Creates Twisted Edwards curve with EdDSA signatures.\n * @example\n * import { Field } from '@noble/curves/abstract/modular';\n * // Before that, define BigInt-s: a, d, p, n, Gx, Gy, h\n * const curve = twistedEdwards({ a, d, Fp: Field(p), n, Gx, Gy, h })\n */\nexport function twistedEdwards(curveDef) {\n    const CURVE = validateOpts(curveDef);\n    const { Fp, n: CURVE_ORDER, prehash: prehash, hash: cHash, randomBytes, nByteLength, h: cofactor, } = CURVE;\n    const MASK = _2n << (BigInt(nByteLength * 8) - _1n);\n    const modP = Fp.create; // Function overrides\n    const Fn = Field(CURVE.n, CURVE.nBitLength);\n    // sqrt(u/v)\n    const uvRatio = CURVE.uvRatio ||\n        ((u, v) => {\n            try {\n                return { isValid: true, value: Fp.sqrt(u * Fp.inv(v)) };\n            }\n            catch (e) {\n                return { isValid: false, value: _0n };\n            }\n        });\n    const adjustScalarBytes = CURVE.adjustScalarBytes || ((bytes) => bytes); // NOOP\n    const domain = CURVE.domain ||\n        ((data, ctx, phflag) => {\n            abool('phflag', phflag);\n            if (ctx.length || phflag)\n                throw new Error('Contexts/pre-hash are not supported');\n            return data;\n        }); // NOOP\n    // 0 <= n < MASK\n    // Coordinates larger than Fp.ORDER are allowed for zip215\n    function aCoordinate(title, n) {\n        ut.aInRange('coordinate ' + title, n, _0n, MASK);\n    }\n    function assertPoint(other) {\n        if (!(other instanceof Point))\n            throw new Error('ExtendedPoint expected');\n    }\n    // Converts Extended point to default (x, y) coordinates.\n    // Can accept precomputed Z^-1 - for example, from invertBatch.\n    const toAffineMemo = memoized((p, iz) => {\n        const { ex: x, ey: y, ez: z } = p;\n        const is0 = p.is0();\n        if (iz == null)\n            iz = is0 ? _8n : Fp.inv(z); // 8 was chosen arbitrarily\n        const ax = modP(x * iz);\n        const ay = modP(y * iz);\n        const zz = modP(z * iz);\n        if (is0)\n            return { x: _0n, y: _1n };\n        if (zz !== _1n)\n            throw new Error('invZ was invalid');\n        return { x: ax, y: ay };\n    });\n    const assertValidMemo = memoized((p) => {\n        const { a, d } = CURVE;\n        if (p.is0())\n            throw new Error('bad point: ZERO'); // TODO: optimize, with vars below?\n        // Equation in affine coordinates: ax + y = 1 + dxy\n        // Equation in projective coordinates (X/Z, Y/Z, Z):  (aX + Y)Z = Z + dXY\n        const { ex: X, ey: Y, ez: Z, et: T } = p;\n        const X2 = modP(X * X); // X\n        const Y2 = modP(Y * Y); // Y\n        const Z2 = modP(Z * Z); // Z\n        const Z4 = modP(Z2 * Z2); // Z\n        const aX2 = modP(X2 * a); // aX\n        const left = modP(Z2 * modP(aX2 + Y2)); // (aX + Y)Z\n        const right = modP(Z4 + modP(d * modP(X2 * Y2))); // Z + dXY\n        if (left !== right)\n            throw new Error('bad point: equation left != right (1)');\n        // In Extended coordinates we also have T, which is x*y=T/Z: check X*Y == Z*T\n        const XY = modP(X * Y);\n        const ZT = modP(Z * T);\n        if (XY !== ZT)\n            throw new Error('bad point: equation left != right (2)');\n        return true;\n    });\n    // Extended Point works in extended coordinates: (x, y, z, t)  (x=x/z, y=y/z, t=xy).\n    // https://en.wikipedia.org/wiki/Twisted_Edwards_curve#Extended_coordinates\n    class Point {\n        constructor(ex, ey, ez, et) {\n            this.ex = ex;\n            this.ey = ey;\n            this.ez = ez;\n            this.et = et;\n            aCoordinate('x', ex);\n            aCoordinate('y', ey);\n            aCoordinate('z', ez);\n            aCoordinate('t', et);\n            Object.freeze(this);\n        }\n        get x() {\n            return this.toAffine().x;\n        }\n        get y() {\n            return this.toAffine().y;\n        }\n        static fromAffine(p) {\n            if (p instanceof Point)\n                throw new Error('extended point not allowed');\n            const { x, y } = p || {};\n            aCoordinate('x', x);\n            aCoordinate('y', y);\n            return new Point(x, y, _1n, modP(x * y));\n        }\n        static normalizeZ(points) {\n            const toInv = Fp.invertBatch(points.map((p) => p.ez));\n            return points.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);\n        }\n        // Multiscalar Multiplication\n        static msm(points, scalars) {\n            return pippenger(Point, Fn, points, scalars);\n        }\n        // \"Private method\", don't use it directly\n        _setWindowSize(windowSize) {\n            wnaf.setWindowSize(this, windowSize);\n        }\n        // Not required for fromHex(), which always creates valid points.\n        // Could be useful for fromAffine().\n        assertValidity() {\n            assertValidMemo(this);\n        }\n        // Compare one point to another.\n        equals(other) {\n            assertPoint(other);\n            const { ex: X1, ey: Y1, ez: Z1 } = this;\n            const { ex: X2, ey: Y2, ez: Z2 } = other;\n            const X1Z2 = modP(X1 * Z2);\n            const X2Z1 = modP(X2 * Z1);\n            const Y1Z2 = modP(Y1 * Z2);\n            const Y2Z1 = modP(Y2 * Z1);\n            return X1Z2 === X2Z1 && Y1Z2 === Y2Z1;\n        }\n        is0() {\n            return this.equals(Point.ZERO);\n        }\n        negate() {\n            // Flips point sign to a negative one (-x, y in affine coords)\n            return new Point(modP(-this.ex), this.ey, this.ez, modP(-this.et));\n        }\n        // Fast algo for doubling Extended Point.\n        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#doubling-dbl-2008-hwcd\n        // Cost: 4M + 4S + 1*a + 6add + 1*2.\n        double() {\n            const { a } = CURVE;\n            const { ex: X1, ey: Y1, ez: Z1 } = this;\n            const A = modP(X1 * X1); // A = X12\n            const B = modP(Y1 * Y1); // B = Y12\n            const C = modP(_2n * modP(Z1 * Z1)); // C = 2*Z12\n            const D = modP(a * A); // D = a*A\n            const x1y1 = X1 + Y1;\n            const E = modP(modP(x1y1 * x1y1) - A - B); // E = (X1+Y1)2-A-B\n            const G = D + B; // G = D+B\n            const F = G - C; // F = G-C\n            const H = D - B; // H = D-B\n            const X3 = modP(E * F); // X3 = E*F\n            const Y3 = modP(G * H); // Y3 = G*H\n            const T3 = modP(E * H); // T3 = E*H\n            const Z3 = modP(F * G); // Z3 = F*G\n            return new Point(X3, Y3, Z3, T3);\n        }\n        // Fast algo for adding 2 Extended Points.\n        // https://hyperelliptic.org/EFD/g1p/auto-twisted-extended.html#addition-add-2008-hwcd\n        // Cost: 9M + 1*a + 1*d + 7add.\n        add(other) {\n            assertPoint(other);\n            const { a, d } = CURVE;\n            const { ex: X1, ey: Y1, ez: Z1, et: T1 } = this;\n            const { ex: X2, ey: Y2, ez: Z2, et: T2 } = other;\n            // Faster algo for adding 2 Extended Points when curve's a=-1.\n            // http://hyperelliptic.org/EFD/g1p/auto-twisted-extended-1.html#addition-add-2008-hwcd-4\n            // Cost: 8M + 8add + 2*2.\n            // Note: It does not check whether the `other` point is valid.\n            if (a === BigInt(-1)) {\n                const A = modP((Y1 - X1) * (Y2 + X2));\n                const B = modP((Y1 + X1) * (Y2 - X2));\n                const F = modP(B - A);\n                if (F === _0n)\n                    return this.double(); // Same point. Tests say it doesn't affect timing\n                const C = modP(Z1 * _2n * T2);\n                const D = modP(T1 * _2n * Z2);\n                const E = D + C;\n                const G = B + A;\n                const H = D - C;\n                const X3 = modP(E * F);\n                const Y3 = modP(G * H);\n                const T3 = modP(E * H);\n                const Z3 = modP(F * G);\n                return new Point(X3, Y3, Z3, T3);\n            }\n            const A = modP(X1 * X2); // A = X1*X2\n            const B = modP(Y1 * Y2); // B = Y1*Y2\n            const C = modP(T1 * d * T2); // C = T1*d*T2\n            const D = modP(Z1 * Z2); // D = Z1*Z2\n            const E = modP((X1 + Y1) * (X2 + Y2) - A - B); // E = (X1+Y1)*(X2+Y2)-A-B\n            const F = D - C; // F = D-C\n            const G = D + C; // G = D+C\n            const H = modP(B - a * A); // H = B-a*A\n            const X3 = modP(E * F); // X3 = E*F\n            const Y3 = modP(G * H); // Y3 = G*H\n            const T3 = modP(E * H); // T3 = E*H\n            const Z3 = modP(F * G); // Z3 = F*G\n            return new Point(X3, Y3, Z3, T3);\n        }\n        subtract(other) {\n            return this.add(other.negate());\n        }\n        wNAF(n) {\n            return wnaf.wNAFCached(this, n, Point.normalizeZ);\n        }\n        // Constant-time multiplication.\n        multiply(scalar) {\n            const n = scalar;\n            ut.aInRange('scalar', n, _1n, CURVE_ORDER); // 1 <= scalar < L\n            const { p, f } = this.wNAF(n);\n            return Point.normalizeZ([p, f])[0];\n        }\n        // Non-constant-time multiplication. Uses double-and-add algorithm.\n        // It's faster, but should only be used when you don't care about\n        // an exposed private key e.g. sig verification.\n        // Does NOT allow scalars higher than CURVE.n.\n        multiplyUnsafe(scalar) {\n            const n = scalar;\n            ut.aInRange('scalar', n, _0n, CURVE_ORDER); // 0 <= scalar < L\n            if (n === _0n)\n                return I;\n            if (this.equals(I) || n === _1n)\n                return this;\n            if (this.equals(G))\n                return this.wNAF(n).p;\n            return wnaf.unsafeLadder(this, n);\n        }\n        // Checks if point is of small order.\n        // If you add something to small order point, you will have \"dirty\"\n        // point with torsion component.\n        // Multiplies point by cofactor and checks if the result is 0.\n        isSmallOrder() {\n            return this.multiplyUnsafe(cofactor).is0();\n        }\n        // Multiplies point by curve order and checks if the result is 0.\n        // Returns `false` is the point is dirty.\n        isTorsionFree() {\n            return wnaf.unsafeLadder(this, CURVE_ORDER).is0();\n        }\n        // Converts Extended point to default (x, y) coordinates.\n        // Can accept precomputed Z^-1 - for example, from invertBatch.\n        toAffine(iz) {\n            return toAffineMemo(this, iz);\n        }\n        clearCofactor() {\n            const { h: cofactor } = CURVE;\n            if (cofactor === _1n)\n                return this;\n            return this.multiplyUnsafe(cofactor);\n        }\n        // Converts hash string or Uint8Array to Point.\n        // Uses algo from RFC8032 5.1.3.\n        static fromHex(hex, zip215 = false) {\n            const { d, a } = CURVE;\n            const len = Fp.BYTES;\n            hex = ensureBytes('pointHex', hex, len); // copy hex to a new array\n            abool('zip215', zip215);\n            const normed = hex.slice(); // copy again, we'll manipulate it\n            const lastByte = hex[len - 1]; // select last byte\n            normed[len - 1] = lastByte & ~0x80; // clear last bit\n            const y = ut.bytesToNumberLE(normed);\n            // RFC8032 prohibits >= p, but ZIP215 doesn't\n            // zip215=true:  0 <= y < MASK (2^256 for ed25519)\n            // zip215=false: 0 <= y < P (2^255-19 for ed25519)\n            const max = zip215 ? MASK : Fp.ORDER;\n            ut.aInRange('pointHex.y', y, _0n, max);\n            // Ed25519: x = (y-1)/(dy+1) mod p. Ed448: x = (y-1)/(dy-1) mod p. Generic case:\n            // ax+y=1+dxy => y-1=dxy-ax => y-1=x(dy-a) => x=(y-1)/(dy-a)\n            const y2 = modP(y * y); // denominator is always non-0 mod p.\n            const u = modP(y2 - _1n); // u = y - 1\n            const v = modP(d * y2 - a); // v = d y + 1.\n            let { isValid, value: x } = uvRatio(u, v); // (u/v)\n            if (!isValid)\n                throw new Error('Point.fromHex: invalid y coordinate');\n            const isXOdd = (x & _1n) === _1n; // There are 2 square roots. Use x_0 bit to select proper\n            const isLastByteOdd = (lastByte & 0x80) !== 0; // x_0, last bit\n            if (!zip215 && x === _0n && isLastByteOdd)\n                // if x=0 and x_0 = 1, fail\n                throw new Error('Point.fromHex: x=0 and x_0=1');\n            if (isLastByteOdd !== isXOdd)\n                x = modP(-x); // if x_0 != x mod 2, set x = p-x\n            return Point.fromAffine({ x, y });\n        }\n        static fromPrivateKey(privKey) {\n            return getExtendedPublicKey(privKey).point;\n        }\n        toRawBytes() {\n            const { x, y } = this.toAffine();\n            const bytes = ut.numberToBytesLE(y, Fp.BYTES); // each y has 2 x values (x, -y)\n            bytes[bytes.length - 1] |= x & _1n ? 0x80 : 0; // when compressing, it's enough to store y\n            return bytes; // and use the last byte to encode sign of x\n        }\n        toHex() {\n            return ut.bytesToHex(this.toRawBytes()); // Same as toRawBytes, but returns string.\n        }\n    }\n    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, _1n, modP(CURVE.Gx * CURVE.Gy));\n    Point.ZERO = new Point(_0n, _1n, _1n, _0n); // 0, 1, 1, 0\n    const { BASE: G, ZERO: I } = Point;\n    const wnaf = wNAF(Point, nByteLength * 8);\n    function modN(a) {\n        return mod(a, CURVE_ORDER);\n    }\n    // Little-endian SHA512 with modulo n\n    function modN_LE(hash) {\n        return modN(ut.bytesToNumberLE(hash));\n    }\n    /** Convenience method that creates public key and other stuff. RFC8032 5.1.5 */\n    function getExtendedPublicKey(key) {\n        const len = nByteLength;\n        key = ensureBytes('private key', key, len);\n        // Hash private key with curve's hash function to produce uniformingly random input\n        // Check byte lengths: ensure(64, h(ensure(32, key)))\n        const hashed = ensureBytes('hashed private key', cHash(key), 2 * len);\n        const head = adjustScalarBytes(hashed.slice(0, len)); // clear first half bits, produce FE\n        const prefix = hashed.slice(len, 2 * len); // second half is called key prefix (5.1.6)\n        const scalar = modN_LE(head); // The actual private scalar\n        const point = G.multiply(scalar); // Point on Edwards curve aka public key\n        const pointBytes = point.toRawBytes(); // Uint8Array representation\n        return { head, prefix, scalar, point, pointBytes };\n    }\n    // Calculates EdDSA pub key. RFC8032 5.1.5. Privkey is hashed. Use first half with 3 bits cleared\n    function getPublicKey(privKey) {\n        return getExtendedPublicKey(privKey).pointBytes;\n    }\n    // int('LE', SHA512(dom2(F, C) || msgs)) mod N\n    function hashDomainToScalar(context = new Uint8Array(), ...msgs) {\n        const msg = ut.concatBytes(...msgs);\n        return modN_LE(cHash(domain(msg, ensureBytes('context', context), !!prehash)));\n    }\n    /** Signs message with privateKey. RFC8032 5.1.6 */\n    function sign(msg, privKey, options = {}) {\n        msg = ensureBytes('message', msg);\n        if (prehash)\n            msg = prehash(msg); // for ed25519ph etc.\n        const { prefix, scalar, pointBytes } = getExtendedPublicKey(privKey);\n        const r = hashDomainToScalar(options.context, prefix, msg); // r = dom2(F, C) || prefix || PH(M)\n        const R = G.multiply(r).toRawBytes(); // R = rG\n        const k = hashDomainToScalar(options.context, R, pointBytes, msg); // R || A || PH(M)\n        const s = modN(r + k * scalar); // S = (r + k * s) mod L\n        ut.aInRange('signature.s', s, _0n, CURVE_ORDER); // 0 <= s < l\n        const res = ut.concatBytes(R, ut.numberToBytesLE(s, Fp.BYTES));\n        return ensureBytes('result', res, nByteLength * 2); // 64-byte signature\n    }\n    const verifyOpts = VERIFY_DEFAULT;\n    function verify(sig, msg, publicKey, options = verifyOpts) {\n        const { context, zip215 } = options;\n        const len = Fp.BYTES; // Verifies EdDSA signature against message and public key. RFC8032 5.1.7.\n        sig = ensureBytes('signature', sig, 2 * len); // An extended group equation is checked.\n        msg = ensureBytes('message', msg);\n        if (zip215 !== undefined)\n            abool('zip215', zip215);\n        if (prehash)\n            msg = prehash(msg); // for ed25519ph, etc\n        const s = ut.bytesToNumberLE(sig.slice(len, 2 * len));\n        // zip215: true is good for consensus-critical apps and allows points < 2^256\n        // zip215: false follows RFC8032 / NIST186-5 and restricts points to CURVE.p\n        let A, R, SB;\n        try {\n            A = Point.fromHex(publicKey, zip215);\n            R = Point.fromHex(sig.slice(0, len), zip215);\n            SB = G.multiplyUnsafe(s); // 0 <= s < l is done inside\n        }\n        catch (error) {\n            return false;\n        }\n        if (!zip215 && A.isSmallOrder())\n            return false;\n        const k = hashDomainToScalar(context, R.toRawBytes(), A.toRawBytes(), msg);\n        const RkA = R.add(A.multiplyUnsafe(k));\n        // [8][S]B = [8]R + [8][k]A'\n        return RkA.subtract(SB).clearCofactor().equals(Point.ZERO);\n    }\n    G._setWindowSize(8); // Enable precomputes. Slows down first publicKey computation by 20ms.\n    const utils = {\n        getExtendedPublicKey,\n        // ed25519 private keys are uniform 32b. No need to check for modulo bias, like in secp256k1.\n        randomPrivateKey: () => randomBytes(Fp.BYTES),\n        /**\n         * We're doing scalar multiplication (used in getPublicKey etc) with precomputed BASE_POINT\n         * values. This slows down first getPublicKey() by milliseconds (see Speed section),\n         * but allows to speed-up subsequent getPublicKey() calls up to 20x.\n         * @param windowSize 2, 4, 8, 16\n         */\n        precompute(windowSize = 8, point = Point.BASE) {\n            point._setWindowSize(windowSize);\n            point.multiply(BigInt(3));\n            return point;\n        },\n    };\n    return {\n        CURVE,\n        getPublicKey,\n        sign,\n        verify,\n        ExtendedPoint: Point,\n        utils,\n    };\n}\n//# sourceMappingURL=edwards.js.map","/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\nimport { sha512 } from '@noble/hashes/sha512';\nimport { concatBytes, randomBytes, utf8ToBytes } from '@noble/hashes/utils';\nimport { twistedEdwards } from './abstract/edwards.js';\nimport { createHasher, expand_message_xmd } from './abstract/hash-to-curve.js';\nimport { Field, FpSqrtEven, isNegativeLE, mod, pow2 } from './abstract/modular.js';\nimport { montgomery } from './abstract/montgomery.js';\nimport { bytesToHex, bytesToNumberLE, ensureBytes, equalBytes, numberToBytesLE, } from './abstract/utils.js';\n/**\n * ed25519 Twisted Edwards curve with following addons:\n * - X25519 ECDH\n * - Ristretto cofactor elimination\n * - Elligator hash-to-group / point indistinguishability\n */\nconst ED25519_P = BigInt('57896044618658097711785492504343953926634992332820282019728792003956564819949');\n// (-1) aka (a) aka 2^((p-1)/4)\nconst ED25519_SQRT_M1 = /* @__PURE__ */ BigInt('19681161376707505956807079304988542015446066515923890162744021073123829784752');\n// prettier-ignore\nconst _0n = BigInt(0), _1n = BigInt(1), _2n = BigInt(2), _3n = BigInt(3);\n// prettier-ignore\nconst _5n = BigInt(5), _8n = BigInt(8);\nfunction ed25519_pow_2_252_3(x) {\n    // prettier-ignore\n    const _10n = BigInt(10), _20n = BigInt(20), _40n = BigInt(40), _80n = BigInt(80);\n    const P = ED25519_P;\n    const x2 = (x * x) % P;\n    const b2 = (x2 * x) % P; // x^3, 11\n    const b4 = (pow2(b2, _2n, P) * b2) % P; // x^15, 1111\n    const b5 = (pow2(b4, _1n, P) * x) % P; // x^31\n    const b10 = (pow2(b5, _5n, P) * b5) % P;\n    const b20 = (pow2(b10, _10n, P) * b10) % P;\n    const b40 = (pow2(b20, _20n, P) * b20) % P;\n    const b80 = (pow2(b40, _40n, P) * b40) % P;\n    const b160 = (pow2(b80, _80n, P) * b80) % P;\n    const b240 = (pow2(b160, _80n, P) * b80) % P;\n    const b250 = (pow2(b240, _10n, P) * b10) % P;\n    const pow_p_5_8 = (pow2(b250, _2n, P) * x) % P;\n    // ^ To pow to (p+3)/8, multiply it by x.\n    return { pow_p_5_8, b2 };\n}\nfunction adjustScalarBytes(bytes) {\n    // Section 5: For X25519, in order to decode 32 random bytes as an integer scalar,\n    // set the three least significant bits of the first byte\n    bytes[0] &= 248; // 0b1111_1000\n    // and the most significant bit of the last to zero,\n    bytes[31] &= 127; // 0b0111_1111\n    // set the second most significant bit of the last byte to 1\n    bytes[31] |= 64; // 0b0100_0000\n    return bytes;\n}\n// sqrt(u/v)\nfunction uvRatio(u, v) {\n    const P = ED25519_P;\n    const v3 = mod(v * v * v, P); // v\n    const v7 = mod(v3 * v3 * v, P); // v\n    // (p+3)/8 and (p-5)/8\n    const pow = ed25519_pow_2_252_3(u * v7).pow_p_5_8;\n    let x = mod(u * v3 * pow, P); // (uv)(uv)^(p-5)/8\n    const vx2 = mod(v * x * x, P); // vx\n    const root1 = x; // First root candidate\n    const root2 = mod(x * ED25519_SQRT_M1, P); // Second root candidate\n    const useRoot1 = vx2 === u; // If vx = u (mod p), x is a square root\n    const useRoot2 = vx2 === mod(-u, P); // If vx = -u, set x <-- x * 2^((p-1)/4)\n    const noRoot = vx2 === mod(-u * ED25519_SQRT_M1, P); // There is no valid root, vx = -u(-1)\n    if (useRoot1)\n        x = root1;\n    if (useRoot2 || noRoot)\n        x = root2; // We return root2 anyway, for const-time\n    if (isNegativeLE(x, P))\n        x = mod(-x, P);\n    return { isValid: useRoot1 || useRoot2, value: x };\n}\n// Just in case\nexport const ED25519_TORSION_SUBGROUP = [\n    '0100000000000000000000000000000000000000000000000000000000000000',\n    'c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac037a',\n    '0000000000000000000000000000000000000000000000000000000000000080',\n    '26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc05',\n    'ecffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff7f',\n    '26e8958fc2b227b045c3f489f2ef98f0d5dfac05d3c63339b13802886d53fc85',\n    '0000000000000000000000000000000000000000000000000000000000000000',\n    'c7176a703d4dd84fba3c0b760d10670f2a2053fa2c39ccc64ec7fd7792ac03fa',\n];\nconst Fp = /* @__PURE__ */ (() => Field(ED25519_P, undefined, true))();\nconst ed25519Defaults = /* @__PURE__ */ (() => ({\n    // Param: a\n    a: BigInt(-1), // Fp.create(-1) is proper; our way still works and is faster\n    // d is equal to -121665/121666 over finite field.\n    // Negative number is P - number, and division is invert(number, P)\n    d: BigInt('37095705934669439343138083508754565189542113879843219016388785533085940283555'),\n    // Finite field p over which we'll do calculations; 2n**255n - 19n\n    Fp,\n    // Subgroup order: how many points curve has\n    // 2n**252n + 27742317777372353535851937790883648493n;\n    n: BigInt('7237005577332262213973186563042994240857116359379907606001950938285454250989'),\n    // Cofactor\n    h: _8n,\n    // Base point (x, y) aka generator point\n    Gx: BigInt('15112221349535400772501151409588531511454012693041857206046113283949847762202'),\n    Gy: BigInt('46316835694926478169428394003475163141307993866256225615783033603165251855960'),\n    hash: sha512,\n    randomBytes,\n    adjustScalarBytes,\n    // dom2\n    // Ratio of u to v. Allows us to combine inversion and square root. Uses algo from RFC8032 5.1.3.\n    // Constant-time, u/v\n    uvRatio,\n}))();\n/**\n * ed25519 curve with EdDSA signatures.\n */\nexport const ed25519 = /* @__PURE__ */ (() => twistedEdwards(ed25519Defaults))();\nfunction ed25519_domain(data, ctx, phflag) {\n    if (ctx.length > 255)\n        throw new Error('Context is too big');\n    return concatBytes(utf8ToBytes('SigEd25519 no Ed25519 collisions'), new Uint8Array([phflag ? 1 : 0, ctx.length]), ctx, data);\n}\nexport const ed25519ctx = /* @__PURE__ */ (() => twistedEdwards({\n    ...ed25519Defaults,\n    domain: ed25519_domain,\n}))();\nexport const ed25519ph = /* @__PURE__ */ (() => twistedEdwards(Object.assign({}, ed25519Defaults, {\n    domain: ed25519_domain,\n    prehash: sha512,\n})))();\nexport const x25519 = /* @__PURE__ */ (() => montgomery({\n    P: ED25519_P,\n    a: BigInt(486662),\n    montgomeryBits: 255, // n is 253 bits\n    nByteLength: 32,\n    Gu: BigInt(9),\n    powPminus2: (x) => {\n        const P = ED25519_P;\n        // x^(p-2) aka x^(2^255-21)\n        const { pow_p_5_8, b2 } = ed25519_pow_2_252_3(x);\n        return mod(pow2(pow_p_5_8, _3n, P) * b2, P);\n    },\n    adjustScalarBytes,\n    randomBytes,\n}))();\n/**\n * Converts ed25519 public key to x25519 public key. Uses formula:\n * * `(u, v) = ((1+y)/(1-y), sqrt(-486664)*u/x)`\n * * `(x, y) = (sqrt(-486664)*u/v, (u-1)/(u+1))`\n * @example\n *   const someonesPub = ed25519.getPublicKey(ed25519.utils.randomPrivateKey());\n *   const aPriv = x25519.utils.randomPrivateKey();\n *   x25519.getSharedSecret(aPriv, edwardsToMontgomeryPub(someonesPub))\n */\nexport function edwardsToMontgomeryPub(edwardsPub) {\n    const { y } = ed25519.ExtendedPoint.fromHex(edwardsPub);\n    const _1n = BigInt(1);\n    return Fp.toBytes(Fp.create((_1n + y) * Fp.inv(_1n - y)));\n}\nexport const edwardsToMontgomery = edwardsToMontgomeryPub; // deprecated\n/**\n * Converts ed25519 secret key to x25519 secret key.\n * @example\n *   const someonesPub = x25519.getPublicKey(x25519.utils.randomPrivateKey());\n *   const aPriv = ed25519.utils.randomPrivateKey();\n *   x25519.getSharedSecret(edwardsToMontgomeryPriv(aPriv), someonesPub)\n */\nexport function edwardsToMontgomeryPriv(edwardsPriv) {\n    const hashed = ed25519Defaults.hash(edwardsPriv.subarray(0, 32));\n    return ed25519Defaults.adjustScalarBytes(hashed).subarray(0, 32);\n}\n// Hash To Curve Elligator2 Map (NOTE: different from ristretto255 elligator)\n// NOTE: very important part is usage of FpSqrtEven for ELL2_C1_EDWARDS, since\n// SageMath returns different root first and everything falls apart\nconst ELL2_C1 = /* @__PURE__ */ (() => (Fp.ORDER + _3n) / _8n)(); // 1. c1 = (q + 3) / 8       # Integer arithmetic\nconst ELL2_C2 = /* @__PURE__ */ (() => Fp.pow(_2n, ELL2_C1))(); // 2. c2 = 2^c1\nconst ELL2_C3 = /* @__PURE__ */ (() => Fp.sqrt(Fp.neg(Fp.ONE)))(); // 3. c3 = sqrt(-1)\n// prettier-ignore\nfunction map_to_curve_elligator2_curve25519(u) {\n    const ELL2_C4 = (Fp.ORDER - _5n) / _8n; // 4. c4 = (q - 5) / 8       # Integer arithmetic\n    const ELL2_J = BigInt(486662);\n    let tv1 = Fp.sqr(u); //  1.  tv1 = u^2\n    tv1 = Fp.mul(tv1, _2n); //  2.  tv1 = 2 * tv1\n    let xd = Fp.add(tv1, Fp.ONE); //  3.   xd = tv1 + 1         # Nonzero: -1 is square (mod p), tv1 is not\n    let x1n = Fp.neg(ELL2_J); //  4.  x1n = -J              # x1 = x1n / xd = -J / (1 + 2 * u^2)\n    let tv2 = Fp.sqr(xd); //  5.  tv2 = xd^2\n    let gxd = Fp.mul(tv2, xd); //  6.  gxd = tv2 * xd        # gxd = xd^3\n    let gx1 = Fp.mul(tv1, ELL2_J); //  7.  gx1 = J * tv1         # x1n + J * xd\n    gx1 = Fp.mul(gx1, x1n); //  8.  gx1 = gx1 * x1n       # x1n^2 + J * x1n * xd\n    gx1 = Fp.add(gx1, tv2); //  9.  gx1 = gx1 + tv2       # x1n^2 + J * x1n * xd + xd^2\n    gx1 = Fp.mul(gx1, x1n); //  10. gx1 = gx1 * x1n       # x1n^3 + J * x1n^2 * xd + x1n * xd^2\n    let tv3 = Fp.sqr(gxd); //  11. tv3 = gxd^2\n    tv2 = Fp.sqr(tv3); //  12. tv2 = tv3^2           # gxd^4\n    tv3 = Fp.mul(tv3, gxd); //  13. tv3 = tv3 * gxd       # gxd^3\n    tv3 = Fp.mul(tv3, gx1); //  14. tv3 = tv3 * gx1       # gx1 * gxd^3\n    tv2 = Fp.mul(tv2, tv3); //  15. tv2 = tv2 * tv3       # gx1 * gxd^7\n    let y11 = Fp.pow(tv2, ELL2_C4); //  16. y11 = tv2^c4        # (gx1 * gxd^7)^((p - 5) / 8)\n    y11 = Fp.mul(y11, tv3); //  17. y11 = y11 * tv3       # gx1*gxd^3*(gx1*gxd^7)^((p-5)/8)\n    let y12 = Fp.mul(y11, ELL2_C3); //  18. y12 = y11 * c3\n    tv2 = Fp.sqr(y11); //  19. tv2 = y11^2\n    tv2 = Fp.mul(tv2, gxd); //  20. tv2 = tv2 * gxd\n    let e1 = Fp.eql(tv2, gx1); //  21.  e1 = tv2 == gx1\n    let y1 = Fp.cmov(y12, y11, e1); //  22.  y1 = CMOV(y12, y11, e1)  # If g(x1) is square, this is its sqrt\n    let x2n = Fp.mul(x1n, tv1); //  23. x2n = x1n * tv1       # x2 = x2n / xd = 2 * u^2 * x1n / xd\n    let y21 = Fp.mul(y11, u); //  24. y21 = y11 * u\n    y21 = Fp.mul(y21, ELL2_C2); //  25. y21 = y21 * c2\n    let y22 = Fp.mul(y21, ELL2_C3); //  26. y22 = y21 * c3\n    let gx2 = Fp.mul(gx1, tv1); //  27. gx2 = gx1 * tv1       # g(x2) = gx2 / gxd = 2 * u^2 * g(x1)\n    tv2 = Fp.sqr(y21); //  28. tv2 = y21^2\n    tv2 = Fp.mul(tv2, gxd); //  29. tv2 = tv2 * gxd\n    let e2 = Fp.eql(tv2, gx2); //  30.  e2 = tv2 == gx2\n    let y2 = Fp.cmov(y22, y21, e2); //  31.  y2 = CMOV(y22, y21, e2)  # If g(x2) is square, this is its sqrt\n    tv2 = Fp.sqr(y1); //  32. tv2 = y1^2\n    tv2 = Fp.mul(tv2, gxd); //  33. tv2 = tv2 * gxd\n    let e3 = Fp.eql(tv2, gx1); //  34.  e3 = tv2 == gx1\n    let xn = Fp.cmov(x2n, x1n, e3); //  35.  xn = CMOV(x2n, x1n, e3)  # If e3, x = x1, else x = x2\n    let y = Fp.cmov(y2, y1, e3); //  36.   y = CMOV(y2, y1, e3)    # If e3, y = y1, else y = y2\n    let e4 = Fp.isOdd(y); //  37.  e4 = sgn0(y) == 1        # Fix sign of y\n    y = Fp.cmov(y, Fp.neg(y), e3 !== e4); //  38.   y = CMOV(y, -y, e3 XOR e4)\n    return { xMn: xn, xMd: xd, yMn: y, yMd: _1n }; //  39. return (xn, xd, y, 1)\n}\nconst ELL2_C1_EDWARDS = /* @__PURE__ */ (() => FpSqrtEven(Fp, Fp.neg(BigInt(486664))))(); // sgn0(c1) MUST equal 0\nfunction map_to_curve_elligator2_edwards25519(u) {\n    const { xMn, xMd, yMn, yMd } = map_to_curve_elligator2_curve25519(u); //  1.  (xMn, xMd, yMn, yMd) =\n    // map_to_curve_elligator2_curve25519(u)\n    let xn = Fp.mul(xMn, yMd); //  2.  xn = xMn * yMd\n    xn = Fp.mul(xn, ELL2_C1_EDWARDS); //  3.  xn = xn * c1\n    let xd = Fp.mul(xMd, yMn); //  4.  xd = xMd * yMn    # xn / xd = c1 * xM / yM\n    let yn = Fp.sub(xMn, xMd); //  5.  yn = xMn - xMd\n    let yd = Fp.add(xMn, xMd); //  6.  yd = xMn + xMd    # (n / d - 1) / (n / d + 1) = (n - d) / (n + d)\n    let tv1 = Fp.mul(xd, yd); //  7. tv1 = xd * yd\n    let e = Fp.eql(tv1, Fp.ZERO); //  8.   e = tv1 == 0\n    xn = Fp.cmov(xn, Fp.ZERO, e); //  9.  xn = CMOV(xn, 0, e)\n    xd = Fp.cmov(xd, Fp.ONE, e); //  10. xd = CMOV(xd, 1, e)\n    yn = Fp.cmov(yn, Fp.ONE, e); //  11. yn = CMOV(yn, 1, e)\n    yd = Fp.cmov(yd, Fp.ONE, e); //  12. yd = CMOV(yd, 1, e)\n    const inv = Fp.invertBatch([xd, yd]); // batch division\n    return { x: Fp.mul(xn, inv[0]), y: Fp.mul(yn, inv[1]) }; //  13. return (xn, xd, yn, yd)\n}\nconst htf = /* @__PURE__ */ (() => createHasher(ed25519.ExtendedPoint, (scalars) => map_to_curve_elligator2_edwards25519(scalars[0]), {\n    DST: 'edwards25519_XMD:SHA-512_ELL2_RO_',\n    encodeDST: 'edwards25519_XMD:SHA-512_ELL2_NU_',\n    p: Fp.ORDER,\n    m: 1,\n    k: 128,\n    expand: 'xmd',\n    hash: sha512,\n}))();\nexport const hashToCurve = /* @__PURE__ */ (() => htf.hashToCurve)();\nexport const encodeToCurve = /* @__PURE__ */ (() => htf.encodeToCurve)();\nfunction assertRstPoint(other) {\n    if (!(other instanceof RistPoint))\n        throw new Error('RistrettoPoint expected');\n}\n// (-1) aka (a) aka 2^((p-1)/4)\nconst SQRT_M1 = ED25519_SQRT_M1;\n// (ad - 1)\nconst SQRT_AD_MINUS_ONE = /* @__PURE__ */ BigInt('25063068953384623474111414158702152701244531502492656460079210482610430750235');\n// 1 / (a-d)\nconst INVSQRT_A_MINUS_D = /* @__PURE__ */ BigInt('54469307008909316920995813868745141605393597292927456921205312896311721017578');\n// 1-d\nconst ONE_MINUS_D_SQ = /* @__PURE__ */ BigInt('1159843021668779879193775521855586647937357759715417654439879720876111806838');\n// (d-1)\nconst D_MINUS_ONE_SQ = /* @__PURE__ */ BigInt('40440834346308536858101042469323190826248399146238708352240133220865137265952');\n// Calculates 1/(number)\nconst invertSqrt = (number) => uvRatio(_1n, number);\nconst MAX_255B = /* @__PURE__ */ BigInt('0x7fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff');\nconst bytes255ToNumberLE = (bytes) => ed25519.CURVE.Fp.create(bytesToNumberLE(bytes) & MAX_255B);\n// Computes Elligator map for Ristretto\n// https://ristretto.group/formulas/elligator.html\nfunction calcElligatorRistrettoMap(r0) {\n    const { d } = ed25519.CURVE;\n    const P = ed25519.CURVE.Fp.ORDER;\n    const mod = ed25519.CURVE.Fp.create;\n    const r = mod(SQRT_M1 * r0 * r0); // 1\n    const Ns = mod((r + _1n) * ONE_MINUS_D_SQ); // 2\n    let c = BigInt(-1); // 3\n    const D = mod((c - d * r) * mod(r + d)); // 4\n    let { isValid: Ns_D_is_sq, value: s } = uvRatio(Ns, D); // 5\n    let s_ = mod(s * r0); // 6\n    if (!isNegativeLE(s_, P))\n        s_ = mod(-s_);\n    if (!Ns_D_is_sq)\n        s = s_; // 7\n    if (!Ns_D_is_sq)\n        c = r; // 8\n    const Nt = mod(c * (r - _1n) * D_MINUS_ONE_SQ - D); // 9\n    const s2 = s * s;\n    const W0 = mod((s + s) * D); // 10\n    const W1 = mod(Nt * SQRT_AD_MINUS_ONE); // 11\n    const W2 = mod(_1n - s2); // 12\n    const W3 = mod(_1n + s2); // 13\n    return new ed25519.ExtendedPoint(mod(W0 * W3), mod(W2 * W1), mod(W1 * W3), mod(W0 * W2));\n}\n/**\n * Each ed25519/ExtendedPoint has 8 different equivalent points. This can be\n * a source of bugs for protocols like ring signatures. Ristretto was created to solve this.\n * Ristretto point operates in X:Y:Z:T extended coordinates like ExtendedPoint,\n * but it should work in its own namespace: do not combine those two.\n * https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-ristretto255-decaf448\n */\nclass RistPoint {\n    // Private property to discourage combining ExtendedPoint + RistrettoPoint\n    // Always use Ristretto encoding/decoding instead.\n    constructor(ep) {\n        this.ep = ep;\n    }\n    static fromAffine(ap) {\n        return new RistPoint(ed25519.ExtendedPoint.fromAffine(ap));\n    }\n    /**\n     * Takes uniform output of 64-byte hash function like sha512 and converts it to `RistrettoPoint`.\n     * The hash-to-group operation applies Elligator twice and adds the results.\n     * **Note:** this is one-way map, there is no conversion from point to hash.\n     * https://ristretto.group/formulas/elligator.html\n     * @param hex 64-byte output of a hash function\n     */\n    static hashToCurve(hex) {\n        hex = ensureBytes('ristrettoHash', hex, 64);\n        const r1 = bytes255ToNumberLE(hex.slice(0, 32));\n        const R1 = calcElligatorRistrettoMap(r1);\n        const r2 = bytes255ToNumberLE(hex.slice(32, 64));\n        const R2 = calcElligatorRistrettoMap(r2);\n        return new RistPoint(R1.add(R2));\n    }\n    /**\n     * Converts ristretto-encoded string to ristretto point.\n     * https://ristretto.group/formulas/decoding.html\n     * @param hex Ristretto-encoded 32 bytes. Not every 32-byte string is valid ristretto encoding\n     */\n    static fromHex(hex) {\n        hex = ensureBytes('ristrettoHex', hex, 32);\n        const { a, d } = ed25519.CURVE;\n        const P = ed25519.CURVE.Fp.ORDER;\n        const mod = ed25519.CURVE.Fp.create;\n        const emsg = 'RistrettoPoint.fromHex: the hex is not valid encoding of RistrettoPoint';\n        const s = bytes255ToNumberLE(hex);\n        // 1. Check that s_bytes is the canonical encoding of a field element, or else abort.\n        // 3. Check that s is non-negative, or else abort\n        if (!equalBytes(numberToBytesLE(s, 32), hex) || isNegativeLE(s, P))\n            throw new Error(emsg);\n        const s2 = mod(s * s);\n        const u1 = mod(_1n + a * s2); // 4 (a is -1)\n        const u2 = mod(_1n - a * s2); // 5\n        const u1_2 = mod(u1 * u1);\n        const u2_2 = mod(u2 * u2);\n        const v = mod(a * d * u1_2 - u2_2); // 6\n        const { isValid, value: I } = invertSqrt(mod(v * u2_2)); // 7\n        const Dx = mod(I * u2); // 8\n        const Dy = mod(I * Dx * v); // 9\n        let x = mod((s + s) * Dx); // 10\n        if (isNegativeLE(x, P))\n            x = mod(-x); // 10\n        const y = mod(u1 * Dy); // 11\n        const t = mod(x * y); // 12\n        if (!isValid || isNegativeLE(t, P) || y === _0n)\n            throw new Error(emsg);\n        return new RistPoint(new ed25519.ExtendedPoint(x, y, _1n, t));\n    }\n    /**\n     * Encodes ristretto point to Uint8Array.\n     * https://ristretto.group/formulas/encoding.html\n     */\n    toRawBytes() {\n        let { ex: x, ey: y, ez: z, et: t } = this.ep;\n        const P = ed25519.CURVE.Fp.ORDER;\n        const mod = ed25519.CURVE.Fp.create;\n        const u1 = mod(mod(z + y) * mod(z - y)); // 1\n        const u2 = mod(x * y); // 2\n        // Square root always exists\n        const u2sq = mod(u2 * u2);\n        const { value: invsqrt } = invertSqrt(mod(u1 * u2sq)); // 3\n        const D1 = mod(invsqrt * u1); // 4\n        const D2 = mod(invsqrt * u2); // 5\n        const zInv = mod(D1 * D2 * t); // 6\n        let D; // 7\n        if (isNegativeLE(t * zInv, P)) {\n            let _x = mod(y * SQRT_M1);\n            let _y = mod(x * SQRT_M1);\n            x = _x;\n            y = _y;\n            D = mod(D1 * INVSQRT_A_MINUS_D);\n        }\n        else {\n            D = D2; // 8\n        }\n        if (isNegativeLE(x * zInv, P))\n            y = mod(-y); // 9\n        let s = mod((z - y) * D); // 10 (check footer's note, no sqrt(-a))\n        if (isNegativeLE(s, P))\n            s = mod(-s);\n        return numberToBytesLE(s, 32); // 11\n    }\n    toHex() {\n        return bytesToHex(this.toRawBytes());\n    }\n    toString() {\n        return this.toHex();\n    }\n    // Compare one point to another.\n    equals(other) {\n        assertRstPoint(other);\n        const { ex: X1, ey: Y1 } = this.ep;\n        const { ex: X2, ey: Y2 } = other.ep;\n        const mod = ed25519.CURVE.Fp.create;\n        // (x1 * y2 == y1 * x2) | (y1 * y2 == x1 * x2)\n        const one = mod(X1 * Y2) === mod(Y1 * X2);\n        const two = mod(Y1 * Y2) === mod(X1 * X2);\n        return one || two;\n    }\n    add(other) {\n        assertRstPoint(other);\n        return new RistPoint(this.ep.add(other.ep));\n    }\n    subtract(other) {\n        assertRstPoint(other);\n        return new RistPoint(this.ep.subtract(other.ep));\n    }\n    multiply(scalar) {\n        return new RistPoint(this.ep.multiply(scalar));\n    }\n    multiplyUnsafe(scalar) {\n        return new RistPoint(this.ep.multiplyUnsafe(scalar));\n    }\n    double() {\n        return new RistPoint(this.ep.double());\n    }\n    negate() {\n        return new RistPoint(this.ep.negate());\n    }\n}\nexport const RistrettoPoint = /* @__PURE__ */ (() => {\n    if (!RistPoint.BASE)\n        RistPoint.BASE = new RistPoint(ed25519.ExtendedPoint.BASE);\n    if (!RistPoint.ZERO)\n        RistPoint.ZERO = new RistPoint(ed25519.ExtendedPoint.ZERO);\n    return RistPoint;\n})();\n// Hashing to ristretto255. https://www.rfc-editor.org/rfc/rfc9380#appendix-B\nexport const hashToRistretto255 = (msg, options) => {\n    const d = options.DST;\n    const DST = typeof d === 'string' ? utf8ToBytes(d) : d;\n    const uniform_bytes = expand_message_xmd(msg, DST, 64, sha512);\n    const P = RistPoint.hashToCurve(uniform_bytes);\n    return P;\n};\nexport const hash_to_ristretto255 = hashToRistretto255; // legacy\n//# sourceMappingURL=ed25519.js.map","import { ed25519 as ed } from '@noble/curves/ed25519';\nconst PUBLIC_KEY_BYTE_LENGTH = 32;\nconst PRIVATE_KEY_BYTE_LENGTH = 64; // private key is actually 32 bytes but for historical reasons we concat private and public keys\nconst KEYS_BYTE_LENGTH = 32;\nexport { PUBLIC_KEY_BYTE_LENGTH as publicKeyLength };\nexport { PRIVATE_KEY_BYTE_LENGTH as privateKeyLength };\nexport function generateKey() {\n    // the actual private key (32 bytes)\n    const privateKeyRaw = ed.utils.randomPrivateKey();\n    const publicKey = ed.getPublicKey(privateKeyRaw);\n    // concatenated the public key to the private key\n    const privateKey = concatKeys(privateKeyRaw, publicKey);\n    return {\n        privateKey,\n        publicKey\n    };\n}\n/**\n * Generate keypair from a 32 byte uint8array\n */\nexport function generateKeyFromSeed(seed) {\n    if (seed.length !== KEYS_BYTE_LENGTH) {\n        throw new TypeError('\"seed\" must be 32 bytes in length.');\n    }\n    else if (!(seed instanceof Uint8Array)) {\n        throw new TypeError('\"seed\" must be a node.js Buffer, or Uint8Array.');\n    }\n    // based on node forges algorithm, the seed is used directly as private key\n    const privateKeyRaw = seed;\n    const publicKey = ed.getPublicKey(privateKeyRaw);\n    const privateKey = concatKeys(privateKeyRaw, publicKey);\n    return {\n        privateKey,\n        publicKey\n    };\n}\nexport function hashAndSign(privateKey, msg) {\n    const privateKeyRaw = privateKey.subarray(0, KEYS_BYTE_LENGTH);\n    return ed.sign(msg instanceof Uint8Array ? msg : msg.subarray(), privateKeyRaw);\n}\nexport function hashAndVerify(publicKey, sig, msg) {\n    return ed.verify(sig, msg instanceof Uint8Array ? msg : msg.subarray(), publicKey);\n}\nfunction concatKeys(privateKeyRaw, publicKey) {\n    const privateKey = new Uint8Array(PRIVATE_KEY_BYTE_LENGTH);\n    for (let i = 0; i < KEYS_BYTE_LENGTH; i++) {\n        privateKey[i] = privateKeyRaw[i];\n        privateKey[KEYS_BYTE_LENGTH + i] = publicKey[i];\n    }\n    return privateKey;\n}\n//# sourceMappingURL=index.browser.js.map","import { base58btc } from 'multiformats/bases/base58';\nimport { CID } from 'multiformats/cid';\nimport {} from 'multiformats/hashes/digest';\nimport { identity } from 'multiformats/hashes/identity';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { publicKeyToProtobuf } from '../index.js';\nimport { ensureEd25519Key } from './utils.js';\nimport * as crypto from './index.js';\nexport class Ed25519PublicKey {\n    type = 'Ed25519';\n    raw;\n    constructor(key) {\n        this.raw = ensureEd25519Key(key, crypto.publicKeyLength);\n    }\n    toMultihash() {\n        return identity.digest(publicKeyToProtobuf(this));\n    }\n    toCID() {\n        return CID.createV1(114, this.toMultihash());\n    }\n    toString() {\n        return base58btc.encode(this.toMultihash().bytes).substring(1);\n    }\n    equals(key) {\n        if (key == null || !(key.raw instanceof Uint8Array)) {\n            return false;\n        }\n        return uint8ArrayEquals(this.raw, key.raw);\n    }\n    verify(data, sig) {\n        return crypto.hashAndVerify(this.raw, sig, data);\n    }\n}\nexport class Ed25519PrivateKey {\n    type = 'Ed25519';\n    raw;\n    publicKey;\n    // key       - 64 byte Uint8Array containing private key\n    // publicKey - 32 byte Uint8Array containing public key\n    constructor(key, publicKey) {\n        this.raw = ensureEd25519Key(key, crypto.privateKeyLength);\n        this.publicKey = new Ed25519PublicKey(publicKey);\n    }\n    equals(key) {\n        if (key == null || !(key.raw instanceof Uint8Array)) {\n            return false;\n        }\n        return uint8ArrayEquals(this.raw, key.raw);\n    }\n    sign(message) {\n        return crypto.hashAndSign(this.raw, message);\n    }\n}\n//# sourceMappingURL=ed25519.js.map","import { InvalidParametersError } from '@libp2p/interface';\nimport { Ed25519PublicKey as Ed25519PublicKeyClass, Ed25519PrivateKey as Ed25519PrivateKeyClass } from './ed25519.js';\nimport * as crypto from './index.js';\nexport function unmarshalEd25519PrivateKey(bytes) {\n    // Try the old, redundant public key version\n    if (bytes.length > crypto.privateKeyLength) {\n        bytes = ensureEd25519Key(bytes, crypto.privateKeyLength + crypto.publicKeyLength);\n        const privateKeyBytes = bytes.subarray(0, crypto.privateKeyLength);\n        const publicKeyBytes = bytes.subarray(crypto.privateKeyLength, bytes.length);\n        return new Ed25519PrivateKeyClass(privateKeyBytes, publicKeyBytes);\n    }\n    bytes = ensureEd25519Key(bytes, crypto.privateKeyLength);\n    const privateKeyBytes = bytes.subarray(0, crypto.privateKeyLength);\n    const publicKeyBytes = bytes.subarray(crypto.publicKeyLength);\n    return new Ed25519PrivateKeyClass(privateKeyBytes, publicKeyBytes);\n}\nexport function unmarshalEd25519PublicKey(bytes) {\n    bytes = ensureEd25519Key(bytes, crypto.publicKeyLength);\n    return new Ed25519PublicKeyClass(bytes);\n}\nexport async function generateEd25519KeyPair() {\n    const { privateKey, publicKey } = crypto.generateKey();\n    return new Ed25519PrivateKeyClass(privateKey, publicKey);\n}\nexport async function generateEd25519KeyPairFromSeed(seed) {\n    const { privateKey, publicKey } = crypto.generateKeyFromSeed(seed);\n    return new Ed25519PrivateKeyClass(privateKey, publicKey);\n}\nexport function ensureEd25519Key(key, length) {\n    key = Uint8Array.from(key ?? []);\n    if (key.length !== length) {\n        throw new InvalidParametersError(`Key must be a Uint8Array of length ${length}, got ${key.length}`);\n    }\n    return key;\n}\n//# sourceMappingURL=utils.js.map","const f32 = new Float32Array([-0]);\nconst f8b = new Uint8Array(f32.buffer);\n/**\n * Writes a 32 bit float to a buffer using little endian byte order\n */\nexport function writeFloatLE(val, buf, pos) {\n    f32[0] = val;\n    buf[pos] = f8b[0];\n    buf[pos + 1] = f8b[1];\n    buf[pos + 2] = f8b[2];\n    buf[pos + 3] = f8b[3];\n}\n/**\n * Writes a 32 bit float to a buffer using big endian byte order\n */\nexport function writeFloatBE(val, buf, pos) {\n    f32[0] = val;\n    buf[pos] = f8b[3];\n    buf[pos + 1] = f8b[2];\n    buf[pos + 2] = f8b[1];\n    buf[pos + 3] = f8b[0];\n}\n/**\n * Reads a 32 bit float from a buffer using little endian byte order\n */\nexport function readFloatLE(buf, pos) {\n    f8b[0] = buf[pos];\n    f8b[1] = buf[pos + 1];\n    f8b[2] = buf[pos + 2];\n    f8b[3] = buf[pos + 3];\n    return f32[0];\n}\n/**\n * Reads a 32 bit float from a buffer using big endian byte order\n */\nexport function readFloatBE(buf, pos) {\n    f8b[3] = buf[pos];\n    f8b[2] = buf[pos + 1];\n    f8b[1] = buf[pos + 2];\n    f8b[0] = buf[pos + 3];\n    return f32[0];\n}\nconst f64 = new Float64Array([-0]);\nconst d8b = new Uint8Array(f64.buffer);\n/**\n * Writes a 64 bit double to a buffer using little endian byte order\n */\nexport function writeDoubleLE(val, buf, pos) {\n    f64[0] = val;\n    buf[pos] = d8b[0];\n    buf[pos + 1] = d8b[1];\n    buf[pos + 2] = d8b[2];\n    buf[pos + 3] = d8b[3];\n    buf[pos + 4] = d8b[4];\n    buf[pos + 5] = d8b[5];\n    buf[pos + 6] = d8b[6];\n    buf[pos + 7] = d8b[7];\n}\n/**\n * Writes a 64 bit double to a buffer using big endian byte order\n */\nexport function writeDoubleBE(val, buf, pos) {\n    f64[0] = val;\n    buf[pos] = d8b[7];\n    buf[pos + 1] = d8b[6];\n    buf[pos + 2] = d8b[5];\n    buf[pos + 3] = d8b[4];\n    buf[pos + 4] = d8b[3];\n    buf[pos + 5] = d8b[2];\n    buf[pos + 6] = d8b[1];\n    buf[pos + 7] = d8b[0];\n}\n/**\n * Reads a 64 bit double from a buffer using little endian byte order\n */\nexport function readDoubleLE(buf, pos) {\n    d8b[0] = buf[pos];\n    d8b[1] = buf[pos + 1];\n    d8b[2] = buf[pos + 2];\n    d8b[3] = buf[pos + 3];\n    d8b[4] = buf[pos + 4];\n    d8b[5] = buf[pos + 5];\n    d8b[6] = buf[pos + 6];\n    d8b[7] = buf[pos + 7];\n    return f64[0];\n}\n/**\n * Reads a 64 bit double from a buffer using big endian byte order\n */\nexport function readDoubleBE(buf, pos) {\n    d8b[7] = buf[pos];\n    d8b[6] = buf[pos + 1];\n    d8b[5] = buf[pos + 2];\n    d8b[4] = buf[pos + 3];\n    d8b[3] = buf[pos + 4];\n    d8b[2] = buf[pos + 5];\n    d8b[1] = buf[pos + 6];\n    d8b[0] = buf[pos + 7];\n    return f64[0];\n}\n//# sourceMappingURL=float.js.map","// the largest BigInt we can safely downcast to a Number\nconst MAX_SAFE_NUMBER_INTEGER = BigInt(Number.MAX_SAFE_INTEGER);\nconst MIN_SAFE_NUMBER_INTEGER = BigInt(Number.MIN_SAFE_INTEGER);\n/**\n * Constructs new long bits.\n *\n * @classdesc Helper class for working with the low and high bits of a 64 bit value.\n * @memberof util\n * @function Object() { [native code] }\n * @param {number} lo - Low 32 bits, unsigned\n * @param {number} hi - High 32 bits, unsigned\n */\nexport class LongBits {\n    lo;\n    hi;\n    constructor(lo, hi) {\n        // note that the casts below are theoretically unnecessary as of today, but older statically\n        // generated converter code might still call the ctor with signed 32bits. kept for compat.\n        /**\n         * Low bits\n         */\n        this.lo = lo | 0;\n        /**\n         * High bits\n         */\n        this.hi = hi | 0;\n    }\n    /**\n     * Converts this long bits to a possibly unsafe JavaScript number\n     */\n    toNumber(unsigned = false) {\n        if (!unsigned && (this.hi >>> 31) > 0) {\n            const lo = ~this.lo + 1 >>> 0;\n            let hi = ~this.hi >>> 0;\n            if (lo === 0) {\n                hi = hi + 1 >>> 0;\n            }\n            return -(lo + hi * 4294967296);\n        }\n        return this.lo + this.hi * 4294967296;\n    }\n    /**\n     * Converts this long bits to a bigint\n     */\n    toBigInt(unsigned = false) {\n        if (unsigned) {\n            return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);\n        }\n        if ((this.hi >>> 31) !== 0) {\n            const lo = ~this.lo + 1 >>> 0;\n            let hi = ~this.hi >>> 0;\n            if (lo === 0) {\n                hi = hi + 1 >>> 0;\n            }\n            return -(BigInt(lo) + (BigInt(hi) << 32n));\n        }\n        return BigInt(this.lo >>> 0) + (BigInt(this.hi >>> 0) << 32n);\n    }\n    /**\n     * Converts this long bits to a string\n     */\n    toString(unsigned = false) {\n        return this.toBigInt(unsigned).toString();\n    }\n    /**\n     * Zig-zag encodes this long bits\n     */\n    zzEncode() {\n        const mask = this.hi >> 31;\n        this.hi = ((this.hi << 1 | this.lo >>> 31) ^ mask) >>> 0;\n        this.lo = (this.lo << 1 ^ mask) >>> 0;\n        return this;\n    }\n    /**\n     * Zig-zag decodes this long bits\n     */\n    zzDecode() {\n        const mask = -(this.lo & 1);\n        this.lo = ((this.lo >>> 1 | this.hi << 31) ^ mask) >>> 0;\n        this.hi = (this.hi >>> 1 ^ mask) >>> 0;\n        return this;\n    }\n    /**\n     * Calculates the length of this longbits when encoded as a varint.\n     */\n    length() {\n        const part0 = this.lo;\n        const part1 = (this.lo >>> 28 | this.hi << 4) >>> 0;\n        const part2 = this.hi >>> 24;\n        return part2 === 0\n            ? part1 === 0\n                ? part0 < 16384\n                    ? part0 < 128 ? 1 : 2\n                    : part0 < 2097152 ? 3 : 4\n                : part1 < 16384\n                    ? part1 < 128 ? 5 : 6\n                    : part1 < 2097152 ? 7 : 8\n            : part2 < 128 ? 9 : 10;\n    }\n    /**\n     * Constructs new long bits from the specified number\n     */\n    static fromBigInt(value) {\n        if (value === 0n) {\n            return zero;\n        }\n        if (value < MAX_SAFE_NUMBER_INTEGER && value > MIN_SAFE_NUMBER_INTEGER) {\n            return this.fromNumber(Number(value));\n        }\n        const negative = value < 0n;\n        if (negative) {\n            value = -value;\n        }\n        let hi = value >> 32n;\n        let lo = value - (hi << 32n);\n        if (negative) {\n            hi = ~hi | 0n;\n            lo = ~lo | 0n;\n            if (++lo > TWO_32) {\n                lo = 0n;\n                if (++hi > TWO_32) {\n                    hi = 0n;\n                }\n            }\n        }\n        return new LongBits(Number(lo), Number(hi));\n    }\n    /**\n     * Constructs new long bits from the specified number\n     */\n    static fromNumber(value) {\n        if (value === 0) {\n            return zero;\n        }\n        const sign = value < 0;\n        if (sign) {\n            value = -value;\n        }\n        let lo = value >>> 0;\n        let hi = (value - lo) / 4294967296 >>> 0;\n        if (sign) {\n            hi = ~hi >>> 0;\n            lo = ~lo >>> 0;\n            if (++lo > 4294967295) {\n                lo = 0;\n                if (++hi > 4294967295) {\n                    hi = 0;\n                }\n            }\n        }\n        return new LongBits(lo, hi);\n    }\n    /**\n     * Constructs new long bits from a number, long or string\n     */\n    static from(value) {\n        if (typeof value === 'number') {\n            return LongBits.fromNumber(value);\n        }\n        if (typeof value === 'bigint') {\n            return LongBits.fromBigInt(value);\n        }\n        if (typeof value === 'string') {\n            return LongBits.fromBigInt(BigInt(value));\n        }\n        return value.low != null || value.high != null ? new LongBits(value.low >>> 0, value.high >>> 0) : zero;\n    }\n}\nconst zero = new LongBits(0, 0);\nzero.toBigInt = function () { return 0n; };\nzero.zzEncode = zero.zzDecode = function () { return this; };\nzero.length = function () { return 1; };\nconst TWO_32 = 4294967296n;\n//# sourceMappingURL=longbits.js.map","/**\n * Calculates the UTF8 byte length of a string\n */\nexport function length(string) {\n    let len = 0;\n    let c = 0;\n    for (let i = 0; i < string.length; ++i) {\n        c = string.charCodeAt(i);\n        if (c < 128) {\n            len += 1;\n        }\n        else if (c < 2048) {\n            len += 2;\n        }\n        else if ((c & 0xFC00) === 0xD800 && (string.charCodeAt(i + 1) & 0xFC00) === 0xDC00) {\n            ++i;\n            len += 4;\n        }\n        else {\n            len += 3;\n        }\n    }\n    return len;\n}\n/**\n * Reads UTF8 bytes as a string\n */\nexport function read(buffer, start, end) {\n    const len = end - start;\n    if (len < 1) {\n        return '';\n    }\n    let parts;\n    const chunk = [];\n    let i = 0; // char offset\n    let t; // temporary\n    while (start < end) {\n        t = buffer[start++];\n        if (t < 128) {\n            chunk[i++] = t;\n        }\n        else if (t > 191 && t < 224) {\n            chunk[i++] = (t & 31) << 6 | buffer[start++] & 63;\n        }\n        else if (t > 239 && t < 365) {\n            t = ((t & 7) << 18 | (buffer[start++] & 63) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63) - 0x10000;\n            chunk[i++] = 0xD800 + (t >> 10);\n            chunk[i++] = 0xDC00 + (t & 1023);\n        }\n        else {\n            chunk[i++] = (t & 15) << 12 | (buffer[start++] & 63) << 6 | buffer[start++] & 63;\n        }\n        if (i > 8191) {\n            (parts ?? (parts = [])).push(String.fromCharCode.apply(String, chunk));\n            i = 0;\n        }\n    }\n    if (parts != null) {\n        if (i > 0) {\n            parts.push(String.fromCharCode.apply(String, chunk.slice(0, i)));\n        }\n        return parts.join('');\n    }\n    return String.fromCharCode.apply(String, chunk.slice(0, i));\n}\n/**\n * Writes a string as UTF8 bytes\n */\nexport function write(string, buffer, offset) {\n    const start = offset;\n    let c1; // character 1\n    let c2; // character 2\n    for (let i = 0; i < string.length; ++i) {\n        c1 = string.charCodeAt(i);\n        if (c1 < 128) {\n            buffer[offset++] = c1;\n        }\n        else if (c1 < 2048) {\n            buffer[offset++] = c1 >> 6 | 192;\n            buffer[offset++] = c1 & 63 | 128;\n        }\n        else if ((c1 & 0xFC00) === 0xD800 && ((c2 = string.charCodeAt(i + 1)) & 0xFC00) === 0xDC00) {\n            c1 = 0x10000 + ((c1 & 0x03FF) << 10) + (c2 & 0x03FF);\n            ++i;\n            buffer[offset++] = c1 >> 18 | 240;\n            buffer[offset++] = c1 >> 12 & 63 | 128;\n            buffer[offset++] = c1 >> 6 & 63 | 128;\n            buffer[offset++] = c1 & 63 | 128;\n        }\n        else {\n            buffer[offset++] = c1 >> 12 | 224;\n            buffer[offset++] = c1 >> 6 & 63 | 128;\n            buffer[offset++] = c1 & 63 | 128;\n        }\n    }\n    return offset - start;\n}\n//# sourceMappingURL=utf8.js.map","import { decodeUint8Array, encodingLength } from 'uint8-varint';\nimport { readFloatLE, readDoubleLE } from './float.js';\nimport { LongBits } from './longbits.js';\nimport * as utf8 from './utf8.js';\n/* istanbul ignore next */\nfunction indexOutOfRange(reader, writeLength) {\n    return RangeError(`index out of range: ${reader.pos} + ${writeLength ?? 1} > ${reader.len}`);\n}\nfunction readFixed32End(buf, end) {\n    return (buf[end - 4] |\n        buf[end - 3] << 8 |\n        buf[end - 2] << 16 |\n        buf[end - 1] << 24) >>> 0;\n}\n/**\n * Constructs a new reader instance using the specified buffer.\n */\nexport class Uint8ArrayReader {\n    buf;\n    pos;\n    len;\n    _slice = Uint8Array.prototype.subarray;\n    constructor(buffer) {\n        /**\n         * Read buffer\n         */\n        this.buf = buffer;\n        /**\n         * Read buffer position\n         */\n        this.pos = 0;\n        /**\n         * Read buffer length\n         */\n        this.len = buffer.length;\n    }\n    /**\n     * Reads a varint as an unsigned 32 bit value\n     */\n    uint32() {\n        let value = 4294967295;\n        value = (this.buf[this.pos] & 127) >>> 0;\n        if (this.buf[this.pos++] < 128)\n            return value;\n        value = (value | (this.buf[this.pos] & 127) << 7) >>> 0;\n        if (this.buf[this.pos++] < 128)\n            return value;\n        value = (value | (this.buf[this.pos] & 127) << 14) >>> 0;\n        if (this.buf[this.pos++] < 128)\n            return value;\n        value = (value | (this.buf[this.pos] & 127) << 21) >>> 0;\n        if (this.buf[this.pos++] < 128)\n            return value;\n        value = (value | (this.buf[this.pos] & 15) << 28) >>> 0;\n        if (this.buf[this.pos++] < 128)\n            return value;\n        if ((this.pos += 5) > this.len) {\n            this.pos = this.len;\n            throw indexOutOfRange(this, 10);\n        }\n        return value;\n    }\n    /**\n     * Reads a varint as a signed 32 bit value\n     */\n    int32() {\n        return this.uint32() | 0;\n    }\n    /**\n     * Reads a zig-zag encoded varint as a signed 32 bit value\n     */\n    sint32() {\n        const value = this.uint32();\n        return value >>> 1 ^ -(value & 1) | 0;\n    }\n    /**\n     * Reads a varint as a boolean\n     */\n    bool() {\n        return this.uint32() !== 0;\n    }\n    /**\n     * Reads fixed 32 bits as an unsigned 32 bit integer\n     */\n    fixed32() {\n        if (this.pos + 4 > this.len) {\n            throw indexOutOfRange(this, 4);\n        }\n        const res = readFixed32End(this.buf, this.pos += 4);\n        return res;\n    }\n    /**\n     * Reads fixed 32 bits as a signed 32 bit integer\n     */\n    sfixed32() {\n        if (this.pos + 4 > this.len) {\n            throw indexOutOfRange(this, 4);\n        }\n        const res = readFixed32End(this.buf, this.pos += 4) | 0;\n        return res;\n    }\n    /**\n     * Reads a float (32 bit) as a number\n     */\n    float() {\n        if (this.pos + 4 > this.len) {\n            throw indexOutOfRange(this, 4);\n        }\n        const value = readFloatLE(this.buf, this.pos);\n        this.pos += 4;\n        return value;\n    }\n    /**\n     * Reads a double (64 bit float) as a number\n     */\n    double() {\n        /* istanbul ignore if */\n        if (this.pos + 8 > this.len) {\n            throw indexOutOfRange(this, 4);\n        }\n        const value = readDoubleLE(this.buf, this.pos);\n        this.pos += 8;\n        return value;\n    }\n    /**\n     * Reads a sequence of bytes preceded by its length as a varint\n     */\n    bytes() {\n        const length = this.uint32();\n        const start = this.pos;\n        const end = this.pos + length;\n        /* istanbul ignore if */\n        if (end > this.len) {\n            throw indexOutOfRange(this, length);\n        }\n        this.pos += length;\n        return start === end // fix for IE 10/Win8 and others' subarray returning array of size 1\n            ? new Uint8Array(0)\n            : this.buf.subarray(start, end);\n    }\n    /**\n     * Reads a string preceded by its byte length as a varint\n     */\n    string() {\n        const bytes = this.bytes();\n        return utf8.read(bytes, 0, bytes.length);\n    }\n    /**\n     * Skips the specified number of bytes if specified, otherwise skips a varint\n     */\n    skip(length) {\n        if (typeof length === 'number') {\n            /* istanbul ignore if */\n            if (this.pos + length > this.len) {\n                throw indexOutOfRange(this, length);\n            }\n            this.pos += length;\n        }\n        else {\n            do {\n                /* istanbul ignore if */\n                if (this.pos >= this.len) {\n                    throw indexOutOfRange(this);\n                }\n            } while ((this.buf[this.pos++] & 128) !== 0);\n        }\n        return this;\n    }\n    /**\n     * Skips the next element of the specified wire type\n     */\n    skipType(wireType) {\n        switch (wireType) {\n            case 0:\n                this.skip();\n                break;\n            case 1:\n                this.skip(8);\n                break;\n            case 2:\n                this.skip(this.uint32());\n                break;\n            case 3:\n                while ((wireType = this.uint32() & 7) !== 4) {\n                    this.skipType(wireType);\n                }\n                break;\n            case 5:\n                this.skip(4);\n                break;\n            /* istanbul ignore next */\n            default:\n                throw Error(`invalid wire type ${wireType} at offset ${this.pos}`);\n        }\n        return this;\n    }\n    readLongVarint() {\n        // tends to deopt with local vars for octet etc.\n        const bits = new LongBits(0, 0);\n        let i = 0;\n        if (this.len - this.pos > 4) { // fast route (lo)\n            for (; i < 4; ++i) {\n                // 1st..4th\n                bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n                if (this.buf[this.pos++] < 128) {\n                    return bits;\n                }\n            }\n            // 5th\n            bits.lo = (bits.lo | (this.buf[this.pos] & 127) << 28) >>> 0;\n            bits.hi = (bits.hi | (this.buf[this.pos] & 127) >> 4) >>> 0;\n            if (this.buf[this.pos++] < 128) {\n                return bits;\n            }\n            i = 0;\n        }\n        else {\n            for (; i < 3; ++i) {\n                /* istanbul ignore if */\n                if (this.pos >= this.len) {\n                    throw indexOutOfRange(this);\n                }\n                // 1st..3th\n                bits.lo = (bits.lo | (this.buf[this.pos] & 127) << i * 7) >>> 0;\n                if (this.buf[this.pos++] < 128) {\n                    return bits;\n                }\n            }\n            // 4th\n            bits.lo = (bits.lo | (this.buf[this.pos++] & 127) << i * 7) >>> 0;\n            return bits;\n        }\n        if (this.len - this.pos > 4) { // fast route (hi)\n            for (; i < 5; ++i) {\n                // 6th..10th\n                bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n                if (this.buf[this.pos++] < 128) {\n                    return bits;\n                }\n            }\n        }\n        else {\n            for (; i < 5; ++i) {\n                if (this.pos >= this.len) {\n                    throw indexOutOfRange(this);\n                }\n                // 6th..10th\n                bits.hi = (bits.hi | (this.buf[this.pos] & 127) << i * 7 + 3) >>> 0;\n                if (this.buf[this.pos++] < 128) {\n                    return bits;\n                }\n            }\n        }\n        throw Error('invalid varint encoding');\n    }\n    readFixed64() {\n        if (this.pos + 8 > this.len) {\n            throw indexOutOfRange(this, 8);\n        }\n        const lo = readFixed32End(this.buf, this.pos += 4);\n        const hi = readFixed32End(this.buf, this.pos += 4);\n        return new LongBits(lo, hi);\n    }\n    /**\n     * Reads a varint as a signed 64 bit value\n     */\n    int64() {\n        return this.readLongVarint().toBigInt();\n    }\n    /**\n     * Reads a varint as a signed 64 bit value returned as a possibly unsafe\n     * JavaScript number\n     */\n    int64Number() {\n        return this.readLongVarint().toNumber();\n    }\n    /**\n     * Reads a varint as a signed 64 bit value returned as a string\n     */\n    int64String() {\n        return this.readLongVarint().toString();\n    }\n    /**\n     * Reads a varint as an unsigned 64 bit value\n     */\n    uint64() {\n        return this.readLongVarint().toBigInt(true);\n    }\n    /**\n     * Reads a varint as an unsigned 64 bit value returned as a possibly unsafe\n     * JavaScript number\n     */\n    uint64Number() {\n        const value = decodeUint8Array(this.buf, this.pos);\n        this.pos += encodingLength(value);\n        return value;\n    }\n    /**\n     * Reads a varint as an unsigned 64 bit value returned as a string\n     */\n    uint64String() {\n        return this.readLongVarint().toString(true);\n    }\n    /**\n     * Reads a zig-zag encoded varint as a signed 64 bit value\n     */\n    sint64() {\n        return this.readLongVarint().zzDecode().toBigInt();\n    }\n    /**\n     * Reads a zig-zag encoded varint as a signed 64 bit value returned as a\n     * possibly unsafe JavaScript number\n     */\n    sint64Number() {\n        return this.readLongVarint().zzDecode().toNumber();\n    }\n    /**\n     * Reads a zig-zag encoded varint as a signed 64 bit value returned as a\n     * string\n     */\n    sint64String() {\n        return this.readLongVarint().zzDecode().toString();\n    }\n    /**\n     * Reads fixed 64 bits\n     */\n    fixed64() {\n        return this.readFixed64().toBigInt();\n    }\n    /**\n     * Reads fixed 64 bits returned as a possibly unsafe JavaScript number\n     */\n    fixed64Number() {\n        return this.readFixed64().toNumber();\n    }\n    /**\n     * Reads fixed 64 bits returned as a string\n     */\n    fixed64String() {\n        return this.readFixed64().toString();\n    }\n    /**\n     * Reads zig-zag encoded fixed 64 bits\n     */\n    sfixed64() {\n        return this.readFixed64().toBigInt();\n    }\n    /**\n     * Reads zig-zag encoded fixed 64 bits returned as a possibly unsafe\n     * JavaScript number\n     */\n    sfixed64Number() {\n        return this.readFixed64().toNumber();\n    }\n    /**\n     * Reads zig-zag encoded fixed 64 bits returned as a string\n     */\n    sfixed64String() {\n        return this.readFixed64().toString();\n    }\n}\nexport function createReader(buf) {\n    return new Uint8ArrayReader(buf instanceof Uint8Array ? buf : buf.subarray());\n}\n//# sourceMappingURL=reader.js.map","import { createReader } from './utils/reader.js';\nexport function decodeMessage(buf, codec, opts) {\n    const reader = createReader(buf);\n    return codec.decode(reader, undefined, opts);\n}\n//# sourceMappingURL=decode.js.map","import { allocUnsafe } from 'uint8arrays/alloc';\n/**\n * A general purpose buffer pool\n */\nexport default function pool(size) {\n    const SIZE = size ?? 8192;\n    const MAX = SIZE >>> 1;\n    let slab;\n    let offset = SIZE;\n    return function poolAlloc(size) {\n        if (size < 1 || size > MAX) {\n            return allocUnsafe(size);\n        }\n        if (offset + size > SIZE) {\n            slab = allocUnsafe(SIZE);\n            offset = 0;\n        }\n        const buf = slab.subarray(offset, offset += size);\n        if ((offset & 7) !== 0) {\n            // align to 32 bit\n            offset = (offset | 7) + 1;\n        }\n        return buf;\n    };\n}\n//# sourceMappingURL=pool.js.map","import { encodeUint8Array, encodingLength } from 'uint8-varint';\nimport { allocUnsafe } from 'uint8arrays/alloc';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { writeFloatLE, writeDoubleLE } from './float.js';\nimport { LongBits } from './longbits.js';\nimport pool from './pool.js';\nimport * as utf8 from './utf8.js';\n/**\n * Constructs a new writer operation instance.\n *\n * @classdesc Scheduled writer operation\n */\nclass Op {\n    /**\n     * Function to call\n     */\n    fn;\n    /**\n     * Value byte length\n     */\n    len;\n    /**\n     * Next operation\n     */\n    next;\n    /**\n     * Value to write\n     */\n    val;\n    constructor(fn, len, val) {\n        this.fn = fn;\n        this.len = len;\n        this.next = undefined;\n        this.val = val; // type varies\n    }\n}\n/* istanbul ignore next */\nfunction noop() { } // eslint-disable-line no-empty-function\n/**\n * Constructs a new writer state instance\n */\nclass State {\n    /**\n     * Current head\n     */\n    head;\n    /**\n     * Current tail\n     */\n    tail;\n    /**\n     * Current buffer length\n     */\n    len;\n    /**\n     * Next state\n     */\n    next;\n    constructor(writer) {\n        this.head = writer.head;\n        this.tail = writer.tail;\n        this.len = writer.len;\n        this.next = writer.states;\n    }\n}\nconst bufferPool = pool();\n/**\n * Allocates a buffer of the specified size\n */\nfunction alloc(size) {\n    if (globalThis.Buffer != null) {\n        return allocUnsafe(size);\n    }\n    return bufferPool(size);\n}\n/**\n * When a value is written, the writer calculates its byte length and puts it into a linked\n * list of operations to perform when finish() is called. This both allows us to allocate\n * buffers of the exact required size and reduces the amount of work we have to do compared\n * to first calculating over objects and then encoding over objects. In our case, the encoding\n * part is just a linked list walk calling operations with already prepared values.\n */\nclass Uint8ArrayWriter {\n    /**\n     * Current length\n     */\n    len;\n    /**\n     * Operations head\n     */\n    head;\n    /**\n     * Operations tail\n     */\n    tail;\n    /**\n     * Linked forked states\n     */\n    states;\n    constructor() {\n        this.len = 0;\n        this.head = new Op(noop, 0, 0);\n        this.tail = this.head;\n        this.states = null;\n    }\n    /**\n     * Pushes a new operation to the queue\n     */\n    _push(fn, len, val) {\n        this.tail = this.tail.next = new Op(fn, len, val);\n        this.len += len;\n        return this;\n    }\n    /**\n     * Writes an unsigned 32 bit value as a varint\n     */\n    uint32(value) {\n        // here, the call to this.push has been inlined and a varint specific Op subclass is used.\n        // uint32 is by far the most frequently used operation and benefits significantly from this.\n        this.len += (this.tail = this.tail.next = new VarintOp((value = value >>> 0) <\n            128\n            ? 1\n            : value < 16384\n                ? 2\n                : value < 2097152\n                    ? 3\n                    : value < 268435456\n                        ? 4\n                        : 5, value)).len;\n        return this;\n    }\n    /**\n     * Writes a signed 32 bit value as a varint`\n     */\n    int32(value) {\n        return value < 0\n            ? this._push(writeVarint64, 10, LongBits.fromNumber(value)) // 10 bytes per spec\n            : this.uint32(value);\n    }\n    /**\n     * Writes a 32 bit value as a varint, zig-zag encoded\n     */\n    sint32(value) {\n        return this.uint32((value << 1 ^ value >> 31) >>> 0);\n    }\n    /**\n     * Writes an unsigned 64 bit value as a varint\n     */\n    uint64(value) {\n        const bits = LongBits.fromBigInt(value);\n        return this._push(writeVarint64, bits.length(), bits);\n    }\n    /**\n     * Writes an unsigned 64 bit value as a varint\n     */\n    uint64Number(value) {\n        return this._push(encodeUint8Array, encodingLength(value), value);\n    }\n    /**\n     * Writes an unsigned 64 bit value as a varint\n     */\n    uint64String(value) {\n        return this.uint64(BigInt(value));\n    }\n    /**\n     * Writes a signed 64 bit value as a varint\n     */\n    int64(value) {\n        return this.uint64(value);\n    }\n    /**\n     * Writes a signed 64 bit value as a varint\n     */\n    int64Number(value) {\n        return this.uint64Number(value);\n    }\n    /**\n     * Writes a signed 64 bit value as a varint\n     */\n    int64String(value) {\n        return this.uint64String(value);\n    }\n    /**\n     * Writes a signed 64 bit value as a varint, zig-zag encoded\n     */\n    sint64(value) {\n        const bits = LongBits.fromBigInt(value).zzEncode();\n        return this._push(writeVarint64, bits.length(), bits);\n    }\n    /**\n     * Writes a signed 64 bit value as a varint, zig-zag encoded\n     */\n    sint64Number(value) {\n        const bits = LongBits.fromNumber(value).zzEncode();\n        return this._push(writeVarint64, bits.length(), bits);\n    }\n    /**\n     * Writes a signed 64 bit value as a varint, zig-zag encoded\n     */\n    sint64String(value) {\n        return this.sint64(BigInt(value));\n    }\n    /**\n     * Writes a boolish value as a varint\n     */\n    bool(value) {\n        return this._push(writeByte, 1, value ? 1 : 0);\n    }\n    /**\n     * Writes an unsigned 32 bit value as fixed 32 bits\n     */\n    fixed32(value) {\n        return this._push(writeFixed32, 4, value >>> 0);\n    }\n    /**\n     * Writes a signed 32 bit value as fixed 32 bits\n     */\n    sfixed32(value) {\n        return this.fixed32(value);\n    }\n    /**\n     * Writes an unsigned 64 bit value as fixed 64 bits\n     */\n    fixed64(value) {\n        const bits = LongBits.fromBigInt(value);\n        return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);\n    }\n    /**\n     * Writes an unsigned 64 bit value as fixed 64 bits\n     */\n    fixed64Number(value) {\n        const bits = LongBits.fromNumber(value);\n        return this._push(writeFixed32, 4, bits.lo)._push(writeFixed32, 4, bits.hi);\n    }\n    /**\n     * Writes an unsigned 64 bit value as fixed 64 bits\n     */\n    fixed64String(value) {\n        return this.fixed64(BigInt(value));\n    }\n    /**\n     * Writes a signed 64 bit value as fixed 64 bits\n     */\n    sfixed64(value) {\n        return this.fixed64(value);\n    }\n    /**\n     * Writes a signed 64 bit value as fixed 64 bits\n     */\n    sfixed64Number(value) {\n        return this.fixed64Number(value);\n    }\n    /**\n     * Writes a signed 64 bit value as fixed 64 bits\n     */\n    sfixed64String(value) {\n        return this.fixed64String(value);\n    }\n    /**\n     * Writes a float (32 bit)\n     */\n    float(value) {\n        return this._push(writeFloatLE, 4, value);\n    }\n    /**\n     * Writes a double (64 bit float).\n     *\n     * @function\n     * @param {number} value - Value to write\n     * @returns {Writer} `this`\n     */\n    double(value) {\n        return this._push(writeDoubleLE, 8, value);\n    }\n    /**\n     * Writes a sequence of bytes\n     */\n    bytes(value) {\n        const len = value.length >>> 0;\n        if (len === 0) {\n            return this._push(writeByte, 1, 0);\n        }\n        return this.uint32(len)._push(writeBytes, len, value);\n    }\n    /**\n     * Writes a string\n     */\n    string(value) {\n        const len = utf8.length(value);\n        return len !== 0\n            ? this.uint32(len)._push(utf8.write, len, value)\n            : this._push(writeByte, 1, 0);\n    }\n    /**\n     * Forks this writer's state by pushing it to a stack.\n     * Calling {@link Writer#reset|reset} or {@link Writer#ldelim|ldelim} resets the writer to the previous state.\n     */\n    fork() {\n        this.states = new State(this);\n        this.head = this.tail = new Op(noop, 0, 0);\n        this.len = 0;\n        return this;\n    }\n    /**\n     * Resets this instance to the last state\n     */\n    reset() {\n        if (this.states != null) {\n            this.head = this.states.head;\n            this.tail = this.states.tail;\n            this.len = this.states.len;\n            this.states = this.states.next;\n        }\n        else {\n            this.head = this.tail = new Op(noop, 0, 0);\n            this.len = 0;\n        }\n        return this;\n    }\n    /**\n     * Resets to the last state and appends the fork state's current write length as a varint followed by its operations.\n     */\n    ldelim() {\n        const head = this.head;\n        const tail = this.tail;\n        const len = this.len;\n        this.reset().uint32(len);\n        if (len !== 0) {\n            this.tail.next = head.next; // skip noop\n            this.tail = tail;\n            this.len += len;\n        }\n        return this;\n    }\n    /**\n     * Finishes the write operation\n     */\n    finish() {\n        let head = this.head.next; // skip noop\n        const buf = alloc(this.len);\n        let pos = 0;\n        while (head != null) {\n            head.fn(head.val, buf, pos);\n            pos += head.len;\n            head = head.next;\n        }\n        // this.head = this.tail = null;\n        return buf;\n    }\n}\nfunction writeByte(val, buf, pos) {\n    buf[pos] = val & 255;\n}\nfunction writeVarint32(val, buf, pos) {\n    while (val > 127) {\n        buf[pos++] = val & 127 | 128;\n        val >>>= 7;\n    }\n    buf[pos] = val;\n}\n/**\n * Constructs a new varint writer operation instance.\n *\n * @classdesc Scheduled varint writer operation\n */\nclass VarintOp extends Op {\n    next;\n    constructor(len, val) {\n        super(writeVarint32, len, val);\n        this.next = undefined;\n    }\n}\nfunction writeVarint64(val, buf, pos) {\n    while (val.hi !== 0) {\n        buf[pos++] = val.lo & 127 | 128;\n        val.lo = (val.lo >>> 7 | val.hi << 25) >>> 0;\n        val.hi >>>= 7;\n    }\n    while (val.lo > 127) {\n        buf[pos++] = val.lo & 127 | 128;\n        val.lo = val.lo >>> 7;\n    }\n    buf[pos++] = val.lo;\n}\nfunction writeFixed32(val, buf, pos) {\n    buf[pos] = val & 255;\n    buf[pos + 1] = val >>> 8 & 255;\n    buf[pos + 2] = val >>> 16 & 255;\n    buf[pos + 3] = val >>> 24;\n}\nfunction writeBytes(val, buf, pos) {\n    buf.set(val, pos);\n}\nif (globalThis.Buffer != null) {\n    Uint8ArrayWriter.prototype.bytes = function (value) {\n        const len = value.length >>> 0;\n        this.uint32(len);\n        if (len > 0) {\n            this._push(writeBytesBuffer, len, value);\n        }\n        return this;\n    };\n    Uint8ArrayWriter.prototype.string = function (value) {\n        const len = globalThis.Buffer.byteLength(value);\n        this.uint32(len);\n        if (len > 0) {\n            this._push(writeStringBuffer, len, value);\n        }\n        return this;\n    };\n}\nfunction writeBytesBuffer(val, buf, pos) {\n    buf.set(val, pos); // faster than copy (requires node >= 4 where Buffers extend Uint8Array and set is properly inherited)\n    // also works for plain array values\n}\nfunction writeStringBuffer(val, buf, pos) {\n    if (val.length < 40) {\n        // plain js is faster for short strings (probably due to redundant assertions)\n        utf8.write(val, buf, pos);\n        // @ts-expect-error buf isn't a Uint8Array?\n    }\n    else if (buf.utf8Write != null) {\n        // @ts-expect-error buf isn't a Uint8Array?\n        buf.utf8Write(val, pos);\n    }\n    else {\n        buf.set(uint8ArrayFromString(val), pos);\n    }\n}\n/**\n * Creates a new writer\n */\nexport function createWriter() {\n    return new Uint8ArrayWriter();\n}\n//# sourceMappingURL=writer.js.map","import { createWriter } from './utils/writer.js';\nexport function encodeMessage(message, codec) {\n    const w = createWriter();\n    codec.encode(message, w, {\n        lengthDelimited: false\n    });\n    return w.finish();\n}\n//# sourceMappingURL=encode.js.map","// https://developers.google.com/protocol-buffers/docs/encoding#structure\nexport var CODEC_TYPES;\n(function (CODEC_TYPES) {\n    CODEC_TYPES[CODEC_TYPES[\"VARINT\"] = 0] = \"VARINT\";\n    CODEC_TYPES[CODEC_TYPES[\"BIT64\"] = 1] = \"BIT64\";\n    CODEC_TYPES[CODEC_TYPES[\"LENGTH_DELIMITED\"] = 2] = \"LENGTH_DELIMITED\";\n    CODEC_TYPES[CODEC_TYPES[\"START_GROUP\"] = 3] = \"START_GROUP\";\n    CODEC_TYPES[CODEC_TYPES[\"END_GROUP\"] = 4] = \"END_GROUP\";\n    CODEC_TYPES[CODEC_TYPES[\"BIT32\"] = 5] = \"BIT32\";\n})(CODEC_TYPES || (CODEC_TYPES = {}));\nexport function createCodec(name, type, encode, decode) {\n    return {\n        name,\n        type,\n        encode,\n        decode\n    };\n}\n//# sourceMappingURL=codec.js.map","import { createCodec, CODEC_TYPES } from '../codec.js';\nexport function enumeration(v) {\n    function findValue(val) {\n        // Use the reverse mapping to look up the enum key for the stored value\n        // https://www.typescriptlang.org/docs/handbook/enums.html#reverse-mappings\n        if (v[val.toString()] == null) {\n            throw new Error('Invalid enum value');\n        }\n        return v[val];\n    }\n    const encode = function enumEncode(val, writer) {\n        const enumValue = findValue(val);\n        writer.int32(enumValue);\n    };\n    const decode = function enumDecode(reader) {\n        const val = reader.int32();\n        return findValue(val);\n    };\n    // @ts-expect-error yeah yeah\n    return createCodec('enum', CODEC_TYPES.VARINT, encode, decode);\n}\n//# sourceMappingURL=enum.js.map","import { createCodec, CODEC_TYPES } from '../codec.js';\nexport function message(encode, decode) {\n    return createCodec('message', CODEC_TYPES.LENGTH_DELIMITED, encode, decode);\n}\n//# sourceMappingURL=message.js.map","/**\n * @packageDocumentation\n *\n * This module contains serialization/deserialization code used when encoding/decoding protobufs.\n *\n * It should be declared as a dependency of your project:\n *\n * ```console\n * npm i protons-runtime\n * ```\n */\nexport { decodeMessage } from './decode.js';\nexport { encodeMessage } from './encode.js';\nexport { enumeration } from './codecs/enum.js';\nexport { message } from './codecs/message.js';\nexport { createReader as reader } from './utils/reader.js';\nexport { createWriter as writer } from './utils/writer.js';\n/**\n * This will be removed in a future release\n *\n * @deprecated\n */\nexport class CodeError extends Error {\n    code;\n    constructor(message, code) {\n        super(message);\n        this.code = code;\n    }\n}\n/**\n * Thrown when a repeated field has too many elements\n */\nexport class MaxLengthError extends Error {\n    /**\n     * This will be removed in a future release\n     *\n     * @deprecated use the `.name` property instead\n     */\n    code = 'ERR_MAX_LENGTH';\n    name = 'MaxLengthError';\n}\n/**\n * Thrown when a map has too many elements\n */\nexport class MaxSizeError extends Error {\n    /**\n     * This will be removed in a future release\n     *\n     * @deprecated use the `.name` property instead\n     */\n    code = 'ERR_MAX_SIZE';\n    name = 'MaxSizeError';\n}\nexport class ParseError extends Error {\n    /**\n     * This will be removed in a future release\n     *\n     * @deprecated use the `.name` property instead\n     */\n    code = 'ERR_PARSE_ERROR';\n    name = 'ParseError';\n}\nexport class NoMessagesFoundError extends Error {\n    /**\n     * This will be removed in a future release\n     *\n     * @deprecated use the `.name` property instead\n     */\n    code = 'ERR_NO_MESSAGES_FOUND';\n    name = 'NoMessagesFoundError';\n}\n//# sourceMappingURL=index.js.map","/* eslint-disable import/export */\n/* eslint-disable complexity */\n/* eslint-disable @typescript-eslint/no-namespace */\n/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */\n/* eslint-disable @typescript-eslint/no-empty-interface */\nimport { decodeMessage, encodeMessage, enumeration, message } from 'protons-runtime';\nexport var KeyType;\n(function (KeyType) {\n    KeyType[\"RSA\"] = \"RSA\";\n    KeyType[\"Ed25519\"] = \"Ed25519\";\n    KeyType[\"secp256k1\"] = \"secp256k1\";\n})(KeyType || (KeyType = {}));\nvar __KeyTypeValues;\n(function (__KeyTypeValues) {\n    __KeyTypeValues[__KeyTypeValues[\"RSA\"] = 0] = \"RSA\";\n    __KeyTypeValues[__KeyTypeValues[\"Ed25519\"] = 1] = \"Ed25519\";\n    __KeyTypeValues[__KeyTypeValues[\"secp256k1\"] = 2] = \"secp256k1\";\n})(__KeyTypeValues || (__KeyTypeValues = {}));\n(function (KeyType) {\n    KeyType.codec = () => {\n        return enumeration(__KeyTypeValues);\n    };\n})(KeyType || (KeyType = {}));\nexport var PublicKey;\n(function (PublicKey) {\n    let _codec;\n    PublicKey.codec = () => {\n        if (_codec == null) {\n            _codec = message((obj, w, opts = {}) => {\n                if (opts.lengthDelimited !== false) {\n                    w.fork();\n                }\n                if (obj.Type != null) {\n                    w.uint32(8);\n                    KeyType.codec().encode(obj.Type, w);\n                }\n                if (obj.Data != null) {\n                    w.uint32(18);\n                    w.bytes(obj.Data);\n                }\n                if (opts.lengthDelimited !== false) {\n                    w.ldelim();\n                }\n            }, (reader, length, opts = {}) => {\n                const obj = {};\n                const end = length == null ? reader.len : reader.pos + length;\n                while (reader.pos < end) {\n                    const tag = reader.uint32();\n                    switch (tag >>> 3) {\n                        case 1: {\n                            obj.Type = KeyType.codec().decode(reader);\n                            break;\n                        }\n                        case 2: {\n                            obj.Data = reader.bytes();\n                            break;\n                        }\n                        default: {\n                            reader.skipType(tag & 7);\n                            break;\n                        }\n                    }\n                }\n                return obj;\n            });\n        }\n        return _codec;\n    };\n    PublicKey.encode = (obj) => {\n        return encodeMessage(obj, PublicKey.codec());\n    };\n    PublicKey.decode = (buf, opts) => {\n        return decodeMessage(buf, PublicKey.codec(), opts);\n    };\n})(PublicKey || (PublicKey = {}));\nexport var PrivateKey;\n(function (PrivateKey) {\n    let _codec;\n    PrivateKey.codec = () => {\n        if (_codec == null) {\n            _codec = message((obj, w, opts = {}) => {\n                if (opts.lengthDelimited !== false) {\n                    w.fork();\n                }\n                if (obj.Type != null) {\n                    w.uint32(8);\n                    KeyType.codec().encode(obj.Type, w);\n                }\n                if (obj.Data != null) {\n                    w.uint32(18);\n                    w.bytes(obj.Data);\n                }\n                if (opts.lengthDelimited !== false) {\n                    w.ldelim();\n                }\n            }, (reader, length, opts = {}) => {\n                const obj = {};\n                const end = length == null ? reader.len : reader.pos + length;\n                while (reader.pos < end) {\n                    const tag = reader.uint32();\n                    switch (tag >>> 3) {\n                        case 1: {\n                            obj.Type = KeyType.codec().decode(reader);\n                            break;\n                        }\n                        case 2: {\n                            obj.Data = reader.bytes();\n                            break;\n                        }\n                        default: {\n                            reader.skipType(tag & 7);\n                            break;\n                        }\n                    }\n                }\n                return obj;\n            });\n        }\n        return _codec;\n    };\n    PrivateKey.encode = (obj) => {\n        return encodeMessage(obj, PrivateKey.codec());\n    };\n    PrivateKey.decode = (buf, opts) => {\n        return decodeMessage(buf, PrivateKey.codec(), opts);\n    };\n})(PrivateKey || (PrivateKey = {}));\n//# sourceMappingURL=keys.js.map","/*!\n Copyright (c) Peculiar Ventures, LLC\n*/\n\nfunction getUTCDate(date) {\r\n    return new Date(date.getTime() + (date.getTimezoneOffset() * 60000));\r\n}\r\nfunction getParametersValue(parameters, name, defaultValue) {\r\n    var _a;\r\n    if ((parameters instanceof Object) === false) {\r\n        return defaultValue;\r\n    }\r\n    return (_a = parameters[name]) !== null && _a !== void 0 ? _a : defaultValue;\r\n}\r\nfunction bufferToHexCodes(inputBuffer, inputOffset = 0, inputLength = (inputBuffer.byteLength - inputOffset), insertSpace = false) {\r\n    let result = \"\";\r\n    for (const item of (new Uint8Array(inputBuffer, inputOffset, inputLength))) {\r\n        const str = item.toString(16).toUpperCase();\r\n        if (str.length === 1) {\r\n            result += \"0\";\r\n        }\r\n        result += str;\r\n        if (insertSpace) {\r\n            result += \" \";\r\n        }\r\n    }\r\n    return result.trim();\r\n}\r\nfunction checkBufferParams(baseBlock, inputBuffer, inputOffset, inputLength) {\r\n    if (!(inputBuffer instanceof ArrayBuffer)) {\r\n        baseBlock.error = \"Wrong parameter: inputBuffer must be \\\"ArrayBuffer\\\"\";\r\n        return false;\r\n    }\r\n    if (!inputBuffer.byteLength) {\r\n        baseBlock.error = \"Wrong parameter: inputBuffer has zero length\";\r\n        return false;\r\n    }\r\n    if (inputOffset < 0) {\r\n        baseBlock.error = \"Wrong parameter: inputOffset less than zero\";\r\n        return false;\r\n    }\r\n    if (inputLength < 0) {\r\n        baseBlock.error = \"Wrong parameter: inputLength less than zero\";\r\n        return false;\r\n    }\r\n    if ((inputBuffer.byteLength - inputOffset - inputLength) < 0) {\r\n        baseBlock.error = \"End of input reached before message was fully decoded (inconsistent offset and length values)\";\r\n        return false;\r\n    }\r\n    return true;\r\n}\r\nfunction utilFromBase(inputBuffer, inputBase) {\r\n    let result = 0;\r\n    if (inputBuffer.length === 1) {\r\n        return inputBuffer[0];\r\n    }\r\n    for (let i = (inputBuffer.length - 1); i >= 0; i--) {\r\n        result += inputBuffer[(inputBuffer.length - 1) - i] * Math.pow(2, inputBase * i);\r\n    }\r\n    return result;\r\n}\r\nfunction utilToBase(value, base, reserved = (-1)) {\r\n    const internalReserved = reserved;\r\n    let internalValue = value;\r\n    let result = 0;\r\n    let biggest = Math.pow(2, base);\r\n    for (let i = 1; i < 8; i++) {\r\n        if (value < biggest) {\r\n            let retBuf;\r\n            if (internalReserved < 0) {\r\n                retBuf = new ArrayBuffer(i);\r\n                result = i;\r\n            }\r\n            else {\r\n                if (internalReserved < i) {\r\n                    return (new ArrayBuffer(0));\r\n                }\r\n                retBuf = new ArrayBuffer(internalReserved);\r\n                result = internalReserved;\r\n            }\r\n            const retView = new Uint8Array(retBuf);\r\n            for (let j = (i - 1); j >= 0; j--) {\r\n                const basis = Math.pow(2, j * base);\r\n                retView[result - j - 1] = Math.floor(internalValue / basis);\r\n                internalValue -= (retView[result - j - 1]) * basis;\r\n            }\r\n            return retBuf;\r\n        }\r\n        biggest *= Math.pow(2, base);\r\n    }\r\n    return new ArrayBuffer(0);\r\n}\r\nfunction utilConcatBuf(...buffers) {\r\n    let outputLength = 0;\r\n    let prevLength = 0;\r\n    for (const buffer of buffers) {\r\n        outputLength += buffer.byteLength;\r\n    }\r\n    const retBuf = new ArrayBuffer(outputLength);\r\n    const retView = new Uint8Array(retBuf);\r\n    for (const buffer of buffers) {\r\n        retView.set(new Uint8Array(buffer), prevLength);\r\n        prevLength += buffer.byteLength;\r\n    }\r\n    return retBuf;\r\n}\r\nfunction utilConcatView(...views) {\r\n    let outputLength = 0;\r\n    let prevLength = 0;\r\n    for (const view of views) {\r\n        outputLength += view.length;\r\n    }\r\n    const retBuf = new ArrayBuffer(outputLength);\r\n    const retView = new Uint8Array(retBuf);\r\n    for (const view of views) {\r\n        retView.set(view, prevLength);\r\n        prevLength += view.length;\r\n    }\r\n    return retView;\r\n}\r\nfunction utilDecodeTC() {\r\n    const buf = new Uint8Array(this.valueHex);\r\n    if (this.valueHex.byteLength >= 2) {\r\n        const condition1 = (buf[0] === 0xFF) && (buf[1] & 0x80);\r\n        const condition2 = (buf[0] === 0x00) && ((buf[1] & 0x80) === 0x00);\r\n        if (condition1 || condition2) {\r\n            this.warnings.push(\"Needlessly long format\");\r\n        }\r\n    }\r\n    const bigIntBuffer = new ArrayBuffer(this.valueHex.byteLength);\r\n    const bigIntView = new Uint8Array(bigIntBuffer);\r\n    for (let i = 0; i < this.valueHex.byteLength; i++) {\r\n        bigIntView[i] = 0;\r\n    }\r\n    bigIntView[0] = (buf[0] & 0x80);\r\n    const bigInt = utilFromBase(bigIntView, 8);\r\n    const smallIntBuffer = new ArrayBuffer(this.valueHex.byteLength);\r\n    const smallIntView = new Uint8Array(smallIntBuffer);\r\n    for (let j = 0; j < this.valueHex.byteLength; j++) {\r\n        smallIntView[j] = buf[j];\r\n    }\r\n    smallIntView[0] &= 0x7F;\r\n    const smallInt = utilFromBase(smallIntView, 8);\r\n    return (smallInt - bigInt);\r\n}\r\nfunction utilEncodeTC(value) {\r\n    const modValue = (value < 0) ? (value * (-1)) : value;\r\n    let bigInt = 128;\r\n    for (let i = 1; i < 8; i++) {\r\n        if (modValue <= bigInt) {\r\n            if (value < 0) {\r\n                const smallInt = bigInt - modValue;\r\n                const retBuf = utilToBase(smallInt, 8, i);\r\n                const retView = new Uint8Array(retBuf);\r\n                retView[0] |= 0x80;\r\n                return retBuf;\r\n            }\r\n            let retBuf = utilToBase(modValue, 8, i);\r\n            let retView = new Uint8Array(retBuf);\r\n            if (retView[0] & 0x80) {\r\n                const tempBuf = retBuf.slice(0);\r\n                const tempView = new Uint8Array(tempBuf);\r\n                retBuf = new ArrayBuffer(retBuf.byteLength + 1);\r\n                retView = new Uint8Array(retBuf);\r\n                for (let k = 0; k < tempBuf.byteLength; k++) {\r\n                    retView[k + 1] = tempView[k];\r\n                }\r\n                retView[0] = 0x00;\r\n            }\r\n            return retBuf;\r\n        }\r\n        bigInt *= Math.pow(2, 8);\r\n    }\r\n    return (new ArrayBuffer(0));\r\n}\r\nfunction isEqualBuffer(inputBuffer1, inputBuffer2) {\r\n    if (inputBuffer1.byteLength !== inputBuffer2.byteLength) {\r\n        return false;\r\n    }\r\n    const view1 = new Uint8Array(inputBuffer1);\r\n    const view2 = new Uint8Array(inputBuffer2);\r\n    for (let i = 0; i < view1.length; i++) {\r\n        if (view1[i] !== view2[i]) {\r\n            return false;\r\n        }\r\n    }\r\n    return true;\r\n}\r\nfunction padNumber(inputNumber, fullLength) {\r\n    const str = inputNumber.toString(10);\r\n    if (fullLength < str.length) {\r\n        return \"\";\r\n    }\r\n    const dif = fullLength - str.length;\r\n    const padding = new Array(dif);\r\n    for (let i = 0; i < dif; i++) {\r\n        padding[i] = \"0\";\r\n    }\r\n    const paddingString = padding.join(\"\");\r\n    return paddingString.concat(str);\r\n}\r\nconst base64Template = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=\";\r\nconst base64UrlTemplate = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=\";\r\nfunction toBase64(input, useUrlTemplate = false, skipPadding = false, skipLeadingZeros = false) {\r\n    let i = 0;\r\n    let flag1 = 0;\r\n    let flag2 = 0;\r\n    let output = \"\";\r\n    const template = (useUrlTemplate) ? base64UrlTemplate : base64Template;\r\n    if (skipLeadingZeros) {\r\n        let nonZeroPosition = 0;\r\n        for (let i = 0; i < input.length; i++) {\r\n            if (input.charCodeAt(i) !== 0) {\r\n                nonZeroPosition = i;\r\n                break;\r\n            }\r\n        }\r\n        input = input.slice(nonZeroPosition);\r\n    }\r\n    while (i < input.length) {\r\n        const chr1 = input.charCodeAt(i++);\r\n        if (i >= input.length) {\r\n            flag1 = 1;\r\n        }\r\n        const chr2 = input.charCodeAt(i++);\r\n        if (i >= input.length) {\r\n            flag2 = 1;\r\n        }\r\n        const chr3 = input.charCodeAt(i++);\r\n        const enc1 = chr1 >> 2;\r\n        const enc2 = ((chr1 & 0x03) << 4) | (chr2 >> 4);\r\n        let enc3 = ((chr2 & 0x0F) << 2) | (chr3 >> 6);\r\n        let enc4 = chr3 & 0x3F;\r\n        if (flag1 === 1) {\r\n            enc3 = enc4 = 64;\r\n        }\r\n        else {\r\n            if (flag2 === 1) {\r\n                enc4 = 64;\r\n            }\r\n        }\r\n        if (skipPadding) {\r\n            if (enc3 === 64) {\r\n                output += `${template.charAt(enc1)}${template.charAt(enc2)}`;\r\n            }\r\n            else {\r\n                if (enc4 === 64) {\r\n                    output += `${template.charAt(enc1)}${template.charAt(enc2)}${template.charAt(enc3)}`;\r\n                }\r\n                else {\r\n                    output += `${template.charAt(enc1)}${template.charAt(enc2)}${template.charAt(enc3)}${template.charAt(enc4)}`;\r\n                }\r\n            }\r\n        }\r\n        else {\r\n            output += `${template.charAt(enc1)}${template.charAt(enc2)}${template.charAt(enc3)}${template.charAt(enc4)}`;\r\n        }\r\n    }\r\n    return output;\r\n}\r\nfunction fromBase64(input, useUrlTemplate = false, cutTailZeros = false) {\r\n    const template = (useUrlTemplate) ? base64UrlTemplate : base64Template;\r\n    function indexOf(toSearch) {\r\n        for (let i = 0; i < 64; i++) {\r\n            if (template.charAt(i) === toSearch)\r\n                return i;\r\n        }\r\n        return 64;\r\n    }\r\n    function test(incoming) {\r\n        return ((incoming === 64) ? 0x00 : incoming);\r\n    }\r\n    let i = 0;\r\n    let output = \"\";\r\n    while (i < input.length) {\r\n        const enc1 = indexOf(input.charAt(i++));\r\n        const enc2 = (i >= input.length) ? 0x00 : indexOf(input.charAt(i++));\r\n        const enc3 = (i >= input.length) ? 0x00 : indexOf(input.charAt(i++));\r\n        const enc4 = (i >= input.length) ? 0x00 : indexOf(input.charAt(i++));\r\n        const chr1 = (test(enc1) << 2) | (test(enc2) >> 4);\r\n        const chr2 = ((test(enc2) & 0x0F) << 4) | (test(enc3) >> 2);\r\n        const chr3 = ((test(enc3) & 0x03) << 6) | test(enc4);\r\n        output += String.fromCharCode(chr1);\r\n        if (enc3 !== 64) {\r\n            output += String.fromCharCode(chr2);\r\n        }\r\n        if (enc4 !== 64) {\r\n            output += String.fromCharCode(chr3);\r\n        }\r\n    }\r\n    if (cutTailZeros) {\r\n        const outputLength = output.length;\r\n        let nonZeroStart = (-1);\r\n        for (let i = (outputLength - 1); i >= 0; i--) {\r\n            if (output.charCodeAt(i) !== 0) {\r\n                nonZeroStart = i;\r\n                break;\r\n            }\r\n        }\r\n        if (nonZeroStart !== (-1)) {\r\n            output = output.slice(0, nonZeroStart + 1);\r\n        }\r\n        else {\r\n            output = \"\";\r\n        }\r\n    }\r\n    return output;\r\n}\r\nfunction arrayBufferToString(buffer) {\r\n    let resultString = \"\";\r\n    const view = new Uint8Array(buffer);\r\n    for (const element of view) {\r\n        resultString += String.fromCharCode(element);\r\n    }\r\n    return resultString;\r\n}\r\nfunction stringToArrayBuffer(str) {\r\n    const stringLength = str.length;\r\n    const resultBuffer = new ArrayBuffer(stringLength);\r\n    const resultView = new Uint8Array(resultBuffer);\r\n    for (let i = 0; i < stringLength; i++) {\r\n        resultView[i] = str.charCodeAt(i);\r\n    }\r\n    return resultBuffer;\r\n}\r\nconst log2 = Math.log(2);\r\nfunction nearestPowerOf2(length) {\r\n    const base = (Math.log(length) / log2);\r\n    const floor = Math.floor(base);\r\n    const round = Math.round(base);\r\n    return ((floor === round) ? floor : round);\r\n}\r\nfunction clearProps(object, propsArray) {\r\n    for (const prop of propsArray) {\r\n        delete object[prop];\r\n    }\r\n}\n\nexport { arrayBufferToString, bufferToHexCodes, checkBufferParams, clearProps, fromBase64, getParametersValue, getUTCDate, isEqualBuffer, nearestPowerOf2, padNumber, stringToArrayBuffer, toBase64, utilConcatBuf, utilConcatView, utilDecodeTC, utilEncodeTC, utilFromBase, utilToBase };\n","/*!\n * Copyright (c) 2014, GMO GlobalSign\n * Copyright (c) 2015-2022, Peculiar Ventures\n * All rights reserved.\n * \n * Author 2014-2019, Yury Strozhevsky\n * \n * Redistribution and use in source and binary forms, with or without modification,\n * are permitted provided that the following conditions are met:\n * \n * * Redistributions of source code must retain the above copyright notice, this\n *   list of conditions and the following disclaimer.\n * \n * * Redistributions in binary form must reproduce the above copyright notice, this\n *   list of conditions and the following disclaimer in the documentation and/or\n *   other materials provided with the distribution.\n * \n * * Neither the name of the copyright holder nor the names of its\n *   contributors may be used to endorse or promote products derived from\n *   this software without specific prior written permission.\n * \n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR\n * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON\n * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n * \n */\n\nimport * as pvtsutils from 'pvtsutils';\nimport * as pvutils from 'pvutils';\n\nfunction assertBigInt() {\r\n    if (typeof BigInt === \"undefined\") {\r\n        throw new Error(\"BigInt is not defined. Your environment doesn't implement BigInt.\");\r\n    }\r\n}\r\nfunction concat(buffers) {\r\n    let outputLength = 0;\r\n    let prevLength = 0;\r\n    for (let i = 0; i < buffers.length; i++) {\r\n        const buffer = buffers[i];\r\n        outputLength += buffer.byteLength;\r\n    }\r\n    const retView = new Uint8Array(outputLength);\r\n    for (let i = 0; i < buffers.length; i++) {\r\n        const buffer = buffers[i];\r\n        retView.set(new Uint8Array(buffer), prevLength);\r\n        prevLength += buffer.byteLength;\r\n    }\r\n    return retView.buffer;\r\n}\r\nfunction checkBufferParams(baseBlock, inputBuffer, inputOffset, inputLength) {\r\n    if (!(inputBuffer instanceof Uint8Array)) {\r\n        baseBlock.error = \"Wrong parameter: inputBuffer must be 'Uint8Array'\";\r\n        return false;\r\n    }\r\n    if (!inputBuffer.byteLength) {\r\n        baseBlock.error = \"Wrong parameter: inputBuffer has zero length\";\r\n        return false;\r\n    }\r\n    if (inputOffset < 0) {\r\n        baseBlock.error = \"Wrong parameter: inputOffset less than zero\";\r\n        return false;\r\n    }\r\n    if (inputLength < 0) {\r\n        baseBlock.error = \"Wrong parameter: inputLength less than zero\";\r\n        return false;\r\n    }\r\n    if ((inputBuffer.byteLength - inputOffset - inputLength) < 0) {\r\n        baseBlock.error = \"End of input reached before message was fully decoded (inconsistent offset and length values)\";\r\n        return false;\r\n    }\r\n    return true;\r\n}\n\nclass ViewWriter {\r\n    constructor() {\r\n        this.items = [];\r\n    }\r\n    write(buf) {\r\n        this.items.push(buf);\r\n    }\r\n    final() {\r\n        return concat(this.items);\r\n    }\r\n}\n\nconst powers2 = [new Uint8Array([1])];\r\nconst digitsString = \"0123456789\";\r\nconst NAME = \"name\";\r\nconst VALUE_HEX_VIEW = \"valueHexView\";\r\nconst IS_HEX_ONLY = \"isHexOnly\";\r\nconst ID_BLOCK = \"idBlock\";\r\nconst TAG_CLASS = \"tagClass\";\r\nconst TAG_NUMBER = \"tagNumber\";\r\nconst IS_CONSTRUCTED = \"isConstructed\";\r\nconst FROM_BER = \"fromBER\";\r\nconst TO_BER = \"toBER\";\r\nconst LOCAL = \"local\";\r\nconst EMPTY_STRING = \"\";\r\nconst EMPTY_BUFFER = new ArrayBuffer(0);\r\nconst EMPTY_VIEW = new Uint8Array(0);\r\nconst END_OF_CONTENT_NAME = \"EndOfContent\";\r\nconst OCTET_STRING_NAME = \"OCTET STRING\";\r\nconst BIT_STRING_NAME = \"BIT STRING\";\n\nfunction HexBlock(BaseClass) {\r\n    var _a;\r\n    return _a = class Some extends BaseClass {\r\n            constructor(...args) {\r\n                var _a;\r\n                super(...args);\r\n                const params = args[0] || {};\r\n                this.isHexOnly = (_a = params.isHexOnly) !== null && _a !== void 0 ? _a : false;\r\n                this.valueHexView = params.valueHex ? pvtsutils.BufferSourceConverter.toUint8Array(params.valueHex) : EMPTY_VIEW;\r\n            }\r\n            get valueHex() {\r\n                return this.valueHexView.slice().buffer;\r\n            }\r\n            set valueHex(value) {\r\n                this.valueHexView = new Uint8Array(value);\r\n            }\r\n            fromBER(inputBuffer, inputOffset, inputLength) {\r\n                const view = inputBuffer instanceof ArrayBuffer ? new Uint8Array(inputBuffer) : inputBuffer;\r\n                if (!checkBufferParams(this, view, inputOffset, inputLength)) {\r\n                    return -1;\r\n                }\r\n                const endLength = inputOffset + inputLength;\r\n                this.valueHexView = view.subarray(inputOffset, endLength);\r\n                if (!this.valueHexView.length) {\r\n                    this.warnings.push(\"Zero buffer length\");\r\n                    return inputOffset;\r\n                }\r\n                this.blockLength = inputLength;\r\n                return endLength;\r\n            }\r\n            toBER(sizeOnly = false) {\r\n                if (!this.isHexOnly) {\r\n                    this.error = \"Flag 'isHexOnly' is not set, abort\";\r\n                    return EMPTY_BUFFER;\r\n                }\r\n                if (sizeOnly) {\r\n                    return new ArrayBuffer(this.valueHexView.byteLength);\r\n                }\r\n                return (this.valueHexView.byteLength === this.valueHexView.buffer.byteLength)\r\n                    ? this.valueHexView.buffer\r\n                    : this.valueHexView.slice().buffer;\r\n            }\r\n            toJSON() {\r\n                return {\r\n                    ...super.toJSON(),\r\n                    isHexOnly: this.isHexOnly,\r\n                    valueHex: pvtsutils.Convert.ToHex(this.valueHexView),\r\n                };\r\n            }\r\n        },\r\n        _a.NAME = \"hexBlock\",\r\n        _a;\r\n}\n\nclass LocalBaseBlock {\r\n    constructor({ blockLength = 0, error = EMPTY_STRING, warnings = [], valueBeforeDecode = EMPTY_VIEW, } = {}) {\r\n        this.blockLength = blockLength;\r\n        this.error = error;\r\n        this.warnings = warnings;\r\n        this.valueBeforeDecodeView = pvtsutils.BufferSourceConverter.toUint8Array(valueBeforeDecode);\r\n    }\r\n    static blockName() {\r\n        return this.NAME;\r\n    }\r\n    get valueBeforeDecode() {\r\n        return this.valueBeforeDecodeView.slice().buffer;\r\n    }\r\n    set valueBeforeDecode(value) {\r\n        this.valueBeforeDecodeView = new Uint8Array(value);\r\n    }\r\n    toJSON() {\r\n        return {\r\n            blockName: this.constructor.NAME,\r\n            blockLength: this.blockLength,\r\n            error: this.error,\r\n            warnings: this.warnings,\r\n            valueBeforeDecode: pvtsutils.Convert.ToHex(this.valueBeforeDecodeView),\r\n        };\r\n    }\r\n}\r\nLocalBaseBlock.NAME = \"baseBlock\";\n\nclass ValueBlock extends LocalBaseBlock {\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        throw TypeError(\"User need to make a specific function in a class which extends 'ValueBlock'\");\r\n    }\r\n    toBER(sizeOnly, writer) {\r\n        throw TypeError(\"User need to make a specific function in a class which extends 'ValueBlock'\");\r\n    }\r\n}\r\nValueBlock.NAME = \"valueBlock\";\n\nclass LocalIdentificationBlock extends HexBlock(LocalBaseBlock) {\r\n    constructor({ idBlock = {}, } = {}) {\r\n        var _a, _b, _c, _d;\r\n        super();\r\n        if (idBlock) {\r\n            this.isHexOnly = (_a = idBlock.isHexOnly) !== null && _a !== void 0 ? _a : false;\r\n            this.valueHexView = idBlock.valueHex ? pvtsutils.BufferSourceConverter.toUint8Array(idBlock.valueHex) : EMPTY_VIEW;\r\n            this.tagClass = (_b = idBlock.tagClass) !== null && _b !== void 0 ? _b : -1;\r\n            this.tagNumber = (_c = idBlock.tagNumber) !== null && _c !== void 0 ? _c : -1;\r\n            this.isConstructed = (_d = idBlock.isConstructed) !== null && _d !== void 0 ? _d : false;\r\n        }\r\n        else {\r\n            this.tagClass = -1;\r\n            this.tagNumber = -1;\r\n            this.isConstructed = false;\r\n        }\r\n    }\r\n    toBER(sizeOnly = false) {\r\n        let firstOctet = 0;\r\n        switch (this.tagClass) {\r\n            case 1:\r\n                firstOctet |= 0x00;\r\n                break;\r\n            case 2:\r\n                firstOctet |= 0x40;\r\n                break;\r\n            case 3:\r\n                firstOctet |= 0x80;\r\n                break;\r\n            case 4:\r\n                firstOctet |= 0xC0;\r\n                break;\r\n            default:\r\n                this.error = \"Unknown tag class\";\r\n                return EMPTY_BUFFER;\r\n        }\r\n        if (this.isConstructed)\r\n            firstOctet |= 0x20;\r\n        if (this.tagNumber < 31 && !this.isHexOnly) {\r\n            const retView = new Uint8Array(1);\r\n            if (!sizeOnly) {\r\n                let number = this.tagNumber;\r\n                number &= 0x1F;\r\n                firstOctet |= number;\r\n                retView[0] = firstOctet;\r\n            }\r\n            return retView.buffer;\r\n        }\r\n        if (!this.isHexOnly) {\r\n            const encodedBuf = pvutils.utilToBase(this.tagNumber, 7);\r\n            const encodedView = new Uint8Array(encodedBuf);\r\n            const size = encodedBuf.byteLength;\r\n            const retView = new Uint8Array(size + 1);\r\n            retView[0] = (firstOctet | 0x1F);\r\n            if (!sizeOnly) {\r\n                for (let i = 0; i < (size - 1); i++)\r\n                    retView[i + 1] = encodedView[i] | 0x80;\r\n                retView[size] = encodedView[size - 1];\r\n            }\r\n            return retView.buffer;\r\n        }\r\n        const retView = new Uint8Array(this.valueHexView.byteLength + 1);\r\n        retView[0] = (firstOctet | 0x1F);\r\n        if (!sizeOnly) {\r\n            const curView = this.valueHexView;\r\n            for (let i = 0; i < (curView.length - 1); i++)\r\n                retView[i + 1] = curView[i] | 0x80;\r\n            retView[this.valueHexView.byteLength] = curView[curView.length - 1];\r\n        }\r\n        return retView.buffer;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const inputView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {\r\n            return -1;\r\n        }\r\n        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);\r\n        if (intBuffer.length === 0) {\r\n            this.error = \"Zero buffer length\";\r\n            return -1;\r\n        }\r\n        const tagClassMask = intBuffer[0] & 0xC0;\r\n        switch (tagClassMask) {\r\n            case 0x00:\r\n                this.tagClass = (1);\r\n                break;\r\n            case 0x40:\r\n                this.tagClass = (2);\r\n                break;\r\n            case 0x80:\r\n                this.tagClass = (3);\r\n                break;\r\n            case 0xC0:\r\n                this.tagClass = (4);\r\n                break;\r\n            default:\r\n                this.error = \"Unknown tag class\";\r\n                return -1;\r\n        }\r\n        this.isConstructed = (intBuffer[0] & 0x20) === 0x20;\r\n        this.isHexOnly = false;\r\n        const tagNumberMask = intBuffer[0] & 0x1F;\r\n        if (tagNumberMask !== 0x1F) {\r\n            this.tagNumber = (tagNumberMask);\r\n            this.blockLength = 1;\r\n        }\r\n        else {\r\n            let count = 1;\r\n            let intTagNumberBuffer = this.valueHexView = new Uint8Array(255);\r\n            let tagNumberBufferMaxLength = 255;\r\n            while (intBuffer[count] & 0x80) {\r\n                intTagNumberBuffer[count - 1] = intBuffer[count] & 0x7F;\r\n                count++;\r\n                if (count >= intBuffer.length) {\r\n                    this.error = \"End of input reached before message was fully decoded\";\r\n                    return -1;\r\n                }\r\n                if (count === tagNumberBufferMaxLength) {\r\n                    tagNumberBufferMaxLength += 255;\r\n                    const tempBufferView = new Uint8Array(tagNumberBufferMaxLength);\r\n                    for (let i = 0; i < intTagNumberBuffer.length; i++)\r\n                        tempBufferView[i] = intTagNumberBuffer[i];\r\n                    intTagNumberBuffer = this.valueHexView = new Uint8Array(tagNumberBufferMaxLength);\r\n                }\r\n            }\r\n            this.blockLength = (count + 1);\r\n            intTagNumberBuffer[count - 1] = intBuffer[count] & 0x7F;\r\n            const tempBufferView = new Uint8Array(count);\r\n            for (let i = 0; i < count; i++)\r\n                tempBufferView[i] = intTagNumberBuffer[i];\r\n            intTagNumberBuffer = this.valueHexView = new Uint8Array(count);\r\n            intTagNumberBuffer.set(tempBufferView);\r\n            if (this.blockLength <= 9)\r\n                this.tagNumber = pvutils.utilFromBase(intTagNumberBuffer, 7);\r\n            else {\r\n                this.isHexOnly = true;\r\n                this.warnings.push(\"Tag too long, represented as hex-coded\");\r\n            }\r\n        }\r\n        if (((this.tagClass === 1)) &&\r\n            (this.isConstructed)) {\r\n            switch (this.tagNumber) {\r\n                case 1:\r\n                case 2:\r\n                case 5:\r\n                case 6:\r\n                case 9:\r\n                case 13:\r\n                case 14:\r\n                case 23:\r\n                case 24:\r\n                case 31:\r\n                case 32:\r\n                case 33:\r\n                case 34:\r\n                    this.error = \"Constructed encoding used for primitive type\";\r\n                    return -1;\r\n            }\r\n        }\r\n        return (inputOffset + this.blockLength);\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            tagClass: this.tagClass,\r\n            tagNumber: this.tagNumber,\r\n            isConstructed: this.isConstructed,\r\n        };\r\n    }\r\n}\r\nLocalIdentificationBlock.NAME = \"identificationBlock\";\n\nclass LocalLengthBlock extends LocalBaseBlock {\r\n    constructor({ lenBlock = {}, } = {}) {\r\n        var _a, _b, _c;\r\n        super();\r\n        this.isIndefiniteForm = (_a = lenBlock.isIndefiniteForm) !== null && _a !== void 0 ? _a : false;\r\n        this.longFormUsed = (_b = lenBlock.longFormUsed) !== null && _b !== void 0 ? _b : false;\r\n        this.length = (_c = lenBlock.length) !== null && _c !== void 0 ? _c : 0;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const view = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        if (!checkBufferParams(this, view, inputOffset, inputLength)) {\r\n            return -1;\r\n        }\r\n        const intBuffer = view.subarray(inputOffset, inputOffset + inputLength);\r\n        if (intBuffer.length === 0) {\r\n            this.error = \"Zero buffer length\";\r\n            return -1;\r\n        }\r\n        if (intBuffer[0] === 0xFF) {\r\n            this.error = \"Length block 0xFF is reserved by standard\";\r\n            return -1;\r\n        }\r\n        this.isIndefiniteForm = intBuffer[0] === 0x80;\r\n        if (this.isIndefiniteForm) {\r\n            this.blockLength = 1;\r\n            return (inputOffset + this.blockLength);\r\n        }\r\n        this.longFormUsed = !!(intBuffer[0] & 0x80);\r\n        if (this.longFormUsed === false) {\r\n            this.length = (intBuffer[0]);\r\n            this.blockLength = 1;\r\n            return (inputOffset + this.blockLength);\r\n        }\r\n        const count = intBuffer[0] & 0x7F;\r\n        if (count > 8) {\r\n            this.error = \"Too big integer\";\r\n            return -1;\r\n        }\r\n        if ((count + 1) > intBuffer.length) {\r\n            this.error = \"End of input reached before message was fully decoded\";\r\n            return -1;\r\n        }\r\n        const lenOffset = inputOffset + 1;\r\n        const lengthBufferView = view.subarray(lenOffset, lenOffset + count);\r\n        if (lengthBufferView[count - 1] === 0x00)\r\n            this.warnings.push(\"Needlessly long encoded length\");\r\n        this.length = pvutils.utilFromBase(lengthBufferView, 8);\r\n        if (this.longFormUsed && (this.length <= 127))\r\n            this.warnings.push(\"Unnecessary usage of long length form\");\r\n        this.blockLength = count + 1;\r\n        return (inputOffset + this.blockLength);\r\n    }\r\n    toBER(sizeOnly = false) {\r\n        let retBuf;\r\n        let retView;\r\n        if (this.length > 127)\r\n            this.longFormUsed = true;\r\n        if (this.isIndefiniteForm) {\r\n            retBuf = new ArrayBuffer(1);\r\n            if (sizeOnly === false) {\r\n                retView = new Uint8Array(retBuf);\r\n                retView[0] = 0x80;\r\n            }\r\n            return retBuf;\r\n        }\r\n        if (this.longFormUsed) {\r\n            const encodedBuf = pvutils.utilToBase(this.length, 8);\r\n            if (encodedBuf.byteLength > 127) {\r\n                this.error = \"Too big length\";\r\n                return (EMPTY_BUFFER);\r\n            }\r\n            retBuf = new ArrayBuffer(encodedBuf.byteLength + 1);\r\n            if (sizeOnly)\r\n                return retBuf;\r\n            const encodedView = new Uint8Array(encodedBuf);\r\n            retView = new Uint8Array(retBuf);\r\n            retView[0] = encodedBuf.byteLength | 0x80;\r\n            for (let i = 0; i < encodedBuf.byteLength; i++)\r\n                retView[i + 1] = encodedView[i];\r\n            return retBuf;\r\n        }\r\n        retBuf = new ArrayBuffer(1);\r\n        if (sizeOnly === false) {\r\n            retView = new Uint8Array(retBuf);\r\n            retView[0] = this.length;\r\n        }\r\n        return retBuf;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            isIndefiniteForm: this.isIndefiniteForm,\r\n            longFormUsed: this.longFormUsed,\r\n            length: this.length,\r\n        };\r\n    }\r\n}\r\nLocalLengthBlock.NAME = \"lengthBlock\";\n\nconst typeStore = {};\n\nclass BaseBlock extends LocalBaseBlock {\r\n    constructor({ name = EMPTY_STRING, optional = false, primitiveSchema, ...parameters } = {}, valueBlockType) {\r\n        super(parameters);\r\n        this.name = name;\r\n        this.optional = optional;\r\n        if (primitiveSchema) {\r\n            this.primitiveSchema = primitiveSchema;\r\n        }\r\n        this.idBlock = new LocalIdentificationBlock(parameters);\r\n        this.lenBlock = new LocalLengthBlock(parameters);\r\n        this.valueBlock = valueBlockType ? new valueBlockType(parameters) : new ValueBlock(parameters);\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const resultOffset = this.valueBlock.fromBER(inputBuffer, inputOffset, (this.lenBlock.isIndefiniteForm) ? inputLength : this.lenBlock.length);\r\n        if (resultOffset === -1) {\r\n            this.error = this.valueBlock.error;\r\n            return resultOffset;\r\n        }\r\n        if (!this.idBlock.error.length)\r\n            this.blockLength += this.idBlock.blockLength;\r\n        if (!this.lenBlock.error.length)\r\n            this.blockLength += this.lenBlock.blockLength;\r\n        if (!this.valueBlock.error.length)\r\n            this.blockLength += this.valueBlock.blockLength;\r\n        return resultOffset;\r\n    }\r\n    toBER(sizeOnly, writer) {\r\n        const _writer = writer || new ViewWriter();\r\n        if (!writer) {\r\n            prepareIndefiniteForm(this);\r\n        }\r\n        const idBlockBuf = this.idBlock.toBER(sizeOnly);\r\n        _writer.write(idBlockBuf);\r\n        if (this.lenBlock.isIndefiniteForm) {\r\n            _writer.write(new Uint8Array([0x80]).buffer);\r\n            this.valueBlock.toBER(sizeOnly, _writer);\r\n            _writer.write(new ArrayBuffer(2));\r\n        }\r\n        else {\r\n            const valueBlockBuf = this.valueBlock.toBER(sizeOnly);\r\n            this.lenBlock.length = valueBlockBuf.byteLength;\r\n            const lenBlockBuf = this.lenBlock.toBER(sizeOnly);\r\n            _writer.write(lenBlockBuf);\r\n            _writer.write(valueBlockBuf);\r\n        }\r\n        if (!writer) {\r\n            return _writer.final();\r\n        }\r\n        return EMPTY_BUFFER;\r\n    }\r\n    toJSON() {\r\n        const object = {\r\n            ...super.toJSON(),\r\n            idBlock: this.idBlock.toJSON(),\r\n            lenBlock: this.lenBlock.toJSON(),\r\n            valueBlock: this.valueBlock.toJSON(),\r\n            name: this.name,\r\n            optional: this.optional,\r\n        };\r\n        if (this.primitiveSchema)\r\n            object.primitiveSchema = this.primitiveSchema.toJSON();\r\n        return object;\r\n    }\r\n    toString(encoding = \"ascii\") {\r\n        if (encoding === \"ascii\") {\r\n            return this.onAsciiEncoding();\r\n        }\r\n        return pvtsutils.Convert.ToHex(this.toBER());\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME} : ${pvtsutils.Convert.ToHex(this.valueBlock.valueBeforeDecodeView)}`;\r\n    }\r\n    isEqual(other) {\r\n        if (this === other) {\r\n            return true;\r\n        }\r\n        if (!(other instanceof this.constructor)) {\r\n            return false;\r\n        }\r\n        const thisRaw = this.toBER();\r\n        const otherRaw = other.toBER();\r\n        return pvutils.isEqualBuffer(thisRaw, otherRaw);\r\n    }\r\n}\r\nBaseBlock.NAME = \"BaseBlock\";\r\nfunction prepareIndefiniteForm(baseBlock) {\r\n    if (baseBlock instanceof typeStore.Constructed) {\r\n        for (const value of baseBlock.valueBlock.value) {\r\n            if (prepareIndefiniteForm(value)) {\r\n                baseBlock.lenBlock.isIndefiniteForm = true;\r\n            }\r\n        }\r\n    }\r\n    return !!baseBlock.lenBlock.isIndefiniteForm;\r\n}\n\nclass BaseStringBlock extends BaseBlock {\r\n    constructor({ value = EMPTY_STRING, ...parameters } = {}, stringValueBlockType) {\r\n        super(parameters, stringValueBlockType);\r\n        if (value) {\r\n            this.fromString(value);\r\n        }\r\n    }\r\n    getValue() {\r\n        return this.valueBlock.value;\r\n    }\r\n    setValue(value) {\r\n        this.valueBlock.value = value;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const resultOffset = this.valueBlock.fromBER(inputBuffer, inputOffset, (this.lenBlock.isIndefiniteForm) ? inputLength : this.lenBlock.length);\r\n        if (resultOffset === -1) {\r\n            this.error = this.valueBlock.error;\r\n            return resultOffset;\r\n        }\r\n        this.fromBuffer(this.valueBlock.valueHexView);\r\n        if (!this.idBlock.error.length)\r\n            this.blockLength += this.idBlock.blockLength;\r\n        if (!this.lenBlock.error.length)\r\n            this.blockLength += this.lenBlock.blockLength;\r\n        if (!this.valueBlock.error.length)\r\n            this.blockLength += this.valueBlock.blockLength;\r\n        return resultOffset;\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME} : '${this.valueBlock.value}'`;\r\n    }\r\n}\r\nBaseStringBlock.NAME = \"BaseStringBlock\";\n\nclass LocalPrimitiveValueBlock extends HexBlock(ValueBlock) {\r\n    constructor({ isHexOnly = true, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.isHexOnly = isHexOnly;\r\n    }\r\n}\r\nLocalPrimitiveValueBlock.NAME = \"PrimitiveValueBlock\";\n\nvar _a$w;\r\nclass Primitive extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, LocalPrimitiveValueBlock);\r\n        this.idBlock.isConstructed = false;\r\n    }\r\n}\r\n_a$w = Primitive;\r\n(() => {\r\n    typeStore.Primitive = _a$w;\r\n})();\r\nPrimitive.NAME = \"PRIMITIVE\";\n\nfunction localChangeType(inputObject, newType) {\r\n    if (inputObject instanceof newType) {\r\n        return inputObject;\r\n    }\r\n    const newObject = new newType();\r\n    newObject.idBlock = inputObject.idBlock;\r\n    newObject.lenBlock = inputObject.lenBlock;\r\n    newObject.warnings = inputObject.warnings;\r\n    newObject.valueBeforeDecodeView = inputObject.valueBeforeDecodeView;\r\n    return newObject;\r\n}\r\nfunction localFromBER(inputBuffer, inputOffset = 0, inputLength = inputBuffer.length) {\r\n    const incomingOffset = inputOffset;\r\n    let returnObject = new BaseBlock({}, ValueBlock);\r\n    const baseBlock = new LocalBaseBlock();\r\n    if (!checkBufferParams(baseBlock, inputBuffer, inputOffset, inputLength)) {\r\n        returnObject.error = baseBlock.error;\r\n        return {\r\n            offset: -1,\r\n            result: returnObject\r\n        };\r\n    }\r\n    const intBuffer = inputBuffer.subarray(inputOffset, inputOffset + inputLength);\r\n    if (!intBuffer.length) {\r\n        returnObject.error = \"Zero buffer length\";\r\n        return {\r\n            offset: -1,\r\n            result: returnObject\r\n        };\r\n    }\r\n    let resultOffset = returnObject.idBlock.fromBER(inputBuffer, inputOffset, inputLength);\r\n    if (returnObject.idBlock.warnings.length) {\r\n        returnObject.warnings.concat(returnObject.idBlock.warnings);\r\n    }\r\n    if (resultOffset === -1) {\r\n        returnObject.error = returnObject.idBlock.error;\r\n        return {\r\n            offset: -1,\r\n            result: returnObject\r\n        };\r\n    }\r\n    inputOffset = resultOffset;\r\n    inputLength -= returnObject.idBlock.blockLength;\r\n    resultOffset = returnObject.lenBlock.fromBER(inputBuffer, inputOffset, inputLength);\r\n    if (returnObject.lenBlock.warnings.length) {\r\n        returnObject.warnings.concat(returnObject.lenBlock.warnings);\r\n    }\r\n    if (resultOffset === -1) {\r\n        returnObject.error = returnObject.lenBlock.error;\r\n        return {\r\n            offset: -1,\r\n            result: returnObject\r\n        };\r\n    }\r\n    inputOffset = resultOffset;\r\n    inputLength -= returnObject.lenBlock.blockLength;\r\n    if (!returnObject.idBlock.isConstructed &&\r\n        returnObject.lenBlock.isIndefiniteForm) {\r\n        returnObject.error = \"Indefinite length form used for primitive encoding form\";\r\n        return {\r\n            offset: -1,\r\n            result: returnObject\r\n        };\r\n    }\r\n    let newASN1Type = BaseBlock;\r\n    switch (returnObject.idBlock.tagClass) {\r\n        case 1:\r\n            if ((returnObject.idBlock.tagNumber >= 37) &&\r\n                (returnObject.idBlock.isHexOnly === false)) {\r\n                returnObject.error = \"UNIVERSAL 37 and upper tags are reserved by ASN.1 standard\";\r\n                return {\r\n                    offset: -1,\r\n                    result: returnObject\r\n                };\r\n            }\r\n            switch (returnObject.idBlock.tagNumber) {\r\n                case 0:\r\n                    if ((returnObject.idBlock.isConstructed) &&\r\n                        (returnObject.lenBlock.length > 0)) {\r\n                        returnObject.error = \"Type [UNIVERSAL 0] is reserved\";\r\n                        return {\r\n                            offset: -1,\r\n                            result: returnObject\r\n                        };\r\n                    }\r\n                    newASN1Type = typeStore.EndOfContent;\r\n                    break;\r\n                case 1:\r\n                    newASN1Type = typeStore.Boolean;\r\n                    break;\r\n                case 2:\r\n                    newASN1Type = typeStore.Integer;\r\n                    break;\r\n                case 3:\r\n                    newASN1Type = typeStore.BitString;\r\n                    break;\r\n                case 4:\r\n                    newASN1Type = typeStore.OctetString;\r\n                    break;\r\n                case 5:\r\n                    newASN1Type = typeStore.Null;\r\n                    break;\r\n                case 6:\r\n                    newASN1Type = typeStore.ObjectIdentifier;\r\n                    break;\r\n                case 10:\r\n                    newASN1Type = typeStore.Enumerated;\r\n                    break;\r\n                case 12:\r\n                    newASN1Type = typeStore.Utf8String;\r\n                    break;\r\n                case 13:\r\n                    newASN1Type = typeStore.RelativeObjectIdentifier;\r\n                    break;\r\n                case 14:\r\n                    newASN1Type = typeStore.TIME;\r\n                    break;\r\n                case 15:\r\n                    returnObject.error = \"[UNIVERSAL 15] is reserved by ASN.1 standard\";\r\n                    return {\r\n                        offset: -1,\r\n                        result: returnObject\r\n                    };\r\n                case 16:\r\n                    newASN1Type = typeStore.Sequence;\r\n                    break;\r\n                case 17:\r\n                    newASN1Type = typeStore.Set;\r\n                    break;\r\n                case 18:\r\n                    newASN1Type = typeStore.NumericString;\r\n                    break;\r\n                case 19:\r\n                    newASN1Type = typeStore.PrintableString;\r\n                    break;\r\n                case 20:\r\n                    newASN1Type = typeStore.TeletexString;\r\n                    break;\r\n                case 21:\r\n                    newASN1Type = typeStore.VideotexString;\r\n                    break;\r\n                case 22:\r\n                    newASN1Type = typeStore.IA5String;\r\n                    break;\r\n                case 23:\r\n                    newASN1Type = typeStore.UTCTime;\r\n                    break;\r\n                case 24:\r\n                    newASN1Type = typeStore.GeneralizedTime;\r\n                    break;\r\n                case 25:\r\n                    newASN1Type = typeStore.GraphicString;\r\n                    break;\r\n                case 26:\r\n                    newASN1Type = typeStore.VisibleString;\r\n                    break;\r\n                case 27:\r\n                    newASN1Type = typeStore.GeneralString;\r\n                    break;\r\n                case 28:\r\n                    newASN1Type = typeStore.UniversalString;\r\n                    break;\r\n                case 29:\r\n                    newASN1Type = typeStore.CharacterString;\r\n                    break;\r\n                case 30:\r\n                    newASN1Type = typeStore.BmpString;\r\n                    break;\r\n                case 31:\r\n                    newASN1Type = typeStore.DATE;\r\n                    break;\r\n                case 32:\r\n                    newASN1Type = typeStore.TimeOfDay;\r\n                    break;\r\n                case 33:\r\n                    newASN1Type = typeStore.DateTime;\r\n                    break;\r\n                case 34:\r\n                    newASN1Type = typeStore.Duration;\r\n                    break;\r\n                default: {\r\n                    const newObject = returnObject.idBlock.isConstructed\r\n                        ? new typeStore.Constructed()\r\n                        : new typeStore.Primitive();\r\n                    newObject.idBlock = returnObject.idBlock;\r\n                    newObject.lenBlock = returnObject.lenBlock;\r\n                    newObject.warnings = returnObject.warnings;\r\n                    returnObject = newObject;\r\n                }\r\n            }\r\n            break;\r\n        case 2:\r\n        case 3:\r\n        case 4:\r\n        default: {\r\n            newASN1Type = returnObject.idBlock.isConstructed\r\n                ? typeStore.Constructed\r\n                : typeStore.Primitive;\r\n        }\r\n    }\r\n    returnObject = localChangeType(returnObject, newASN1Type);\r\n    resultOffset = returnObject.fromBER(inputBuffer, inputOffset, returnObject.lenBlock.isIndefiniteForm ? inputLength : returnObject.lenBlock.length);\r\n    returnObject.valueBeforeDecodeView = inputBuffer.subarray(incomingOffset, incomingOffset + returnObject.blockLength);\r\n    return {\r\n        offset: resultOffset,\r\n        result: returnObject\r\n    };\r\n}\r\nfunction fromBER(inputBuffer) {\r\n    if (!inputBuffer.byteLength) {\r\n        const result = new BaseBlock({}, ValueBlock);\r\n        result.error = \"Input buffer has zero length\";\r\n        return {\r\n            offset: -1,\r\n            result\r\n        };\r\n    }\r\n    return localFromBER(pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer).slice(), 0, inputBuffer.byteLength);\r\n}\n\nfunction checkLen(indefiniteLength, length) {\r\n    if (indefiniteLength) {\r\n        return 1;\r\n    }\r\n    return length;\r\n}\r\nclass LocalConstructedValueBlock extends ValueBlock {\r\n    constructor({ value = [], isIndefiniteForm = false, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.value = value;\r\n        this.isIndefiniteForm = isIndefiniteForm;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const view = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        if (!checkBufferParams(this, view, inputOffset, inputLength)) {\r\n            return -1;\r\n        }\r\n        this.valueBeforeDecodeView = view.subarray(inputOffset, inputOffset + inputLength);\r\n        if (this.valueBeforeDecodeView.length === 0) {\r\n            this.warnings.push(\"Zero buffer length\");\r\n            return inputOffset;\r\n        }\r\n        let currentOffset = inputOffset;\r\n        while (checkLen(this.isIndefiniteForm, inputLength) > 0) {\r\n            const returnObject = localFromBER(view, currentOffset, inputLength);\r\n            if (returnObject.offset === -1) {\r\n                this.error = returnObject.result.error;\r\n                this.warnings.concat(returnObject.result.warnings);\r\n                return -1;\r\n            }\r\n            currentOffset = returnObject.offset;\r\n            this.blockLength += returnObject.result.blockLength;\r\n            inputLength -= returnObject.result.blockLength;\r\n            this.value.push(returnObject.result);\r\n            if (this.isIndefiniteForm && returnObject.result.constructor.NAME === END_OF_CONTENT_NAME) {\r\n                break;\r\n            }\r\n        }\r\n        if (this.isIndefiniteForm) {\r\n            if (this.value[this.value.length - 1].constructor.NAME === END_OF_CONTENT_NAME) {\r\n                this.value.pop();\r\n            }\r\n            else {\r\n                this.warnings.push(\"No EndOfContent block encoded\");\r\n            }\r\n        }\r\n        return currentOffset;\r\n    }\r\n    toBER(sizeOnly, writer) {\r\n        const _writer = writer || new ViewWriter();\r\n        for (let i = 0; i < this.value.length; i++) {\r\n            this.value[i].toBER(sizeOnly, _writer);\r\n        }\r\n        if (!writer) {\r\n            return _writer.final();\r\n        }\r\n        return EMPTY_BUFFER;\r\n    }\r\n    toJSON() {\r\n        const object = {\r\n            ...super.toJSON(),\r\n            isIndefiniteForm: this.isIndefiniteForm,\r\n            value: [],\r\n        };\r\n        for (const value of this.value) {\r\n            object.value.push(value.toJSON());\r\n        }\r\n        return object;\r\n    }\r\n}\r\nLocalConstructedValueBlock.NAME = \"ConstructedValueBlock\";\n\nvar _a$v;\r\nclass Constructed extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, LocalConstructedValueBlock);\r\n        this.idBlock.isConstructed = true;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        this.valueBlock.isIndefiniteForm = this.lenBlock.isIndefiniteForm;\r\n        const resultOffset = this.valueBlock.fromBER(inputBuffer, inputOffset, (this.lenBlock.isIndefiniteForm) ? inputLength : this.lenBlock.length);\r\n        if (resultOffset === -1) {\r\n            this.error = this.valueBlock.error;\r\n            return resultOffset;\r\n        }\r\n        if (!this.idBlock.error.length)\r\n            this.blockLength += this.idBlock.blockLength;\r\n        if (!this.lenBlock.error.length)\r\n            this.blockLength += this.lenBlock.blockLength;\r\n        if (!this.valueBlock.error.length)\r\n            this.blockLength += this.valueBlock.blockLength;\r\n        return resultOffset;\r\n    }\r\n    onAsciiEncoding() {\r\n        const values = [];\r\n        for (const value of this.valueBlock.value) {\r\n            values.push(value.toString(\"ascii\").split(\"\\n\").map(o => `  ${o}`).join(\"\\n\"));\r\n        }\r\n        const blockName = this.idBlock.tagClass === 3\r\n            ? `[${this.idBlock.tagNumber}]`\r\n            : this.constructor.NAME;\r\n        return values.length\r\n            ? `${blockName} :\\n${values.join(\"\\n\")}`\r\n            : `${blockName} :`;\r\n    }\r\n}\r\n_a$v = Constructed;\r\n(() => {\r\n    typeStore.Constructed = _a$v;\r\n})();\r\nConstructed.NAME = \"CONSTRUCTED\";\n\nclass LocalEndOfContentValueBlock extends ValueBlock {\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        return inputOffset;\r\n    }\r\n    toBER(sizeOnly) {\r\n        return EMPTY_BUFFER;\r\n    }\r\n}\r\nLocalEndOfContentValueBlock.override = \"EndOfContentValueBlock\";\n\nvar _a$u;\r\nclass EndOfContent extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, LocalEndOfContentValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 0;\r\n    }\r\n}\r\n_a$u = EndOfContent;\r\n(() => {\r\n    typeStore.EndOfContent = _a$u;\r\n})();\r\nEndOfContent.NAME = END_OF_CONTENT_NAME;\n\nvar _a$t;\r\nclass Null extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, ValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 5;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        if (this.lenBlock.length > 0)\r\n            this.warnings.push(\"Non-zero length of value block for Null type\");\r\n        if (!this.idBlock.error.length)\r\n            this.blockLength += this.idBlock.blockLength;\r\n        if (!this.lenBlock.error.length)\r\n            this.blockLength += this.lenBlock.blockLength;\r\n        this.blockLength += inputLength;\r\n        if ((inputOffset + inputLength) > inputBuffer.byteLength) {\r\n            this.error = \"End of input reached before message was fully decoded (inconsistent offset and length values)\";\r\n            return -1;\r\n        }\r\n        return (inputOffset + inputLength);\r\n    }\r\n    toBER(sizeOnly, writer) {\r\n        const retBuf = new ArrayBuffer(2);\r\n        if (!sizeOnly) {\r\n            const retView = new Uint8Array(retBuf);\r\n            retView[0] = 0x05;\r\n            retView[1] = 0x00;\r\n        }\r\n        if (writer) {\r\n            writer.write(retBuf);\r\n        }\r\n        return retBuf;\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME}`;\r\n    }\r\n}\r\n_a$t = Null;\r\n(() => {\r\n    typeStore.Null = _a$t;\r\n})();\r\nNull.NAME = \"NULL\";\n\nclass LocalBooleanValueBlock extends HexBlock(ValueBlock) {\r\n    constructor({ value, ...parameters } = {}) {\r\n        super(parameters);\r\n        if (parameters.valueHex) {\r\n            this.valueHexView = pvtsutils.BufferSourceConverter.toUint8Array(parameters.valueHex);\r\n        }\r\n        else {\r\n            this.valueHexView = new Uint8Array(1);\r\n        }\r\n        if (value) {\r\n            this.value = value;\r\n        }\r\n    }\r\n    get value() {\r\n        for (const octet of this.valueHexView) {\r\n            if (octet > 0) {\r\n                return true;\r\n            }\r\n        }\r\n        return false;\r\n    }\r\n    set value(value) {\r\n        this.valueHexView[0] = value ? 0xFF : 0x00;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const inputView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {\r\n            return -1;\r\n        }\r\n        this.valueHexView = inputView.subarray(inputOffset, inputOffset + inputLength);\r\n        if (inputLength > 1)\r\n            this.warnings.push(\"Boolean value encoded in more then 1 octet\");\r\n        this.isHexOnly = true;\r\n        pvutils.utilDecodeTC.call(this);\r\n        this.blockLength = inputLength;\r\n        return (inputOffset + inputLength);\r\n    }\r\n    toBER() {\r\n        return this.valueHexView.slice();\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            value: this.value,\r\n        };\r\n    }\r\n}\r\nLocalBooleanValueBlock.NAME = \"BooleanValueBlock\";\n\nvar _a$s;\r\nclass Boolean extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, LocalBooleanValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 1;\r\n    }\r\n    getValue() {\r\n        return this.valueBlock.value;\r\n    }\r\n    setValue(value) {\r\n        this.valueBlock.value = value;\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME} : ${this.getValue}`;\r\n    }\r\n}\r\n_a$s = Boolean;\r\n(() => {\r\n    typeStore.Boolean = _a$s;\r\n})();\r\nBoolean.NAME = \"BOOLEAN\";\n\nclass LocalOctetStringValueBlock extends HexBlock(LocalConstructedValueBlock) {\r\n    constructor({ isConstructed = false, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.isConstructed = isConstructed;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        let resultOffset = 0;\r\n        if (this.isConstructed) {\r\n            this.isHexOnly = false;\r\n            resultOffset = LocalConstructedValueBlock.prototype.fromBER.call(this, inputBuffer, inputOffset, inputLength);\r\n            if (resultOffset === -1)\r\n                return resultOffset;\r\n            for (let i = 0; i < this.value.length; i++) {\r\n                const currentBlockName = this.value[i].constructor.NAME;\r\n                if (currentBlockName === END_OF_CONTENT_NAME) {\r\n                    if (this.isIndefiniteForm)\r\n                        break;\r\n                    else {\r\n                        this.error = \"EndOfContent is unexpected, OCTET STRING may consists of OCTET STRINGs only\";\r\n                        return -1;\r\n                    }\r\n                }\r\n                if (currentBlockName !== OCTET_STRING_NAME) {\r\n                    this.error = \"OCTET STRING may consists of OCTET STRINGs only\";\r\n                    return -1;\r\n                }\r\n            }\r\n        }\r\n        else {\r\n            this.isHexOnly = true;\r\n            resultOffset = super.fromBER(inputBuffer, inputOffset, inputLength);\r\n            this.blockLength = inputLength;\r\n        }\r\n        return resultOffset;\r\n    }\r\n    toBER(sizeOnly, writer) {\r\n        if (this.isConstructed)\r\n            return LocalConstructedValueBlock.prototype.toBER.call(this, sizeOnly, writer);\r\n        return sizeOnly\r\n            ? new ArrayBuffer(this.valueHexView.byteLength)\r\n            : this.valueHexView.slice().buffer;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            isConstructed: this.isConstructed,\r\n        };\r\n    }\r\n}\r\nLocalOctetStringValueBlock.NAME = \"OctetStringValueBlock\";\n\nvar _a$r;\r\nclass OctetString extends BaseBlock {\r\n    constructor({ idBlock = {}, lenBlock = {}, ...parameters } = {}) {\r\n        var _b, _c;\r\n        (_b = parameters.isConstructed) !== null && _b !== void 0 ? _b : (parameters.isConstructed = !!((_c = parameters.value) === null || _c === void 0 ? void 0 : _c.length));\r\n        super({\r\n            idBlock: {\r\n                isConstructed: parameters.isConstructed,\r\n                ...idBlock,\r\n            },\r\n            lenBlock: {\r\n                ...lenBlock,\r\n                isIndefiniteForm: !!parameters.isIndefiniteForm,\r\n            },\r\n            ...parameters,\r\n        }, LocalOctetStringValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 4;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        this.valueBlock.isConstructed = this.idBlock.isConstructed;\r\n        this.valueBlock.isIndefiniteForm = this.lenBlock.isIndefiniteForm;\r\n        if (inputLength === 0) {\r\n            if (this.idBlock.error.length === 0)\r\n                this.blockLength += this.idBlock.blockLength;\r\n            if (this.lenBlock.error.length === 0)\r\n                this.blockLength += this.lenBlock.blockLength;\r\n            return inputOffset;\r\n        }\r\n        if (!this.valueBlock.isConstructed) {\r\n            const view = inputBuffer instanceof ArrayBuffer ? new Uint8Array(inputBuffer) : inputBuffer;\r\n            const buf = view.subarray(inputOffset, inputOffset + inputLength);\r\n            try {\r\n                if (buf.byteLength) {\r\n                    const asn = localFromBER(buf, 0, buf.byteLength);\r\n                    if (asn.offset !== -1 && asn.offset === inputLength) {\r\n                        this.valueBlock.value = [asn.result];\r\n                    }\r\n                }\r\n            }\r\n            catch (e) {\r\n            }\r\n        }\r\n        return super.fromBER(inputBuffer, inputOffset, inputLength);\r\n    }\r\n    onAsciiEncoding() {\r\n        if (this.valueBlock.isConstructed || (this.valueBlock.value && this.valueBlock.value.length)) {\r\n            return Constructed.prototype.onAsciiEncoding.call(this);\r\n        }\r\n        return `${this.constructor.NAME} : ${pvtsutils.Convert.ToHex(this.valueBlock.valueHexView)}`;\r\n    }\r\n    getValue() {\r\n        if (!this.idBlock.isConstructed) {\r\n            return this.valueBlock.valueHexView.slice().buffer;\r\n        }\r\n        const array = [];\r\n        for (const content of this.valueBlock.value) {\r\n            if (content instanceof OctetString) {\r\n                array.push(content.valueBlock.valueHexView);\r\n            }\r\n        }\r\n        return pvtsutils.BufferSourceConverter.concat(array);\r\n    }\r\n}\r\n_a$r = OctetString;\r\n(() => {\r\n    typeStore.OctetString = _a$r;\r\n})();\r\nOctetString.NAME = OCTET_STRING_NAME;\n\nclass LocalBitStringValueBlock extends HexBlock(LocalConstructedValueBlock) {\r\n    constructor({ unusedBits = 0, isConstructed = false, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.unusedBits = unusedBits;\r\n        this.isConstructed = isConstructed;\r\n        this.blockLength = this.valueHexView.byteLength;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        if (!inputLength) {\r\n            return inputOffset;\r\n        }\r\n        let resultOffset = -1;\r\n        if (this.isConstructed) {\r\n            resultOffset = LocalConstructedValueBlock.prototype.fromBER.call(this, inputBuffer, inputOffset, inputLength);\r\n            if (resultOffset === -1)\r\n                return resultOffset;\r\n            for (const value of this.value) {\r\n                const currentBlockName = value.constructor.NAME;\r\n                if (currentBlockName === END_OF_CONTENT_NAME) {\r\n                    if (this.isIndefiniteForm)\r\n                        break;\r\n                    else {\r\n                        this.error = \"EndOfContent is unexpected, BIT STRING may consists of BIT STRINGs only\";\r\n                        return -1;\r\n                    }\r\n                }\r\n                if (currentBlockName !== BIT_STRING_NAME) {\r\n                    this.error = \"BIT STRING may consists of BIT STRINGs only\";\r\n                    return -1;\r\n                }\r\n                const valueBlock = value.valueBlock;\r\n                if ((this.unusedBits > 0) && (valueBlock.unusedBits > 0)) {\r\n                    this.error = \"Using of \\\"unused bits\\\" inside constructive BIT STRING allowed for least one only\";\r\n                    return -1;\r\n                }\r\n                this.unusedBits = valueBlock.unusedBits;\r\n            }\r\n            return resultOffset;\r\n        }\r\n        const inputView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {\r\n            return -1;\r\n        }\r\n        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);\r\n        this.unusedBits = intBuffer[0];\r\n        if (this.unusedBits > 7) {\r\n            this.error = \"Unused bits for BitString must be in range 0-7\";\r\n            return -1;\r\n        }\r\n        if (!this.unusedBits) {\r\n            const buf = intBuffer.subarray(1);\r\n            try {\r\n                if (buf.byteLength) {\r\n                    const asn = localFromBER(buf, 0, buf.byteLength);\r\n                    if (asn.offset !== -1 && asn.offset === (inputLength - 1)) {\r\n                        this.value = [asn.result];\r\n                    }\r\n                }\r\n            }\r\n            catch (e) {\r\n            }\r\n        }\r\n        this.valueHexView = intBuffer.subarray(1);\r\n        this.blockLength = intBuffer.length;\r\n        return (inputOffset + inputLength);\r\n    }\r\n    toBER(sizeOnly, writer) {\r\n        if (this.isConstructed) {\r\n            return LocalConstructedValueBlock.prototype.toBER.call(this, sizeOnly, writer);\r\n        }\r\n        if (sizeOnly) {\r\n            return new ArrayBuffer(this.valueHexView.byteLength + 1);\r\n        }\r\n        if (!this.valueHexView.byteLength) {\r\n            return EMPTY_BUFFER;\r\n        }\r\n        const retView = new Uint8Array(this.valueHexView.length + 1);\r\n        retView[0] = this.unusedBits;\r\n        retView.set(this.valueHexView, 1);\r\n        return retView.buffer;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            unusedBits: this.unusedBits,\r\n            isConstructed: this.isConstructed,\r\n        };\r\n    }\r\n}\r\nLocalBitStringValueBlock.NAME = \"BitStringValueBlock\";\n\nvar _a$q;\r\nclass BitString extends BaseBlock {\r\n    constructor({ idBlock = {}, lenBlock = {}, ...parameters } = {}) {\r\n        var _b, _c;\r\n        (_b = parameters.isConstructed) !== null && _b !== void 0 ? _b : (parameters.isConstructed = !!((_c = parameters.value) === null || _c === void 0 ? void 0 : _c.length));\r\n        super({\r\n            idBlock: {\r\n                isConstructed: parameters.isConstructed,\r\n                ...idBlock,\r\n            },\r\n            lenBlock: {\r\n                ...lenBlock,\r\n                isIndefiniteForm: !!parameters.isIndefiniteForm,\r\n            },\r\n            ...parameters,\r\n        }, LocalBitStringValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 3;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        this.valueBlock.isConstructed = this.idBlock.isConstructed;\r\n        this.valueBlock.isIndefiniteForm = this.lenBlock.isIndefiniteForm;\r\n        return super.fromBER(inputBuffer, inputOffset, inputLength);\r\n    }\r\n    onAsciiEncoding() {\r\n        if (this.valueBlock.isConstructed || (this.valueBlock.value && this.valueBlock.value.length)) {\r\n            return Constructed.prototype.onAsciiEncoding.call(this);\r\n        }\r\n        else {\r\n            const bits = [];\r\n            const valueHex = this.valueBlock.valueHexView;\r\n            for (const byte of valueHex) {\r\n                bits.push(byte.toString(2).padStart(8, \"0\"));\r\n            }\r\n            const bitsStr = bits.join(\"\");\r\n            return `${this.constructor.NAME} : ${bitsStr.substring(0, bitsStr.length - this.valueBlock.unusedBits)}`;\r\n        }\r\n    }\r\n}\r\n_a$q = BitString;\r\n(() => {\r\n    typeStore.BitString = _a$q;\r\n})();\r\nBitString.NAME = BIT_STRING_NAME;\n\nvar _a$p;\r\nfunction viewAdd(first, second) {\r\n    const c = new Uint8Array([0]);\r\n    const firstView = new Uint8Array(first);\r\n    const secondView = new Uint8Array(second);\r\n    let firstViewCopy = firstView.slice(0);\r\n    const firstViewCopyLength = firstViewCopy.length - 1;\r\n    const secondViewCopy = secondView.slice(0);\r\n    const secondViewCopyLength = secondViewCopy.length - 1;\r\n    let value = 0;\r\n    const max = (secondViewCopyLength < firstViewCopyLength) ? firstViewCopyLength : secondViewCopyLength;\r\n    let counter = 0;\r\n    for (let i = max; i >= 0; i--, counter++) {\r\n        switch (true) {\r\n            case (counter < secondViewCopy.length):\r\n                value = firstViewCopy[firstViewCopyLength - counter] + secondViewCopy[secondViewCopyLength - counter] + c[0];\r\n                break;\r\n            default:\r\n                value = firstViewCopy[firstViewCopyLength - counter] + c[0];\r\n        }\r\n        c[0] = value / 10;\r\n        switch (true) {\r\n            case (counter >= firstViewCopy.length):\r\n                firstViewCopy = pvutils.utilConcatView(new Uint8Array([value % 10]), firstViewCopy);\r\n                break;\r\n            default:\r\n                firstViewCopy[firstViewCopyLength - counter] = value % 10;\r\n        }\r\n    }\r\n    if (c[0] > 0)\r\n        firstViewCopy = pvutils.utilConcatView(c, firstViewCopy);\r\n    return firstViewCopy;\r\n}\r\nfunction power2(n) {\r\n    if (n >= powers2.length) {\r\n        for (let p = powers2.length; p <= n; p++) {\r\n            const c = new Uint8Array([0]);\r\n            let digits = (powers2[p - 1]).slice(0);\r\n            for (let i = (digits.length - 1); i >= 0; i--) {\r\n                const newValue = new Uint8Array([(digits[i] << 1) + c[0]]);\r\n                c[0] = newValue[0] / 10;\r\n                digits[i] = newValue[0] % 10;\r\n            }\r\n            if (c[0] > 0)\r\n                digits = pvutils.utilConcatView(c, digits);\r\n            powers2.push(digits);\r\n        }\r\n    }\r\n    return powers2[n];\r\n}\r\nfunction viewSub(first, second) {\r\n    let b = 0;\r\n    const firstView = new Uint8Array(first);\r\n    const secondView = new Uint8Array(second);\r\n    const firstViewCopy = firstView.slice(0);\r\n    const firstViewCopyLength = firstViewCopy.length - 1;\r\n    const secondViewCopy = secondView.slice(0);\r\n    const secondViewCopyLength = secondViewCopy.length - 1;\r\n    let value;\r\n    let counter = 0;\r\n    for (let i = secondViewCopyLength; i >= 0; i--, counter++) {\r\n        value = firstViewCopy[firstViewCopyLength - counter] - secondViewCopy[secondViewCopyLength - counter] - b;\r\n        switch (true) {\r\n            case (value < 0):\r\n                b = 1;\r\n                firstViewCopy[firstViewCopyLength - counter] = value + 10;\r\n                break;\r\n            default:\r\n                b = 0;\r\n                firstViewCopy[firstViewCopyLength - counter] = value;\r\n        }\r\n    }\r\n    if (b > 0) {\r\n        for (let i = (firstViewCopyLength - secondViewCopyLength + 1); i >= 0; i--, counter++) {\r\n            value = firstViewCopy[firstViewCopyLength - counter] - b;\r\n            if (value < 0) {\r\n                b = 1;\r\n                firstViewCopy[firstViewCopyLength - counter] = value + 10;\r\n            }\r\n            else {\r\n                b = 0;\r\n                firstViewCopy[firstViewCopyLength - counter] = value;\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    return firstViewCopy.slice();\r\n}\r\nclass LocalIntegerValueBlock extends HexBlock(ValueBlock) {\r\n    constructor({ value, ...parameters } = {}) {\r\n        super(parameters);\r\n        this._valueDec = 0;\r\n        if (parameters.valueHex) {\r\n            this.setValueHex();\r\n        }\r\n        if (value !== undefined) {\r\n            this.valueDec = value;\r\n        }\r\n    }\r\n    setValueHex() {\r\n        if (this.valueHexView.length >= 4) {\r\n            this.warnings.push(\"Too big Integer for decoding, hex only\");\r\n            this.isHexOnly = true;\r\n            this._valueDec = 0;\r\n        }\r\n        else {\r\n            this.isHexOnly = false;\r\n            if (this.valueHexView.length > 0) {\r\n                this._valueDec = pvutils.utilDecodeTC.call(this);\r\n            }\r\n        }\r\n    }\r\n    set valueDec(v) {\r\n        this._valueDec = v;\r\n        this.isHexOnly = false;\r\n        this.valueHexView = new Uint8Array(pvutils.utilEncodeTC(v));\r\n    }\r\n    get valueDec() {\r\n        return this._valueDec;\r\n    }\r\n    fromDER(inputBuffer, inputOffset, inputLength, expectedLength = 0) {\r\n        const offset = this.fromBER(inputBuffer, inputOffset, inputLength);\r\n        if (offset === -1)\r\n            return offset;\r\n        const view = this.valueHexView;\r\n        if ((view[0] === 0x00) && ((view[1] & 0x80) !== 0)) {\r\n            this.valueHexView = view.subarray(1);\r\n        }\r\n        else {\r\n            if (expectedLength !== 0) {\r\n                if (view.length < expectedLength) {\r\n                    if ((expectedLength - view.length) > 1)\r\n                        expectedLength = view.length + 1;\r\n                    this.valueHexView = view.subarray(expectedLength - view.length);\r\n                }\r\n            }\r\n        }\r\n        return offset;\r\n    }\r\n    toDER(sizeOnly = false) {\r\n        const view = this.valueHexView;\r\n        switch (true) {\r\n            case ((view[0] & 0x80) !== 0):\r\n                {\r\n                    const updatedView = new Uint8Array(this.valueHexView.length + 1);\r\n                    updatedView[0] = 0x00;\r\n                    updatedView.set(view, 1);\r\n                    this.valueHexView = updatedView;\r\n                }\r\n                break;\r\n            case ((view[0] === 0x00) && ((view[1] & 0x80) === 0)):\r\n                {\r\n                    this.valueHexView = this.valueHexView.subarray(1);\r\n                }\r\n                break;\r\n        }\r\n        return this.toBER(sizeOnly);\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const resultOffset = super.fromBER(inputBuffer, inputOffset, inputLength);\r\n        if (resultOffset === -1) {\r\n            return resultOffset;\r\n        }\r\n        this.setValueHex();\r\n        return resultOffset;\r\n    }\r\n    toBER(sizeOnly) {\r\n        return sizeOnly\r\n            ? new ArrayBuffer(this.valueHexView.length)\r\n            : this.valueHexView.slice().buffer;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            valueDec: this.valueDec,\r\n        };\r\n    }\r\n    toString() {\r\n        const firstBit = (this.valueHexView.length * 8) - 1;\r\n        let digits = new Uint8Array((this.valueHexView.length * 8) / 3);\r\n        let bitNumber = 0;\r\n        let currentByte;\r\n        const asn1View = this.valueHexView;\r\n        let result = \"\";\r\n        let flag = false;\r\n        for (let byteNumber = (asn1View.byteLength - 1); byteNumber >= 0; byteNumber--) {\r\n            currentByte = asn1View[byteNumber];\r\n            for (let i = 0; i < 8; i++) {\r\n                if ((currentByte & 1) === 1) {\r\n                    switch (bitNumber) {\r\n                        case firstBit:\r\n                            digits = viewSub(power2(bitNumber), digits);\r\n                            result = \"-\";\r\n                            break;\r\n                        default:\r\n                            digits = viewAdd(digits, power2(bitNumber));\r\n                    }\r\n                }\r\n                bitNumber++;\r\n                currentByte >>= 1;\r\n            }\r\n        }\r\n        for (let i = 0; i < digits.length; i++) {\r\n            if (digits[i])\r\n                flag = true;\r\n            if (flag)\r\n                result += digitsString.charAt(digits[i]);\r\n        }\r\n        if (flag === false)\r\n            result += digitsString.charAt(0);\r\n        return result;\r\n    }\r\n}\r\n_a$p = LocalIntegerValueBlock;\r\nLocalIntegerValueBlock.NAME = \"IntegerValueBlock\";\r\n(() => {\r\n    Object.defineProperty(_a$p.prototype, \"valueHex\", {\r\n        set: function (v) {\r\n            this.valueHexView = new Uint8Array(v);\r\n            this.setValueHex();\r\n        },\r\n        get: function () {\r\n            return this.valueHexView.slice().buffer;\r\n        },\r\n    });\r\n})();\n\nvar _a$o;\r\nclass Integer extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, LocalIntegerValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 2;\r\n    }\r\n    toBigInt() {\r\n        assertBigInt();\r\n        return BigInt(this.valueBlock.toString());\r\n    }\r\n    static fromBigInt(value) {\r\n        assertBigInt();\r\n        const bigIntValue = BigInt(value);\r\n        const writer = new ViewWriter();\r\n        const hex = bigIntValue.toString(16).replace(/^-/, \"\");\r\n        const view = new Uint8Array(pvtsutils.Convert.FromHex(hex));\r\n        if (bigIntValue < 0) {\r\n            const first = new Uint8Array(view.length + (view[0] & 0x80 ? 1 : 0));\r\n            first[0] |= 0x80;\r\n            const firstInt = BigInt(`0x${pvtsutils.Convert.ToHex(first)}`);\r\n            const secondInt = firstInt + bigIntValue;\r\n            const second = pvtsutils.BufferSourceConverter.toUint8Array(pvtsutils.Convert.FromHex(secondInt.toString(16)));\r\n            second[0] |= 0x80;\r\n            writer.write(second);\r\n        }\r\n        else {\r\n            if (view[0] & 0x80) {\r\n                writer.write(new Uint8Array([0]));\r\n            }\r\n            writer.write(view);\r\n        }\r\n        const res = new Integer({\r\n            valueHex: writer.final(),\r\n        });\r\n        return res;\r\n    }\r\n    convertToDER() {\r\n        const integer = new Integer({ valueHex: this.valueBlock.valueHexView });\r\n        integer.valueBlock.toDER();\r\n        return integer;\r\n    }\r\n    convertFromDER() {\r\n        return new Integer({\r\n            valueHex: this.valueBlock.valueHexView[0] === 0\r\n                ? this.valueBlock.valueHexView.subarray(1)\r\n                : this.valueBlock.valueHexView,\r\n        });\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME} : ${this.valueBlock.toString()}`;\r\n    }\r\n}\r\n_a$o = Integer;\r\n(() => {\r\n    typeStore.Integer = _a$o;\r\n})();\r\nInteger.NAME = \"INTEGER\";\n\nvar _a$n;\r\nclass Enumerated extends Integer {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 10;\r\n    }\r\n}\r\n_a$n = Enumerated;\r\n(() => {\r\n    typeStore.Enumerated = _a$n;\r\n})();\r\nEnumerated.NAME = \"ENUMERATED\";\n\nclass LocalSidValueBlock extends HexBlock(ValueBlock) {\r\n    constructor({ valueDec = -1, isFirstSid = false, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.valueDec = valueDec;\r\n        this.isFirstSid = isFirstSid;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        if (!inputLength) {\r\n            return inputOffset;\r\n        }\r\n        const inputView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        if (!checkBufferParams(this, inputView, inputOffset, inputLength)) {\r\n            return -1;\r\n        }\r\n        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);\r\n        this.valueHexView = new Uint8Array(inputLength);\r\n        for (let i = 0; i < inputLength; i++) {\r\n            this.valueHexView[i] = intBuffer[i] & 0x7F;\r\n            this.blockLength++;\r\n            if ((intBuffer[i] & 0x80) === 0x00)\r\n                break;\r\n        }\r\n        const tempView = new Uint8Array(this.blockLength);\r\n        for (let i = 0; i < this.blockLength; i++) {\r\n            tempView[i] = this.valueHexView[i];\r\n        }\r\n        this.valueHexView = tempView;\r\n        if ((intBuffer[this.blockLength - 1] & 0x80) !== 0x00) {\r\n            this.error = \"End of input reached before message was fully decoded\";\r\n            return -1;\r\n        }\r\n        if (this.valueHexView[0] === 0x00)\r\n            this.warnings.push(\"Needlessly long format of SID encoding\");\r\n        if (this.blockLength <= 8)\r\n            this.valueDec = pvutils.utilFromBase(this.valueHexView, 7);\r\n        else {\r\n            this.isHexOnly = true;\r\n            this.warnings.push(\"Too big SID for decoding, hex only\");\r\n        }\r\n        return (inputOffset + this.blockLength);\r\n    }\r\n    set valueBigInt(value) {\r\n        assertBigInt();\r\n        let bits = BigInt(value).toString(2);\r\n        while (bits.length % 7) {\r\n            bits = \"0\" + bits;\r\n        }\r\n        const bytes = new Uint8Array(bits.length / 7);\r\n        for (let i = 0; i < bytes.length; i++) {\r\n            bytes[i] = parseInt(bits.slice(i * 7, i * 7 + 7), 2) + (i + 1 < bytes.length ? 0x80 : 0);\r\n        }\r\n        this.fromBER(bytes.buffer, 0, bytes.length);\r\n    }\r\n    toBER(sizeOnly) {\r\n        if (this.isHexOnly) {\r\n            if (sizeOnly)\r\n                return (new ArrayBuffer(this.valueHexView.byteLength));\r\n            const curView = this.valueHexView;\r\n            const retView = new Uint8Array(this.blockLength);\r\n            for (let i = 0; i < (this.blockLength - 1); i++)\r\n                retView[i] = curView[i] | 0x80;\r\n            retView[this.blockLength - 1] = curView[this.blockLength - 1];\r\n            return retView.buffer;\r\n        }\r\n        const encodedBuf = pvutils.utilToBase(this.valueDec, 7);\r\n        if (encodedBuf.byteLength === 0) {\r\n            this.error = \"Error during encoding SID value\";\r\n            return EMPTY_BUFFER;\r\n        }\r\n        const retView = new Uint8Array(encodedBuf.byteLength);\r\n        if (!sizeOnly) {\r\n            const encodedView = new Uint8Array(encodedBuf);\r\n            const len = encodedBuf.byteLength - 1;\r\n            for (let i = 0; i < len; i++)\r\n                retView[i] = encodedView[i] | 0x80;\r\n            retView[len] = encodedView[len];\r\n        }\r\n        return retView;\r\n    }\r\n    toString() {\r\n        let result = \"\";\r\n        if (this.isHexOnly)\r\n            result = pvtsutils.Convert.ToHex(this.valueHexView);\r\n        else {\r\n            if (this.isFirstSid) {\r\n                let sidValue = this.valueDec;\r\n                if (this.valueDec <= 39)\r\n                    result = \"0.\";\r\n                else {\r\n                    if (this.valueDec <= 79) {\r\n                        result = \"1.\";\r\n                        sidValue -= 40;\r\n                    }\r\n                    else {\r\n                        result = \"2.\";\r\n                        sidValue -= 80;\r\n                    }\r\n                }\r\n                result += sidValue.toString();\r\n            }\r\n            else\r\n                result = this.valueDec.toString();\r\n        }\r\n        return result;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            valueDec: this.valueDec,\r\n            isFirstSid: this.isFirstSid,\r\n        };\r\n    }\r\n}\r\nLocalSidValueBlock.NAME = \"sidBlock\";\n\nclass LocalObjectIdentifierValueBlock extends ValueBlock {\r\n    constructor({ value = EMPTY_STRING, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.value = [];\r\n        if (value) {\r\n            this.fromString(value);\r\n        }\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        let resultOffset = inputOffset;\r\n        while (inputLength > 0) {\r\n            const sidBlock = new LocalSidValueBlock();\r\n            resultOffset = sidBlock.fromBER(inputBuffer, resultOffset, inputLength);\r\n            if (resultOffset === -1) {\r\n                this.blockLength = 0;\r\n                this.error = sidBlock.error;\r\n                return resultOffset;\r\n            }\r\n            if (this.value.length === 0)\r\n                sidBlock.isFirstSid = true;\r\n            this.blockLength += sidBlock.blockLength;\r\n            inputLength -= sidBlock.blockLength;\r\n            this.value.push(sidBlock);\r\n        }\r\n        return resultOffset;\r\n    }\r\n    toBER(sizeOnly) {\r\n        const retBuffers = [];\r\n        for (let i = 0; i < this.value.length; i++) {\r\n            const valueBuf = this.value[i].toBER(sizeOnly);\r\n            if (valueBuf.byteLength === 0) {\r\n                this.error = this.value[i].error;\r\n                return EMPTY_BUFFER;\r\n            }\r\n            retBuffers.push(valueBuf);\r\n        }\r\n        return concat(retBuffers);\r\n    }\r\n    fromString(string) {\r\n        this.value = [];\r\n        let pos1 = 0;\r\n        let pos2 = 0;\r\n        let sid = \"\";\r\n        let flag = false;\r\n        do {\r\n            pos2 = string.indexOf(\".\", pos1);\r\n            if (pos2 === -1)\r\n                sid = string.substring(pos1);\r\n            else\r\n                sid = string.substring(pos1, pos2);\r\n            pos1 = pos2 + 1;\r\n            if (flag) {\r\n                const sidBlock = this.value[0];\r\n                let plus = 0;\r\n                switch (sidBlock.valueDec) {\r\n                    case 0:\r\n                        break;\r\n                    case 1:\r\n                        plus = 40;\r\n                        break;\r\n                    case 2:\r\n                        plus = 80;\r\n                        break;\r\n                    default:\r\n                        this.value = [];\r\n                        return;\r\n                }\r\n                const parsedSID = parseInt(sid, 10);\r\n                if (isNaN(parsedSID))\r\n                    return;\r\n                sidBlock.valueDec = parsedSID + plus;\r\n                flag = false;\r\n            }\r\n            else {\r\n                const sidBlock = new LocalSidValueBlock();\r\n                if (sid > Number.MAX_SAFE_INTEGER) {\r\n                    assertBigInt();\r\n                    const sidValue = BigInt(sid);\r\n                    sidBlock.valueBigInt = sidValue;\r\n                }\r\n                else {\r\n                    sidBlock.valueDec = parseInt(sid, 10);\r\n                    if (isNaN(sidBlock.valueDec))\r\n                        return;\r\n                }\r\n                if (!this.value.length) {\r\n                    sidBlock.isFirstSid = true;\r\n                    flag = true;\r\n                }\r\n                this.value.push(sidBlock);\r\n            }\r\n        } while (pos2 !== -1);\r\n    }\r\n    toString() {\r\n        let result = \"\";\r\n        let isHexOnly = false;\r\n        for (let i = 0; i < this.value.length; i++) {\r\n            isHexOnly = this.value[i].isHexOnly;\r\n            let sidStr = this.value[i].toString();\r\n            if (i !== 0)\r\n                result = `${result}.`;\r\n            if (isHexOnly) {\r\n                sidStr = `{${sidStr}}`;\r\n                if (this.value[i].isFirstSid)\r\n                    result = `2.{${sidStr} - 80}`;\r\n                else\r\n                    result += sidStr;\r\n            }\r\n            else\r\n                result += sidStr;\r\n        }\r\n        return result;\r\n    }\r\n    toJSON() {\r\n        const object = {\r\n            ...super.toJSON(),\r\n            value: this.toString(),\r\n            sidArray: [],\r\n        };\r\n        for (let i = 0; i < this.value.length; i++) {\r\n            object.sidArray.push(this.value[i].toJSON());\r\n        }\r\n        return object;\r\n    }\r\n}\r\nLocalObjectIdentifierValueBlock.NAME = \"ObjectIdentifierValueBlock\";\n\nvar _a$m;\r\nclass ObjectIdentifier extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, LocalObjectIdentifierValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 6;\r\n    }\r\n    getValue() {\r\n        return this.valueBlock.toString();\r\n    }\r\n    setValue(value) {\r\n        this.valueBlock.fromString(value);\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME} : ${this.valueBlock.toString() || \"empty\"}`;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            value: this.getValue(),\r\n        };\r\n    }\r\n}\r\n_a$m = ObjectIdentifier;\r\n(() => {\r\n    typeStore.ObjectIdentifier = _a$m;\r\n})();\r\nObjectIdentifier.NAME = \"OBJECT IDENTIFIER\";\n\nclass LocalRelativeSidValueBlock extends HexBlock(LocalBaseBlock) {\r\n    constructor({ valueDec = 0, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.valueDec = valueDec;\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        if (inputLength === 0)\r\n            return inputOffset;\r\n        const inputView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        if (!checkBufferParams(this, inputView, inputOffset, inputLength))\r\n            return -1;\r\n        const intBuffer = inputView.subarray(inputOffset, inputOffset + inputLength);\r\n        this.valueHexView = new Uint8Array(inputLength);\r\n        for (let i = 0; i < inputLength; i++) {\r\n            this.valueHexView[i] = intBuffer[i] & 0x7F;\r\n            this.blockLength++;\r\n            if ((intBuffer[i] & 0x80) === 0x00)\r\n                break;\r\n        }\r\n        const tempView = new Uint8Array(this.blockLength);\r\n        for (let i = 0; i < this.blockLength; i++)\r\n            tempView[i] = this.valueHexView[i];\r\n        this.valueHexView = tempView;\r\n        if ((intBuffer[this.blockLength - 1] & 0x80) !== 0x00) {\r\n            this.error = \"End of input reached before message was fully decoded\";\r\n            return -1;\r\n        }\r\n        if (this.valueHexView[0] === 0x00)\r\n            this.warnings.push(\"Needlessly long format of SID encoding\");\r\n        if (this.blockLength <= 8)\r\n            this.valueDec = pvutils.utilFromBase(this.valueHexView, 7);\r\n        else {\r\n            this.isHexOnly = true;\r\n            this.warnings.push(\"Too big SID for decoding, hex only\");\r\n        }\r\n        return (inputOffset + this.blockLength);\r\n    }\r\n    toBER(sizeOnly) {\r\n        if (this.isHexOnly) {\r\n            if (sizeOnly)\r\n                return (new ArrayBuffer(this.valueHexView.byteLength));\r\n            const curView = this.valueHexView;\r\n            const retView = new Uint8Array(this.blockLength);\r\n            for (let i = 0; i < (this.blockLength - 1); i++)\r\n                retView[i] = curView[i] | 0x80;\r\n            retView[this.blockLength - 1] = curView[this.blockLength - 1];\r\n            return retView.buffer;\r\n        }\r\n        const encodedBuf = pvutils.utilToBase(this.valueDec, 7);\r\n        if (encodedBuf.byteLength === 0) {\r\n            this.error = \"Error during encoding SID value\";\r\n            return EMPTY_BUFFER;\r\n        }\r\n        const retView = new Uint8Array(encodedBuf.byteLength);\r\n        if (!sizeOnly) {\r\n            const encodedView = new Uint8Array(encodedBuf);\r\n            const len = encodedBuf.byteLength - 1;\r\n            for (let i = 0; i < len; i++)\r\n                retView[i] = encodedView[i] | 0x80;\r\n            retView[len] = encodedView[len];\r\n        }\r\n        return retView.buffer;\r\n    }\r\n    toString() {\r\n        let result = \"\";\r\n        if (this.isHexOnly)\r\n            result = pvtsutils.Convert.ToHex(this.valueHexView);\r\n        else {\r\n            result = this.valueDec.toString();\r\n        }\r\n        return result;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            valueDec: this.valueDec,\r\n        };\r\n    }\r\n}\r\nLocalRelativeSidValueBlock.NAME = \"relativeSidBlock\";\n\nclass LocalRelativeObjectIdentifierValueBlock extends ValueBlock {\r\n    constructor({ value = EMPTY_STRING, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.value = [];\r\n        if (value) {\r\n            this.fromString(value);\r\n        }\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        let resultOffset = inputOffset;\r\n        while (inputLength > 0) {\r\n            const sidBlock = new LocalRelativeSidValueBlock();\r\n            resultOffset = sidBlock.fromBER(inputBuffer, resultOffset, inputLength);\r\n            if (resultOffset === -1) {\r\n                this.blockLength = 0;\r\n                this.error = sidBlock.error;\r\n                return resultOffset;\r\n            }\r\n            this.blockLength += sidBlock.blockLength;\r\n            inputLength -= sidBlock.blockLength;\r\n            this.value.push(sidBlock);\r\n        }\r\n        return resultOffset;\r\n    }\r\n    toBER(sizeOnly, writer) {\r\n        const retBuffers = [];\r\n        for (let i = 0; i < this.value.length; i++) {\r\n            const valueBuf = this.value[i].toBER(sizeOnly);\r\n            if (valueBuf.byteLength === 0) {\r\n                this.error = this.value[i].error;\r\n                return EMPTY_BUFFER;\r\n            }\r\n            retBuffers.push(valueBuf);\r\n        }\r\n        return concat(retBuffers);\r\n    }\r\n    fromString(string) {\r\n        this.value = [];\r\n        let pos1 = 0;\r\n        let pos2 = 0;\r\n        let sid = \"\";\r\n        do {\r\n            pos2 = string.indexOf(\".\", pos1);\r\n            if (pos2 === -1)\r\n                sid = string.substring(pos1);\r\n            else\r\n                sid = string.substring(pos1, pos2);\r\n            pos1 = pos2 + 1;\r\n            const sidBlock = new LocalRelativeSidValueBlock();\r\n            sidBlock.valueDec = parseInt(sid, 10);\r\n            if (isNaN(sidBlock.valueDec))\r\n                return true;\r\n            this.value.push(sidBlock);\r\n        } while (pos2 !== -1);\r\n        return true;\r\n    }\r\n    toString() {\r\n        let result = \"\";\r\n        let isHexOnly = false;\r\n        for (let i = 0; i < this.value.length; i++) {\r\n            isHexOnly = this.value[i].isHexOnly;\r\n            let sidStr = this.value[i].toString();\r\n            if (i !== 0)\r\n                result = `${result}.`;\r\n            if (isHexOnly) {\r\n                sidStr = `{${sidStr}}`;\r\n                result += sidStr;\r\n            }\r\n            else\r\n                result += sidStr;\r\n        }\r\n        return result;\r\n    }\r\n    toJSON() {\r\n        const object = {\r\n            ...super.toJSON(),\r\n            value: this.toString(),\r\n            sidArray: [],\r\n        };\r\n        for (let i = 0; i < this.value.length; i++)\r\n            object.sidArray.push(this.value[i].toJSON());\r\n        return object;\r\n    }\r\n}\r\nLocalRelativeObjectIdentifierValueBlock.NAME = \"RelativeObjectIdentifierValueBlock\";\n\nvar _a$l;\r\nclass RelativeObjectIdentifier extends BaseBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters, LocalRelativeObjectIdentifierValueBlock);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 13;\r\n    }\r\n    getValue() {\r\n        return this.valueBlock.toString();\r\n    }\r\n    setValue(value) {\r\n        this.valueBlock.fromString(value);\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME} : ${this.valueBlock.toString() || \"empty\"}`;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            value: this.getValue(),\r\n        };\r\n    }\r\n}\r\n_a$l = RelativeObjectIdentifier;\r\n(() => {\r\n    typeStore.RelativeObjectIdentifier = _a$l;\r\n})();\r\nRelativeObjectIdentifier.NAME = \"RelativeObjectIdentifier\";\n\nvar _a$k;\r\nclass Sequence extends Constructed {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 16;\r\n    }\r\n}\r\n_a$k = Sequence;\r\n(() => {\r\n    typeStore.Sequence = _a$k;\r\n})();\r\nSequence.NAME = \"SEQUENCE\";\n\nvar _a$j;\r\nclass Set extends Constructed {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 17;\r\n    }\r\n}\r\n_a$j = Set;\r\n(() => {\r\n    typeStore.Set = _a$j;\r\n})();\r\nSet.NAME = \"SET\";\n\nclass LocalStringValueBlock extends HexBlock(ValueBlock) {\r\n    constructor({ ...parameters } = {}) {\r\n        super(parameters);\r\n        this.isHexOnly = true;\r\n        this.value = EMPTY_STRING;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            value: this.value,\r\n        };\r\n    }\r\n}\r\nLocalStringValueBlock.NAME = \"StringValueBlock\";\n\nclass LocalSimpleStringValueBlock extends LocalStringValueBlock {\r\n}\r\nLocalSimpleStringValueBlock.NAME = \"SimpleStringValueBlock\";\n\nclass LocalSimpleStringBlock extends BaseStringBlock {\r\n    constructor({ ...parameters } = {}) {\r\n        super(parameters, LocalSimpleStringValueBlock);\r\n    }\r\n    fromBuffer(inputBuffer) {\r\n        this.valueBlock.value = String.fromCharCode.apply(null, pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer));\r\n    }\r\n    fromString(inputString) {\r\n        const strLen = inputString.length;\r\n        const view = this.valueBlock.valueHexView = new Uint8Array(strLen);\r\n        for (let i = 0; i < strLen; i++)\r\n            view[i] = inputString.charCodeAt(i);\r\n        this.valueBlock.value = inputString;\r\n    }\r\n}\r\nLocalSimpleStringBlock.NAME = \"SIMPLE STRING\";\n\nclass LocalUtf8StringValueBlock extends LocalSimpleStringBlock {\r\n    fromBuffer(inputBuffer) {\r\n        this.valueBlock.valueHexView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n        try {\r\n            this.valueBlock.value = pvtsutils.Convert.ToUtf8String(inputBuffer);\r\n        }\r\n        catch (ex) {\r\n            this.warnings.push(`Error during \"decodeURIComponent\": ${ex}, using raw string`);\r\n            this.valueBlock.value = pvtsutils.Convert.ToBinary(inputBuffer);\r\n        }\r\n    }\r\n    fromString(inputString) {\r\n        this.valueBlock.valueHexView = new Uint8Array(pvtsutils.Convert.FromUtf8String(inputString));\r\n        this.valueBlock.value = inputString;\r\n    }\r\n}\r\nLocalUtf8StringValueBlock.NAME = \"Utf8StringValueBlock\";\n\nvar _a$i;\r\nclass Utf8String extends LocalUtf8StringValueBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 12;\r\n    }\r\n}\r\n_a$i = Utf8String;\r\n(() => {\r\n    typeStore.Utf8String = _a$i;\r\n})();\r\nUtf8String.NAME = \"UTF8String\";\n\nclass LocalBmpStringValueBlock extends LocalSimpleStringBlock {\r\n    fromBuffer(inputBuffer) {\r\n        this.valueBlock.value = pvtsutils.Convert.ToUtf16String(inputBuffer);\r\n        this.valueBlock.valueHexView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer);\r\n    }\r\n    fromString(inputString) {\r\n        this.valueBlock.value = inputString;\r\n        this.valueBlock.valueHexView = new Uint8Array(pvtsutils.Convert.FromUtf16String(inputString));\r\n    }\r\n}\r\nLocalBmpStringValueBlock.NAME = \"BmpStringValueBlock\";\n\nvar _a$h;\r\nclass BmpString extends LocalBmpStringValueBlock {\r\n    constructor({ ...parameters } = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 30;\r\n    }\r\n}\r\n_a$h = BmpString;\r\n(() => {\r\n    typeStore.BmpString = _a$h;\r\n})();\r\nBmpString.NAME = \"BMPString\";\n\nclass LocalUniversalStringValueBlock extends LocalSimpleStringBlock {\r\n    fromBuffer(inputBuffer) {\r\n        const copyBuffer = ArrayBuffer.isView(inputBuffer) ? inputBuffer.slice().buffer : inputBuffer.slice(0);\r\n        const valueView = new Uint8Array(copyBuffer);\r\n        for (let i = 0; i < valueView.length; i += 4) {\r\n            valueView[i] = valueView[i + 3];\r\n            valueView[i + 1] = valueView[i + 2];\r\n            valueView[i + 2] = 0x00;\r\n            valueView[i + 3] = 0x00;\r\n        }\r\n        this.valueBlock.value = String.fromCharCode.apply(null, new Uint32Array(copyBuffer));\r\n    }\r\n    fromString(inputString) {\r\n        const strLength = inputString.length;\r\n        const valueHexView = this.valueBlock.valueHexView = new Uint8Array(strLength * 4);\r\n        for (let i = 0; i < strLength; i++) {\r\n            const codeBuf = pvutils.utilToBase(inputString.charCodeAt(i), 8);\r\n            const codeView = new Uint8Array(codeBuf);\r\n            if (codeView.length > 4)\r\n                continue;\r\n            const dif = 4 - codeView.length;\r\n            for (let j = (codeView.length - 1); j >= 0; j--)\r\n                valueHexView[i * 4 + j + dif] = codeView[j];\r\n        }\r\n        this.valueBlock.value = inputString;\r\n    }\r\n}\r\nLocalUniversalStringValueBlock.NAME = \"UniversalStringValueBlock\";\n\nvar _a$g;\r\nclass UniversalString extends LocalUniversalStringValueBlock {\r\n    constructor({ ...parameters } = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 28;\r\n    }\r\n}\r\n_a$g = UniversalString;\r\n(() => {\r\n    typeStore.UniversalString = _a$g;\r\n})();\r\nUniversalString.NAME = \"UniversalString\";\n\nvar _a$f;\r\nclass NumericString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 18;\r\n    }\r\n}\r\n_a$f = NumericString;\r\n(() => {\r\n    typeStore.NumericString = _a$f;\r\n})();\r\nNumericString.NAME = \"NumericString\";\n\nvar _a$e;\r\nclass PrintableString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 19;\r\n    }\r\n}\r\n_a$e = PrintableString;\r\n(() => {\r\n    typeStore.PrintableString = _a$e;\r\n})();\r\nPrintableString.NAME = \"PrintableString\";\n\nvar _a$d;\r\nclass TeletexString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 20;\r\n    }\r\n}\r\n_a$d = TeletexString;\r\n(() => {\r\n    typeStore.TeletexString = _a$d;\r\n})();\r\nTeletexString.NAME = \"TeletexString\";\n\nvar _a$c;\r\nclass VideotexString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 21;\r\n    }\r\n}\r\n_a$c = VideotexString;\r\n(() => {\r\n    typeStore.VideotexString = _a$c;\r\n})();\r\nVideotexString.NAME = \"VideotexString\";\n\nvar _a$b;\r\nclass IA5String extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 22;\r\n    }\r\n}\r\n_a$b = IA5String;\r\n(() => {\r\n    typeStore.IA5String = _a$b;\r\n})();\r\nIA5String.NAME = \"IA5String\";\n\nvar _a$a;\r\nclass GraphicString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 25;\r\n    }\r\n}\r\n_a$a = GraphicString;\r\n(() => {\r\n    typeStore.GraphicString = _a$a;\r\n})();\r\nGraphicString.NAME = \"GraphicString\";\n\nvar _a$9;\r\nclass VisibleString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 26;\r\n    }\r\n}\r\n_a$9 = VisibleString;\r\n(() => {\r\n    typeStore.VisibleString = _a$9;\r\n})();\r\nVisibleString.NAME = \"VisibleString\";\n\nvar _a$8;\r\nclass GeneralString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 27;\r\n    }\r\n}\r\n_a$8 = GeneralString;\r\n(() => {\r\n    typeStore.GeneralString = _a$8;\r\n})();\r\nGeneralString.NAME = \"GeneralString\";\n\nvar _a$7;\r\nclass CharacterString extends LocalSimpleStringBlock {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 29;\r\n    }\r\n}\r\n_a$7 = CharacterString;\r\n(() => {\r\n    typeStore.CharacterString = _a$7;\r\n})();\r\nCharacterString.NAME = \"CharacterString\";\n\nvar _a$6;\r\nclass UTCTime extends VisibleString {\r\n    constructor({ value, valueDate, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.year = 0;\r\n        this.month = 0;\r\n        this.day = 0;\r\n        this.hour = 0;\r\n        this.minute = 0;\r\n        this.second = 0;\r\n        if (value) {\r\n            this.fromString(value);\r\n            this.valueBlock.valueHexView = new Uint8Array(value.length);\r\n            for (let i = 0; i < value.length; i++)\r\n                this.valueBlock.valueHexView[i] = value.charCodeAt(i);\r\n        }\r\n        if (valueDate) {\r\n            this.fromDate(valueDate);\r\n            this.valueBlock.valueHexView = new Uint8Array(this.toBuffer());\r\n        }\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 23;\r\n    }\r\n    fromBuffer(inputBuffer) {\r\n        this.fromString(String.fromCharCode.apply(null, pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer)));\r\n    }\r\n    toBuffer() {\r\n        const str = this.toString();\r\n        const buffer = new ArrayBuffer(str.length);\r\n        const view = new Uint8Array(buffer);\r\n        for (let i = 0; i < str.length; i++)\r\n            view[i] = str.charCodeAt(i);\r\n        return buffer;\r\n    }\r\n    fromDate(inputDate) {\r\n        this.year = inputDate.getUTCFullYear();\r\n        this.month = inputDate.getUTCMonth() + 1;\r\n        this.day = inputDate.getUTCDate();\r\n        this.hour = inputDate.getUTCHours();\r\n        this.minute = inputDate.getUTCMinutes();\r\n        this.second = inputDate.getUTCSeconds();\r\n    }\r\n    toDate() {\r\n        return (new Date(Date.UTC(this.year, this.month - 1, this.day, this.hour, this.minute, this.second)));\r\n    }\r\n    fromString(inputString) {\r\n        const parser = /(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})Z/ig;\r\n        const parserArray = parser.exec(inputString);\r\n        if (parserArray === null) {\r\n            this.error = \"Wrong input string for conversion\";\r\n            return;\r\n        }\r\n        const year = parseInt(parserArray[1], 10);\r\n        if (year >= 50)\r\n            this.year = 1900 + year;\r\n        else\r\n            this.year = 2000 + year;\r\n        this.month = parseInt(parserArray[2], 10);\r\n        this.day = parseInt(parserArray[3], 10);\r\n        this.hour = parseInt(parserArray[4], 10);\r\n        this.minute = parseInt(parserArray[5], 10);\r\n        this.second = parseInt(parserArray[6], 10);\r\n    }\r\n    toString(encoding = \"iso\") {\r\n        if (encoding === \"iso\") {\r\n            const outputArray = new Array(7);\r\n            outputArray[0] = pvutils.padNumber(((this.year < 2000) ? (this.year - 1900) : (this.year - 2000)), 2);\r\n            outputArray[1] = pvutils.padNumber(this.month, 2);\r\n            outputArray[2] = pvutils.padNumber(this.day, 2);\r\n            outputArray[3] = pvutils.padNumber(this.hour, 2);\r\n            outputArray[4] = pvutils.padNumber(this.minute, 2);\r\n            outputArray[5] = pvutils.padNumber(this.second, 2);\r\n            outputArray[6] = \"Z\";\r\n            return outputArray.join(\"\");\r\n        }\r\n        return super.toString(encoding);\r\n    }\r\n    onAsciiEncoding() {\r\n        return `${this.constructor.NAME} : ${this.toDate().toISOString()}`;\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            year: this.year,\r\n            month: this.month,\r\n            day: this.day,\r\n            hour: this.hour,\r\n            minute: this.minute,\r\n            second: this.second,\r\n        };\r\n    }\r\n}\r\n_a$6 = UTCTime;\r\n(() => {\r\n    typeStore.UTCTime = _a$6;\r\n})();\r\nUTCTime.NAME = \"UTCTime\";\n\nvar _a$5;\r\nclass GeneralizedTime extends UTCTime {\r\n    constructor(parameters = {}) {\r\n        var _b;\r\n        super(parameters);\r\n        (_b = this.millisecond) !== null && _b !== void 0 ? _b : (this.millisecond = 0);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 24;\r\n    }\r\n    fromDate(inputDate) {\r\n        super.fromDate(inputDate);\r\n        this.millisecond = inputDate.getUTCMilliseconds();\r\n    }\r\n    toDate() {\r\n        return (new Date(Date.UTC(this.year, this.month - 1, this.day, this.hour, this.minute, this.second, this.millisecond)));\r\n    }\r\n    fromString(inputString) {\r\n        let isUTC = false;\r\n        let timeString = \"\";\r\n        let dateTimeString = \"\";\r\n        let fractionPart = 0;\r\n        let parser;\r\n        let hourDifference = 0;\r\n        let minuteDifference = 0;\r\n        if (inputString[inputString.length - 1] === \"Z\") {\r\n            timeString = inputString.substring(0, inputString.length - 1);\r\n            isUTC = true;\r\n        }\r\n        else {\r\n            const number = new Number(inputString[inputString.length - 1]);\r\n            if (isNaN(number.valueOf()))\r\n                throw new Error(\"Wrong input string for conversion\");\r\n            timeString = inputString;\r\n        }\r\n        if (isUTC) {\r\n            if (timeString.indexOf(\"+\") !== -1)\r\n                throw new Error(\"Wrong input string for conversion\");\r\n            if (timeString.indexOf(\"-\") !== -1)\r\n                throw new Error(\"Wrong input string for conversion\");\r\n        }\r\n        else {\r\n            let multiplier = 1;\r\n            let differencePosition = timeString.indexOf(\"+\");\r\n            let differenceString = \"\";\r\n            if (differencePosition === -1) {\r\n                differencePosition = timeString.indexOf(\"-\");\r\n                multiplier = -1;\r\n            }\r\n            if (differencePosition !== -1) {\r\n                differenceString = timeString.substring(differencePosition + 1);\r\n                timeString = timeString.substring(0, differencePosition);\r\n                if ((differenceString.length !== 2) && (differenceString.length !== 4))\r\n                    throw new Error(\"Wrong input string for conversion\");\r\n                let number = parseInt(differenceString.substring(0, 2), 10);\r\n                if (isNaN(number.valueOf()))\r\n                    throw new Error(\"Wrong input string for conversion\");\r\n                hourDifference = multiplier * number;\r\n                if (differenceString.length === 4) {\r\n                    number = parseInt(differenceString.substring(2, 4), 10);\r\n                    if (isNaN(number.valueOf()))\r\n                        throw new Error(\"Wrong input string for conversion\");\r\n                    minuteDifference = multiplier * number;\r\n                }\r\n            }\r\n        }\r\n        let fractionPointPosition = timeString.indexOf(\".\");\r\n        if (fractionPointPosition === -1)\r\n            fractionPointPosition = timeString.indexOf(\",\");\r\n        if (fractionPointPosition !== -1) {\r\n            const fractionPartCheck = new Number(`0${timeString.substring(fractionPointPosition)}`);\r\n            if (isNaN(fractionPartCheck.valueOf()))\r\n                throw new Error(\"Wrong input string for conversion\");\r\n            fractionPart = fractionPartCheck.valueOf();\r\n            dateTimeString = timeString.substring(0, fractionPointPosition);\r\n        }\r\n        else\r\n            dateTimeString = timeString;\r\n        switch (true) {\r\n            case (dateTimeString.length === 8):\r\n                parser = /(\\d{4})(\\d{2})(\\d{2})/ig;\r\n                if (fractionPointPosition !== -1)\r\n                    throw new Error(\"Wrong input string for conversion\");\r\n                break;\r\n            case (dateTimeString.length === 10):\r\n                parser = /(\\d{4})(\\d{2})(\\d{2})(\\d{2})/ig;\r\n                if (fractionPointPosition !== -1) {\r\n                    let fractionResult = 60 * fractionPart;\r\n                    this.minute = Math.floor(fractionResult);\r\n                    fractionResult = 60 * (fractionResult - this.minute);\r\n                    this.second = Math.floor(fractionResult);\r\n                    fractionResult = 1000 * (fractionResult - this.second);\r\n                    this.millisecond = Math.floor(fractionResult);\r\n                }\r\n                break;\r\n            case (dateTimeString.length === 12):\r\n                parser = /(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})/ig;\r\n                if (fractionPointPosition !== -1) {\r\n                    let fractionResult = 60 * fractionPart;\r\n                    this.second = Math.floor(fractionResult);\r\n                    fractionResult = 1000 * (fractionResult - this.second);\r\n                    this.millisecond = Math.floor(fractionResult);\r\n                }\r\n                break;\r\n            case (dateTimeString.length === 14):\r\n                parser = /(\\d{4})(\\d{2})(\\d{2})(\\d{2})(\\d{2})(\\d{2})/ig;\r\n                if (fractionPointPosition !== -1) {\r\n                    const fractionResult = 1000 * fractionPart;\r\n                    this.millisecond = Math.floor(fractionResult);\r\n                }\r\n                break;\r\n            default:\r\n                throw new Error(\"Wrong input string for conversion\");\r\n        }\r\n        const parserArray = parser.exec(dateTimeString);\r\n        if (parserArray === null)\r\n            throw new Error(\"Wrong input string for conversion\");\r\n        for (let j = 1; j < parserArray.length; j++) {\r\n            switch (j) {\r\n                case 1:\r\n                    this.year = parseInt(parserArray[j], 10);\r\n                    break;\r\n                case 2:\r\n                    this.month = parseInt(parserArray[j], 10);\r\n                    break;\r\n                case 3:\r\n                    this.day = parseInt(parserArray[j], 10);\r\n                    break;\r\n                case 4:\r\n                    this.hour = parseInt(parserArray[j], 10) + hourDifference;\r\n                    break;\r\n                case 5:\r\n                    this.minute = parseInt(parserArray[j], 10) + minuteDifference;\r\n                    break;\r\n                case 6:\r\n                    this.second = parseInt(parserArray[j], 10);\r\n                    break;\r\n                default:\r\n                    throw new Error(\"Wrong input string for conversion\");\r\n            }\r\n        }\r\n        if (isUTC === false) {\r\n            const tempDate = new Date(this.year, this.month, this.day, this.hour, this.minute, this.second, this.millisecond);\r\n            this.year = tempDate.getUTCFullYear();\r\n            this.month = tempDate.getUTCMonth();\r\n            this.day = tempDate.getUTCDay();\r\n            this.hour = tempDate.getUTCHours();\r\n            this.minute = tempDate.getUTCMinutes();\r\n            this.second = tempDate.getUTCSeconds();\r\n            this.millisecond = tempDate.getUTCMilliseconds();\r\n        }\r\n    }\r\n    toString(encoding = \"iso\") {\r\n        if (encoding === \"iso\") {\r\n            const outputArray = [];\r\n            outputArray.push(pvutils.padNumber(this.year, 4));\r\n            outputArray.push(pvutils.padNumber(this.month, 2));\r\n            outputArray.push(pvutils.padNumber(this.day, 2));\r\n            outputArray.push(pvutils.padNumber(this.hour, 2));\r\n            outputArray.push(pvutils.padNumber(this.minute, 2));\r\n            outputArray.push(pvutils.padNumber(this.second, 2));\r\n            if (this.millisecond !== 0) {\r\n                outputArray.push(\".\");\r\n                outputArray.push(pvutils.padNumber(this.millisecond, 3));\r\n            }\r\n            outputArray.push(\"Z\");\r\n            return outputArray.join(\"\");\r\n        }\r\n        return super.toString(encoding);\r\n    }\r\n    toJSON() {\r\n        return {\r\n            ...super.toJSON(),\r\n            millisecond: this.millisecond,\r\n        };\r\n    }\r\n}\r\n_a$5 = GeneralizedTime;\r\n(() => {\r\n    typeStore.GeneralizedTime = _a$5;\r\n})();\r\nGeneralizedTime.NAME = \"GeneralizedTime\";\n\nvar _a$4;\r\nclass DATE extends Utf8String {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 31;\r\n    }\r\n}\r\n_a$4 = DATE;\r\n(() => {\r\n    typeStore.DATE = _a$4;\r\n})();\r\nDATE.NAME = \"DATE\";\n\nvar _a$3;\r\nclass TimeOfDay extends Utf8String {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 32;\r\n    }\r\n}\r\n_a$3 = TimeOfDay;\r\n(() => {\r\n    typeStore.TimeOfDay = _a$3;\r\n})();\r\nTimeOfDay.NAME = \"TimeOfDay\";\n\nvar _a$2;\r\nclass DateTime extends Utf8String {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 33;\r\n    }\r\n}\r\n_a$2 = DateTime;\r\n(() => {\r\n    typeStore.DateTime = _a$2;\r\n})();\r\nDateTime.NAME = \"DateTime\";\n\nvar _a$1;\r\nclass Duration extends Utf8String {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 34;\r\n    }\r\n}\r\n_a$1 = Duration;\r\n(() => {\r\n    typeStore.Duration = _a$1;\r\n})();\r\nDuration.NAME = \"Duration\";\n\nvar _a;\r\nclass TIME extends Utf8String {\r\n    constructor(parameters = {}) {\r\n        super(parameters);\r\n        this.idBlock.tagClass = 1;\r\n        this.idBlock.tagNumber = 14;\r\n    }\r\n}\r\n_a = TIME;\r\n(() => {\r\n    typeStore.TIME = _a;\r\n})();\r\nTIME.NAME = \"TIME\";\n\nclass Any {\r\n    constructor({ name = EMPTY_STRING, optional = false, } = {}) {\r\n        this.name = name;\r\n        this.optional = optional;\r\n    }\r\n}\n\nclass Choice extends Any {\r\n    constructor({ value = [], ...parameters } = {}) {\r\n        super(parameters);\r\n        this.value = value;\r\n    }\r\n}\n\nclass Repeated extends Any {\r\n    constructor({ value = new Any(), local = false, ...parameters } = {}) {\r\n        super(parameters);\r\n        this.value = value;\r\n        this.local = local;\r\n    }\r\n}\n\nclass RawData {\r\n    constructor({ data = EMPTY_VIEW } = {}) {\r\n        this.dataView = pvtsutils.BufferSourceConverter.toUint8Array(data);\r\n    }\r\n    get data() {\r\n        return this.dataView.slice().buffer;\r\n    }\r\n    set data(value) {\r\n        this.dataView = pvtsutils.BufferSourceConverter.toUint8Array(value);\r\n    }\r\n    fromBER(inputBuffer, inputOffset, inputLength) {\r\n        const endLength = inputOffset + inputLength;\r\n        this.dataView = pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer).subarray(inputOffset, endLength);\r\n        return endLength;\r\n    }\r\n    toBER(sizeOnly) {\r\n        return this.dataView.slice().buffer;\r\n    }\r\n}\n\nfunction compareSchema(root, inputData, inputSchema) {\r\n    if (inputSchema instanceof Choice) {\r\n        for (let j = 0; j < inputSchema.value.length; j++) {\r\n            const result = compareSchema(root, inputData, inputSchema.value[j]);\r\n            if (result.verified) {\r\n                return {\r\n                    verified: true,\r\n                    result: root\r\n                };\r\n            }\r\n        }\r\n        {\r\n            const _result = {\r\n                verified: false,\r\n                result: {\r\n                    error: \"Wrong values for Choice type\"\r\n                },\r\n            };\r\n            if (inputSchema.hasOwnProperty(NAME))\r\n                _result.name = inputSchema.name;\r\n            return _result;\r\n        }\r\n    }\r\n    if (inputSchema instanceof Any) {\r\n        if (inputSchema.hasOwnProperty(NAME))\r\n            root[inputSchema.name] = inputData;\r\n        return {\r\n            verified: true,\r\n            result: root\r\n        };\r\n    }\r\n    if ((root instanceof Object) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong root object\" }\r\n        };\r\n    }\r\n    if ((inputData instanceof Object) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 data\" }\r\n        };\r\n    }\r\n    if ((inputSchema instanceof Object) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    if ((ID_BLOCK in inputSchema) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    if ((FROM_BER in inputSchema.idBlock) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    if ((TO_BER in inputSchema.idBlock) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    const encodedId = inputSchema.idBlock.toBER(false);\r\n    if (encodedId.byteLength === 0) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Error encoding idBlock for ASN.1 schema\" }\r\n        };\r\n    }\r\n    const decodedOffset = inputSchema.idBlock.fromBER(encodedId, 0, encodedId.byteLength);\r\n    if (decodedOffset === -1) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Error decoding idBlock for ASN.1 schema\" }\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.hasOwnProperty(TAG_CLASS) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.tagClass !== inputData.idBlock.tagClass) {\r\n        return {\r\n            verified: false,\r\n            result: root\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.hasOwnProperty(TAG_NUMBER) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.tagNumber !== inputData.idBlock.tagNumber) {\r\n        return {\r\n            verified: false,\r\n            result: root\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.hasOwnProperty(IS_CONSTRUCTED) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.isConstructed !== inputData.idBlock.isConstructed) {\r\n        return {\r\n            verified: false,\r\n            result: root\r\n        };\r\n    }\r\n    if (!(IS_HEX_ONLY in inputSchema.idBlock)) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema\" }\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.isHexOnly !== inputData.idBlock.isHexOnly) {\r\n        return {\r\n            verified: false,\r\n            result: root\r\n        };\r\n    }\r\n    if (inputSchema.idBlock.isHexOnly) {\r\n        if ((VALUE_HEX_VIEW in inputSchema.idBlock) === false) {\r\n            return {\r\n                verified: false,\r\n                result: { error: \"Wrong ASN.1 schema\" }\r\n            };\r\n        }\r\n        const schemaView = inputSchema.idBlock.valueHexView;\r\n        const asn1View = inputData.idBlock.valueHexView;\r\n        if (schemaView.length !== asn1View.length) {\r\n            return {\r\n                verified: false,\r\n                result: root\r\n            };\r\n        }\r\n        for (let i = 0; i < schemaView.length; i++) {\r\n            if (schemaView[i] !== asn1View[1]) {\r\n                return {\r\n                    verified: false,\r\n                    result: root\r\n                };\r\n            }\r\n        }\r\n    }\r\n    if (inputSchema.name) {\r\n        inputSchema.name = inputSchema.name.replace(/^\\s+|\\s+$/g, EMPTY_STRING);\r\n        if (inputSchema.name)\r\n            root[inputSchema.name] = inputData;\r\n    }\r\n    if (inputSchema instanceof typeStore.Constructed) {\r\n        let admission = 0;\r\n        let result = {\r\n            verified: false,\r\n            result: {\r\n                error: \"Unknown error\",\r\n            }\r\n        };\r\n        let maxLength = inputSchema.valueBlock.value.length;\r\n        if (maxLength > 0) {\r\n            if (inputSchema.valueBlock.value[0] instanceof Repeated) {\r\n                maxLength = inputData.valueBlock.value.length;\r\n            }\r\n        }\r\n        if (maxLength === 0) {\r\n            return {\r\n                verified: true,\r\n                result: root\r\n            };\r\n        }\r\n        if ((inputData.valueBlock.value.length === 0) &&\r\n            (inputSchema.valueBlock.value.length !== 0)) {\r\n            let _optional = true;\r\n            for (let i = 0; i < inputSchema.valueBlock.value.length; i++)\r\n                _optional = _optional && (inputSchema.valueBlock.value[i].optional || false);\r\n            if (_optional) {\r\n                return {\r\n                    verified: true,\r\n                    result: root\r\n                };\r\n            }\r\n            if (inputSchema.name) {\r\n                inputSchema.name = inputSchema.name.replace(/^\\s+|\\s+$/g, EMPTY_STRING);\r\n                if (inputSchema.name)\r\n                    delete root[inputSchema.name];\r\n            }\r\n            root.error = \"Inconsistent object length\";\r\n            return {\r\n                verified: false,\r\n                result: root\r\n            };\r\n        }\r\n        for (let i = 0; i < maxLength; i++) {\r\n            if ((i - admission) >= inputData.valueBlock.value.length) {\r\n                if (inputSchema.valueBlock.value[i].optional === false) {\r\n                    const _result = {\r\n                        verified: false,\r\n                        result: root\r\n                    };\r\n                    root.error = \"Inconsistent length between ASN.1 data and schema\";\r\n                    if (inputSchema.name) {\r\n                        inputSchema.name = inputSchema.name.replace(/^\\s+|\\s+$/g, EMPTY_STRING);\r\n                        if (inputSchema.name) {\r\n                            delete root[inputSchema.name];\r\n                            _result.name = inputSchema.name;\r\n                        }\r\n                    }\r\n                    return _result;\r\n                }\r\n            }\r\n            else {\r\n                if (inputSchema.valueBlock.value[0] instanceof Repeated) {\r\n                    result = compareSchema(root, inputData.valueBlock.value[i], inputSchema.valueBlock.value[0].value);\r\n                    if (result.verified === false) {\r\n                        if (inputSchema.valueBlock.value[0].optional)\r\n                            admission++;\r\n                        else {\r\n                            if (inputSchema.name) {\r\n                                inputSchema.name = inputSchema.name.replace(/^\\s+|\\s+$/g, EMPTY_STRING);\r\n                                if (inputSchema.name)\r\n                                    delete root[inputSchema.name];\r\n                            }\r\n                            return result;\r\n                        }\r\n                    }\r\n                    if ((NAME in inputSchema.valueBlock.value[0]) && (inputSchema.valueBlock.value[0].name.length > 0)) {\r\n                        let arrayRoot = {};\r\n                        if ((LOCAL in inputSchema.valueBlock.value[0]) && (inputSchema.valueBlock.value[0].local))\r\n                            arrayRoot = inputData;\r\n                        else\r\n                            arrayRoot = root;\r\n                        if (typeof arrayRoot[inputSchema.valueBlock.value[0].name] === \"undefined\")\r\n                            arrayRoot[inputSchema.valueBlock.value[0].name] = [];\r\n                        arrayRoot[inputSchema.valueBlock.value[0].name].push(inputData.valueBlock.value[i]);\r\n                    }\r\n                }\r\n                else {\r\n                    result = compareSchema(root, inputData.valueBlock.value[i - admission], inputSchema.valueBlock.value[i]);\r\n                    if (result.verified === false) {\r\n                        if (inputSchema.valueBlock.value[i].optional)\r\n                            admission++;\r\n                        else {\r\n                            if (inputSchema.name) {\r\n                                inputSchema.name = inputSchema.name.replace(/^\\s+|\\s+$/g, EMPTY_STRING);\r\n                                if (inputSchema.name)\r\n                                    delete root[inputSchema.name];\r\n                            }\r\n                            return result;\r\n                        }\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        if (result.verified === false) {\r\n            const _result = {\r\n                verified: false,\r\n                result: root\r\n            };\r\n            if (inputSchema.name) {\r\n                inputSchema.name = inputSchema.name.replace(/^\\s+|\\s+$/g, EMPTY_STRING);\r\n                if (inputSchema.name) {\r\n                    delete root[inputSchema.name];\r\n                    _result.name = inputSchema.name;\r\n                }\r\n            }\r\n            return _result;\r\n        }\r\n        return {\r\n            verified: true,\r\n            result: root\r\n        };\r\n    }\r\n    if (inputSchema.primitiveSchema &&\r\n        (VALUE_HEX_VIEW in inputData.valueBlock)) {\r\n        const asn1 = localFromBER(inputData.valueBlock.valueHexView);\r\n        if (asn1.offset === -1) {\r\n            const _result = {\r\n                verified: false,\r\n                result: asn1.result\r\n            };\r\n            if (inputSchema.name) {\r\n                inputSchema.name = inputSchema.name.replace(/^\\s+|\\s+$/g, EMPTY_STRING);\r\n                if (inputSchema.name) {\r\n                    delete root[inputSchema.name];\r\n                    _result.name = inputSchema.name;\r\n                }\r\n            }\r\n            return _result;\r\n        }\r\n        return compareSchema(root, asn1.result, inputSchema.primitiveSchema);\r\n    }\r\n    return {\r\n        verified: true,\r\n        result: root\r\n    };\r\n}\r\nfunction verifySchema(inputBuffer, inputSchema) {\r\n    if ((inputSchema instanceof Object) === false) {\r\n        return {\r\n            verified: false,\r\n            result: { error: \"Wrong ASN.1 schema type\" }\r\n        };\r\n    }\r\n    const asn1 = localFromBER(pvtsutils.BufferSourceConverter.toUint8Array(inputBuffer));\r\n    if (asn1.offset === -1) {\r\n        return {\r\n            verified: false,\r\n            result: asn1.result\r\n        };\r\n    }\r\n    return compareSchema(asn1.result, asn1.result, inputSchema);\r\n}\n\nexport { Any, BaseBlock, BaseStringBlock, BitString, BmpString, Boolean, CharacterString, Choice, Constructed, DATE, DateTime, Duration, EndOfContent, Enumerated, GeneralString, GeneralizedTime, GraphicString, HexBlock, IA5String, Integer, Null, NumericString, ObjectIdentifier, OctetString, Primitive, PrintableString, RawData, RelativeObjectIdentifier, Repeated, Sequence, Set, TIME, TeletexString, TimeOfDay, UTCTime, UniversalString, Utf8String, ValueBlock, VideotexString, ViewWriter, VisibleString, compareSchema, fromBER, verifySchema };\n","/**\n * Signing a message failed\n */\nexport class SigningError extends Error {\n    constructor(message = 'An error occurred while signing a message') {\n        super(message);\n        this.name = 'SigningError';\n    }\n}\n/**\n * Verifying a message signature failed\n */\nexport class VerificationError extends Error {\n    constructor(message = 'An error occurred while verifying a message') {\n        super(message);\n        this.name = 'VerificationError';\n    }\n}\n/**\n * WebCrypto was not available in the current context\n */\nexport class WebCryptoMissingError extends Error {\n    constructor(message = 'Missing Web Crypto API') {\n        super(message);\n        this.name = 'WebCryptoMissingError';\n    }\n}\n//# sourceMappingURL=errors.js.map","/* eslint-env browser */\nimport { WebCryptoMissingError } from '../errors.js';\n// Check native crypto exists and is enabled (In insecure context `self.crypto`\n// exists but `self.crypto.subtle` does not).\nexport default {\n    get(win = globalThis) {\n        const nativeCrypto = win.crypto;\n        if (nativeCrypto?.subtle == null) {\n            throw new WebCryptoMissingError('Missing Web Crypto API. ' +\n                'The most likely cause of this error is that this page is being accessed ' +\n                'from an insecure context (i.e. not HTTPS). For more information and ' +\n                'possible resolutions see ' +\n                'https://github.com/libp2p/js-libp2p/blob/main/packages/crypto/README.md#web-crypto-api');\n        }\n        return nativeCrypto;\n    }\n};\n//# sourceMappingURL=webcrypto.browser.js.map","import webcrypto from './webcrypto.js';\nexport default webcrypto;\n//# sourceMappingURL=index.js.map","import { InvalidParametersError } from '@libp2p/interface';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport randomBytes from '../../random-bytes.js';\nimport webcrypto from '../../webcrypto/index.js';\nimport * as utils from './utils.js';\nexport { utils };\nexport async function generateRSAKey(bits) {\n    const pair = await webcrypto.get().subtle.generateKey({\n        name: 'RSASSA-PKCS1-v1_5',\n        modulusLength: bits,\n        publicExponent: new Uint8Array([0x01, 0x00, 0x01]),\n        hash: { name: 'SHA-256' }\n    }, true, ['sign', 'verify']);\n    const keys = await exportKey(pair);\n    return {\n        privateKey: keys[0],\n        publicKey: keys[1]\n    };\n}\nexport { randomBytes as getRandomValues };\nexport async function hashAndSign(key, msg) {\n    const privateKey = await webcrypto.get().subtle.importKey('jwk', key, {\n        name: 'RSASSA-PKCS1-v1_5',\n        hash: { name: 'SHA-256' }\n    }, false, ['sign']);\n    const sig = await webcrypto.get().subtle.sign({ name: 'RSASSA-PKCS1-v1_5' }, privateKey, msg instanceof Uint8Array ? msg : msg.subarray());\n    return new Uint8Array(sig, 0, sig.byteLength);\n}\nexport async function hashAndVerify(key, sig, msg) {\n    const publicKey = await webcrypto.get().subtle.importKey('jwk', key, {\n        name: 'RSASSA-PKCS1-v1_5',\n        hash: { name: 'SHA-256' }\n    }, false, ['verify']);\n    return webcrypto.get().subtle.verify({ name: 'RSASSA-PKCS1-v1_5' }, publicKey, sig, msg instanceof Uint8Array ? msg : msg.subarray());\n}\nasync function exportKey(pair) {\n    if (pair.privateKey == null || pair.publicKey == null) {\n        throw new InvalidParametersError('Private and public key are required');\n    }\n    return Promise.all([\n        webcrypto.get().subtle.exportKey('jwk', pair.privateKey),\n        webcrypto.get().subtle.exportKey('jwk', pair.publicKey)\n    ]);\n}\nexport function rsaKeySize(jwk) {\n    if (jwk.kty !== 'RSA') {\n        throw new InvalidParametersError('invalid key type');\n    }\n    else if (jwk.n == null) {\n        throw new InvalidParametersError('invalid key modulus');\n    }\n    const bytes = uint8ArrayFromString(jwk.n, 'base64url');\n    return bytes.length * 8;\n}\n//# sourceMappingURL=index.browser.js.map","import { base58btc } from 'multiformats/bases/base58';\nimport { CID } from 'multiformats/cid';\nimport {} from 'multiformats/hashes/digest';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { hashAndSign, utils, hashAndVerify } from './index.js';\nexport class RSAPublicKey {\n    type = 'RSA';\n    _key;\n    _raw;\n    _multihash;\n    constructor(key, digest) {\n        this._key = key;\n        this._multihash = digest;\n    }\n    get raw() {\n        if (this._raw == null) {\n            this._raw = utils.jwkToPkix(this._key);\n        }\n        return this._raw;\n    }\n    toMultihash() {\n        return this._multihash;\n    }\n    toCID() {\n        return CID.createV1(114, this._multihash);\n    }\n    toString() {\n        return base58btc.encode(this.toMultihash().bytes).substring(1);\n    }\n    equals(key) {\n        if (key == null || !(key.raw instanceof Uint8Array)) {\n            return false;\n        }\n        return uint8ArrayEquals(this.raw, key.raw);\n    }\n    verify(data, sig) {\n        return hashAndVerify(this._key, sig, data);\n    }\n}\nexport class RSAPrivateKey {\n    type = 'RSA';\n    _key;\n    _raw;\n    publicKey;\n    constructor(key, publicKey) {\n        this._key = key;\n        this.publicKey = publicKey;\n    }\n    get raw() {\n        if (this._raw == null) {\n            this._raw = utils.jwkToPkcs1(this._key);\n        }\n        return this._raw;\n    }\n    equals(key) {\n        if (key == null || !(key.raw instanceof Uint8Array)) {\n            return false;\n        }\n        return uint8ArrayEquals(this.raw, key.raw);\n    }\n    sign(message) {\n        return hashAndSign(this._key, message);\n    }\n}\n//# sourceMappingURL=rsa.js.map","import { InvalidParametersError, InvalidPublicKeyError } from '@libp2p/interface';\nimport { sha256 } from '@noble/hashes/sha256';\nimport * as asn1js from 'asn1js';\nimport { create } from 'multiformats/hashes/digest';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport * as pb from '../keys.js';\nimport { RSAPrivateKey as RSAPrivateKeyClass, RSAPublicKey as RSAPublicKeyClass } from './rsa.js';\nimport { generateRSAKey, rsaKeySize } from './index.js';\nexport const MAX_RSA_KEY_SIZE = 8192;\nconst SHA2_256_CODE = 0x12;\n/**\n * Convert a PKCS#1 in ASN1 DER format to a JWK key\n */\nexport function pkcs1ToJwk(bytes) {\n    const { result } = asn1js.fromBER(bytes);\n    // @ts-expect-error this looks fragile but DER is a canonical format so we are\n    // safe to have deeply property chains like this\n    const values = result.valueBlock.value;\n    const key = {\n        n: asn1jsIntegerToBase64(values[1]),\n        e: asn1jsIntegerToBase64(values[2]),\n        d: asn1jsIntegerToBase64(values[3]),\n        p: asn1jsIntegerToBase64(values[4]),\n        q: asn1jsIntegerToBase64(values[5]),\n        dp: asn1jsIntegerToBase64(values[6]),\n        dq: asn1jsIntegerToBase64(values[7]),\n        qi: asn1jsIntegerToBase64(values[8]),\n        kty: 'RSA',\n        alg: 'RS256'\n    };\n    return key;\n}\n/**\n * Convert a JWK key into PKCS#1 in ASN1 DER format\n */\nexport function jwkToPkcs1(jwk) {\n    if (jwk.n == null || jwk.e == null || jwk.d == null || jwk.p == null || jwk.q == null || jwk.dp == null || jwk.dq == null || jwk.qi == null) {\n        throw new InvalidParametersError('JWK was missing components');\n    }\n    const root = new asn1js.Sequence({\n        value: [\n            new asn1js.Integer({ value: 0 }),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.n, 'base64url'))),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.e, 'base64url'))),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.d, 'base64url'))),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.p, 'base64url'))),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.q, 'base64url'))),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.dp, 'base64url'))),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.dq, 'base64url'))),\n            asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.qi, 'base64url')))\n        ]\n    });\n    const der = root.toBER();\n    return new Uint8Array(der, 0, der.byteLength);\n}\n/**\n * Convert a PKIX in ASN1 DER format to a JWK key\n */\nexport function pkixToJwk(bytes) {\n    const { result } = asn1js.fromBER(bytes);\n    // @ts-expect-error this looks fragile but DER is a canonical format so we are\n    // safe to have deeply property chains like this\n    const values = result.valueBlock.value[1].valueBlock.value[0].valueBlock.value;\n    return {\n        kty: 'RSA',\n        n: asn1jsIntegerToBase64(values[0]),\n        e: asn1jsIntegerToBase64(values[1])\n    };\n}\n/**\n * Convert a JWK key to PKIX in ASN1 DER format\n */\nexport function jwkToPkix(jwk) {\n    if (jwk.n == null || jwk.e == null) {\n        throw new InvalidParametersError('JWK was missing components');\n    }\n    const root = new asn1js.Sequence({\n        value: [\n            new asn1js.Sequence({\n                value: [\n                    // rsaEncryption\n                    new asn1js.ObjectIdentifier({\n                        value: '1.2.840.113549.1.1.1'\n                    }),\n                    new asn1js.Null()\n                ]\n            }),\n            // this appears to be a bug in asn1js.js - this should really be a Sequence\n            // and not a BitString but it generates the same bytes as node-forge so \n            new asn1js.BitString({\n                valueHex: new asn1js.Sequence({\n                    value: [\n                        asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.n, 'base64url'))),\n                        asn1js.Integer.fromBigInt(bufToBn(uint8ArrayFromString(jwk.e, 'base64url')))\n                    ]\n                }).toBER()\n            })\n        ]\n    });\n    const der = root.toBER();\n    return new Uint8Array(der, 0, der.byteLength);\n}\nfunction asn1jsIntegerToBase64(int) {\n    let buf = int.valueBlock.valueHexView;\n    // chrome rejects values with leading 0s\n    while (buf[0] === 0) {\n        buf = buf.subarray(1);\n    }\n    return uint8ArrayToString(buf, 'base64url');\n}\nfunction bufToBn(u8) {\n    const hex = [];\n    u8.forEach(function (i) {\n        let h = i.toString(16);\n        if (h.length % 2 > 0) {\n            h = `0${h}`;\n        }\n        hex.push(h);\n    });\n    return BigInt('0x' + hex.join(''));\n}\n/**\n * Turn PCKS#1 DER bytes to a PrivateKey\n */\nexport function pkcs1ToRSAPrivateKey(bytes) {\n    const jwk = pkcs1ToJwk(bytes);\n    return jwkToRSAPrivateKey(jwk);\n}\n/**\n * Turn PKIX bytes to a PublicKey\n */\nexport function pkixToRSAPublicKey(bytes) {\n    const jwk = pkixToJwk(bytes);\n    if (rsaKeySize(jwk) > MAX_RSA_KEY_SIZE) {\n        throw new InvalidPublicKeyError('Key size is too large');\n    }\n    const hash = sha256(pb.PublicKey.encode({\n        Type: pb.KeyType.RSA,\n        Data: bytes\n    }));\n    const digest = create(SHA2_256_CODE, hash);\n    return new RSAPublicKeyClass(jwk, digest);\n}\nexport function jwkToRSAPrivateKey(jwk) {\n    if (rsaKeySize(jwk) > MAX_RSA_KEY_SIZE) {\n        throw new InvalidParametersError('Key size is too large');\n    }\n    const keys = jwkToJWKKeyPair(jwk);\n    const hash = sha256(pb.PublicKey.encode({\n        Type: pb.KeyType.RSA,\n        Data: jwkToPkix(keys.publicKey)\n    }));\n    const digest = create(SHA2_256_CODE, hash);\n    return new RSAPrivateKeyClass(keys.privateKey, new RSAPublicKeyClass(keys.publicKey, digest));\n}\nexport async function generateRSAKeyPair(bits) {\n    if (bits > MAX_RSA_KEY_SIZE) {\n        throw new InvalidParametersError('Key size is too large');\n    }\n    const keys = await generateRSAKey(bits);\n    const hash = sha256(pb.PublicKey.encode({\n        Type: pb.KeyType.RSA,\n        Data: jwkToPkix(keys.publicKey)\n    }));\n    const digest = create(SHA2_256_CODE, hash);\n    return new RSAPrivateKeyClass(keys.privateKey, new RSAPublicKeyClass(keys.publicKey, digest));\n}\n/**\n * Takes a jwk key and returns a JWK KeyPair\n */\nexport function jwkToJWKKeyPair(key) {\n    if (key == null) {\n        throw new InvalidParametersError('Missing key parameter');\n    }\n    return {\n        privateKey: key,\n        publicKey: {\n            kty: key.kty,\n            n: key.n,\n            e: key.e\n        }\n    };\n}\n//# sourceMappingURL=utils.js.map","import { hash as assertHash, bytes as assertBytes, exists as assertExists } from './_assert.js';\nimport { Hash, toBytes } from './utils.js';\n// HMAC (RFC 2104)\nexport class HMAC extends Hash {\n    constructor(hash, _key) {\n        super();\n        this.finished = false;\n        this.destroyed = false;\n        assertHash(hash);\n        const key = toBytes(_key);\n        this.iHash = hash.create();\n        if (typeof this.iHash.update !== 'function')\n            throw new Error('Expected instance of class which extends utils.Hash');\n        this.blockLen = this.iHash.blockLen;\n        this.outputLen = this.iHash.outputLen;\n        const blockLen = this.blockLen;\n        const pad = new Uint8Array(blockLen);\n        // blockLen can be bigger than outputLen\n        pad.set(key.length > blockLen ? hash.create().update(key).digest() : key);\n        for (let i = 0; i < pad.length; i++)\n            pad[i] ^= 0x36;\n        this.iHash.update(pad);\n        // By doing update (processing of first block) of outer hash here we can re-use it between multiple calls via clone\n        this.oHash = hash.create();\n        // Undo internal XOR && apply outer XOR\n        for (let i = 0; i < pad.length; i++)\n            pad[i] ^= 0x36 ^ 0x5c;\n        this.oHash.update(pad);\n        pad.fill(0);\n    }\n    update(buf) {\n        assertExists(this);\n        this.iHash.update(buf);\n        return this;\n    }\n    digestInto(out) {\n        assertExists(this);\n        assertBytes(out, this.outputLen);\n        this.finished = true;\n        this.iHash.digestInto(out);\n        this.oHash.update(out);\n        this.oHash.digestInto(out);\n        this.destroy();\n    }\n    digest() {\n        const out = new Uint8Array(this.oHash.outputLen);\n        this.digestInto(out);\n        return out;\n    }\n    _cloneInto(to) {\n        // Create new instance without calling constructor since key already in state and we don't know it.\n        to || (to = Object.create(Object.getPrototypeOf(this), {}));\n        const { oHash, iHash, finished, destroyed, blockLen, outputLen } = this;\n        to = to;\n        to.finished = finished;\n        to.destroyed = destroyed;\n        to.blockLen = blockLen;\n        to.outputLen = outputLen;\n        to.oHash = oHash._cloneInto(to.oHash);\n        to.iHash = iHash._cloneInto(to.iHash);\n        return to;\n    }\n    destroy() {\n        this.destroyed = true;\n        this.oHash.destroy();\n        this.iHash.destroy();\n    }\n}\n/**\n * HMAC: RFC2104 message authentication code.\n * @param hash - function that would be used e.g. sha256\n * @param key - message key\n * @param message - message data\n * @example\n * import { hmac } from '@noble/hashes/hmac';\n * import { sha256 } from '@noble/hashes/sha2';\n * const mac1 = hmac(sha256, 'key', 'message');\n */\nexport const hmac = (hash, key, message) => new HMAC(hash, key).update(message).digest();\nhmac.create = (hash, key) => new HMAC(hash, key);\n//# sourceMappingURL=hmac.js.map","/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\n// Short Weierstrass curve. The formula is: y = x + ax + b\nimport { validateBasic, wNAF, pippenger, } from './curve.js';\nimport * as mod from './modular.js';\nimport * as ut from './utils.js';\nimport { ensureBytes, memoized, abool } from './utils.js';\nfunction validateSigVerOpts(opts) {\n    if (opts.lowS !== undefined)\n        abool('lowS', opts.lowS);\n    if (opts.prehash !== undefined)\n        abool('prehash', opts.prehash);\n}\nfunction validatePointOpts(curve) {\n    const opts = validateBasic(curve);\n    ut.validateObject(opts, {\n        a: 'field',\n        b: 'field',\n    }, {\n        allowedPrivateKeyLengths: 'array',\n        wrapPrivateKey: 'boolean',\n        isTorsionFree: 'function',\n        clearCofactor: 'function',\n        allowInfinityPoint: 'boolean',\n        fromBytes: 'function',\n        toBytes: 'function',\n    });\n    const { endo, Fp, a } = opts;\n    if (endo) {\n        if (!Fp.eql(a, Fp.ZERO)) {\n            throw new Error('Endomorphism can only be defined for Koblitz curves that have a=0');\n        }\n        if (typeof endo !== 'object' ||\n            typeof endo.beta !== 'bigint' ||\n            typeof endo.splitScalar !== 'function') {\n            throw new Error('Expected endomorphism with beta: bigint and splitScalar: function');\n        }\n    }\n    return Object.freeze({ ...opts });\n}\nconst { bytesToNumberBE: b2n, hexToBytes: h2b } = ut;\n/**\n * ASN.1 DER encoding utilities. ASN is very complex & fragile. Format:\n *\n *     [0x30 (SEQUENCE), bytelength, 0x02 (INTEGER), intLength, R, 0x02 (INTEGER), intLength, S]\n *\n * Docs: https://letsencrypt.org/docs/a-warm-welcome-to-asn1-and-der/, https://luca.ntop.org/Teaching/Appunti/asn1.html\n */\nexport const DER = {\n    // asn.1 DER encoding utils\n    Err: class DERErr extends Error {\n        constructor(m = '') {\n            super(m);\n        }\n    },\n    // Basic building block is TLV (Tag-Length-Value)\n    _tlv: {\n        encode: (tag, data) => {\n            const { Err: E } = DER;\n            if (tag < 0 || tag > 256)\n                throw new E('tlv.encode: wrong tag');\n            if (data.length & 1)\n                throw new E('tlv.encode: unpadded data');\n            const dataLen = data.length / 2;\n            const len = ut.numberToHexUnpadded(dataLen);\n            if ((len.length / 2) & 128)\n                throw new E('tlv.encode: long form length too big');\n            // length of length with long form flag\n            const lenLen = dataLen > 127 ? ut.numberToHexUnpadded((len.length / 2) | 128) : '';\n            return `${ut.numberToHexUnpadded(tag)}${lenLen}${len}${data}`;\n        },\n        // v - value, l - left bytes (unparsed)\n        decode(tag, data) {\n            const { Err: E } = DER;\n            let pos = 0;\n            if (tag < 0 || tag > 256)\n                throw new E('tlv.encode: wrong tag');\n            if (data.length < 2 || data[pos++] !== tag)\n                throw new E('tlv.decode: wrong tlv');\n            const first = data[pos++];\n            const isLong = !!(first & 128); // First bit of first length byte is flag for short/long form\n            let length = 0;\n            if (!isLong)\n                length = first;\n            else {\n                // Long form: [longFlag(1bit), lengthLength(7bit), length (BE)]\n                const lenLen = first & 127;\n                if (!lenLen)\n                    throw new E('tlv.decode(long): indefinite length not supported');\n                if (lenLen > 4)\n                    throw new E('tlv.decode(long): byte length is too big'); // this will overflow u32 in js\n                const lengthBytes = data.subarray(pos, pos + lenLen);\n                if (lengthBytes.length !== lenLen)\n                    throw new E('tlv.decode: length bytes not complete');\n                if (lengthBytes[0] === 0)\n                    throw new E('tlv.decode(long): zero leftmost byte');\n                for (const b of lengthBytes)\n                    length = (length << 8) | b;\n                pos += lenLen;\n                if (length < 128)\n                    throw new E('tlv.decode(long): not minimal encoding');\n            }\n            const v = data.subarray(pos, pos + length);\n            if (v.length !== length)\n                throw new E('tlv.decode: wrong value length');\n            return { v, l: data.subarray(pos + length) };\n        },\n    },\n    // https://crypto.stackexchange.com/a/57734 Leftmost bit of first byte is 'negative' flag,\n    // since we always use positive integers here. It must always be empty:\n    // - add zero byte if exists\n    // - if next byte doesn't have a flag, leading zero is not allowed (minimal encoding)\n    _int: {\n        encode(num) {\n            const { Err: E } = DER;\n            if (num < _0n)\n                throw new E('integer: negative integers are not allowed');\n            let hex = ut.numberToHexUnpadded(num);\n            // Pad with zero byte if negative flag is present\n            if (Number.parseInt(hex[0], 16) & 0b1000)\n                hex = '00' + hex;\n            if (hex.length & 1)\n                throw new E('unexpected assertion');\n            return hex;\n        },\n        decode(data) {\n            const { Err: E } = DER;\n            if (data[0] & 128)\n                throw new E('Invalid signature integer: negative');\n            if (data[0] === 0x00 && !(data[1] & 128))\n                throw new E('Invalid signature integer: unnecessary leading zero');\n            return b2n(data);\n        },\n    },\n    toSig(hex) {\n        // parse DER signature\n        const { Err: E, _int: int, _tlv: tlv } = DER;\n        const data = typeof hex === 'string' ? h2b(hex) : hex;\n        ut.abytes(data);\n        const { v: seqBytes, l: seqLeftBytes } = tlv.decode(0x30, data);\n        if (seqLeftBytes.length)\n            throw new E('Invalid signature: left bytes after parsing');\n        const { v: rBytes, l: rLeftBytes } = tlv.decode(0x02, seqBytes);\n        const { v: sBytes, l: sLeftBytes } = tlv.decode(0x02, rLeftBytes);\n        if (sLeftBytes.length)\n            throw new E('Invalid signature: left bytes after parsing');\n        return { r: int.decode(rBytes), s: int.decode(sBytes) };\n    },\n    hexFromSig(sig) {\n        const { _tlv: tlv, _int: int } = DER;\n        const seq = `${tlv.encode(0x02, int.encode(sig.r))}${tlv.encode(0x02, int.encode(sig.s))}`;\n        return tlv.encode(0x30, seq);\n    },\n};\n// Be friendly to bad ECMAScript parsers by not using bigint literals\n// prettier-ignore\nconst _0n = BigInt(0), _1n = BigInt(1), _2n = BigInt(2), _3n = BigInt(3), _4n = BigInt(4);\nexport function weierstrassPoints(opts) {\n    const CURVE = validatePointOpts(opts);\n    const { Fp } = CURVE; // All curves has same field / group length as for now, but they can differ\n    const Fn = mod.Field(CURVE.n, CURVE.nBitLength);\n    const toBytes = CURVE.toBytes ||\n        ((_c, point, _isCompressed) => {\n            const a = point.toAffine();\n            return ut.concatBytes(Uint8Array.from([0x04]), Fp.toBytes(a.x), Fp.toBytes(a.y));\n        });\n    const fromBytes = CURVE.fromBytes ||\n        ((bytes) => {\n            // const head = bytes[0];\n            const tail = bytes.subarray(1);\n            // if (head !== 0x04) throw new Error('Only non-compressed encoding is supported');\n            const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));\n            const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));\n            return { x, y };\n        });\n    /**\n     * y = x + ax + b: Short weierstrass curve formula\n     * @returns y\n     */\n    function weierstrassEquation(x) {\n        const { a, b } = CURVE;\n        const x2 = Fp.sqr(x); // x * x\n        const x3 = Fp.mul(x2, x); // x2 * x\n        return Fp.add(Fp.add(x3, Fp.mul(x, a)), b); // x3 + a * x + b\n    }\n    // Validate whether the passed curve params are valid.\n    // We check if curve equation works for generator point.\n    // `assertValidity()` won't work: `isTorsionFree()` is not available at this point in bls12-381.\n    // ProjectivePoint class has not been initialized yet.\n    if (!Fp.eql(Fp.sqr(CURVE.Gy), weierstrassEquation(CURVE.Gx)))\n        throw new Error('bad generator point: equation left != right');\n    // Valid group elements reside in range 1..n-1\n    function isWithinCurveOrder(num) {\n        return ut.inRange(num, _1n, CURVE.n);\n    }\n    // Validates if priv key is valid and converts it to bigint.\n    // Supports options allowedPrivateKeyLengths and wrapPrivateKey.\n    function normPrivateKeyToScalar(key) {\n        const { allowedPrivateKeyLengths: lengths, nByteLength, wrapPrivateKey, n: N } = CURVE;\n        if (lengths && typeof key !== 'bigint') {\n            if (ut.isBytes(key))\n                key = ut.bytesToHex(key);\n            // Normalize to hex string, pad. E.g. P521 would norm 130-132 char hex to 132-char bytes\n            if (typeof key !== 'string' || !lengths.includes(key.length))\n                throw new Error('Invalid key');\n            key = key.padStart(nByteLength * 2, '0');\n        }\n        let num;\n        try {\n            num =\n                typeof key === 'bigint'\n                    ? key\n                    : ut.bytesToNumberBE(ensureBytes('private key', key, nByteLength));\n        }\n        catch (error) {\n            throw new Error(`private key must be ${nByteLength} bytes, hex or bigint, not ${typeof key}`);\n        }\n        if (wrapPrivateKey)\n            num = mod.mod(num, N); // disabled by default, enabled for BLS\n        ut.aInRange('private key', num, _1n, N); // num in range [1..N-1]\n        return num;\n    }\n    function assertPrjPoint(other) {\n        if (!(other instanceof Point))\n            throw new Error('ProjectivePoint expected');\n    }\n    // Memoized toAffine / validity check. They are heavy. Points are immutable.\n    // Converts Projective point to affine (x, y) coordinates.\n    // Can accept precomputed Z^-1 - for example, from invertBatch.\n    // (x, y, z)  (x=x/z, y=y/z)\n    const toAffineMemo = memoized((p, iz) => {\n        const { px: x, py: y, pz: z } = p;\n        // Fast-path for normalized points\n        if (Fp.eql(z, Fp.ONE))\n            return { x, y };\n        const is0 = p.is0();\n        // If invZ was 0, we return zero point. However we still want to execute\n        // all operations, so we replace invZ with a random number, 1.\n        if (iz == null)\n            iz = is0 ? Fp.ONE : Fp.inv(z);\n        const ax = Fp.mul(x, iz);\n        const ay = Fp.mul(y, iz);\n        const zz = Fp.mul(z, iz);\n        if (is0)\n            return { x: Fp.ZERO, y: Fp.ZERO };\n        if (!Fp.eql(zz, Fp.ONE))\n            throw new Error('invZ was invalid');\n        return { x: ax, y: ay };\n    });\n    // NOTE: on exception this will crash 'cached' and no value will be set.\n    // Otherwise true will be return\n    const assertValidMemo = memoized((p) => {\n        if (p.is0()) {\n            // (0, 1, 0) aka ZERO is invalid in most contexts.\n            // In BLS, ZERO can be serialized, so we allow it.\n            // (0, 0, 0) is wrong representation of ZERO and is always invalid.\n            if (CURVE.allowInfinityPoint && !Fp.is0(p.py))\n                return;\n            throw new Error('bad point: ZERO');\n        }\n        // Some 3rd-party test vectors require different wording between here & `fromCompressedHex`\n        const { x, y } = p.toAffine();\n        // Check if x, y are valid field elements\n        if (!Fp.isValid(x) || !Fp.isValid(y))\n            throw new Error('bad point: x or y not FE');\n        const left = Fp.sqr(y); // y\n        const right = weierstrassEquation(x); // x + ax + b\n        if (!Fp.eql(left, right))\n            throw new Error('bad point: equation left != right');\n        if (!p.isTorsionFree())\n            throw new Error('bad point: not in prime-order subgroup');\n        return true;\n    });\n    /**\n     * Projective Point works in 3d / projective (homogeneous) coordinates: (x, y, z)  (x=x/z, y=y/z)\n     * Default Point works in 2d / affine coordinates: (x, y)\n     * We're doing calculations in projective, because its operations don't require costly inversion.\n     */\n    class Point {\n        constructor(px, py, pz) {\n            this.px = px;\n            this.py = py;\n            this.pz = pz;\n            if (px == null || !Fp.isValid(px))\n                throw new Error('x required');\n            if (py == null || !Fp.isValid(py))\n                throw new Error('y required');\n            if (pz == null || !Fp.isValid(pz))\n                throw new Error('z required');\n            Object.freeze(this);\n        }\n        // Does not validate if the point is on-curve.\n        // Use fromHex instead, or call assertValidity() later.\n        static fromAffine(p) {\n            const { x, y } = p || {};\n            if (!p || !Fp.isValid(x) || !Fp.isValid(y))\n                throw new Error('invalid affine point');\n            if (p instanceof Point)\n                throw new Error('projective point not allowed');\n            const is0 = (i) => Fp.eql(i, Fp.ZERO);\n            // fromAffine(x:0, y:0) would produce (x:0, y:0, z:1), but we need (x:0, y:1, z:0)\n            if (is0(x) && is0(y))\n                return Point.ZERO;\n            return new Point(x, y, Fp.ONE);\n        }\n        get x() {\n            return this.toAffine().x;\n        }\n        get y() {\n            return this.toAffine().y;\n        }\n        /**\n         * Takes a bunch of Projective Points but executes only one\n         * inversion on all of them. Inversion is very slow operation,\n         * so this improves performance massively.\n         * Optimization: converts a list of projective points to a list of identical points with Z=1.\n         */\n        static normalizeZ(points) {\n            const toInv = Fp.invertBatch(points.map((p) => p.pz));\n            return points.map((p, i) => p.toAffine(toInv[i])).map(Point.fromAffine);\n        }\n        /**\n         * Converts hash string or Uint8Array to Point.\n         * @param hex short/long ECDSA hex\n         */\n        static fromHex(hex) {\n            const P = Point.fromAffine(fromBytes(ensureBytes('pointHex', hex)));\n            P.assertValidity();\n            return P;\n        }\n        // Multiplies generator point by privateKey.\n        static fromPrivateKey(privateKey) {\n            return Point.BASE.multiply(normPrivateKeyToScalar(privateKey));\n        }\n        // Multiscalar Multiplication\n        static msm(points, scalars) {\n            return pippenger(Point, Fn, points, scalars);\n        }\n        // \"Private method\", don't use it directly\n        _setWindowSize(windowSize) {\n            wnaf.setWindowSize(this, windowSize);\n        }\n        // A point on curve is valid if it conforms to equation.\n        assertValidity() {\n            assertValidMemo(this);\n        }\n        hasEvenY() {\n            const { y } = this.toAffine();\n            if (Fp.isOdd)\n                return !Fp.isOdd(y);\n            throw new Error(\"Field doesn't support isOdd\");\n        }\n        /**\n         * Compare one point to another.\n         */\n        equals(other) {\n            assertPrjPoint(other);\n            const { px: X1, py: Y1, pz: Z1 } = this;\n            const { px: X2, py: Y2, pz: Z2 } = other;\n            const U1 = Fp.eql(Fp.mul(X1, Z2), Fp.mul(X2, Z1));\n            const U2 = Fp.eql(Fp.mul(Y1, Z2), Fp.mul(Y2, Z1));\n            return U1 && U2;\n        }\n        /**\n         * Flips point to one corresponding to (x, -y) in Affine coordinates.\n         */\n        negate() {\n            return new Point(this.px, Fp.neg(this.py), this.pz);\n        }\n        // Renes-Costello-Batina exception-free doubling formula.\n        // There is 30% faster Jacobian formula, but it is not complete.\n        // https://eprint.iacr.org/2015/1060, algorithm 3\n        // Cost: 8M + 3S + 3*a + 2*b3 + 15add.\n        double() {\n            const { a, b } = CURVE;\n            const b3 = Fp.mul(b, _3n);\n            const { px: X1, py: Y1, pz: Z1 } = this;\n            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore\n            let t0 = Fp.mul(X1, X1); // step 1\n            let t1 = Fp.mul(Y1, Y1);\n            let t2 = Fp.mul(Z1, Z1);\n            let t3 = Fp.mul(X1, Y1);\n            t3 = Fp.add(t3, t3); // step 5\n            Z3 = Fp.mul(X1, Z1);\n            Z3 = Fp.add(Z3, Z3);\n            X3 = Fp.mul(a, Z3);\n            Y3 = Fp.mul(b3, t2);\n            Y3 = Fp.add(X3, Y3); // step 10\n            X3 = Fp.sub(t1, Y3);\n            Y3 = Fp.add(t1, Y3);\n            Y3 = Fp.mul(X3, Y3);\n            X3 = Fp.mul(t3, X3);\n            Z3 = Fp.mul(b3, Z3); // step 15\n            t2 = Fp.mul(a, t2);\n            t3 = Fp.sub(t0, t2);\n            t3 = Fp.mul(a, t3);\n            t3 = Fp.add(t3, Z3);\n            Z3 = Fp.add(t0, t0); // step 20\n            t0 = Fp.add(Z3, t0);\n            t0 = Fp.add(t0, t2);\n            t0 = Fp.mul(t0, t3);\n            Y3 = Fp.add(Y3, t0);\n            t2 = Fp.mul(Y1, Z1); // step 25\n            t2 = Fp.add(t2, t2);\n            t0 = Fp.mul(t2, t3);\n            X3 = Fp.sub(X3, t0);\n            Z3 = Fp.mul(t2, t1);\n            Z3 = Fp.add(Z3, Z3); // step 30\n            Z3 = Fp.add(Z3, Z3);\n            return new Point(X3, Y3, Z3);\n        }\n        // Renes-Costello-Batina exception-free addition formula.\n        // There is 30% faster Jacobian formula, but it is not complete.\n        // https://eprint.iacr.org/2015/1060, algorithm 1\n        // Cost: 12M + 0S + 3*a + 3*b3 + 23add.\n        add(other) {\n            assertPrjPoint(other);\n            const { px: X1, py: Y1, pz: Z1 } = this;\n            const { px: X2, py: Y2, pz: Z2 } = other;\n            let X3 = Fp.ZERO, Y3 = Fp.ZERO, Z3 = Fp.ZERO; // prettier-ignore\n            const a = CURVE.a;\n            const b3 = Fp.mul(CURVE.b, _3n);\n            let t0 = Fp.mul(X1, X2); // step 1\n            let t1 = Fp.mul(Y1, Y2);\n            let t2 = Fp.mul(Z1, Z2);\n            let t3 = Fp.add(X1, Y1);\n            let t4 = Fp.add(X2, Y2); // step 5\n            t3 = Fp.mul(t3, t4);\n            t4 = Fp.add(t0, t1);\n            t3 = Fp.sub(t3, t4);\n            t4 = Fp.add(X1, Z1);\n            let t5 = Fp.add(X2, Z2); // step 10\n            t4 = Fp.mul(t4, t5);\n            t5 = Fp.add(t0, t2);\n            t4 = Fp.sub(t4, t5);\n            t5 = Fp.add(Y1, Z1);\n            X3 = Fp.add(Y2, Z2); // step 15\n            t5 = Fp.mul(t5, X3);\n            X3 = Fp.add(t1, t2);\n            t5 = Fp.sub(t5, X3);\n            Z3 = Fp.mul(a, t4);\n            X3 = Fp.mul(b3, t2); // step 20\n            Z3 = Fp.add(X3, Z3);\n            X3 = Fp.sub(t1, Z3);\n            Z3 = Fp.add(t1, Z3);\n            Y3 = Fp.mul(X3, Z3);\n            t1 = Fp.add(t0, t0); // step 25\n            t1 = Fp.add(t1, t0);\n            t2 = Fp.mul(a, t2);\n            t4 = Fp.mul(b3, t4);\n            t1 = Fp.add(t1, t2);\n            t2 = Fp.sub(t0, t2); // step 30\n            t2 = Fp.mul(a, t2);\n            t4 = Fp.add(t4, t2);\n            t0 = Fp.mul(t1, t4);\n            Y3 = Fp.add(Y3, t0);\n            t0 = Fp.mul(t5, t4); // step 35\n            X3 = Fp.mul(t3, X3);\n            X3 = Fp.sub(X3, t0);\n            t0 = Fp.mul(t3, t1);\n            Z3 = Fp.mul(t5, Z3);\n            Z3 = Fp.add(Z3, t0); // step 40\n            return new Point(X3, Y3, Z3);\n        }\n        subtract(other) {\n            return this.add(other.negate());\n        }\n        is0() {\n            return this.equals(Point.ZERO);\n        }\n        wNAF(n) {\n            return wnaf.wNAFCached(this, n, Point.normalizeZ);\n        }\n        /**\n         * Non-constant-time multiplication. Uses double-and-add algorithm.\n         * It's faster, but should only be used when you don't care about\n         * an exposed private key e.g. sig verification, which works over *public* keys.\n         */\n        multiplyUnsafe(sc) {\n            ut.aInRange('scalar', sc, _0n, CURVE.n);\n            const I = Point.ZERO;\n            if (sc === _0n)\n                return I;\n            if (sc === _1n)\n                return this;\n            const { endo } = CURVE;\n            if (!endo)\n                return wnaf.unsafeLadder(this, sc);\n            // Apply endomorphism\n            let { k1neg, k1, k2neg, k2 } = endo.splitScalar(sc);\n            let k1p = I;\n            let k2p = I;\n            let d = this;\n            while (k1 > _0n || k2 > _0n) {\n                if (k1 & _1n)\n                    k1p = k1p.add(d);\n                if (k2 & _1n)\n                    k2p = k2p.add(d);\n                d = d.double();\n                k1 >>= _1n;\n                k2 >>= _1n;\n            }\n            if (k1neg)\n                k1p = k1p.negate();\n            if (k2neg)\n                k2p = k2p.negate();\n            k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);\n            return k1p.add(k2p);\n        }\n        /**\n         * Constant time multiplication.\n         * Uses wNAF method. Windowed method may be 10% faster,\n         * but takes 2x longer to generate and consumes 2x memory.\n         * Uses precomputes when available.\n         * Uses endomorphism for Koblitz curves.\n         * @param scalar by which the point would be multiplied\n         * @returns New point\n         */\n        multiply(scalar) {\n            const { endo, n: N } = CURVE;\n            ut.aInRange('scalar', scalar, _1n, N);\n            let point, fake; // Fake point is used to const-time mult\n            if (endo) {\n                const { k1neg, k1, k2neg, k2 } = endo.splitScalar(scalar);\n                let { p: k1p, f: f1p } = this.wNAF(k1);\n                let { p: k2p, f: f2p } = this.wNAF(k2);\n                k1p = wnaf.constTimeNegate(k1neg, k1p);\n                k2p = wnaf.constTimeNegate(k2neg, k2p);\n                k2p = new Point(Fp.mul(k2p.px, endo.beta), k2p.py, k2p.pz);\n                point = k1p.add(k2p);\n                fake = f1p.add(f2p);\n            }\n            else {\n                const { p, f } = this.wNAF(scalar);\n                point = p;\n                fake = f;\n            }\n            // Normalize `z` for both points, but return only real one\n            return Point.normalizeZ([point, fake])[0];\n        }\n        /**\n         * Efficiently calculate `aP + bQ`. Unsafe, can expose private key, if used incorrectly.\n         * Not using Strauss-Shamir trick: precomputation tables are faster.\n         * The trick could be useful if both P and Q are not G (not in our case).\n         * @returns non-zero affine point\n         */\n        multiplyAndAddUnsafe(Q, a, b) {\n            const G = Point.BASE; // No Strauss-Shamir trick: we have 10% faster G precomputes\n            const mul = (P, a // Select faster multiply() method\n            ) => (a === _0n || a === _1n || !P.equals(G) ? P.multiplyUnsafe(a) : P.multiply(a));\n            const sum = mul(this, a).add(mul(Q, b));\n            return sum.is0() ? undefined : sum;\n        }\n        // Converts Projective point to affine (x, y) coordinates.\n        // Can accept precomputed Z^-1 - for example, from invertBatch.\n        // (x, y, z)  (x=x/z, y=y/z)\n        toAffine(iz) {\n            return toAffineMemo(this, iz);\n        }\n        isTorsionFree() {\n            const { h: cofactor, isTorsionFree } = CURVE;\n            if (cofactor === _1n)\n                return true; // No subgroups, always torsion-free\n            if (isTorsionFree)\n                return isTorsionFree(Point, this);\n            throw new Error('isTorsionFree() has not been declared for the elliptic curve');\n        }\n        clearCofactor() {\n            const { h: cofactor, clearCofactor } = CURVE;\n            if (cofactor === _1n)\n                return this; // Fast-path\n            if (clearCofactor)\n                return clearCofactor(Point, this);\n            return this.multiplyUnsafe(CURVE.h);\n        }\n        toRawBytes(isCompressed = true) {\n            abool('isCompressed', isCompressed);\n            this.assertValidity();\n            return toBytes(Point, this, isCompressed);\n        }\n        toHex(isCompressed = true) {\n            abool('isCompressed', isCompressed);\n            return ut.bytesToHex(this.toRawBytes(isCompressed));\n        }\n    }\n    Point.BASE = new Point(CURVE.Gx, CURVE.Gy, Fp.ONE);\n    Point.ZERO = new Point(Fp.ZERO, Fp.ONE, Fp.ZERO);\n    const _bits = CURVE.nBitLength;\n    const wnaf = wNAF(Point, CURVE.endo ? Math.ceil(_bits / 2) : _bits);\n    // Validate if generator point is on curve\n    return {\n        CURVE,\n        ProjectivePoint: Point,\n        normPrivateKeyToScalar,\n        weierstrassEquation,\n        isWithinCurveOrder,\n    };\n}\nfunction validateOpts(curve) {\n    const opts = validateBasic(curve);\n    ut.validateObject(opts, {\n        hash: 'hash',\n        hmac: 'function',\n        randomBytes: 'function',\n    }, {\n        bits2int: 'function',\n        bits2int_modN: 'function',\n        lowS: 'boolean',\n    });\n    return Object.freeze({ lowS: true, ...opts });\n}\n/**\n * Creates short weierstrass curve and ECDSA signature methods for it.\n * @example\n * import { Field } from '@noble/curves/abstract/modular';\n * // Before that, define BigInt-s: a, b, p, n, Gx, Gy\n * const curve = weierstrass({ a, b, Fp: Field(p), n, Gx, Gy, h: 1n })\n */\nexport function weierstrass(curveDef) {\n    const CURVE = validateOpts(curveDef);\n    const { Fp, n: CURVE_ORDER } = CURVE;\n    const compressedLen = Fp.BYTES + 1; // e.g. 33 for 32\n    const uncompressedLen = 2 * Fp.BYTES + 1; // e.g. 65 for 32\n    function modN(a) {\n        return mod.mod(a, CURVE_ORDER);\n    }\n    function invN(a) {\n        return mod.invert(a, CURVE_ORDER);\n    }\n    const { ProjectivePoint: Point, normPrivateKeyToScalar, weierstrassEquation, isWithinCurveOrder, } = weierstrassPoints({\n        ...CURVE,\n        toBytes(_c, point, isCompressed) {\n            const a = point.toAffine();\n            const x = Fp.toBytes(a.x);\n            const cat = ut.concatBytes;\n            abool('isCompressed', isCompressed);\n            if (isCompressed) {\n                return cat(Uint8Array.from([point.hasEvenY() ? 0x02 : 0x03]), x);\n            }\n            else {\n                return cat(Uint8Array.from([0x04]), x, Fp.toBytes(a.y));\n            }\n        },\n        fromBytes(bytes) {\n            const len = bytes.length;\n            const head = bytes[0];\n            const tail = bytes.subarray(1);\n            // this.assertValidity() is done inside of fromHex\n            if (len === compressedLen && (head === 0x02 || head === 0x03)) {\n                const x = ut.bytesToNumberBE(tail);\n                if (!ut.inRange(x, _1n, Fp.ORDER))\n                    throw new Error('Point is not on curve');\n                const y2 = weierstrassEquation(x); // y = x + ax + b\n                let y;\n                try {\n                    y = Fp.sqrt(y2); // y = y ^ (p+1)/4\n                }\n                catch (sqrtError) {\n                    const suffix = sqrtError instanceof Error ? ': ' + sqrtError.message : '';\n                    throw new Error('Point is not on curve' + suffix);\n                }\n                const isYOdd = (y & _1n) === _1n;\n                // ECDSA\n                const isHeadOdd = (head & 1) === 1;\n                if (isHeadOdd !== isYOdd)\n                    y = Fp.neg(y);\n                return { x, y };\n            }\n            else if (len === uncompressedLen && head === 0x04) {\n                const x = Fp.fromBytes(tail.subarray(0, Fp.BYTES));\n                const y = Fp.fromBytes(tail.subarray(Fp.BYTES, 2 * Fp.BYTES));\n                return { x, y };\n            }\n            else {\n                throw new Error(`Point of length ${len} was invalid. Expected ${compressedLen} compressed bytes or ${uncompressedLen} uncompressed bytes`);\n            }\n        },\n    });\n    const numToNByteStr = (num) => ut.bytesToHex(ut.numberToBytesBE(num, CURVE.nByteLength));\n    function isBiggerThanHalfOrder(number) {\n        const HALF = CURVE_ORDER >> _1n;\n        return number > HALF;\n    }\n    function normalizeS(s) {\n        return isBiggerThanHalfOrder(s) ? modN(-s) : s;\n    }\n    // slice bytes num\n    const slcNum = (b, from, to) => ut.bytesToNumberBE(b.slice(from, to));\n    /**\n     * ECDSA signature with its (r, s) properties. Supports DER & compact representations.\n     */\n    class Signature {\n        constructor(r, s, recovery) {\n            this.r = r;\n            this.s = s;\n            this.recovery = recovery;\n            this.assertValidity();\n        }\n        // pair (bytes of r, bytes of s)\n        static fromCompact(hex) {\n            const l = CURVE.nByteLength;\n            hex = ensureBytes('compactSignature', hex, l * 2);\n            return new Signature(slcNum(hex, 0, l), slcNum(hex, l, 2 * l));\n        }\n        // DER encoded ECDSA signature\n        // https://bitcoin.stackexchange.com/questions/57644/what-are-the-parts-of-a-bitcoin-transaction-input-script\n        static fromDER(hex) {\n            const { r, s } = DER.toSig(ensureBytes('DER', hex));\n            return new Signature(r, s);\n        }\n        assertValidity() {\n            ut.aInRange('r', this.r, _1n, CURVE_ORDER); // r in [1..N]\n            ut.aInRange('s', this.s, _1n, CURVE_ORDER); // s in [1..N]\n        }\n        addRecoveryBit(recovery) {\n            return new Signature(this.r, this.s, recovery);\n        }\n        recoverPublicKey(msgHash) {\n            const { r, s, recovery: rec } = this;\n            const h = bits2int_modN(ensureBytes('msgHash', msgHash)); // Truncate hash\n            if (rec == null || ![0, 1, 2, 3].includes(rec))\n                throw new Error('recovery id invalid');\n            const radj = rec === 2 || rec === 3 ? r + CURVE.n : r;\n            if (radj >= Fp.ORDER)\n                throw new Error('recovery id 2 or 3 invalid');\n            const prefix = (rec & 1) === 0 ? '02' : '03';\n            const R = Point.fromHex(prefix + numToNByteStr(radj));\n            const ir = invN(radj); // r^-1\n            const u1 = modN(-h * ir); // -hr^-1\n            const u2 = modN(s * ir); // sr^-1\n            const Q = Point.BASE.multiplyAndAddUnsafe(R, u1, u2); // (sr^-1)R-(hr^-1)G = -(hr^-1)G + (sr^-1)\n            if (!Q)\n                throw new Error('point at infinify'); // unsafe is fine: no priv data leaked\n            Q.assertValidity();\n            return Q;\n        }\n        // Signatures should be low-s, to prevent malleability.\n        hasHighS() {\n            return isBiggerThanHalfOrder(this.s);\n        }\n        normalizeS() {\n            return this.hasHighS() ? new Signature(this.r, modN(-this.s), this.recovery) : this;\n        }\n        // DER-encoded\n        toDERRawBytes() {\n            return ut.hexToBytes(this.toDERHex());\n        }\n        toDERHex() {\n            return DER.hexFromSig({ r: this.r, s: this.s });\n        }\n        // padded bytes of r, then padded bytes of s\n        toCompactRawBytes() {\n            return ut.hexToBytes(this.toCompactHex());\n        }\n        toCompactHex() {\n            return numToNByteStr(this.r) + numToNByteStr(this.s);\n        }\n    }\n    const utils = {\n        isValidPrivateKey(privateKey) {\n            try {\n                normPrivateKeyToScalar(privateKey);\n                return true;\n            }\n            catch (error) {\n                return false;\n            }\n        },\n        normPrivateKeyToScalar: normPrivateKeyToScalar,\n        /**\n         * Produces cryptographically secure private key from random of size\n         * (groupLen + ceil(groupLen / 2)) with modulo bias being negligible.\n         */\n        randomPrivateKey: () => {\n            const length = mod.getMinHashLength(CURVE.n);\n            return mod.mapHashToField(CURVE.randomBytes(length), CURVE.n);\n        },\n        /**\n         * Creates precompute table for an arbitrary EC point. Makes point \"cached\".\n         * Allows to massively speed-up `point.multiply(scalar)`.\n         * @returns cached point\n         * @example\n         * const fast = utils.precompute(8, ProjectivePoint.fromHex(someonesPubKey));\n         * fast.multiply(privKey); // much faster ECDH now\n         */\n        precompute(windowSize = 8, point = Point.BASE) {\n            point._setWindowSize(windowSize);\n            point.multiply(BigInt(3)); // 3 is arbitrary, just need any number here\n            return point;\n        },\n    };\n    /**\n     * Computes public key for a private key. Checks for validity of the private key.\n     * @param privateKey private key\n     * @param isCompressed whether to return compact (default), or full key\n     * @returns Public key, full when isCompressed=false; short when isCompressed=true\n     */\n    function getPublicKey(privateKey, isCompressed = true) {\n        return Point.fromPrivateKey(privateKey).toRawBytes(isCompressed);\n    }\n    /**\n     * Quick and dirty check for item being public key. Does not validate hex, or being on-curve.\n     */\n    function isProbPub(item) {\n        const arr = ut.isBytes(item);\n        const str = typeof item === 'string';\n        const len = (arr || str) && item.length;\n        if (arr)\n            return len === compressedLen || len === uncompressedLen;\n        if (str)\n            return len === 2 * compressedLen || len === 2 * uncompressedLen;\n        if (item instanceof Point)\n            return true;\n        return false;\n    }\n    /**\n     * ECDH (Elliptic Curve Diffie Hellman).\n     * Computes shared public key from private key and public key.\n     * Checks: 1) private key validity 2) shared key is on-curve.\n     * Does NOT hash the result.\n     * @param privateA private key\n     * @param publicB different public key\n     * @param isCompressed whether to return compact (default), or full key\n     * @returns shared public key\n     */\n    function getSharedSecret(privateA, publicB, isCompressed = true) {\n        if (isProbPub(privateA))\n            throw new Error('first arg must be private key');\n        if (!isProbPub(publicB))\n            throw new Error('second arg must be public key');\n        const b = Point.fromHex(publicB); // check for being on-curve\n        return b.multiply(normPrivateKeyToScalar(privateA)).toRawBytes(isCompressed);\n    }\n    // RFC6979: ensure ECDSA msg is X bytes and < N. RFC suggests optional truncating via bits2octets.\n    // FIPS 186-4 4.6 suggests the leftmost min(nBitLen, outLen) bits, which matches bits2int.\n    // bits2int can produce res>N, we can do mod(res, N) since the bitLen is the same.\n    // int2octets can't be used; pads small msgs with 0: unacceptatble for trunc as per RFC vectors\n    const bits2int = CURVE.bits2int ||\n        function (bytes) {\n            // For curves with nBitLength % 8 !== 0: bits2octets(bits2octets(m)) !== bits2octets(m)\n            // for some cases, since bytes.length * 8 is not actual bitLength.\n            const num = ut.bytesToNumberBE(bytes); // check for == u8 done here\n            const delta = bytes.length * 8 - CURVE.nBitLength; // truncate to nBitLength leftmost bits\n            return delta > 0 ? num >> BigInt(delta) : num;\n        };\n    const bits2int_modN = CURVE.bits2int_modN ||\n        function (bytes) {\n            return modN(bits2int(bytes)); // can't use bytesToNumberBE here\n        };\n    // NOTE: pads output with zero as per spec\n    const ORDER_MASK = ut.bitMask(CURVE.nBitLength);\n    /**\n     * Converts to bytes. Checks if num in `[0..ORDER_MASK-1]` e.g.: `[0..2^256-1]`.\n     */\n    function int2octets(num) {\n        ut.aInRange(`num < 2^${CURVE.nBitLength}`, num, _0n, ORDER_MASK);\n        // works with order, can have different size than numToField!\n        return ut.numberToBytesBE(num, CURVE.nByteLength);\n    }\n    // Steps A, D of RFC6979 3.2\n    // Creates RFC6979 seed; converts msg/privKey to numbers.\n    // Used only in sign, not in verify.\n    // NOTE: we cannot assume here that msgHash has same amount of bytes as curve order, this will be wrong at least for P521.\n    // Also it can be bigger for P224 + SHA256\n    function prepSig(msgHash, privateKey, opts = defaultSigOpts) {\n        if (['recovered', 'canonical'].some((k) => k in opts))\n            throw new Error('sign() legacy options not supported');\n        const { hash, randomBytes } = CURVE;\n        let { lowS, prehash, extraEntropy: ent } = opts; // generates low-s sigs by default\n        if (lowS == null)\n            lowS = true; // RFC6979 3.2: we skip step A, because we already provide hash\n        msgHash = ensureBytes('msgHash', msgHash);\n        validateSigVerOpts(opts);\n        if (prehash)\n            msgHash = ensureBytes('prehashed msgHash', hash(msgHash));\n        // We can't later call bits2octets, since nested bits2int is broken for curves\n        // with nBitLength % 8 !== 0. Because of that, we unwrap it here as int2octets call.\n        // const bits2octets = (bits) => int2octets(bits2int_modN(bits))\n        const h1int = bits2int_modN(msgHash);\n        const d = normPrivateKeyToScalar(privateKey); // validate private key, convert to bigint\n        const seedArgs = [int2octets(d), int2octets(h1int)];\n        // extraEntropy. RFC6979 3.6: additional k' (optional).\n        if (ent != null && ent !== false) {\n            // K = HMAC_K(V || 0x00 || int2octets(x) || bits2octets(h1) || k')\n            const e = ent === true ? randomBytes(Fp.BYTES) : ent; // generate random bytes OR pass as-is\n            seedArgs.push(ensureBytes('extraEntropy', e)); // check for being bytes\n        }\n        const seed = ut.concatBytes(...seedArgs); // Step D of RFC6979 3.2\n        const m = h1int; // NOTE: no need to call bits2int second time here, it is inside truncateHash!\n        // Converts signature params into point w r/s, checks result for validity.\n        function k2sig(kBytes) {\n            // RFC 6979 Section 3.2, step 3: k = bits2int(T)\n            const k = bits2int(kBytes); // Cannot use fields methods, since it is group element\n            if (!isWithinCurveOrder(k))\n                return; // Important: all mod() calls here must be done over N\n            const ik = invN(k); // k^-1 mod n\n            const q = Point.BASE.multiply(k).toAffine(); // q = Gk\n            const r = modN(q.x); // r = q.x mod n\n            if (r === _0n)\n                return;\n            // Can use scalar blinding b^-1(bm + bdr) where b  [1,q1] according to\n            // https://tches.iacr.org/index.php/TCHES/article/view/7337/6509. We've decided against it:\n            // a) dependency on CSPRNG b) 15% slowdown c) doesn't really help since bigints are not CT\n            const s = modN(ik * modN(m + r * d)); // Not using blinding here\n            if (s === _0n)\n                return;\n            let recovery = (q.x === r ? 0 : 2) | Number(q.y & _1n); // recovery bit (2 or 3, when q.x > n)\n            let normS = s;\n            if (lowS && isBiggerThanHalfOrder(s)) {\n                normS = normalizeS(s); // if lowS was passed, ensure s is always\n                recovery ^= 1; // // in the bottom half of N\n            }\n            return new Signature(r, normS, recovery); // use normS, not s\n        }\n        return { seed, k2sig };\n    }\n    const defaultSigOpts = { lowS: CURVE.lowS, prehash: false };\n    const defaultVerOpts = { lowS: CURVE.lowS, prehash: false };\n    /**\n     * Signs message hash with a private key.\n     * ```\n     * sign(m, d, k) where\n     *   (x, y) = G  k\n     *   r = x mod n\n     *   s = (m + dr)/k mod n\n     * ```\n     * @param msgHash NOT message. msg needs to be hashed to `msgHash`, or use `prehash`.\n     * @param privKey private key\n     * @param opts lowS for non-malleable sigs. extraEntropy for mixing randomness into k. prehash will hash first arg.\n     * @returns signature with recovery param\n     */\n    function sign(msgHash, privKey, opts = defaultSigOpts) {\n        const { seed, k2sig } = prepSig(msgHash, privKey, opts); // Steps A, D of RFC6979 3.2.\n        const C = CURVE;\n        const drbg = ut.createHmacDrbg(C.hash.outputLen, C.nByteLength, C.hmac);\n        return drbg(seed, k2sig); // Steps B, C, D, E, F, G\n    }\n    // Enable precomputes. Slows down first publicKey computation by 20ms.\n    Point.BASE._setWindowSize(8);\n    // utils.precompute(8, ProjectivePoint.BASE)\n    /**\n     * Verifies a signature against message hash and public key.\n     * Rejects lowS signatures by default: to override,\n     * specify option `{lowS: false}`. Implements section 4.1.4 from https://www.secg.org/sec1-v2.pdf:\n     *\n     * ```\n     * verify(r, s, h, P) where\n     *   U1 = hs^-1 mod n\n     *   U2 = rs^-1 mod n\n     *   R = U1G - U2P\n     *   mod(R.x, n) == r\n     * ```\n     */\n    function verify(signature, msgHash, publicKey, opts = defaultVerOpts) {\n        const sg = signature;\n        msgHash = ensureBytes('msgHash', msgHash);\n        publicKey = ensureBytes('publicKey', publicKey);\n        if ('strict' in opts)\n            throw new Error('options.strict was renamed to lowS');\n        validateSigVerOpts(opts);\n        const { lowS, prehash } = opts;\n        let _sig = undefined;\n        let P;\n        try {\n            if (typeof sg === 'string' || ut.isBytes(sg)) {\n                // Signature can be represented in 2 ways: compact (2*nByteLength) & DER (variable-length).\n                // Since DER can also be 2*nByteLength bytes, we check for it first.\n                try {\n                    _sig = Signature.fromDER(sg);\n                }\n                catch (derError) {\n                    if (!(derError instanceof DER.Err))\n                        throw derError;\n                    _sig = Signature.fromCompact(sg);\n                }\n            }\n            else if (typeof sg === 'object' && typeof sg.r === 'bigint' && typeof sg.s === 'bigint') {\n                const { r, s } = sg;\n                _sig = new Signature(r, s);\n            }\n            else {\n                throw new Error('PARSE');\n            }\n            P = Point.fromHex(publicKey);\n        }\n        catch (error) {\n            if (error.message === 'PARSE')\n                throw new Error(`signature must be Signature instance, Uint8Array or hex string`);\n            return false;\n        }\n        if (lowS && _sig.hasHighS())\n            return false;\n        if (prehash)\n            msgHash = CURVE.hash(msgHash);\n        const { r, s } = _sig;\n        const h = bits2int_modN(msgHash); // Cannot use fields methods, since it is group element\n        const is = invN(s); // s^-1\n        const u1 = modN(h * is); // u1 = hs^-1 mod n\n        const u2 = modN(r * is); // u2 = rs^-1 mod n\n        const R = Point.BASE.multiplyAndAddUnsafe(P, u1, u2)?.toAffine(); // R = u1G + u2P\n        if (!R)\n            return false;\n        const v = modN(R.x);\n        return v === r;\n    }\n    return {\n        CURVE,\n        getPublicKey,\n        getSharedSecret,\n        sign,\n        verify,\n        ProjectivePoint: Point,\n        Signature,\n        utils,\n    };\n}\n/**\n * Implementation of the Shallue and van de Woestijne method for any weierstrass curve.\n * TODO: check if there is a way to merge this with uvRatio in Edwards; move to modular.\n * b = True and y = sqrt(u / v) if (u / v) is square in F, and\n * b = False and y = sqrt(Z * (u / v)) otherwise.\n * @param Fp\n * @param Z\n * @returns\n */\nexport function SWUFpSqrtRatio(Fp, Z) {\n    // Generic implementation\n    const q = Fp.ORDER;\n    let l = _0n;\n    for (let o = q - _1n; o % _2n === _0n; o /= _2n)\n        l += _1n;\n    const c1 = l; // 1. c1, the largest integer such that 2^c1 divides q - 1.\n    // We need 2n ** c1 and 2n ** (c1-1). We can't use **; but we can use <<.\n    // 2n ** c1 == 2n << (c1-1)\n    const _2n_pow_c1_1 = _2n << (c1 - _1n - _1n);\n    const _2n_pow_c1 = _2n_pow_c1_1 * _2n;\n    const c2 = (q - _1n) / _2n_pow_c1; // 2. c2 = (q - 1) / (2^c1)  # Integer arithmetic\n    const c3 = (c2 - _1n) / _2n; // 3. c3 = (c2 - 1) / 2            # Integer arithmetic\n    const c4 = _2n_pow_c1 - _1n; // 4. c4 = 2^c1 - 1                # Integer arithmetic\n    const c5 = _2n_pow_c1_1; // 5. c5 = 2^(c1 - 1)                  # Integer arithmetic\n    const c6 = Fp.pow(Z, c2); // 6. c6 = Z^c2\n    const c7 = Fp.pow(Z, (c2 + _1n) / _2n); // 7. c7 = Z^((c2 + 1) / 2)\n    let sqrtRatio = (u, v) => {\n        let tv1 = c6; // 1. tv1 = c6\n        let tv2 = Fp.pow(v, c4); // 2. tv2 = v^c4\n        let tv3 = Fp.sqr(tv2); // 3. tv3 = tv2^2\n        tv3 = Fp.mul(tv3, v); // 4. tv3 = tv3 * v\n        let tv5 = Fp.mul(u, tv3); // 5. tv5 = u * tv3\n        tv5 = Fp.pow(tv5, c3); // 6. tv5 = tv5^c3\n        tv5 = Fp.mul(tv5, tv2); // 7. tv5 = tv5 * tv2\n        tv2 = Fp.mul(tv5, v); // 8. tv2 = tv5 * v\n        tv3 = Fp.mul(tv5, u); // 9. tv3 = tv5 * u\n        let tv4 = Fp.mul(tv3, tv2); // 10. tv4 = tv3 * tv2\n        tv5 = Fp.pow(tv4, c5); // 11. tv5 = tv4^c5\n        let isQR = Fp.eql(tv5, Fp.ONE); // 12. isQR = tv5 == 1\n        tv2 = Fp.mul(tv3, c7); // 13. tv2 = tv3 * c7\n        tv5 = Fp.mul(tv4, tv1); // 14. tv5 = tv4 * tv1\n        tv3 = Fp.cmov(tv2, tv3, isQR); // 15. tv3 = CMOV(tv2, tv3, isQR)\n        tv4 = Fp.cmov(tv5, tv4, isQR); // 16. tv4 = CMOV(tv5, tv4, isQR)\n        // 17. for i in (c1, c1 - 1, ..., 2):\n        for (let i = c1; i > _1n; i--) {\n            let tv5 = i - _2n; // 18.    tv5 = i - 2\n            tv5 = _2n << (tv5 - _1n); // 19.    tv5 = 2^tv5\n            let tvv5 = Fp.pow(tv4, tv5); // 20.    tv5 = tv4^tv5\n            const e1 = Fp.eql(tvv5, Fp.ONE); // 21.    e1 = tv5 == 1\n            tv2 = Fp.mul(tv3, tv1); // 22.    tv2 = tv3 * tv1\n            tv1 = Fp.mul(tv1, tv1); // 23.    tv1 = tv1 * tv1\n            tvv5 = Fp.mul(tv4, tv1); // 24.    tv5 = tv4 * tv1\n            tv3 = Fp.cmov(tv2, tv3, e1); // 25.    tv3 = CMOV(tv2, tv3, e1)\n            tv4 = Fp.cmov(tvv5, tv4, e1); // 26.    tv4 = CMOV(tv5, tv4, e1)\n        }\n        return { isValid: isQR, value: tv3 };\n    };\n    if (Fp.ORDER % _4n === _3n) {\n        // sqrt_ratio_3mod4(u, v)\n        const c1 = (Fp.ORDER - _3n) / _4n; // 1. c1 = (q - 3) / 4     # Integer arithmetic\n        const c2 = Fp.sqrt(Fp.neg(Z)); // 2. c2 = sqrt(-Z)\n        sqrtRatio = (u, v) => {\n            let tv1 = Fp.sqr(v); // 1. tv1 = v^2\n            const tv2 = Fp.mul(u, v); // 2. tv2 = u * v\n            tv1 = Fp.mul(tv1, tv2); // 3. tv1 = tv1 * tv2\n            let y1 = Fp.pow(tv1, c1); // 4. y1 = tv1^c1\n            y1 = Fp.mul(y1, tv2); // 5. y1 = y1 * tv2\n            const y2 = Fp.mul(y1, c2); // 6. y2 = y1 * c2\n            const tv3 = Fp.mul(Fp.sqr(y1), v); // 7. tv3 = y1^2; 8. tv3 = tv3 * v\n            const isQR = Fp.eql(tv3, u); // 9. isQR = tv3 == u\n            let y = Fp.cmov(y2, y1, isQR); // 10. y = CMOV(y2, y1, isQR)\n            return { isValid: isQR, value: y }; // 11. return (isQR, y) isQR ? y : y*c2\n        };\n    }\n    // No curves uses that\n    // if (Fp.ORDER % _8n === _5n) // sqrt_ratio_5mod8\n    return sqrtRatio;\n}\n/**\n * Simplified Shallue-van de Woestijne-Ulas Method\n * https://www.rfc-editor.org/rfc/rfc9380#section-6.6.2\n */\nexport function mapToCurveSimpleSWU(Fp, opts) {\n    mod.validateField(Fp);\n    if (!Fp.isValid(opts.A) || !Fp.isValid(opts.B) || !Fp.isValid(opts.Z))\n        throw new Error('mapToCurveSimpleSWU: invalid opts');\n    const sqrtRatio = SWUFpSqrtRatio(Fp, opts.Z);\n    if (!Fp.isOdd)\n        throw new Error('Fp.isOdd is not implemented!');\n    // Input: u, an element of F.\n    // Output: (x, y), a point on E.\n    return (u) => {\n        // prettier-ignore\n        let tv1, tv2, tv3, tv4, tv5, tv6, x, y;\n        tv1 = Fp.sqr(u); // 1.  tv1 = u^2\n        tv1 = Fp.mul(tv1, opts.Z); // 2.  tv1 = Z * tv1\n        tv2 = Fp.sqr(tv1); // 3.  tv2 = tv1^2\n        tv2 = Fp.add(tv2, tv1); // 4.  tv2 = tv2 + tv1\n        tv3 = Fp.add(tv2, Fp.ONE); // 5.  tv3 = tv2 + 1\n        tv3 = Fp.mul(tv3, opts.B); // 6.  tv3 = B * tv3\n        tv4 = Fp.cmov(opts.Z, Fp.neg(tv2), !Fp.eql(tv2, Fp.ZERO)); // 7.  tv4 = CMOV(Z, -tv2, tv2 != 0)\n        tv4 = Fp.mul(tv4, opts.A); // 8.  tv4 = A * tv4\n        tv2 = Fp.sqr(tv3); // 9.  tv2 = tv3^2\n        tv6 = Fp.sqr(tv4); // 10. tv6 = tv4^2\n        tv5 = Fp.mul(tv6, opts.A); // 11. tv5 = A * tv6\n        tv2 = Fp.add(tv2, tv5); // 12. tv2 = tv2 + tv5\n        tv2 = Fp.mul(tv2, tv3); // 13. tv2 = tv2 * tv3\n        tv6 = Fp.mul(tv6, tv4); // 14. tv6 = tv6 * tv4\n        tv5 = Fp.mul(tv6, opts.B); // 15. tv5 = B * tv6\n        tv2 = Fp.add(tv2, tv5); // 16. tv2 = tv2 + tv5\n        x = Fp.mul(tv1, tv3); // 17.   x = tv1 * tv3\n        const { isValid, value } = sqrtRatio(tv2, tv6); // 18. (is_gx1_square, y1) = sqrt_ratio(tv2, tv6)\n        y = Fp.mul(tv1, u); // 19.   y = tv1 * u  -> Z * u^3 * y1\n        y = Fp.mul(y, value); // 20.   y = y * y1\n        x = Fp.cmov(x, tv3, isValid); // 21.   x = CMOV(x, tv3, is_gx1_square)\n        y = Fp.cmov(y, value, isValid); // 22.   y = CMOV(y, y1, is_gx1_square)\n        const e1 = Fp.isOdd(u) === Fp.isOdd(y); // 23.  e1 = sgn0(u) == sgn0(y)\n        y = Fp.cmov(Fp.neg(y), y, e1); // 24.   y = CMOV(-y, y, e1)\n        x = Fp.div(x, tv4); // 25.   x = x / tv4\n        return { x, y };\n    };\n}\n//# sourceMappingURL=weierstrass.js.map","/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\nimport { hmac } from '@noble/hashes/hmac';\nimport { concatBytes, randomBytes } from '@noble/hashes/utils';\nimport { weierstrass } from './abstract/weierstrass.js';\n// connects noble-curves to noble-hashes\nexport function getHash(hash) {\n    return {\n        hash,\n        hmac: (key, ...msgs) => hmac(hash, key, concatBytes(...msgs)),\n        randomBytes,\n    };\n}\nexport function createCurve(curveDef, defHash) {\n    const create = (hash) => weierstrass({ ...curveDef, ...getHash(hash) });\n    return Object.freeze({ ...create(defHash), create });\n}\n//# sourceMappingURL=_shortw_utils.js.map","/*! noble-curves - MIT License (c) 2022 Paul Miller (paulmillr.com) */\nimport { sha256 } from '@noble/hashes/sha256';\nimport { randomBytes } from '@noble/hashes/utils';\nimport { createCurve } from './_shortw_utils.js';\nimport { createHasher, isogenyMap } from './abstract/hash-to-curve.js';\nimport { Field, mod, pow2 } from './abstract/modular.js';\nimport { inRange, aInRange, bytesToNumberBE, concatBytes, ensureBytes, numberToBytesBE, } from './abstract/utils.js';\nimport { mapToCurveSimpleSWU } from './abstract/weierstrass.js';\nconst secp256k1P = BigInt('0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffffc2f');\nconst secp256k1N = BigInt('0xfffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141');\nconst _1n = BigInt(1);\nconst _2n = BigInt(2);\nconst divNearest = (a, b) => (a + b / _2n) / b;\n/**\n * n = n^((p+1)/4) for fields p = 3 mod 4. We unwrap the loop and multiply bit-by-bit.\n * (P+1n/4n).toString(2) would produce bits [223x 1, 0, 22x 1, 4x 0, 11, 00]\n */\nfunction sqrtMod(y) {\n    const P = secp256k1P;\n    // prettier-ignore\n    const _3n = BigInt(3), _6n = BigInt(6), _11n = BigInt(11), _22n = BigInt(22);\n    // prettier-ignore\n    const _23n = BigInt(23), _44n = BigInt(44), _88n = BigInt(88);\n    const b2 = (y * y * y) % P; // x^3, 11\n    const b3 = (b2 * b2 * y) % P; // x^7\n    const b6 = (pow2(b3, _3n, P) * b3) % P;\n    const b9 = (pow2(b6, _3n, P) * b3) % P;\n    const b11 = (pow2(b9, _2n, P) * b2) % P;\n    const b22 = (pow2(b11, _11n, P) * b11) % P;\n    const b44 = (pow2(b22, _22n, P) * b22) % P;\n    const b88 = (pow2(b44, _44n, P) * b44) % P;\n    const b176 = (pow2(b88, _88n, P) * b88) % P;\n    const b220 = (pow2(b176, _44n, P) * b44) % P;\n    const b223 = (pow2(b220, _3n, P) * b3) % P;\n    const t1 = (pow2(b223, _23n, P) * b22) % P;\n    const t2 = (pow2(t1, _6n, P) * b2) % P;\n    const root = pow2(t2, _2n, P);\n    if (!Fp.eql(Fp.sqr(root), y))\n        throw new Error('Cannot find square root');\n    return root;\n}\nconst Fp = Field(secp256k1P, undefined, undefined, { sqrt: sqrtMod });\n/**\n * secp256k1 short weierstrass curve and ECDSA signatures over it.\n */\nexport const secp256k1 = createCurve({\n    a: BigInt(0), // equation params: a, b\n    b: BigInt(7), // Seem to be rigid: bitcointalk.org/index.php?topic=289795.msg3183975#msg3183975\n    Fp, // Field's prime: 2n**256n - 2n**32n - 2n**9n - 2n**8n - 2n**7n - 2n**6n - 2n**4n - 1n\n    n: secp256k1N, // Curve order, total count of valid points in the field\n    // Base point (x, y) aka generator point\n    Gx: BigInt('55066263022277343669578718895168534326250603453777594175500187360389116729240'),\n    Gy: BigInt('32670510020758816978083085130507043184471273380659243275938904335757337482424'),\n    h: BigInt(1), // Cofactor\n    lowS: true, // Allow only low-S signatures by default in sign() and verify()\n    /**\n     * secp256k1 belongs to Koblitz curves: it has efficiently computable endomorphism.\n     * Endomorphism uses 2x less RAM, speeds up precomputation by 2x and ECDH / key recovery by 20%.\n     * For precomputed wNAF it trades off 1/2 init time & 1/3 ram for 20% perf hit.\n     * Explanation: https://gist.github.com/paulmillr/eb670806793e84df628a7c434a873066\n     */\n    endo: {\n        beta: BigInt('0x7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee'),\n        splitScalar: (k) => {\n            const n = secp256k1N;\n            const a1 = BigInt('0x3086d221a7d46bcde86c90e49284eb15');\n            const b1 = -_1n * BigInt('0xe4437ed6010e88286f547fa90abfe4c3');\n            const a2 = BigInt('0x114ca50f7a8e2f3f657c1108d9d44cfd8');\n            const b2 = a1;\n            const POW_2_128 = BigInt('0x100000000000000000000000000000000'); // (2n**128n).toString(16)\n            const c1 = divNearest(b2 * k, n);\n            const c2 = divNearest(-b1 * k, n);\n            let k1 = mod(k - c1 * a1 - c2 * a2, n);\n            let k2 = mod(-c1 * b1 - c2 * b2, n);\n            const k1neg = k1 > POW_2_128;\n            const k2neg = k2 > POW_2_128;\n            if (k1neg)\n                k1 = n - k1;\n            if (k2neg)\n                k2 = n - k2;\n            if (k1 > POW_2_128 || k2 > POW_2_128) {\n                throw new Error('splitScalar: Endomorphism failed, k=' + k);\n            }\n            return { k1neg, k1, k2neg, k2 };\n        },\n    },\n}, sha256);\n// Schnorr signatures are superior to ECDSA from above. Below is Schnorr-specific BIP0340 code.\n// https://github.com/bitcoin/bips/blob/master/bip-0340.mediawiki\nconst _0n = BigInt(0);\n/** An object mapping tags to their tagged hash prefix of [SHA256(tag) | SHA256(tag)] */\nconst TAGGED_HASH_PREFIXES = {};\nfunction taggedHash(tag, ...messages) {\n    let tagP = TAGGED_HASH_PREFIXES[tag];\n    if (tagP === undefined) {\n        const tagH = sha256(Uint8Array.from(tag, (c) => c.charCodeAt(0)));\n        tagP = concatBytes(tagH, tagH);\n        TAGGED_HASH_PREFIXES[tag] = tagP;\n    }\n    return sha256(concatBytes(tagP, ...messages));\n}\n// ECDSA compact points are 33-byte. Schnorr is 32: we strip first byte 0x02 or 0x03\nconst pointToBytes = (point) => point.toRawBytes(true).slice(1);\nconst numTo32b = (n) => numberToBytesBE(n, 32);\nconst modP = (x) => mod(x, secp256k1P);\nconst modN = (x) => mod(x, secp256k1N);\nconst Point = secp256k1.ProjectivePoint;\nconst GmulAdd = (Q, a, b) => Point.BASE.multiplyAndAddUnsafe(Q, a, b);\n// Calculate point, scalar and bytes\nfunction schnorrGetExtPubKey(priv) {\n    let d_ = secp256k1.utils.normPrivateKeyToScalar(priv); // same method executed in fromPrivateKey\n    let p = Point.fromPrivateKey(d_); // P = d'G; 0 < d' < n check is done inside\n    const scalar = p.hasEvenY() ? d_ : modN(-d_);\n    return { scalar: scalar, bytes: pointToBytes(p) };\n}\n/**\n * lift_x from BIP340. Convert 32-byte x coordinate to elliptic curve point.\n * @returns valid point checked for being on-curve\n */\nfunction lift_x(x) {\n    aInRange('x', x, _1n, secp256k1P); // Fail if x  p.\n    const xx = modP(x * x);\n    const c = modP(xx * x + BigInt(7)); // Let c = x + 7 mod p.\n    let y = sqrtMod(c); // Let y = c^(p+1)/4 mod p.\n    if (y % _2n !== _0n)\n        y = modP(-y); // Return the unique point P such that x(P) = x and\n    const p = new Point(x, y, _1n); // y(P) = y if y mod 2 = 0 or y(P) = p-y otherwise.\n    p.assertValidity();\n    return p;\n}\nconst num = bytesToNumberBE;\n/**\n * Create tagged hash, convert it to bigint, reduce modulo-n.\n */\nfunction challenge(...args) {\n    return modN(num(taggedHash('BIP0340/challenge', ...args)));\n}\n/**\n * Schnorr public key is just `x` coordinate of Point as per BIP340.\n */\nfunction schnorrGetPublicKey(privateKey) {\n    return schnorrGetExtPubKey(privateKey).bytes; // d'=int(sk). Fail if d'=0 or d'n. Ret bytes(d'G)\n}\n/**\n * Creates Schnorr signature as per BIP340. Verifies itself before returning anything.\n * auxRand is optional and is not the sole source of k generation: bad CSPRNG won't be dangerous.\n */\nfunction schnorrSign(message, privateKey, auxRand = randomBytes(32)) {\n    const m = ensureBytes('message', message);\n    const { bytes: px, scalar: d } = schnorrGetExtPubKey(privateKey); // checks for isWithinCurveOrder\n    const a = ensureBytes('auxRand', auxRand, 32); // Auxiliary random data a: a 32-byte array\n    const t = numTo32b(d ^ num(taggedHash('BIP0340/aux', a))); // Let t be the byte-wise xor of bytes(d) and hash/aux(a)\n    const rand = taggedHash('BIP0340/nonce', t, px, m); // Let rand = hash/nonce(t || bytes(P) || m)\n    const k_ = modN(num(rand)); // Let k' = int(rand) mod n\n    if (k_ === _0n)\n        throw new Error('sign failed: k is zero'); // Fail if k' = 0.\n    const { bytes: rx, scalar: k } = schnorrGetExtPubKey(k_); // Let R = k'G.\n    const e = challenge(rx, px, m); // Let e = int(hash/challenge(bytes(R) || bytes(P) || m)) mod n.\n    const sig = new Uint8Array(64); // Let sig = bytes(R) || bytes((k + ed) mod n).\n    sig.set(rx, 0);\n    sig.set(numTo32b(modN(k + e * d)), 32);\n    // If Verify(bytes(P), m, sig) (see below) returns failure, abort\n    if (!schnorrVerify(sig, m, px))\n        throw new Error('sign: Invalid signature produced');\n    return sig;\n}\n/**\n * Verifies Schnorr signature.\n * Will swallow errors & return false except for initial type validation of arguments.\n */\nfunction schnorrVerify(signature, message, publicKey) {\n    const sig = ensureBytes('signature', signature, 64);\n    const m = ensureBytes('message', message);\n    const pub = ensureBytes('publicKey', publicKey, 32);\n    try {\n        const P = lift_x(num(pub)); // P = lift_x(int(pk)); fail if that fails\n        const r = num(sig.subarray(0, 32)); // Let r = int(sig[0:32]); fail if r  p.\n        if (!inRange(r, _1n, secp256k1P))\n            return false;\n        const s = num(sig.subarray(32, 64)); // Let s = int(sig[32:64]); fail if s  n.\n        if (!inRange(s, _1n, secp256k1N))\n            return false;\n        const e = challenge(numTo32b(r), pointToBytes(P), m); // int(challenge(bytes(r)||bytes(P)||m))%n\n        const R = GmulAdd(P, s, modN(-e)); // R = sG - eP\n        if (!R || !R.hasEvenY() || R.toAffine().x !== r)\n            return false; // -eP == (n-e)P\n        return true; // Fail if is_infinite(R) / not has_even_y(R) / x(R)  r.\n    }\n    catch (error) {\n        return false;\n    }\n}\n/**\n * Schnorr signatures over secp256k1.\n */\nexport const schnorr = /* @__PURE__ */ (() => ({\n    getPublicKey: schnorrGetPublicKey,\n    sign: schnorrSign,\n    verify: schnorrVerify,\n    utils: {\n        randomPrivateKey: secp256k1.utils.randomPrivateKey,\n        lift_x,\n        pointToBytes,\n        numberToBytesBE,\n        bytesToNumberBE,\n        taggedHash,\n        mod,\n    },\n}))();\nconst isoMap = /* @__PURE__ */ (() => isogenyMap(Fp, [\n    // xNum\n    [\n        '0x8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38daaaaa8c7',\n        '0x7d3d4c80bc321d5b9f315cea7fd44c5d595d2fc0bf63b92dfff1044f17c6581',\n        '0x534c328d23f234e6e2a413deca25caece4506144037c40314ecbd0b53d9dd262',\n        '0x8e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38e38daaaaa88c',\n    ],\n    // xDen\n    [\n        '0xd35771193d94918a9ca34ccbb7b640dd86cd409542f8487d9fe6b745781eb49b',\n        '0xedadc6f64383dc1df7c4b2d51b54225406d36b641f5e41bbc52a56612a8c6d14',\n        '0x0000000000000000000000000000000000000000000000000000000000000001', // LAST 1\n    ],\n    // yNum\n    [\n        '0x4bda12f684bda12f684bda12f684bda12f684bda12f684bda12f684b8e38e23c',\n        '0xc75e0c32d5cb7c0fa9d0a54b12a0a6d5647ab046d686da6fdffc90fc201d71a3',\n        '0x29a6194691f91a73715209ef6512e576722830a201be2018a765e85a9ecee931',\n        '0x2f684bda12f684bda12f684bda12f684bda12f684bda12f684bda12f38e38d84',\n    ],\n    // yDen\n    [\n        '0xfffffffffffffffffffffffffffffffffffffffffffffffffffffffefffff93b',\n        '0x7a06534bb8bdb49fd5e9e6632722c2989467c1bfc8e8d978dfb425d2685c2573',\n        '0x6484aa716545ca2cf3a70c3fa8fe337e0a3d21162f0d6299a7bf8192bfd2a76f',\n        '0x0000000000000000000000000000000000000000000000000000000000000001', // LAST 1\n    ],\n].map((i) => i.map((j) => BigInt(j)))))();\nconst mapSWU = /* @__PURE__ */ (() => mapToCurveSimpleSWU(Fp, {\n    A: BigInt('0x3f8731abdd661adca08a5558f0f5d272e953d363cb6f0e5d405447c01a444533'),\n    B: BigInt('1771'),\n    Z: Fp.create(BigInt('-11')),\n}))();\nconst htf = /* @__PURE__ */ (() => createHasher(secp256k1.ProjectivePoint, (scalars) => {\n    const { x, y } = mapSWU(Fp.create(scalars[0]));\n    return isoMap(x, y);\n}, {\n    DST: 'secp256k1_XMD:SHA-256_SSWU_RO_',\n    encodeDST: 'secp256k1_XMD:SHA-256_SSWU_NU_',\n    p: Fp.ORDER,\n    m: 1,\n    k: 128,\n    expand: 'xmd',\n    hash: sha256,\n}))();\nexport const hashToCurve = /* @__PURE__ */ (() => htf.hashToCurve)();\nexport const encodeToCurve = /* @__PURE__ */ (() => htf.encodeToCurve)();\n//# sourceMappingURL=secp256k1.js.map","import { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nexport function base64urlToBuffer(str, len) {\n    let buf = uint8ArrayFromString(str, 'base64urlpad');\n    if (len != null) {\n        if (buf.length > len)\n            throw new Error('byte array longer than desired length');\n        buf = uint8ArrayConcat([new Uint8Array(len - buf.length), buf]);\n    }\n    return buf;\n}\nexport function isPromise(thing) {\n    if (thing == null) {\n        return false;\n    }\n    return typeof thing.then === 'function' &&\n        typeof thing.catch === 'function' &&\n        typeof thing.finally === 'function';\n}\n//# sourceMappingURL=util.js.map","import { secp256k1 as secp } from '@noble/curves/secp256k1';\nimport { sha256 } from 'multiformats/hashes/sha2';\nimport { SigningError, VerificationError } from '../../errors.js';\nimport { isPromise } from '../../util.js';\n/**\n * Hash and sign message with private key\n */\nexport function hashAndSign(key, msg) {\n    const p = sha256.digest(msg instanceof Uint8Array ? msg : msg.subarray());\n    if (isPromise(p)) {\n        return p.then(({ digest }) => secp.sign(digest, key).toDERRawBytes())\n            .catch(err => {\n            throw new SigningError(String(err));\n        });\n    }\n    try {\n        return secp.sign(p.digest, key).toDERRawBytes();\n    }\n    catch (err) {\n        throw new SigningError(String(err));\n    }\n}\n/**\n * Hash message and verify signature with public key\n */\nexport function hashAndVerify(key, sig, msg) {\n    const p = sha256.digest(msg instanceof Uint8Array ? msg : msg.subarray());\n    if (isPromise(p)) {\n        return p.then(({ digest }) => secp.verify(sig, digest, key))\n            .catch(err => {\n            throw new VerificationError(String(err));\n        });\n    }\n    try {\n        return secp.verify(sig, p.digest, key);\n    }\n    catch (err) {\n        throw new VerificationError(String(err));\n    }\n}\n//# sourceMappingURL=index.browser.js.map","import { base58btc } from 'multiformats/bases/base58';\nimport { CID } from 'multiformats/cid';\nimport { identity } from 'multiformats/hashes/identity';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { publicKeyToProtobuf } from '../index.js';\nimport { validateSecp256k1PublicKey, compressSecp256k1PublicKey, computeSecp256k1PublicKey, validateSecp256k1PrivateKey } from './utils.js';\nimport { hashAndVerify, hashAndSign } from './index.js';\nexport class Secp256k1PublicKey {\n    type = 'secp256k1';\n    raw;\n    _key;\n    constructor(key) {\n        this._key = validateSecp256k1PublicKey(key);\n        this.raw = compressSecp256k1PublicKey(this._key);\n    }\n    toMultihash() {\n        return identity.digest(publicKeyToProtobuf(this));\n    }\n    toCID() {\n        return CID.createV1(114, this.toMultihash());\n    }\n    toString() {\n        return base58btc.encode(this.toMultihash().bytes).substring(1);\n    }\n    equals(key) {\n        if (key == null || !(key.raw instanceof Uint8Array)) {\n            return false;\n        }\n        return uint8ArrayEquals(this.raw, key.raw);\n    }\n    verify(data, sig) {\n        return hashAndVerify(this._key, sig, data);\n    }\n}\nexport class Secp256k1PrivateKey {\n    type = 'secp256k1';\n    raw;\n    publicKey;\n    constructor(key, publicKey) {\n        this.raw = validateSecp256k1PrivateKey(key);\n        this.publicKey = new Secp256k1PublicKey(publicKey ?? computeSecp256k1PublicKey(key));\n    }\n    equals(key) {\n        if (key == null || !(key.raw instanceof Uint8Array)) {\n            return false;\n        }\n        return uint8ArrayEquals(this.raw, key.raw);\n    }\n    sign(message) {\n        return hashAndSign(this.raw, message);\n    }\n}\n//# sourceMappingURL=secp256k1.js.map","import { InvalidPrivateKeyError, InvalidPublicKeyError } from '@libp2p/interface';\nimport { secp256k1 as secp } from '@noble/curves/secp256k1';\nimport { Secp256k1PublicKey as Secp256k1PublicKeyClass, Secp256k1PrivateKey as Secp256k1PrivateKeyClass } from './secp256k1.js';\nconst PRIVATE_KEY_BYTE_LENGTH = 32;\nexport { PRIVATE_KEY_BYTE_LENGTH as privateKeyLength };\nexport function unmarshalSecp256k1PrivateKey(bytes) {\n    return new Secp256k1PrivateKeyClass(bytes);\n}\nexport function unmarshalSecp256k1PublicKey(bytes) {\n    return new Secp256k1PublicKeyClass(bytes);\n}\nexport async function generateSecp256k1KeyPair() {\n    const privateKeyBytes = generateSecp256k1PrivateKey();\n    return new Secp256k1PrivateKeyClass(privateKeyBytes);\n}\nexport function compressSecp256k1PublicKey(key) {\n    const point = secp.ProjectivePoint.fromHex(key).toRawBytes(true);\n    return point;\n}\nexport function decompressSecp256k1PublicKey(key) {\n    const point = secp.ProjectivePoint.fromHex(key).toRawBytes(false);\n    return point;\n}\nexport function validateSecp256k1PrivateKey(key) {\n    try {\n        secp.getPublicKey(key, true);\n        return key;\n    }\n    catch (err) {\n        throw new InvalidPrivateKeyError(String(err));\n    }\n}\nexport function validateSecp256k1PublicKey(key) {\n    try {\n        secp.ProjectivePoint.fromHex(key);\n        return key;\n    }\n    catch (err) {\n        throw new InvalidPublicKeyError(String(err));\n    }\n}\nexport function computeSecp256k1PublicKey(privateKey) {\n    try {\n        return secp.getPublicKey(privateKey, true);\n    }\n    catch (err) {\n        throw new InvalidPrivateKeyError(String(err));\n    }\n}\nexport function generateSecp256k1PrivateKey() {\n    return secp.utils.randomPrivateKey();\n}\n//# sourceMappingURL=utils.js.map","/**\n * @packageDocumentation\n *\n * ## Supported Key Types\n *\n * Currently the `'RSA'`, `'ed25519'`, and `secp256k1` types are supported, although ed25519 and secp256k1 keys support only signing and verification of messages.\n *\n * For encryption / decryption support, RSA keys should be used.\n */\nimport { UnsupportedKeyTypeError } from '@libp2p/interface';\nimport { generateEd25519KeyPair, generateEd25519KeyPairFromSeed, unmarshalEd25519PrivateKey, unmarshalEd25519PublicKey } from './ed25519/utils.js';\nimport * as pb from './keys.js';\nimport { pkcs1ToRSAPrivateKey, pkixToRSAPublicKey, generateRSAKeyPair } from './rsa/utils.js';\nimport { generateSecp256k1KeyPair, unmarshalSecp256k1PrivateKey, unmarshalSecp256k1PublicKey } from './secp256k1/utils.js';\nexport { generateEphemeralKeyPair } from './ecdh/index.js';\nexport { keyStretcher } from './key-stretcher.js';\nexport async function generateKeyPair(type, bits) {\n    if (type === 'Ed25519') {\n        return generateEd25519KeyPair();\n    }\n    if (type === 'secp256k1') {\n        return generateSecp256k1KeyPair();\n    }\n    if (type === 'RSA') {\n        return generateRSAKeyPair(bits ?? 2048);\n    }\n    throw new UnsupportedKeyTypeError();\n}\nexport async function generateKeyPairFromSeed(type, seed) {\n    if (type !== 'Ed25519') {\n        throw new UnsupportedKeyTypeError('Seed key derivation only supported for Ed25519 keys');\n    }\n    return generateEd25519KeyPairFromSeed(seed);\n}\n/**\n * Converts a protobuf serialized public key into its representative object\n */\nexport function publicKeyFromProtobuf(buf) {\n    const { Type, Data } = pb.PublicKey.decode(buf);\n    const data = Data ?? new Uint8Array();\n    switch (Type) {\n        case pb.KeyType.RSA:\n            return pkixToRSAPublicKey(data);\n        case pb.KeyType.Ed25519:\n            return unmarshalEd25519PublicKey(data);\n        case pb.KeyType.secp256k1:\n            return unmarshalSecp256k1PublicKey(data);\n        default:\n            throw new UnsupportedKeyTypeError();\n    }\n}\n/**\n * Creates a public key from the raw key bytes\n */\nexport function publicKeyFromRaw(buf) {\n    if (buf.byteLength === 32) {\n        return unmarshalEd25519PublicKey(buf);\n    }\n    else if (buf.byteLength === 33) {\n        return unmarshalSecp256k1PublicKey(buf);\n    }\n    else {\n        return pkixToRSAPublicKey(buf);\n    }\n}\n/**\n * Creates a public key from an identity multihash which contains a protobuf\n * encoded Ed25519 or secp256k1 public key.\n *\n * RSA keys are not supported as in practice we they are not stored in identity\n * multihashes since the hash would be very large.\n */\nexport function publicKeyFromMultihash(digest) {\n    const { Type, Data } = pb.PublicKey.decode(digest.digest);\n    const data = Data ?? new Uint8Array();\n    switch (Type) {\n        case pb.KeyType.Ed25519:\n            return unmarshalEd25519PublicKey(data);\n        case pb.KeyType.secp256k1:\n            return unmarshalSecp256k1PublicKey(data);\n        default:\n            throw new UnsupportedKeyTypeError();\n    }\n}\n/**\n * Converts a public key object into a protobuf serialized public key\n */\nexport function publicKeyToProtobuf(key) {\n    return pb.PublicKey.encode({\n        Type: pb.KeyType[key.type],\n        Data: key.raw\n    });\n}\n/**\n * Converts a protobuf serialized private key into its representative object\n */\nexport function privateKeyFromProtobuf(buf) {\n    const decoded = pb.PrivateKey.decode(buf);\n    const data = decoded.Data ?? new Uint8Array();\n    switch (decoded.Type) {\n        case pb.KeyType.RSA:\n            return pkcs1ToRSAPrivateKey(data);\n        case pb.KeyType.Ed25519:\n            return unmarshalEd25519PrivateKey(data);\n        case pb.KeyType.secp256k1:\n            return unmarshalSecp256k1PrivateKey(data);\n        default:\n            throw new UnsupportedKeyTypeError();\n    }\n}\n/**\n * Creates a private key from the raw key bytes. For Ed25519 keys this requires\n * the public key to be appended to the private key otherwise we can't\n * differentiate between Ed25519 and secp256k1 keys as they are the same length.\n */\nexport function privateKeyFromRaw(buf) {\n    if (buf.byteLength === 64) {\n        return unmarshalEd25519PrivateKey(buf);\n    }\n    else if (buf.byteLength === 32) {\n        return unmarshalSecp256k1PrivateKey(buf);\n    }\n    else {\n        return pkcs1ToRSAPrivateKey(buf);\n    }\n}\n/**\n * Converts a private key object into a protobuf serialized private key\n */\nexport function privateKeyToProtobuf(key) {\n    return pb.PrivateKey.encode({\n        Type: pb.KeyType[key.type],\n        Data: key.raw\n    });\n}\n//# sourceMappingURL=index.js.map","/**\n * All PeerId implementations must use this symbol as the name of a property\n * with a boolean `true` value\n */\nexport const peerIdSymbol = Symbol.for('@libp2p/peer-id');\n/**\n * Returns true if the passed argument is a PeerId implementation\n */\nexport function isPeerId(other) {\n    return Boolean(other?.[peerIdSymbol]);\n}\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * An implementation of a peer id\n *\n * @example\n *\n * ```TypeScript\n * import { peerIdFromString } from '@libp2p/peer-id'\n * const peer = peerIdFromString('k51qzi5uqu5dkwkqm42v9j9kqcam2jiuvloi16g72i4i4amoo2m8u3ol3mqu6s')\n *\n * console.log(peer.toCID()) // CID(bafzaa...)\n * console.log(peer.toString()) // \"12D3K...\"\n * ```\n */\nimport { peerIdSymbol } from '@libp2p/interface';\nimport { base58btc } from 'multiformats/bases/base58';\nimport { CID } from 'multiformats/cid';\nimport { identity } from 'multiformats/hashes/identity';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nconst inspect = Symbol.for('nodejs.util.inspect.custom');\n// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv\nconst LIBP2P_KEY_CODE = 0x72;\nclass PeerIdImpl {\n    type;\n    multihash;\n    publicKey;\n    string;\n    constructor(init) {\n        this.type = init.type;\n        this.multihash = init.multihash;\n        // mark string cache as non-enumerable\n        Object.defineProperty(this, 'string', {\n            enumerable: false,\n            writable: true\n        });\n    }\n    get [Symbol.toStringTag]() {\n        return `PeerId(${this.toString()})`;\n    }\n    [peerIdSymbol] = true;\n    toString() {\n        if (this.string == null) {\n            this.string = base58btc.encode(this.multihash.bytes).slice(1);\n        }\n        return this.string;\n    }\n    toMultihash() {\n        return this.multihash;\n    }\n    // return self-describing String representation\n    // in default format from RFC 0001: https://github.com/libp2p/specs/pull/209\n    toCID() {\n        return CID.createV1(LIBP2P_KEY_CODE, this.multihash);\n    }\n    toJSON() {\n        return this.toString();\n    }\n    /**\n     * Checks the equality of `this` peer against a given PeerId\n     */\n    equals(id) {\n        if (id == null) {\n            return false;\n        }\n        if (id instanceof Uint8Array) {\n            return uint8ArrayEquals(this.multihash.bytes, id);\n        }\n        else if (typeof id === 'string') {\n            return this.toString() === id;\n        }\n        else if (id?.toMultihash()?.bytes != null) {\n            return uint8ArrayEquals(this.multihash.bytes, id.toMultihash().bytes);\n        }\n        else {\n            throw new Error('not valid Id');\n        }\n    }\n    /**\n     * Returns PeerId as a human-readable string\n     * https://nodejs.org/api/util.html#utilinspectcustom\n     *\n     * @example\n     * ```TypeScript\n     * import { peerIdFromString } from '@libp2p/peer-id'\n     *\n     * console.info(peerIdFromString('QmFoo'))\n     * // 'PeerId(QmFoo)'\n     * ```\n     */\n    [inspect]() {\n        return `PeerId(${this.toString()})`;\n    }\n}\nexport class RSAPeerId extends PeerIdImpl {\n    type = 'RSA';\n    publicKey;\n    constructor(init) {\n        super({ ...init, type: 'RSA' });\n        this.publicKey = init.publicKey;\n    }\n}\nexport class Ed25519PeerId extends PeerIdImpl {\n    type = 'Ed25519';\n    publicKey;\n    constructor(init) {\n        super({ ...init, type: 'Ed25519' });\n        this.publicKey = init.publicKey;\n    }\n}\nexport class Secp256k1PeerId extends PeerIdImpl {\n    type = 'secp256k1';\n    publicKey;\n    constructor(init) {\n        super({ ...init, type: 'secp256k1' });\n        this.publicKey = init.publicKey;\n    }\n}\n// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv\nconst TRANSPORT_IPFS_GATEWAY_HTTP_CODE = 0x0920;\nexport class URLPeerId {\n    type = 'url';\n    multihash;\n    publicKey;\n    url;\n    constructor(url) {\n        this.url = url.toString();\n        this.multihash = identity.digest(uint8ArrayFromString(this.url));\n    }\n    [inspect]() {\n        return `PeerId(${this.url})`;\n    }\n    [peerIdSymbol] = true;\n    toString() {\n        return this.toCID().toString();\n    }\n    toMultihash() {\n        return this.multihash;\n    }\n    toCID() {\n        return CID.createV1(TRANSPORT_IPFS_GATEWAY_HTTP_CODE, this.toMultihash());\n    }\n    toJSON() {\n        return this.toString();\n    }\n    equals(other) {\n        if (other == null) {\n            return false;\n        }\n        if (other instanceof Uint8Array) {\n            other = uint8ArrayToString(other);\n        }\n        return other.toString() === this.toString();\n    }\n}\n//# sourceMappingURL=peer-id.js.map","/**\n * @packageDocumentation\n *\n * An implementation of a peer id\n *\n * @example\n *\n * ```TypeScript\n * import { peerIdFromString } from '@libp2p/peer-id'\n * const peer = peerIdFromString('12D3KooWKnDdG3iXw9eTFijk3EWSunZcFi54Zka4wmtqtt6rPxc8')\n *\n * console.log(peer.toCID()) // CID(bafzaa...)\n * console.log(peer.toString()) // \"12D3K...\"\n * ```\n */\nimport { publicKeyFromMultihash } from '@libp2p/crypto/keys';\nimport { InvalidCIDError, InvalidMultihashError, InvalidParametersError, UnsupportedKeyTypeError } from '@libp2p/interface';\nimport { base58btc } from 'multiformats/bases/base58';\nimport {} from 'multiformats/cid';\nimport * as Digest from 'multiformats/hashes/digest';\nimport { identity } from 'multiformats/hashes/identity';\nimport { sha256 } from 'multiformats/hashes/sha2';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport { RSAPeerId as RSAPeerIdClass, Ed25519PeerId as Ed25519PeerIdClass, Secp256k1PeerId as Secp256k1PeerIdClass, URLPeerId as URLPeerIdClass } from './peer-id.js';\n// these values are from https://github.com/multiformats/multicodec/blob/master/table.csv\nconst LIBP2P_KEY_CODE = 0x72;\nconst TRANSPORT_IPFS_GATEWAY_HTTP_CODE = 0x0920;\nexport function peerIdFromString(str, decoder) {\n    let multihash;\n    if (str.charAt(0) === '1' || str.charAt(0) === 'Q') {\n        // identity hash ed25519/secp256k1 key or sha2-256 hash of\n        // rsa public key - base58btc encoded either way\n        multihash = Digest.decode(base58btc.decode(`z${str}`));\n    }\n    else {\n        if (decoder == null) {\n            throw new InvalidParametersError('Please pass a multibase decoder for strings that do not start with \"1\" or \"Q\"');\n        }\n        multihash = Digest.decode(decoder.decode(str));\n    }\n    return peerIdFromMultihash(multihash);\n}\nexport function peerIdFromPublicKey(publicKey) {\n    if (publicKey.type === 'Ed25519') {\n        return new Ed25519PeerIdClass({\n            multihash: publicKey.toCID().multihash,\n            publicKey\n        });\n    }\n    else if (publicKey.type === 'secp256k1') {\n        return new Secp256k1PeerIdClass({\n            multihash: publicKey.toCID().multihash,\n            publicKey\n        });\n    }\n    else if (publicKey.type === 'RSA') {\n        return new RSAPeerIdClass({\n            multihash: publicKey.toCID().multihash,\n            publicKey\n        });\n    }\n    throw new UnsupportedKeyTypeError();\n}\nexport function peerIdFromPrivateKey(privateKey) {\n    return peerIdFromPublicKey(privateKey.publicKey);\n}\nexport function peerIdFromMultihash(multihash) {\n    if (isSha256Multihash(multihash)) {\n        return new RSAPeerIdClass({ multihash });\n    }\n    else if (isIdentityMultihash(multihash)) {\n        try {\n            const publicKey = publicKeyFromMultihash(multihash);\n            if (publicKey.type === 'Ed25519') {\n                return new Ed25519PeerIdClass({ multihash, publicKey });\n            }\n            else if (publicKey.type === 'secp256k1') {\n                return new Secp256k1PeerIdClass({ multihash, publicKey });\n            }\n        }\n        catch (err) {\n            // was not Ed or secp key, try URL\n            const url = uint8ArrayToString(multihash.digest);\n            return new URLPeerIdClass(new URL(url));\n        }\n    }\n    throw new InvalidMultihashError('Supplied PeerID Multihash is invalid');\n}\nexport function peerIdFromCID(cid) {\n    if (cid?.multihash == null || cid.version == null || (cid.version === 1 && (cid.code !== LIBP2P_KEY_CODE) && cid.code !== TRANSPORT_IPFS_GATEWAY_HTTP_CODE)) {\n        throw new InvalidCIDError('Supplied PeerID CID is invalid');\n    }\n    if (cid.code === TRANSPORT_IPFS_GATEWAY_HTTP_CODE) {\n        const url = uint8ArrayToString(cid.multihash.digest);\n        return new URLPeerIdClass(new URL(url));\n    }\n    return peerIdFromMultihash(cid.multihash);\n}\nfunction isIdentityMultihash(multihash) {\n    return multihash.code === identity.code;\n}\nfunction isSha256Multihash(multihash) {\n    return multihash.code === sha256.code;\n}\n//# sourceMappingURL=index.js.map","/**\n * Takes an array of AbortSignals and returns a single signal.\n * If any signals are aborted, the returned signal will be aborted.\n */\nexport function anySignal(signals) {\n    const controller = new globalThis.AbortController();\n    function onAbort() {\n        controller.abort();\n        for (const signal of signals) {\n            if (signal?.removeEventListener != null) {\n                signal.removeEventListener('abort', onAbort);\n            }\n        }\n    }\n    for (const signal of signals) {\n        if (signal?.aborted === true) {\n            onAbort();\n            break;\n        }\n        if (signal?.addEventListener != null) {\n            signal.addEventListener('abort', onAbort);\n        }\n    }\n    function clear() {\n        for (const signal of signals) {\n            if (signal?.removeEventListener != null) {\n                signal.removeEventListener('abort', onAbort);\n            }\n        }\n    }\n    const signal = controller.signal;\n    signal.clear = clear;\n    return signal;\n}\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Allows treating a browser readable stream as an async iterator.\n *\n * @example\n *\n * ```javascript\n * import toIt from 'browser-readablestream-to-it'\n * import all from 'it-all'\n *\n * const content = [0, 1, 2, 3, 4]\n *\n * const stream = new ReadableStream({\n *   start(controller) {\n *     for (let i = 0; i < content.length; i++) {\n *       controller.enqueue(content[i])\n *     }\n *\n *     controller.close()\n *   }\n * })\n *\n * const arr = await all(toIt(stream))\n *\n * console.info(arr) // 0, 1, 2, 3, 4\n * ```\n *\n * ## preventCancel\n *\n * By default a readable stream will have [.cancel](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/cancel) called on it once it has ended or\n * reading has stopped prematurely.\n *\n * To prevent this behaviour, pass `preventCancel: true` as an option:\n *\n * ```javascript\n * const arr = await all(toIt(stream, { preventCancel: true }))\n *\n * console.info(arr) // 0, 1, 2, 3, 4\n * ```\n */\n/**\n * Turns a browser readable stream into an async iterable. Async iteration over\n * returned iterable will lock give stream, preventing any other consumer from\n * acquiring a reader. The lock will be released if iteration loop is broken. To\n * prevent stream cancelling optional `{ preventCancel: true }` could be passed\n * as a second argument.\n */\nexport default async function* browserReadableStreamToIt(stream, options = {}) {\n    const reader = stream.getReader();\n    try {\n        while (true) {\n            const result = await reader.read();\n            if (result.done) {\n                return;\n            }\n            yield result.value;\n        }\n    }\n    finally {\n        if (options.preventCancel !== true) {\n            await reader.cancel();\n        }\n        reader.releaseLock();\n    }\n}\n//# sourceMappingURL=index.js.map","// This is an unfortunate replacement for @sindresorhus/is that we need to\n// re-implement for performance purposes. In particular the is.observable()\n// check is expensive, and unnecessary for our purposes. The values returned\n// are compatible with @sindresorhus/is, however.\n\nconst typeofs = [\n  'string',\n  'number',\n  'bigint',\n  'symbol'\n]\n\nconst objectTypeNames = [\n  'Function',\n  'Generator',\n  'AsyncGenerator',\n  'GeneratorFunction',\n  'AsyncGeneratorFunction',\n  'AsyncFunction',\n  'Observable',\n  'Array',\n  'Buffer',\n  'Object',\n  'RegExp',\n  'Date',\n  'Error',\n  'Map',\n  'Set',\n  'WeakMap',\n  'WeakSet',\n  'ArrayBuffer',\n  'SharedArrayBuffer',\n  'DataView',\n  'Promise',\n  'URL',\n  'HTMLElement',\n  'Int8Array',\n  'Uint8Array',\n  'Uint8ClampedArray',\n  'Int16Array',\n  'Uint16Array',\n  'Int32Array',\n  'Uint32Array',\n  'Float32Array',\n  'Float64Array',\n  'BigInt64Array',\n  'BigUint64Array'\n]\n\n/**\n * @param {any} value\n * @returns {string}\n */\nexport function is (value) {\n  if (value === null) {\n    return 'null'\n  }\n  if (value === undefined) {\n    return 'undefined'\n  }\n  if (value === true || value === false) {\n    return 'boolean'\n  }\n  const typeOf = typeof value\n  if (typeofs.includes(typeOf)) {\n    return typeOf\n  }\n  /* c8 ignore next 4 */\n  // not going to bother testing this, it's not going to be valid anyway\n  if (typeOf === 'function') {\n    return 'Function'\n  }\n  if (Array.isArray(value)) {\n    return 'Array'\n  }\n  if (isBuffer(value)) {\n    return 'Buffer'\n  }\n  const objectType = getObjectType(value)\n  if (objectType) {\n    return objectType\n  }\n  /* c8 ignore next */\n  return 'Object'\n}\n\n/**\n * @param {any} value\n * @returns {boolean}\n */\nfunction isBuffer (value) {\n  return value && value.constructor && value.constructor.isBuffer && value.constructor.isBuffer.call(null, value)\n}\n\n/**\n * @param {any} value\n * @returns {string|undefined}\n */\nfunction getObjectType (value) {\n  const objectTypeName = Object.prototype.toString.call(value).slice(8, -1)\n  if (objectTypeNames.includes(objectTypeName)) {\n    return objectTypeName\n  }\n  /* c8 ignore next */\n  return undefined\n}\n","class Type {\n  /**\n   * @param {number} major\n   * @param {string} name\n   * @param {boolean} terminal\n   */\n  constructor (major, name, terminal) {\n    this.major = major\n    this.majorEncoded = major << 5\n    this.name = name\n    this.terminal = terminal\n  }\n\n  /* c8 ignore next 3 */\n  toString () {\n    return `Type[${this.major}].${this.name}`\n  }\n\n  /**\n   * @param {Type} typ\n   * @returns {number}\n   */\n  compare (typ) {\n    /* c8 ignore next 1 */\n    return this.major < typ.major ? -1 : this.major > typ.major ? 1 : 0\n  }\n}\n\n// convert to static fields when better supported\nType.uint = new Type(0, 'uint', true)\nType.negint = new Type(1, 'negint', true)\nType.bytes = new Type(2, 'bytes', true)\nType.string = new Type(3, 'string', true)\nType.array = new Type(4, 'array', false)\nType.map = new Type(5, 'map', false)\nType.tag = new Type(6, 'tag', false) // terminal?\nType.float = new Type(7, 'float', true)\nType.false = new Type(7, 'false', true)\nType.true = new Type(7, 'true', true)\nType.null = new Type(7, 'null', true)\nType.undefined = new Type(7, 'undefined', true)\nType.break = new Type(7, 'break', true)\n// Type.indefiniteLength = new Type(0, 'indefiniteLength', true)\n\nclass Token {\n  /**\n   * @param {Type} type\n   * @param {any} [value]\n   * @param {number} [encodedLength]\n   */\n  constructor (type, value, encodedLength) {\n    this.type = type\n    this.value = value\n    this.encodedLength = encodedLength\n    /** @type {Uint8Array|undefined} */\n    this.encodedBytes = undefined\n    /** @type {Uint8Array|undefined} */\n    this.byteValue = undefined\n  }\n\n  /* c8 ignore next 3 */\n  toString () {\n    return `Token[${this.type}].${this.value}`\n  }\n}\n\nexport { Type, Token }\n","// Use Uint8Array directly in the browser, use Buffer in Node.js but don't\n// speak its name directly to avoid bundlers pulling in the `Buffer` polyfill\n\n// @ts-ignore\nexport const useBuffer = globalThis.process &&\n  // @ts-ignore\n  !globalThis.process.browser &&\n  // @ts-ignore\n  globalThis.Buffer &&\n  // @ts-ignore\n  typeof globalThis.Buffer.isBuffer === 'function'\n\nconst textDecoder = new TextDecoder()\nconst textEncoder = new TextEncoder()\n\n/**\n * @param {Uint8Array} buf\n * @returns {boolean}\n */\nfunction isBuffer (buf) {\n  // @ts-ignore\n  return useBuffer && globalThis.Buffer.isBuffer(buf)\n}\n\n/**\n * @param {Uint8Array|number[]} buf\n * @returns {Uint8Array}\n */\nexport function asU8A (buf) {\n  /* c8 ignore next */\n  if (!(buf instanceof Uint8Array)) {\n    return Uint8Array.from(buf)\n  }\n  return isBuffer(buf) ? new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength) : buf\n}\n\nexport const toString = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return end - start > 64\n        ? // eslint-disable-line operator-linebreak\n      // @ts-ignore\n        globalThis.Buffer.from(bytes.subarray(start, end)).toString('utf8')\n        : utf8Slice(bytes, start, end)\n    }\n  /* c8 ignore next 11 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return end - start > 64\n        ? textDecoder.decode(bytes.subarray(start, end))\n        : utf8Slice(bytes, start, end)\n    }\n\nexport const fromString = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {string} string\n     */\n    (string) => {\n      return string.length > 64\n        ? // eslint-disable-line operator-linebreak\n      // @ts-ignore\n        globalThis.Buffer.from(string)\n        : utf8ToBytes(string)\n    }\n  /* c8 ignore next 7 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {string} string\n     */\n    (string) => {\n      return string.length > 64 ? textEncoder.encode(string) : utf8ToBytes(string)\n    }\n\n/**\n * Buffer variant not fast enough for what we need\n * @param {number[]} arr\n * @returns {Uint8Array}\n */\nexport const fromArray = (arr) => {\n  return Uint8Array.from(arr)\n}\n\nexport const slice = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      if (isBuffer(bytes)) {\n        return new Uint8Array(bytes.subarray(start, end))\n      }\n      return bytes.slice(start, end)\n    }\n  /* c8 ignore next 9 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} bytes\n     * @param {number} start\n     * @param {number} end\n     */\n    (bytes, start, end) => {\n      return bytes.slice(start, end)\n    }\n\nexport const concat = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array[]} chunks\n     * @param {number} length\n     * @returns {Uint8Array}\n     */\n    (chunks, length) => {\n      // might get a stray plain Array here\n      /* c8 ignore next 1 */\n      chunks = chunks.map((c) => c instanceof Uint8Array\n        ? c\n        // this case is occasionally missed during test runs so becomes coverage-flaky\n        /* c8 ignore next 4 */\n        : // eslint-disable-line operator-linebreak\n        // @ts-ignore\n        globalThis.Buffer.from(c))\n      // @ts-ignore\n      return asU8A(globalThis.Buffer.concat(chunks, length))\n    }\n  /* c8 ignore next 19 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array[]} chunks\n     * @param {number} length\n     * @returns {Uint8Array}\n     */\n    (chunks, length) => {\n      const out = new Uint8Array(length)\n      let off = 0\n      for (let b of chunks) {\n        if (off + b.length > out.length) {\n          // final chunk that's bigger than we need\n          b = b.subarray(0, out.length - off)\n        }\n        out.set(b, off)\n        off += b.length\n      }\n      return out\n    }\n\nexport const alloc = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {number} size\n     * @returns {Uint8Array}\n     */\n    (size) => {\n      // we always write over the contents we expose so this should be safe\n      // @ts-ignore\n      return globalThis.Buffer.allocUnsafe(size)\n    }\n  /* c8 ignore next 8 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {number} size\n     * @returns {Uint8Array}\n     */\n    (size) => {\n      return new Uint8Array(size)\n    }\n\nexport const toHex = useBuffer\n  ? // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} d\n     * @returns {string}\n     */\n    (d) => {\n      if (typeof d === 'string') {\n        return d\n      }\n      // @ts-ignore\n      return globalThis.Buffer.from(toBytes(d)).toString('hex')\n    }\n  /* c8 ignore next 12 */\n  : // eslint-disable-line operator-linebreak\n    /**\n     * @param {Uint8Array} d\n     * @returns {string}\n     */\n    (d) => {\n      if (typeof d === 'string') {\n        return d\n      }\n      // @ts-ignore not smart enough to figure this out\n      return Array.prototype.reduce.call(toBytes(d), (p, c) => `${p}${c.toString(16).padStart(2, '0')}`, '')\n    }\n\nexport const fromHex = useBuffer\n  ? // eslint-disable-line operator-linebreak\n  /**\n   * @param {string|Uint8Array} hex\n   * @returns {Uint8Array}\n   */\n    (hex) => {\n      if (hex instanceof Uint8Array) {\n        return hex\n      }\n      // @ts-ignore\n      return globalThis.Buffer.from(hex, 'hex')\n    }\n  /* c8 ignore next 17 */\n  : // eslint-disable-line operator-linebreak\n  /**\n   * @param {string|Uint8Array} hex\n   * @returns {Uint8Array}\n   */\n    (hex) => {\n      if (hex instanceof Uint8Array) {\n        return hex\n      }\n      if (!hex.length) {\n        return new Uint8Array(0)\n      }\n      return new Uint8Array(hex.split('')\n        .map((/** @type {string} */ c, /** @type {number} */ i, /** @type {string[]} */ d) => i % 2 === 0 ? `0x${c}${d[i + 1]}` : '')\n        .filter(Boolean)\n        .map((/** @type {string} */ e) => parseInt(e, 16)))\n    }\n\n/**\n * @param {Uint8Array|ArrayBuffer|ArrayBufferView} obj\n * @returns {Uint8Array}\n */\nfunction toBytes (obj) {\n  if (obj instanceof Uint8Array && obj.constructor.name === 'Uint8Array') {\n    return obj\n  }\n  if (obj instanceof ArrayBuffer) {\n    return new Uint8Array(obj)\n  }\n  if (ArrayBuffer.isView(obj)) {\n    return new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength)\n  }\n  /* c8 ignore next */\n  throw new Error('Unknown type, must be binary type')\n}\n\n/**\n * @param {Uint8Array} b1\n * @param {Uint8Array} b2\n * @returns {number}\n */\nexport function compare (b1, b2) {\n  /* c8 ignore next 5 */\n  if (isBuffer(b1) && isBuffer(b2)) {\n    // probably not possible to get here in the current API\n    // @ts-ignore Buffer\n    return b1.compare(b2)\n  }\n  for (let i = 0; i < b1.length; i++) {\n    if (b1[i] === b2[i]) {\n      continue\n    }\n    return b1[i] < b2[i] ? -1 : 1\n  } /* c8 ignore next 3 */\n  return 0\n}\n\n// The below code is taken from https://github.com/google/closure-library/blob/8598d87242af59aac233270742c8984e2b2bdbe0/closure/goog/crypt/crypt.js#L117-L143\n// Licensed Apache-2.0.\n\n/**\n * @param {string} str\n * @returns {number[]}\n */\nfunction utf8ToBytes (str) {\n  const out = []\n  let p = 0\n  for (let i = 0; i < str.length; i++) {\n    let c = str.charCodeAt(i)\n    if (c < 128) {\n      out[p++] = c\n    } else if (c < 2048) {\n      out[p++] = (c >> 6) | 192\n      out[p++] = (c & 63) | 128\n    } else if (\n      ((c & 0xFC00) === 0xD800) && (i + 1) < str.length &&\n      ((str.charCodeAt(i + 1) & 0xFC00) === 0xDC00)) {\n      // Surrogate Pair\n      c = 0x10000 + ((c & 0x03FF) << 10) + (str.charCodeAt(++i) & 0x03FF)\n      out[p++] = (c >> 18) | 240\n      out[p++] = ((c >> 12) & 63) | 128\n      out[p++] = ((c >> 6) & 63) | 128\n      out[p++] = (c & 63) | 128\n    } else {\n      out[p++] = (c >> 12) | 224\n      out[p++] = ((c >> 6) & 63) | 128\n      out[p++] = (c & 63) | 128\n    }\n  }\n  return out\n}\n\n// The below code is mostly taken from https://github.com/feross/buffer\n// Licensed MIT. Copyright (c) Feross Aboukhadijeh\n\n/**\n * @param {Uint8Array} buf\n * @param {number} offset\n * @param {number} end\n * @returns {string}\n */\nfunction utf8Slice (buf, offset, end) {\n  const res = []\n\n  while (offset < end) {\n    const firstByte = buf[offset]\n    let codePoint = null\n    let bytesPerSequence = (firstByte > 0xef) ? 4 : (firstByte > 0xdf) ? 3 : (firstByte > 0xbf) ? 2 : 1\n\n    if (offset + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[offset + 1]\n          if ((secondByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1f) << 0x6 | (secondByte & 0x3f)\n            if (tempCodePoint > 0x7f) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[offset + 1]\n          thirdByte = buf[offset + 2]\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0xc | (secondByte & 0x3f) << 0x6 | (thirdByte & 0x3f)\n            /* c8 ignore next 3 */\n            if (tempCodePoint > 0x7ff && (tempCodePoint < 0xd800 || tempCodePoint > 0xdfff)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[offset + 1]\n          thirdByte = buf[offset + 2]\n          fourthByte = buf[offset + 3]\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80 && (fourthByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0x12 | (secondByte & 0x3f) << 0xc | (thirdByte & 0x3f) << 0x6 | (fourthByte & 0x3f)\n            if (tempCodePoint > 0xffff && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    /* c8 ignore next 5 */\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xfffd\n      bytesPerSequence = 1\n    } else if (codePoint > 0xffff) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3ff | 0xd800)\n      codePoint = 0xdc00 | codePoint & 0x3ff\n    }\n\n    res.push(codePoint)\n    offset += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nconst MAX_ARGUMENTS_LENGTH = 0x1000\n\n/**\n * @param {number[]} codePoints\n * @returns {string}\n */\nexport function decodeCodePointsArray (codePoints) {\n  const len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n  /* c8 ignore next 10 */\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  let res = ''\n  let i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n","/**\n * Bl is a list of byte chunks, similar to https://github.com/rvagg/bl but for\n * writing rather than reading.\n * A Bl object accepts set() operations for individual bytes and copyTo() for\n * inserting byte arrays. These write operations don't automatically increment\n * the internal cursor so its \"length\" won't be changed. Instead, increment()\n * must be called to extend its length to cover the inserted data.\n * The toBytes() call will convert all internal memory to a single Uint8Array of\n * the correct length, truncating any data that is stored but hasn't been\n * included by an increment().\n * get() can retrieve a single byte.\n * All operations (except toBytes()) take an \"offset\" argument that will perform\n * the write at the offset _from the current cursor_. For most operations this\n * will be `0` to write at the current cursor position but it can be ahead of\n * the current cursor. Negative offsets probably work but are untested.\n */\n\n// TODO: ipjs doesn't support this, only for test files: https://github.com/mikeal/ipjs/blob/master/src/package/testFile.js#L39\nimport { alloc, concat, slice } from './byte-utils.js'\n\n// the ts-ignores in this file are almost all for the `Uint8Array|number[]` duality that exists\n// for perf reasons. Consider better approaches to this or removing it entirely, it is quite\n// risky because of some assumptions about small chunks === number[] and everything else === Uint8Array.\n\nconst defaultChunkSize = 256\n\nexport class Bl {\n  /**\n   * @param {number} [chunkSize]\n   */\n  constructor (chunkSize = defaultChunkSize) {\n    this.chunkSize = chunkSize\n    /** @type {number} */\n    this.cursor = 0\n    /** @type {number} */\n    this.maxCursor = -1\n    /** @type {(Uint8Array|number[])[]} */\n    this.chunks = []\n    // keep the first chunk around if we can to save allocations for future encodes\n    /** @type {Uint8Array|number[]|null} */\n    this._initReuseChunk = null\n  }\n\n  reset () {\n    this.cursor = 0\n    this.maxCursor = -1\n    if (this.chunks.length) {\n      this.chunks = []\n    }\n    if (this._initReuseChunk !== null) {\n      this.chunks.push(this._initReuseChunk)\n      this.maxCursor = this._initReuseChunk.length - 1\n    }\n  }\n\n  /**\n   * @param {Uint8Array|number[]} bytes\n   */\n  push (bytes) {\n    let topChunk = this.chunks[this.chunks.length - 1]\n    const newMax = this.cursor + bytes.length\n    if (newMax <= this.maxCursor + 1) {\n      // we have at least one chunk and we can fit these bytes into that chunk\n      const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1\n      // @ts-ignore\n      topChunk.set(bytes, chunkPos)\n    } else {\n      // can't fit it in\n      if (topChunk) {\n        // trip the last chunk to `cursor` if we need to\n        const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1\n        if (chunkPos < topChunk.length) {\n          // @ts-ignore\n          this.chunks[this.chunks.length - 1] = topChunk.subarray(0, chunkPos)\n          this.maxCursor = this.cursor - 1\n        }\n      }\n      if (bytes.length < 64 && bytes.length < this.chunkSize) {\n        // make a new chunk and copy the new one into it\n        topChunk = alloc(this.chunkSize)\n        this.chunks.push(topChunk)\n        this.maxCursor += topChunk.length\n        if (this._initReuseChunk === null) {\n          this._initReuseChunk = topChunk\n        }\n        // @ts-ignore\n        topChunk.set(bytes, 0)\n      } else {\n        // push the new bytes in as its own chunk\n        this.chunks.push(bytes)\n        this.maxCursor += bytes.length\n      }\n    }\n    this.cursor += bytes.length\n  }\n\n  /**\n   * @param {boolean} [reset]\n   * @returns {Uint8Array}\n   */\n  toBytes (reset = false) {\n    let byts\n    if (this.chunks.length === 1) {\n      const chunk = this.chunks[0]\n      if (reset && this.cursor > chunk.length / 2) {\n        /* c8 ignore next 2 */\n        // @ts-ignore\n        byts = this.cursor === chunk.length ? chunk : chunk.subarray(0, this.cursor)\n        this._initReuseChunk = null\n        this.chunks = []\n      } else {\n        // @ts-ignore\n        byts = slice(chunk, 0, this.cursor)\n      }\n    } else {\n      // @ts-ignore\n      byts = concat(this.chunks, this.cursor)\n    }\n    if (reset) {\n      this.reset()\n    }\n    return byts\n  }\n}\n","const decodeErrPrefix = 'CBOR decode error:'\nconst encodeErrPrefix = 'CBOR encode error:'\n\nconst uintMinorPrefixBytes = []\nuintMinorPrefixBytes[23] = 1\nuintMinorPrefixBytes[24] = 2\nuintMinorPrefixBytes[25] = 3\nuintMinorPrefixBytes[26] = 5\nuintMinorPrefixBytes[27] = 9\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} need\n */\nfunction assertEnoughData (data, pos, need) {\n  if (data.length - pos < need) {\n    throw new Error(`${decodeErrPrefix} not enough data for type`)\n  }\n}\n\nexport {\n  decodeErrPrefix,\n  encodeErrPrefix,\n  uintMinorPrefixBytes,\n  assertEnoughData\n}\n","/* globals BigInt */\n\nimport { Token, Type } from './token.js'\nimport { decodeErrPrefix, assertEnoughData } from './common.js'\n\nexport const uintBoundaries = [24, 256, 65536, 4294967296, BigInt('18446744073709551616')]\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nexport function readUint8 (data, offset, options) {\n  assertEnoughData(data, offset, 1)\n  const value = data[offset]\n  if (options.strict === true && value < uintBoundaries[0]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nexport function readUint16 (data, offset, options) {\n  assertEnoughData(data, offset, 2)\n  const value = (data[offset] << 8) | data[offset + 1]\n  if (options.strict === true && value < uintBoundaries[1]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number}\n */\nexport function readUint32 (data, offset, options) {\n  assertEnoughData(data, offset, 4)\n  const value = (data[offset] * 16777216 /* 2 ** 24 */) + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3]\n  if (options.strict === true && value < uintBoundaries[2]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  return value\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} offset\n * @param {DecodeOptions} options\n * @returns {number|bigint}\n */\nexport function readUint64 (data, offset, options) {\n  // assume BigInt, convert back to Number if within safe range\n  assertEnoughData(data, offset, 8)\n  const hi = (data[offset] * 16777216 /* 2 ** 24 */) + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3]\n  const lo = (data[offset + 4] * 16777216 /* 2 ** 24 */) + (data[offset + 5] << 16) + (data[offset + 6] << 8) + data[offset + 7]\n  const value = (BigInt(hi) << BigInt(32)) + BigInt(lo)\n  if (options.strict === true && value < uintBoundaries[3]) {\n    throw new Error(`${decodeErrPrefix} integer encoded in more bytes than necessary (strict decode)`)\n  }\n  if (value <= Number.MAX_SAFE_INTEGER) {\n    return Number(value)\n  }\n  if (options.allowBigInt === true) {\n    return value\n  }\n  throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`)\n}\n\n/* not required thanks to quick[] list\nconst oneByteTokens = new Array(24).fill(0).map((v, i) => new Token(Type.uint, i, 1))\nexport function decodeUintCompact (data, pos, minor, options) {\n  return oneByteTokens[minor]\n}\n*/\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint8 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint16 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint32 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint32(data, pos + 1, options), 5)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUint64 (data, pos, _minor, options) {\n  return new Token(Type.uint, readUint64(data, pos + 1, options), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeUint (buf, token) {\n  return encodeUintValue(buf, 0, token.value)\n}\n\n/**\n * @param {Bl} buf\n * @param {number} major\n * @param {number|bigint} uint\n */\nexport function encodeUintValue (buf, major, uint) {\n  if (uint < uintBoundaries[0]) {\n    const nuint = Number(uint)\n    // pack into one byte, minor=0, additional=value\n    buf.push([major | nuint])\n  } else if (uint < uintBoundaries[1]) {\n    const nuint = Number(uint)\n    // pack into two byte, minor=0, additional=24\n    buf.push([major | 24, nuint])\n  } else if (uint < uintBoundaries[2]) {\n    const nuint = Number(uint)\n    // pack into three byte, minor=0, additional=25\n    buf.push([major | 25, nuint >>> 8, nuint & 0xff])\n  } else if (uint < uintBoundaries[3]) {\n    const nuint = Number(uint)\n    // pack into five byte, minor=0, additional=26\n    buf.push([major | 26, (nuint >>> 24) & 0xff, (nuint >>> 16) & 0xff, (nuint >>> 8) & 0xff, nuint & 0xff])\n  } else {\n    const buint = BigInt(uint)\n    if (buint < uintBoundaries[4]) {\n      // pack into nine byte, minor=0, additional=27\n      const set = [major | 27, 0, 0, 0, 0, 0, 0, 0]\n      // simulate bitwise above 32 bits\n      let lo = Number(buint & BigInt(0xffffffff))\n      let hi = Number(buint >> BigInt(32) & BigInt(0xffffffff))\n      set[8] = lo & 0xff\n      lo = lo >> 8\n      set[7] = lo & 0xff\n      lo = lo >> 8\n      set[6] = lo & 0xff\n      lo = lo >> 8\n      set[5] = lo & 0xff\n      set[4] = hi & 0xff\n      hi = hi >> 8\n      set[3] = hi & 0xff\n      hi = hi >> 8\n      set[2] = hi & 0xff\n      hi = hi >> 8\n      set[1] = hi & 0xff\n      buf.push(set)\n    } else {\n      throw new Error(`${decodeErrPrefix} encountered BigInt larger than allowable range`)\n    }\n  }\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeUint.encodedSize = function encodedSize (token) {\n  return encodeUintValue.encodedSize(token.value)\n}\n\n/**\n * @param {number} uint\n * @returns {number}\n */\nencodeUintValue.encodedSize = function encodedSize (uint) {\n  if (uint < uintBoundaries[0]) {\n    return 1\n  }\n  if (uint < uintBoundaries[1]) {\n    return 2\n  }\n  if (uint < uintBoundaries[2]) {\n    return 3\n  }\n  if (uint < uintBoundaries[3]) {\n    return 5\n  }\n  return 9\n}\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeUint.compareTokens = function compareTokens (tok1, tok2) {\n  return tok1.value < tok2.value ? -1 : tok1.value > tok2.value ? 1 : /* c8 ignore next */ 0\n}\n","/* eslint-env es2020 */\n\nimport { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport { decodeErrPrefix } from './common.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint8 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint16 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint32 (data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint32(data, pos + 1, options), 5)\n}\n\nconst neg1b = BigInt(-1)\nconst pos1b = BigInt(1)\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeNegint64 (data, pos, _minor, options) {\n  const int = uint.readUint64(data, pos + 1, options)\n  if (typeof int !== 'bigint') {\n    const value = -1 - int\n    if (value >= Number.MIN_SAFE_INTEGER) {\n      return new Token(Type.negint, value, 9)\n    }\n  }\n  if (options.allowBigInt !== true) {\n    throw new Error(`${decodeErrPrefix} integers outside of the safe integer range are not supported`)\n  }\n  return new Token(Type.negint, neg1b - BigInt(int), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeNegint (buf, token) {\n  const negint = token.value\n  const unsigned = (typeof negint === 'bigint' ? (negint * neg1b - pos1b) : (negint * -1 - 1))\n  uint.encodeUintValue(buf, token.type.majorEncoded, unsigned)\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeNegint.encodedSize = function encodedSize (token) {\n  const negint = token.value\n  const unsigned = (typeof negint === 'bigint' ? (negint * neg1b - pos1b) : (negint * -1 - 1))\n  /* c8 ignore next 4 */\n  // handled by quickEncode, we shouldn't get here but it's included for completeness\n  if (unsigned < uint.uintBoundaries[0]) {\n    return 1\n  }\n  if (unsigned < uint.uintBoundaries[1]) {\n    return 2\n  }\n  if (unsigned < uint.uintBoundaries[2]) {\n    return 3\n  }\n  if (unsigned < uint.uintBoundaries[3]) {\n    return 5\n  }\n  return 9\n}\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeNegint.compareTokens = function compareTokens (tok1, tok2) {\n  // opposite of the uint comparison since we store the uint version in bytes\n  return tok1.value < tok2.value ? 1 : tok1.value > tok2.value ? -1 : /* c8 ignore next */ 0\n}\n","import { Token, Type } from './token.js'\nimport { assertEnoughData, decodeErrPrefix } from './common.js'\nimport * as uint from './0uint.js'\nimport { compare, fromString, slice } from './byte-utils.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken (data, pos, prefix, length) {\n  assertEnoughData(data, pos, prefix + length)\n  const buf = slice(data, pos + prefix, pos + prefix + length)\n  return new Token(Type.bytes, buf, prefix + length)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeBytesCompact (data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBytes64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer bytes lengths not supported`)\n  }\n  return toToken(data, pos, 9, l)\n}\n\n/**\n * `encodedBytes` allows for caching when we do a byte version of a string\n * for key sorting purposes\n * @param {Token} token\n * @returns {Uint8Array}\n */\nfunction tokenBytes (token) {\n  if (token.encodedBytes === undefined) {\n    token.encodedBytes = token.type === Type.string ? fromString(token.value) : token.value\n  }\n  // @ts-ignore c'mon\n  return token.encodedBytes\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeBytes (buf, token) {\n  const bytes = tokenBytes(token)\n  uint.encodeUintValue(buf, token.type.majorEncoded, bytes.length)\n  buf.push(bytes)\n}\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeBytes.encodedSize = function encodedSize (token) {\n  const bytes = tokenBytes(token)\n  return uint.encodeUintValue.encodedSize(bytes.length) + bytes.length\n}\n\n/**\n * @param {Token} tok1\n * @param {Token} tok2\n * @returns {number}\n */\nencodeBytes.compareTokens = function compareTokens (tok1, tok2) {\n  return compareBytes(tokenBytes(tok1), tokenBytes(tok2))\n}\n\n/**\n * @param {Uint8Array} b1\n * @param {Uint8Array} b2\n * @returns {number}\n */\nexport function compareBytes (b1, b2) {\n  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : compare(b1, b2)\n}\n","import { Token, Type } from './token.js'\nimport { assertEnoughData, decodeErrPrefix } from './common.js'\nimport * as uint from './0uint.js'\nimport { encodeBytes } from './2bytes.js'\nimport { toString, slice } from './byte-utils.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} prefix\n * @param {number} length\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction toToken (data, pos, prefix, length, options) {\n  const totLength = prefix + length\n  assertEnoughData(data, pos, totLength)\n  const tok = new Token(Type.string, toString(data, pos + prefix, pos + totLength), totLength)\n  if (options.retainStringBytes === true) {\n    tok.byteValue = slice(data, pos + prefix, pos + totLength)\n  }\n  return tok\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeStringCompact (data, pos, minor, options) {\n  return toToken(data, pos, 1, minor, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options), options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options), options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options), options)\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeString64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer string lengths not supported`)\n  }\n  return toToken(data, pos, 9, l, options)\n}\n\nexport const encodeString = encodeBytes\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport { decodeErrPrefix } from './common.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken (_data, _pos, prefix, length) {\n  return new Token(Type.array, length, prefix)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeArrayCompact (data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArray64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer array lengths not supported`)\n  }\n  return toToken(data, pos, 9, l)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeArrayIndefinite (data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return toToken(data, pos, 1, Infinity)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeArray (buf, token) {\n  uint.encodeUintValue(buf, Type.array.majorEncoded, token.value)\n}\n\n// using an array as a map key, are you sure about this? we can only sort\n// by map length here, it's up to the encoder to decide to look deeper\nencodeArray.compareTokens = uint.encodeUint.compareTokens\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeArray.encodedSize = function encodedSize (token) {\n  return uint.encodeUintValue.encodedSize(token.value)\n}\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport { decodeErrPrefix } from './common.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} prefix\n * @param {number} length\n * @returns {Token}\n */\nfunction toToken (_data, _pos, prefix, length) {\n  return new Token(Type.map, length, prefix)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeMapCompact (data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap8 (data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap16 (data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options))\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap32 (data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options))\n}\n\n// TODO: maybe we shouldn't support this ..\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMap64 (data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options)\n  if (typeof l === 'bigint') {\n    throw new Error(`${decodeErrPrefix} 64-bit integer map lengths not supported`)\n  }\n  return toToken(data, pos, 9, l)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeMapIndefinite (data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return toToken(data, pos, 1, Infinity)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeMap (buf, token) {\n  uint.encodeUintValue(buf, Type.map.majorEncoded, token.value)\n}\n\n// using a map as a map key, are you sure about this? we can only sort\n// by map length here, it's up to the encoder to decide to look deeper\nencodeMap.compareTokens = uint.encodeUint.compareTokens\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeMap.encodedSize = function encodedSize (token) {\n  return uint.encodeUintValue.encodedSize(token.value)\n}\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} minor\n * @param {DecodeOptions} _options\n * @returns {Token}\n */\nexport function decodeTagCompact (_data, _pos, minor, _options) {\n  return new Token(Type.tag, minor, 1)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag8 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint8(data, pos + 1, options), 2)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag16 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint16(data, pos + 1, options), 3)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag32 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint32(data, pos + 1, options), 5)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeTag64 (data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint64(data, pos + 1, options), 9)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n */\nexport function encodeTag (buf, token) {\n  uint.encodeUintValue(buf, Type.tag.majorEncoded, token.value)\n}\n\nencodeTag.compareTokens = uint.encodeUint.compareTokens\n\n/**\n * @param {Token} token\n * @returns {number}\n */\nencodeTag.encodedSize = function encodedSize (token) {\n  return uint.encodeUintValue.encodedSize(token.value)\n}\n","// TODO: shift some of the bytes logic to bytes-utils so we can use Buffer\n// where possible\n\nimport { Token, Type } from './token.js'\nimport { decodeErrPrefix } from './common.js'\nimport { encodeUint } from './0uint.js'\n\n/**\n * @typedef {import('./bl.js').Bl} Bl\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n * @typedef {import('../interface').EncodeOptions} EncodeOptions\n */\n\nconst MINOR_FALSE = 20\nconst MINOR_TRUE = 21\nconst MINOR_NULL = 22\nconst MINOR_UNDEFINED = 23\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeUndefined (_data, _pos, _minor, options) {\n  if (options.allowUndefined === false) {\n    throw new Error(`${decodeErrPrefix} undefined values are not supported`)\n  } else if (options.coerceUndefinedToNull === true) {\n    return new Token(Type.null, null, 1)\n  }\n  return new Token(Type.undefined, undefined, 1)\n}\n\n/**\n * @param {Uint8Array} _data\n * @param {number} _pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeBreak (_data, _pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${decodeErrPrefix} indefinite length items not allowed`)\n  }\n  return new Token(Type.break, undefined, 1)\n}\n\n/**\n * @param {number} value\n * @param {number} bytes\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nfunction createToken (value, bytes, options) {\n  if (options) {\n    if (options.allowNaN === false && Number.isNaN(value)) {\n      throw new Error(`${decodeErrPrefix} NaN values are not supported`)\n    }\n    if (options.allowInfinity === false && (value === Infinity || value === -Infinity)) {\n      throw new Error(`${decodeErrPrefix} Infinity values are not supported`)\n    }\n  }\n  return new Token(Type.float, value, bytes)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeFloat16 (data, pos, _minor, options) {\n  return createToken(readFloat16(data, pos + 1), 3, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeFloat32 (data, pos, _minor, options) {\n  return createToken(readFloat32(data, pos + 1), 5, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} _minor\n * @param {DecodeOptions} options\n * @returns {Token}\n */\nexport function decodeFloat64 (data, pos, _minor, options) {\n  return createToken(readFloat64(data, pos + 1), 9, options)\n}\n\n/**\n * @param {Bl} buf\n * @param {Token} token\n * @param {EncodeOptions} options\n */\nexport function encodeFloat (buf, token, options) {\n  const float = token.value\n\n  if (float === false) {\n    buf.push([Type.float.majorEncoded | MINOR_FALSE])\n  } else if (float === true) {\n    buf.push([Type.float.majorEncoded | MINOR_TRUE])\n  } else if (float === null) {\n    buf.push([Type.float.majorEncoded | MINOR_NULL])\n  } else if (float === undefined) {\n    buf.push([Type.float.majorEncoded | MINOR_UNDEFINED])\n  } else {\n    let decoded\n    let success = false\n    if (!options || options.float64 !== true) {\n      encodeFloat16(float)\n      decoded = readFloat16(ui8a, 1)\n      if (float === decoded || Number.isNaN(float)) {\n        ui8a[0] = 0xf9\n        buf.push(ui8a.slice(0, 3))\n        success = true\n      } else {\n        encodeFloat32(float)\n        decoded = readFloat32(ui8a, 1)\n        if (float === decoded) {\n          ui8a[0] = 0xfa\n          buf.push(ui8a.slice(0, 5))\n          success = true\n        }\n      }\n    }\n    if (!success) {\n      encodeFloat64(float)\n      decoded = readFloat64(ui8a, 1)\n      ui8a[0] = 0xfb\n      buf.push(ui8a.slice(0, 9))\n    }\n  }\n}\n\n/**\n * @param {Token} token\n * @param {EncodeOptions} options\n * @returns {number}\n */\nencodeFloat.encodedSize = function encodedSize (token, options) {\n  const float = token.value\n\n  if (float === false || float === true || float === null || float === undefined) {\n    return 1\n  }\n\n  if (!options || options.float64 !== true) {\n    encodeFloat16(float)\n    let decoded = readFloat16(ui8a, 1)\n    if (float === decoded || Number.isNaN(float)) {\n      return 3\n    }\n    encodeFloat32(float)\n    decoded = readFloat32(ui8a, 1)\n    if (float === decoded) {\n      return 5\n    }\n  }\n  return 9\n}\n\nconst buffer = new ArrayBuffer(9)\nconst dataView = new DataView(buffer, 1)\nconst ui8a = new Uint8Array(buffer, 0)\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat16 (inp) {\n  if (inp === Infinity) {\n    dataView.setUint16(0, 0x7c00, false)\n  } else if (inp === -Infinity) {\n    dataView.setUint16(0, 0xfc00, false)\n  } else if (Number.isNaN(inp)) {\n    dataView.setUint16(0, 0x7e00, false)\n  } else {\n    dataView.setFloat32(0, inp)\n    const valu32 = dataView.getUint32(0)\n    const exponent = (valu32 & 0x7f800000) >> 23\n    const mantissa = valu32 & 0x7fffff\n\n    /* c8 ignore next 6 */\n    if (exponent === 0xff) {\n      // too big, Infinity, but this should be hard (impossible?) to trigger\n      dataView.setUint16(0, 0x7c00, false)\n    } else if (exponent === 0x00) {\n      // 0.0, -0.0 and subnormals, shouldn't be possible to get here because 0.0 should be counted as an int\n      dataView.setUint16(0, ((inp & 0x80000000) >> 16) | (mantissa >> 13), false)\n    } else { // standard numbers\n      // chunks of logic here borrowed from https://github.com/PJK/libcbor/blob/c78f437182533e3efa8d963ff4b945bb635c2284/src/cbor/encoding.c#L127\n      const logicalExponent = exponent - 127\n      // Now we know that 2^exponent <= 0 logically\n      /* c8 ignore next 6 */\n      if (logicalExponent < -24) {\n        /* No unambiguous representation exists, this float is not a half float\n          and is too small to be represented using a half, round off to zero.\n          Consistent with the reference implementation. */\n        // should be difficult (impossible?) to get here in JS\n        dataView.setUint16(0, 0)\n      } else if (logicalExponent < -14) {\n        /* Offset the remaining decimal places by shifting the significand, the\n          value is lost. This is an implementation decision that works around the\n          absence of standard half-float in the language. */\n        dataView.setUint16(0, ((valu32 & 0x80000000) >> 16) | /* sign bit */ (1 << (24 + logicalExponent)), false)\n      } else {\n        dataView.setUint16(0, ((valu32 & 0x80000000) >> 16) | ((logicalExponent + 15) << 10) | (mantissa >> 13), false)\n      }\n    }\n  }\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat16 (ui8a, pos) {\n  if (ui8a.length - pos < 2) {\n    throw new Error(`${decodeErrPrefix} not enough data for float16`)\n  }\n\n  const half = (ui8a[pos] << 8) + ui8a[pos + 1]\n  if (half === 0x7c00) {\n    return Infinity\n  }\n  if (half === 0xfc00) {\n    return -Infinity\n  }\n  if (half === 0x7e00) {\n    return NaN\n  }\n  const exp = (half >> 10) & 0x1f\n  const mant = half & 0x3ff\n  let val\n  if (exp === 0) {\n    val = mant * (2 ** -24)\n  } else if (exp !== 31) {\n    val = (mant + 1024) * (2 ** (exp - 25))\n  /* c8 ignore next 4 */\n  } else {\n    // may not be possible to get here\n    val = mant === 0 ? Infinity : NaN\n  }\n  return (half & 0x8000) ? -val : val\n}\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat32 (inp) {\n  dataView.setFloat32(0, inp, false)\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat32 (ui8a, pos) {\n  if (ui8a.length - pos < 4) {\n    throw new Error(`${decodeErrPrefix} not enough data for float32`)\n  }\n  const offset = (ui8a.byteOffset || 0) + pos\n  return new DataView(ui8a.buffer, offset, 4).getFloat32(0, false)\n}\n\n/**\n * @param {number} inp\n */\nfunction encodeFloat64 (inp) {\n  dataView.setFloat64(0, inp, false)\n}\n\n/**\n * @param {Uint8Array} ui8a\n * @param {number} pos\n * @returns {number}\n */\nfunction readFloat64 (ui8a, pos) {\n  if (ui8a.length - pos < 8) {\n    throw new Error(`${decodeErrPrefix} not enough data for float64`)\n  }\n  const offset = (ui8a.byteOffset || 0) + pos\n  return new DataView(ui8a.buffer, offset, 8).getFloat64(0, false)\n}\n\n/**\n * @param {Token} _tok1\n * @param {Token} _tok2\n * @returns {number}\n */\nencodeFloat.compareTokens = encodeUint.compareTokens\n/*\nencodeFloat.compareTokens = function compareTokens (_tok1, _tok2) {\n  return _tok1\n  throw new Error(`${encodeErrPrefix} cannot use floats as map keys`)\n}\n*/\n","import { Token, Type } from './token.js'\nimport * as uint from './0uint.js'\nimport * as negint from './1negint.js'\nimport * as bytes from './2bytes.js'\nimport * as string from './3string.js'\nimport * as array from './4array.js'\nimport * as map from './5map.js'\nimport * as tag from './6tag.js'\nimport * as float from './7float.js'\nimport { decodeErrPrefix } from './common.js'\nimport { fromArray } from './byte-utils.js'\n\n/**\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n */\n\n/**\n * @param {Uint8Array} data\n * @param {number} pos\n * @param {number} minor\n */\nfunction invalidMinor (data, pos, minor) {\n  throw new Error(`${decodeErrPrefix} encountered invalid minor (${minor}) for major ${data[pos] >>> 5}`)\n}\n\n/**\n * @param {string} msg\n * @returns {()=>any}\n */\nfunction errorer (msg) {\n  return () => { throw new Error(`${decodeErrPrefix} ${msg}`) }\n}\n\n/** @type {((data:Uint8Array, pos:number, minor:number, options?:DecodeOptions) => any)[]} */\nexport const jump = []\n\n// unsigned integer, 0x00..0x17 (0..23)\nfor (let i = 0; i <= 0x17; i++) {\n  jump[i] = invalidMinor // uint.decodeUintCompact, handled by quick[]\n}\njump[0x18] = uint.decodeUint8 // unsigned integer, one-byte uint8_t follows\njump[0x19] = uint.decodeUint16 // unsigned integer, two-byte uint16_t follows\njump[0x1a] = uint.decodeUint32 // unsigned integer, four-byte uint32_t follows\njump[0x1b] = uint.decodeUint64 // unsigned integer, eight-byte uint64_t follows\njump[0x1c] = invalidMinor\njump[0x1d] = invalidMinor\njump[0x1e] = invalidMinor\njump[0x1f] = invalidMinor\n// negative integer, -1-0x00..-1-0x17 (-1..-24)\nfor (let i = 0x20; i <= 0x37; i++) {\n  jump[i] = invalidMinor // negintDecode, handled by quick[]\n}\njump[0x38] = negint.decodeNegint8 // negative integer, -1-n one-byte uint8_t for n follows\njump[0x39] = negint.decodeNegint16 // negative integer, -1-n two-byte uint16_t for n follows\njump[0x3a] = negint.decodeNegint32 // negative integer, -1-n four-byte uint32_t for follows\njump[0x3b] = negint.decodeNegint64 // negative integer, -1-n eight-byte uint64_t for follows\njump[0x3c] = invalidMinor\njump[0x3d] = invalidMinor\njump[0x3e] = invalidMinor\njump[0x3f] = invalidMinor\n// byte string, 0x00..0x17 bytes follow\nfor (let i = 0x40; i <= 0x57; i++) {\n  jump[i] = bytes.decodeBytesCompact\n}\njump[0x58] = bytes.decodeBytes8 // byte string, one-byte uint8_t for n, and then n bytes follow\njump[0x59] = bytes.decodeBytes16 // byte string, two-byte uint16_t for n, and then n bytes follow\njump[0x5a] = bytes.decodeBytes32 // byte string, four-byte uint32_t for n, and then n bytes follow\njump[0x5b] = bytes.decodeBytes64 // byte string, eight-byte uint64_t for n, and then n bytes follow\njump[0x5c] = invalidMinor\njump[0x5d] = invalidMinor\njump[0x5e] = invalidMinor\njump[0x5f] = errorer('indefinite length bytes/strings are not supported') // byte string, byte strings follow, terminated by \"break\"\n// UTF-8 string 0x00..0x17 bytes follow\nfor (let i = 0x60; i <= 0x77; i++) {\n  jump[i] = string.decodeStringCompact\n}\njump[0x78] = string.decodeString8 // UTF-8 string, one-byte uint8_t for n, and then n bytes follow\njump[0x79] = string.decodeString16 // UTF-8 string, two-byte uint16_t for n, and then n bytes follow\njump[0x7a] = string.decodeString32 // UTF-8 string, four-byte uint32_t for n, and then n bytes follow\njump[0x7b] = string.decodeString64 // UTF-8 string, eight-byte uint64_t for n, and then n bytes follow\njump[0x7c] = invalidMinor\njump[0x7d] = invalidMinor\njump[0x7e] = invalidMinor\njump[0x7f] = errorer('indefinite length bytes/strings are not supported') // UTF-8 strings follow, terminated by \"break\"\n// array, 0x00..0x17 data items follow\nfor (let i = 0x80; i <= 0x97; i++) {\n  jump[i] = array.decodeArrayCompact\n}\njump[0x98] = array.decodeArray8 // array, one-byte uint8_t for n, and then n data items follow\njump[0x99] = array.decodeArray16 // array, two-byte uint16_t for n, and then n data items follow\njump[0x9a] = array.decodeArray32 // array, four-byte uint32_t for n, and then n data items follow\njump[0x9b] = array.decodeArray64 // array, eight-byte uint64_t for n, and then n data items follow\njump[0x9c] = invalidMinor\njump[0x9d] = invalidMinor\njump[0x9e] = invalidMinor\njump[0x9f] = array.decodeArrayIndefinite // array, data items follow, terminated by \"break\"\n// map, 0x00..0x17 pairs of data items follow\nfor (let i = 0xa0; i <= 0xb7; i++) {\n  jump[i] = map.decodeMapCompact\n}\njump[0xb8] = map.decodeMap8 // map, one-byte uint8_t for n, and then n pairs of data items follow\njump[0xb9] = map.decodeMap16 // map, two-byte uint16_t for n, and then n pairs of data items follow\njump[0xba] = map.decodeMap32 // map, four-byte uint32_t for n, and then n pairs of data items follow\njump[0xbb] = map.decodeMap64 // map, eight-byte uint64_t for n, and then n pairs of data items follow\njump[0xbc] = invalidMinor\njump[0xbd] = invalidMinor\njump[0xbe] = invalidMinor\njump[0xbf] = map.decodeMapIndefinite // map, pairs of data items follow, terminated by \"break\"\n// tags\nfor (let i = 0xc0; i <= 0xd7; i++) {\n  jump[i] = tag.decodeTagCompact\n}\njump[0xd8] = tag.decodeTag8\njump[0xd9] = tag.decodeTag16\njump[0xda] = tag.decodeTag32\njump[0xdb] = tag.decodeTag64\njump[0xdc] = invalidMinor\njump[0xdd] = invalidMinor\njump[0xde] = invalidMinor\njump[0xdf] = invalidMinor\n// 0xe0..0xf3 simple values, unsupported\nfor (let i = 0xe0; i <= 0xf3; i++) {\n  jump[i] = errorer('simple values are not supported')\n}\njump[0xf4] = invalidMinor // false, handled by quick[]\njump[0xf5] = invalidMinor // true, handled by quick[]\njump[0xf6] = invalidMinor // null, handled by quick[]\njump[0xf7] = float.decodeUndefined // undefined\njump[0xf8] = errorer('simple values are not supported') // simple value, one byte follows, unsupported\njump[0xf9] = float.decodeFloat16 // half-precision float (two-byte IEEE 754)\njump[0xfa] = float.decodeFloat32 // single-precision float (four-byte IEEE 754)\njump[0xfb] = float.decodeFloat64 // double-precision float (eight-byte IEEE 754)\njump[0xfc] = invalidMinor\njump[0xfd] = invalidMinor\njump[0xfe] = invalidMinor\njump[0xff] = float.decodeBreak // \"break\" stop code\n\n/** @type {Token[]} */\nexport const quick = []\n// ints <24\nfor (let i = 0; i < 24; i++) {\n  quick[i] = new Token(Type.uint, i, 1)\n}\n// negints >= -24\nfor (let i = -1; i >= -24; i--) {\n  quick[31 - i] = new Token(Type.negint, i, 1)\n}\n// empty bytes\nquick[0x40] = new Token(Type.bytes, new Uint8Array(0), 1)\n// empty string\nquick[0x60] = new Token(Type.string, '', 1)\n// empty list\nquick[0x80] = new Token(Type.array, 0, 1)\n// empty map\nquick[0xa0] = new Token(Type.map, 0, 1)\n// false\nquick[0xf4] = new Token(Type.false, false, 1)\n// true\nquick[0xf5] = new Token(Type.true, true, 1)\n// null\nquick[0xf6] = new Token(Type.null, null, 1)\n\n/**\n * @param {Token} token\n * @returns {Uint8Array|undefined}\n */\nexport function quickEncodeToken (token) {\n  switch (token.type) {\n    case Type.false:\n      return fromArray([0xf4])\n    case Type.true:\n      return fromArray([0xf5])\n    case Type.null:\n      return fromArray([0xf6])\n    case Type.bytes:\n      if (!token.value.length) {\n        return fromArray([0x40])\n      }\n      return\n    case Type.string:\n      if (token.value === '') {\n        return fromArray([0x60])\n      }\n      return\n    case Type.array:\n      if (token.value === 0) {\n        return fromArray([0x80])\n      }\n      /* c8 ignore next 2 */\n      // shouldn't be possible if this were called when there was only one token\n      return\n    case Type.map:\n      if (token.value === 0) {\n        return fromArray([0xa0])\n      }\n      /* c8 ignore next 2 */\n      // shouldn't be possible if this were called when there was only one token\n      return\n    case Type.uint:\n      if (token.value < 24) {\n        return fromArray([Number(token.value)])\n      }\n      return\n    case Type.negint:\n      if (token.value >= -24) {\n        return fromArray([31 - Number(token.value)])\n      }\n  }\n}\n","import { is } from './is.js'\nimport { Token, Type } from './token.js'\nimport { Bl } from './bl.js'\nimport { encodeErrPrefix } from './common.js'\nimport { quickEncodeToken } from './jump.js'\nimport { asU8A } from './byte-utils.js'\n\nimport { encodeUint } from './0uint.js'\nimport { encodeNegint } from './1negint.js'\nimport { encodeBytes } from './2bytes.js'\nimport { encodeString } from './3string.js'\nimport { encodeArray } from './4array.js'\nimport { encodeMap } from './5map.js'\nimport { encodeTag } from './6tag.js'\nimport { encodeFloat } from './7float.js'\n\n/**\n * @typedef {import('../interface').EncodeOptions} EncodeOptions\n * @typedef {import('../interface').OptionalTypeEncoder} OptionalTypeEncoder\n * @typedef {import('../interface').Reference} Reference\n * @typedef {import('../interface').StrictTypeEncoder} StrictTypeEncoder\n * @typedef {import('../interface').TokenTypeEncoder} TokenTypeEncoder\n * @typedef {import('../interface').TokenOrNestedTokens} TokenOrNestedTokens\n */\n\n/** @type {EncodeOptions} */\nconst defaultEncodeOptions = {\n  float64: false,\n  mapSorter,\n  quickEncodeToken\n}\n\n/** @returns {TokenTypeEncoder[]} */\nexport function makeCborEncoders () {\n  const encoders = []\n  encoders[Type.uint.major] = encodeUint\n  encoders[Type.negint.major] = encodeNegint\n  encoders[Type.bytes.major] = encodeBytes\n  encoders[Type.string.major] = encodeString\n  encoders[Type.array.major] = encodeArray\n  encoders[Type.map.major] = encodeMap\n  encoders[Type.tag.major] = encodeTag\n  encoders[Type.float.major] = encodeFloat\n  return encoders\n}\n\nconst cborEncoders = makeCborEncoders()\n\nconst buf = new Bl()\n\n/** @implements {Reference} */\nclass Ref {\n  /**\n   * @param {object|any[]} obj\n   * @param {Reference|undefined} parent\n   */\n  constructor (obj, parent) {\n    this.obj = obj\n    this.parent = parent\n  }\n\n  /**\n   * @param {object|any[]} obj\n   * @returns {boolean}\n   */\n  includes (obj) {\n    /** @type {Reference|undefined} */\n    let p = this\n    do {\n      if (p.obj === obj) {\n        return true\n      }\n    } while (p = p.parent) // eslint-disable-line\n    return false\n  }\n\n  /**\n   * @param {Reference|undefined} stack\n   * @param {object|any[]} obj\n   * @returns {Reference}\n   */\n  static createCheck (stack, obj) {\n    if (stack && stack.includes(obj)) {\n      throw new Error(`${encodeErrPrefix} object contains circular references`)\n    }\n    return new Ref(obj, stack)\n  }\n}\n\nconst simpleTokens = {\n  null: new Token(Type.null, null),\n  undefined: new Token(Type.undefined, undefined),\n  true: new Token(Type.true, true),\n  false: new Token(Type.false, false),\n  emptyArray: new Token(Type.array, 0),\n  emptyMap: new Token(Type.map, 0)\n}\n\n/** @type {{[typeName: string]: StrictTypeEncoder}} */\nconst typeEncoders = {\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  number (obj, _typ, _options, _refStack) {\n    if (!Number.isInteger(obj) || !Number.isSafeInteger(obj)) {\n      return new Token(Type.float, obj)\n    } else if (obj >= 0) {\n      return new Token(Type.uint, obj)\n    } else {\n      return new Token(Type.negint, obj)\n    }\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  bigint (obj, _typ, _options, _refStack) {\n    if (obj >= BigInt(0)) {\n      return new Token(Type.uint, obj)\n    } else {\n      return new Token(Type.negint, obj)\n    }\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Uint8Array (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, obj)\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  string (obj, _typ, _options, _refStack) {\n    return new Token(Type.string, obj)\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  boolean (obj, _typ, _options, _refStack) {\n    return obj ? simpleTokens.true : simpleTokens.false\n  },\n\n  /**\n   * @param {any} _obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  null (_obj, _typ, _options, _refStack) {\n    return simpleTokens.null\n  },\n\n  /**\n   * @param {any} _obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  undefined (_obj, _typ, _options, _refStack) {\n    return simpleTokens.undefined\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  ArrayBuffer (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj))\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} _options\n   * @param {Reference} [_refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  DataView (obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength))\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} _typ\n   * @param {EncodeOptions} options\n   * @param {Reference} [refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Array (obj, _typ, options, refStack) {\n    if (!obj.length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyArray, new Token(Type.break)]\n      }\n      return simpleTokens.emptyArray\n    }\n    refStack = Ref.createCheck(refStack, obj)\n    const entries = []\n    let i = 0\n    for (const e of obj) {\n      entries[i++] = objectToTokens(e, options, refStack)\n    }\n    if (options.addBreakTokens) {\n      return [new Token(Type.array, obj.length), entries, new Token(Type.break)]\n    }\n    return [new Token(Type.array, obj.length), entries]\n  },\n\n  /**\n   * @param {any} obj\n   * @param {string} typ\n   * @param {EncodeOptions} options\n   * @param {Reference} [refStack]\n   * @returns {TokenOrNestedTokens}\n   */\n  Object (obj, typ, options, refStack) {\n    // could be an Object or a Map\n    const isMap = typ !== 'Object'\n    // it's slightly quicker to use Object.keys() than Object.entries()\n    const keys = isMap ? obj.keys() : Object.keys(obj)\n    const length = isMap ? obj.size : keys.length\n    if (!length) {\n      if (options.addBreakTokens === true) {\n        return [simpleTokens.emptyMap, new Token(Type.break)]\n      }\n      return simpleTokens.emptyMap\n    }\n    refStack = Ref.createCheck(refStack, obj)\n    /** @type {TokenOrNestedTokens[]} */\n    const entries = []\n    let i = 0\n    for (const key of keys) {\n      entries[i++] = [\n        objectToTokens(key, options, refStack),\n        objectToTokens(isMap ? obj.get(key) : obj[key], options, refStack)\n      ]\n    }\n    sortMapEntries(entries, options)\n    if (options.addBreakTokens) {\n      return [new Token(Type.map, length), entries, new Token(Type.break)]\n    }\n    return [new Token(Type.map, length), entries]\n  }\n}\n\ntypeEncoders.Map = typeEncoders.Object\ntypeEncoders.Buffer = typeEncoders.Uint8Array\nfor (const typ of 'Uint8Clamped Uint16 Uint32 Int8 Int16 Int32 BigUint64 BigInt64 Float32 Float64'.split(' ')) {\n  typeEncoders[`${typ}Array`] = typeEncoders.DataView\n}\n\n/**\n * @param {any} obj\n * @param {EncodeOptions} [options]\n * @param {Reference} [refStack]\n * @returns {TokenOrNestedTokens}\n */\nfunction objectToTokens (obj, options = {}, refStack) {\n  const typ = is(obj)\n  const customTypeEncoder = (options && options.typeEncoders && /** @type {OptionalTypeEncoder} */ options.typeEncoders[typ]) || typeEncoders[typ]\n  if (typeof customTypeEncoder === 'function') {\n    const tokens = customTypeEncoder(obj, typ, options, refStack)\n    if (tokens != null) {\n      return tokens\n    }\n  }\n  const typeEncoder = typeEncoders[typ]\n  if (!typeEncoder) {\n    throw new Error(`${encodeErrPrefix} unsupported type: ${typ}`)\n  }\n  return typeEncoder(obj, typ, options, refStack)\n}\n\n/*\nCBOR key sorting is a mess.\n\nThe canonicalisation recommendation from https://tools.ietf.org/html/rfc7049#section-3.9\nincludes the wording:\n\n> The keys in every map must be sorted lowest value to highest.\n> Sorting is performed on the bytes of the representation of the key\n> data items without paying attention to the 3/5 bit splitting for\n> major types.\n> ...\n>  *  If two keys have different lengths, the shorter one sorts\n      earlier;\n>  *  If two keys have the same length, the one with the lower value\n      in (byte-wise) lexical order sorts earlier.\n\n1. It is not clear what \"bytes of the representation of the key\" means: is it\n   the CBOR representation, or the binary representation of the object itself?\n   Consider the int and uint difference here.\n2. It is not clear what \"without paying attention to\" means: do we include it\n   and compare on that? Or do we omit the special prefix byte, (mostly) treating\n   the key in its plain binary representation form.\n\nThe FIDO 2.0: Client To Authenticator Protocol spec takes the original CBOR\nwording and clarifies it according to their understanding.\nhttps://fidoalliance.org/specs/fido-v2.0-rd-20170927/fido-client-to-authenticator-protocol-v2.0-rd-20170927.html#message-encoding\n\n> The keys in every map must be sorted lowest value to highest. Sorting is\n> performed on the bytes of the representation of the key data items without\n> paying attention to the 3/5 bit splitting for major types. The sorting rules\n> are:\n>  * If the major types are different, the one with the lower value in numerical\n>    order sorts earlier.\n>  * If two keys have different lengths, the shorter one sorts earlier;\n>  * If two keys have the same length, the one with the lower value in\n>    (byte-wise) lexical order sorts earlier.\n\nSome other implementations, such as borc, do a full encode then do a\nlength-first, byte-wise-second comparison:\nhttps://github.com/dignifiedquire/borc/blob/b6bae8b0bcde7c3976b0f0f0957208095c392a36/src/encoder.js#L358\nhttps://github.com/dignifiedquire/borc/blob/b6bae8b0bcde7c3976b0f0f0957208095c392a36/src/utils.js#L143-L151\n\nThis has the benefit of being able to easily handle arbitrary keys, including\ncomplex types (maps and arrays).\n\nWe'll opt for the FIDO approach, since it affords some efficies since we don't\nneed a full encode of each key to determine order and can defer to the types\nto determine how to most efficiently order their values (i.e. int and uint\nordering can be done on the numbers, no need for byte-wise, for example).\n\nRecommendation: stick to single key types or you'll get into trouble, and prefer\nstring keys because it's much simpler that way.\n*/\n\n/*\n(UPDATE, Dec 2020)\nhttps://tools.ietf.org/html/rfc8949 is the updated CBOR spec and clarifies some\nof the questions above with a new recommendation for sorting order being much\ncloser to what would be expected in other environments (i.e. no length-first\nweirdness).\nThis new sorting order is not yet implemented here but could be added as an\noption. \"Determinism\" (canonicity) is system dependent and it's difficult to\nchange existing systems that are built with existing expectations. So if a new\nordering is introduced here, the old needs to be kept as well with the user\nhaving the option.\n*/\n\n/**\n * @param {TokenOrNestedTokens[]} entries\n * @param {EncodeOptions} options\n */\nfunction sortMapEntries (entries, options) {\n  if (options.mapSorter) {\n    entries.sort(options.mapSorter)\n  }\n}\n\n/**\n * @param {(Token|Token[])[]} e1\n * @param {(Token|Token[])[]} e2\n * @returns {number}\n */\nfunction mapSorter (e1, e2) {\n  // the key position ([0]) could have a single token or an array\n  // almost always it'll be a single token but complex key might get involved\n  /* c8 ignore next 2 */\n  const keyToken1 = Array.isArray(e1[0]) ? e1[0][0] : e1[0]\n  const keyToken2 = Array.isArray(e2[0]) ? e2[0][0] : e2[0]\n\n  // different key types\n  if (keyToken1.type !== keyToken2.type) {\n    return keyToken1.type.compare(keyToken2.type)\n  }\n\n  const major = keyToken1.type.major\n  // TODO: handle case where cmp === 0 but there are more keyToken e. complex type)\n  const tcmp = cborEncoders[major].compareTokens(keyToken1, keyToken2)\n  /* c8 ignore next 5 */\n  if (tcmp === 0) {\n    // duplicate key or complex type where the first token matched,\n    // i.e. a map or array and we're only comparing the opening token\n    console.warn('WARNING: complex key types used, CBOR key sorting guarantees are gone')\n  }\n  return tcmp\n}\n\n/**\n * @param {Bl} buf\n * @param {TokenOrNestedTokens} tokens\n * @param {TokenTypeEncoder[]} encoders\n * @param {EncodeOptions} options\n */\nfunction tokensToEncoded (buf, tokens, encoders, options) {\n  if (Array.isArray(tokens)) {\n    for (const token of tokens) {\n      tokensToEncoded(buf, token, encoders, options)\n    }\n  } else {\n    encoders[tokens.type.major](buf, tokens, options)\n  }\n}\n\n/**\n * @param {any} data\n * @param {TokenTypeEncoder[]} encoders\n * @param {EncodeOptions} options\n * @returns {Uint8Array}\n */\nfunction encodeCustom (data, encoders, options) {\n  const tokens = objectToTokens(data, options)\n  if (!Array.isArray(tokens) && options.quickEncodeToken) {\n    const quickBytes = options.quickEncodeToken(tokens)\n    if (quickBytes) {\n      return quickBytes\n    }\n    const encoder = encoders[tokens.type.major]\n    if (encoder.encodedSize) {\n      const size = encoder.encodedSize(tokens, options)\n      const buf = new Bl(size)\n      encoder(buf, tokens, options)\n      /* c8 ignore next 4 */\n      // this would be a problem with encodedSize() functions\n      if (buf.chunks.length !== 1) {\n        throw new Error(`Unexpected error: pre-calculated length for ${tokens} was wrong`)\n      }\n      return asU8A(buf.chunks[0])\n    }\n  }\n  buf.reset()\n  tokensToEncoded(buf, tokens, encoders, options)\n  return buf.toBytes(true)\n}\n\n/**\n * @param {any} data\n * @param {EncodeOptions} [options]\n * @returns {Uint8Array}\n */\nfunction encode (data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options)\n  return encodeCustom(data, cborEncoders, options)\n}\n\nexport { objectToTokens, encode, encodeCustom, Ref }\n","import { decodeErrPrefix } from './common.js'\nimport { Type } from './token.js'\nimport { jump, quick } from './jump.js'\n\n/**\n * @typedef {import('./token.js').Token} Token\n * @typedef {import('../interface').DecodeOptions} DecodeOptions\n * @typedef {import('../interface').DecodeTokenizer} DecodeTokenizer\n */\n\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n}\n\n/**\n * @implements {DecodeTokenizer}\n */\nclass Tokeniser {\n  /**\n   * @param {Uint8Array} data\n   * @param {DecodeOptions} options\n   */\n  constructor (data, options = {}) {\n    this._pos = 0\n    this.data = data\n    this.options = options\n  }\n\n  pos () {\n    return this._pos\n  }\n\n  done () {\n    return this._pos >= this.data.length\n  }\n\n  next () {\n    const byt = this.data[this._pos]\n    let token = quick[byt]\n    if (token === undefined) {\n      const decoder = jump[byt]\n      /* c8 ignore next 4 */\n      // if we're here then there's something wrong with our jump or quick lists!\n      if (!decoder) {\n        throw new Error(`${decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, '0')})`)\n      }\n      const minor = byt & 31\n      token = decoder(this.data, this._pos, minor, this.options)\n    }\n    // @ts-ignore we get to assume encodedLength is set (crossing fingers slightly)\n    this._pos += token.encodedLength\n    return token\n  }\n}\n\nconst DONE = Symbol.for('DONE')\nconst BREAK = Symbol.for('BREAK')\n\n/**\n * @param {Token} token\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokenToArray (token, tokeniser, options) {\n  const arr = []\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options)\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        // normal end to indefinite length array\n        break\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed array`)\n    }\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`)\n    }\n    arr[i] = value\n  }\n  return arr\n}\n\n/**\n * @param {Token} token\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokenToMap (token, tokeniser, options) {\n  const useMaps = options.useMaps === true\n  const obj = useMaps ? undefined : {}\n  const m = useMaps ? new Map() : undefined\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options)\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        // normal end to indefinite length map\n        break\n      }\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed map`)\n    }\n    if (key === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`)\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${decodeErrPrefix} non-string keys not supported (got ${typeof key})`)\n    }\n    if (options.rejectDuplicateMapKeys === true) {\n      // @ts-ignore\n      if ((useMaps && m.has(key)) || (!useMaps && (key in obj))) {\n        throw new Error(`${decodeErrPrefix} found repeat map key \"${key}\"`)\n      }\n    }\n    const value = tokensToObject(tokeniser, options)\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`)\n    }\n    if (useMaps) {\n      // @ts-ignore TODO reconsider this .. maybe needs to be strict about key types\n      m.set(key, value)\n    } else {\n      // @ts-ignore TODO reconsider this .. maybe needs to be strict about key types\n      obj[key] = value\n    }\n  }\n  // @ts-ignore c'mon man\n  return useMaps ? m : obj\n}\n\n/**\n * @param {DecodeTokenizer} tokeniser\n * @param {DecodeOptions} options\n * @returns {any|BREAK|DONE}\n */\nfunction tokensToObject (tokeniser, options) {\n  // should we support array as an argument?\n  // check for tokenIter[Symbol.iterator] and replace tokenIter with what that returns?\n  if (tokeniser.done()) {\n    return DONE\n  }\n\n  const token = tokeniser.next()\n\n  if (token.type === Type.break) {\n    return BREAK\n  }\n\n  if (token.type.terminal) {\n    return token.value\n  }\n\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options)\n  }\n\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options)\n  }\n\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options)\n      return options.tags[token.value](tagged)\n    }\n    throw new Error(`${decodeErrPrefix} tag not supported (${token.value})`)\n  }\n  /* c8 ignore next */\n  throw new Error('unsupported')\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {[any, Uint8Array]}\n */\nfunction decodeFirst (data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${decodeErrPrefix} data to decode must be a Uint8Array`)\n  }\n  options = Object.assign({}, defaultDecodeOptions, options)\n  const tokeniser = options.tokenizer || new Tokeniser(data, options)\n  const decoded = tokensToObject(tokeniser, options)\n  if (decoded === DONE) {\n    throw new Error(`${decodeErrPrefix} did not find any content to decode`)\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${decodeErrPrefix} got unexpected break`)\n  }\n  return [decoded, data.subarray(tokeniser.pos())]\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {any}\n */\nfunction decode (data, options) {\n  const [decoded, remainder] = decodeFirst(data, options)\n  if (remainder.length > 0) {\n    throw new Error(`${decodeErrPrefix} too many terminals, data makes no sense`)\n  }\n  return decoded\n}\n\nexport { Tokeniser, tokensToObject, decode, decodeFirst }\n","import { encode } from './lib/encode.js'\nimport { decode, decodeFirst, Tokeniser, tokensToObject } from './lib/decode.js'\nimport { Token, Type } from './lib/token.js'\n\n/**\n * Export the types that were present in the original manual cborg.d.ts\n * @typedef {import('./interface').TagDecoder} TagDecoder\n * There was originally just `TypeEncoder` so don't break types by renaming or not exporting\n * @typedef {import('./interface').OptionalTypeEncoder} TypeEncoder\n * @typedef {import('./interface').DecodeOptions} DecodeOptions\n * @typedef {import('./interface').EncodeOptions} EncodeOptions\n */\n\nexport {\n  decode,\n  decodeFirst,\n  Tokeniser as Tokenizer,\n  tokensToObject,\n  encode,\n  Token,\n  Type\n}\n","export class SignatureCreationError extends Error {\n    static name = 'SignatureCreationError';\n    constructor(message = 'Record signature creation failed') {\n        super(message);\n        this.name = 'SignatureCreationError';\n    }\n}\nexport class SignatureVerificationError extends Error {\n    static name = 'SignatureVerificationError';\n    constructor(message = 'Record signature verification failed') {\n        super(message);\n        this.name = 'SignatureVerificationError';\n    }\n}\nexport class RecordExpiredError extends Error {\n    static name = 'RecordExpiredError';\n    constructor(message = 'Record has expired') {\n        super(message);\n        this.name = 'RecordExpiredError';\n    }\n}\nexport class UnsupportedValidityError extends Error {\n    static name = 'UnsupportedValidityError';\n    constructor(message = 'The validity type is unsupported') {\n        super(message);\n        this.name = 'UnsupportedValidityError';\n    }\n}\nexport class RecordTooLargeError extends Error {\n    static name = 'RecordTooLargeError';\n    constructor(message = 'The record is too large') {\n        super(message);\n        this.name = 'RecordTooLargeError';\n    }\n}\nexport class InvalidValueError extends Error {\n    static name = 'InvalidValueError';\n    constructor(message = 'Value must be a valid content path starting with /') {\n        super(message);\n        this.name = 'InvalidValueError';\n    }\n}\nexport class InvalidRecordDataError extends Error {\n    static name = 'InvalidRecordDataError';\n    constructor(message = 'Invalid record data') {\n        super(message);\n        this.name = 'InvalidRecordDataError';\n    }\n}\nexport class InvalidEmbeddedPublicKeyError extends Error {\n    static name = 'InvalidEmbeddedPublicKeyError';\n    constructor(message = 'Invalid embedded public key') {\n        super(message);\n        this.name = 'InvalidEmbeddedPublicKeyError';\n    }\n}\n//# sourceMappingURL=errors.js.map","/* eslint-disable import/export */\n/* eslint-disable complexity */\n/* eslint-disable @typescript-eslint/no-namespace */\n/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */\n/* eslint-disable @typescript-eslint/no-empty-interface */\nimport { decodeMessage, encodeMessage, enumeration, message } from 'protons-runtime';\nexport var IpnsEntry;\n(function (IpnsEntry) {\n    let ValidityType;\n    (function (ValidityType) {\n        ValidityType[\"EOL\"] = \"EOL\";\n    })(ValidityType = IpnsEntry.ValidityType || (IpnsEntry.ValidityType = {}));\n    let __ValidityTypeValues;\n    (function (__ValidityTypeValues) {\n        __ValidityTypeValues[__ValidityTypeValues[\"EOL\"] = 0] = \"EOL\";\n    })(__ValidityTypeValues || (__ValidityTypeValues = {}));\n    (function (ValidityType) {\n        ValidityType.codec = () => {\n            return enumeration(__ValidityTypeValues);\n        };\n    })(ValidityType = IpnsEntry.ValidityType || (IpnsEntry.ValidityType = {}));\n    let _codec;\n    IpnsEntry.codec = () => {\n        if (_codec == null) {\n            _codec = message((obj, w, opts = {}) => {\n                if (opts.lengthDelimited !== false) {\n                    w.fork();\n                }\n                if (obj.value != null) {\n                    w.uint32(10);\n                    w.bytes(obj.value);\n                }\n                if (obj.signatureV1 != null) {\n                    w.uint32(18);\n                    w.bytes(obj.signatureV1);\n                }\n                if (obj.validityType != null) {\n                    w.uint32(24);\n                    IpnsEntry.ValidityType.codec().encode(obj.validityType, w);\n                }\n                if (obj.validity != null) {\n                    w.uint32(34);\n                    w.bytes(obj.validity);\n                }\n                if (obj.sequence != null) {\n                    w.uint32(40);\n                    w.uint64(obj.sequence);\n                }\n                if (obj.ttl != null) {\n                    w.uint32(48);\n                    w.uint64(obj.ttl);\n                }\n                if (obj.pubKey != null) {\n                    w.uint32(58);\n                    w.bytes(obj.pubKey);\n                }\n                if (obj.signatureV2 != null) {\n                    w.uint32(66);\n                    w.bytes(obj.signatureV2);\n                }\n                if (obj.data != null) {\n                    w.uint32(74);\n                    w.bytes(obj.data);\n                }\n                if (opts.lengthDelimited !== false) {\n                    w.ldelim();\n                }\n            }, (reader, length, opts = {}) => {\n                const obj = {};\n                const end = length == null ? reader.len : reader.pos + length;\n                while (reader.pos < end) {\n                    const tag = reader.uint32();\n                    switch (tag >>> 3) {\n                        case 1: {\n                            obj.value = reader.bytes();\n                            break;\n                        }\n                        case 2: {\n                            obj.signatureV1 = reader.bytes();\n                            break;\n                        }\n                        case 3: {\n                            obj.validityType = IpnsEntry.ValidityType.codec().decode(reader);\n                            break;\n                        }\n                        case 4: {\n                            obj.validity = reader.bytes();\n                            break;\n                        }\n                        case 5: {\n                            obj.sequence = reader.uint64();\n                            break;\n                        }\n                        case 6: {\n                            obj.ttl = reader.uint64();\n                            break;\n                        }\n                        case 7: {\n                            obj.pubKey = reader.bytes();\n                            break;\n                        }\n                        case 8: {\n                            obj.signatureV2 = reader.bytes();\n                            break;\n                        }\n                        case 9: {\n                            obj.data = reader.bytes();\n                            break;\n                        }\n                        default: {\n                            reader.skipType(tag & 7);\n                            break;\n                        }\n                    }\n                }\n                return obj;\n            });\n        }\n        return _codec;\n    };\n    IpnsEntry.encode = (obj) => {\n        return encodeMessage(obj, IpnsEntry.codec());\n    };\n    IpnsEntry.decode = (buf, opts) => {\n        return decodeMessage(buf, IpnsEntry.codec(), opts);\n    };\n})(IpnsEntry || (IpnsEntry = {}));\n//# sourceMappingURL=ipns.js.map","import { publicKeyFromProtobuf } from '@libp2p/crypto/keys';\nimport { InvalidMultihashError } from '@libp2p/interface';\nimport { logger } from '@libp2p/logger';\nimport * as cborg from 'cborg';\nimport { base36 } from 'multiformats/bases/base36';\nimport { CID } from 'multiformats/cid';\nimport * as Digest from 'multiformats/hashes/digest';\nimport { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport { InvalidRecordDataError, InvalidValueError, SignatureVerificationError, UnsupportedValidityError } from './errors.js';\nimport { IpnsEntry } from './pb/ipns.js';\nconst log = logger('ipns:utils');\nconst IPNS_PREFIX = uint8ArrayFromString('/ipns/');\nconst LIBP2P_CID_CODEC = 0x72;\nconst IDENTITY_CODEC = 0x0;\nconst SHA2_256_CODEC = 0x12;\n/**\n * Extracts a public key from the passed PeerId, falling back to the pubKey\n * embedded in the ipns record\n */\nexport function extractPublicKeyFromIPNSRecord(record) {\n    let pubKey;\n    if (record.pubKey != null) {\n        try {\n            pubKey = publicKeyFromProtobuf(record.pubKey);\n        }\n        catch (err) {\n            log.error(err);\n            throw err;\n        }\n    }\n    if (pubKey != null) {\n        return pubKey;\n    }\n}\n/**\n * Utility for creating the record data for being signed\n */\nexport function ipnsRecordDataForV1Sig(value, validityType, validity) {\n    const validityTypeBuffer = uint8ArrayFromString(validityType);\n    return uint8ArrayConcat([value, validity, validityTypeBuffer]);\n}\n/**\n * Utility for creating the record data for being signed\n */\nexport function ipnsRecordDataForV2Sig(data) {\n    const entryData = uint8ArrayFromString('ipns-signature:');\n    return uint8ArrayConcat([entryData, data]);\n}\nexport function marshalIPNSRecord(obj) {\n    if ('signatureV1' in obj) {\n        return IpnsEntry.encode({\n            value: uint8ArrayFromString(obj.value),\n            signatureV1: obj.signatureV1,\n            validityType: obj.validityType,\n            validity: uint8ArrayFromString(obj.validity),\n            sequence: obj.sequence,\n            ttl: obj.ttl,\n            pubKey: obj.pubKey,\n            signatureV2: obj.signatureV2,\n            data: obj.data\n        });\n    }\n    else {\n        return IpnsEntry.encode({\n            pubKey: obj.pubKey,\n            signatureV2: obj.signatureV2,\n            data: obj.data\n        });\n    }\n}\nexport function unmarshalIPNSRecord(buf) {\n    const message = IpnsEntry.decode(buf);\n    // protobufjs returns bigints as numbers\n    if (message.sequence != null) {\n        message.sequence = BigInt(message.sequence);\n    }\n    // protobufjs returns bigints as numbers\n    if (message.ttl != null) {\n        message.ttl = BigInt(message.ttl);\n    }\n    // Check if we have the data field. If we don't, we fail. We've been producing\n    // V1+V2 records for quite a while and we don't support V1-only records during\n    // validation any more\n    if (message.signatureV2 == null || message.data == null) {\n        throw new SignatureVerificationError('Missing data or signatureV2');\n    }\n    const data = parseCborData(message.data);\n    const value = normalizeByteValue(data.Value);\n    const validity = uint8ArrayToString(data.Validity);\n    if (message.value != null && message.signatureV1 != null) {\n        // V1+V2\n        validateCborDataMatchesPbData(message);\n        return {\n            value,\n            validityType: IpnsEntry.ValidityType.EOL,\n            validity,\n            sequence: data.Sequence,\n            ttl: data.TTL,\n            pubKey: message.pubKey,\n            signatureV1: message.signatureV1,\n            signatureV2: message.signatureV2,\n            data: message.data\n        };\n    }\n    else if (message.signatureV2 != null) {\n        // V2-only\n        return {\n            value,\n            validityType: IpnsEntry.ValidityType.EOL,\n            validity,\n            sequence: data.Sequence,\n            ttl: data.TTL,\n            pubKey: message.pubKey,\n            signatureV2: message.signatureV2,\n            data: message.data\n        };\n    }\n    else {\n        throw new Error('invalid record: does not include signatureV1 or signatureV2');\n    }\n}\nexport function multihashToIPNSRoutingKey(digest) {\n    return uint8ArrayConcat([\n        IPNS_PREFIX,\n        digest.bytes\n    ]);\n}\nexport function multihashFromIPNSRoutingKey(key) {\n    const digest = Digest.decode(key.slice(IPNS_PREFIX.length));\n    if (!isCodec(digest, IDENTITY_CODEC) && !isCodec(digest, SHA2_256_CODEC)) {\n        throw new InvalidMultihashError('Multihash in IPNS key was not identity or sha2-256');\n    }\n    return digest;\n}\nexport function createCborData(value, validityType, validity, sequence, ttl) {\n    let ValidityType;\n    if (validityType === IpnsEntry.ValidityType.EOL) {\n        ValidityType = 0;\n    }\n    else {\n        throw new UnsupportedValidityError('The validity type is unsupported');\n    }\n    const data = {\n        Value: value,\n        Validity: validity,\n        ValidityType,\n        Sequence: sequence,\n        TTL: ttl\n    };\n    return cborg.encode(data);\n}\nexport function parseCborData(buf) {\n    const data = cborg.decode(buf);\n    if (data.ValidityType === 0) {\n        data.ValidityType = IpnsEntry.ValidityType.EOL;\n    }\n    else {\n        throw new UnsupportedValidityError('The validity type is unsupported');\n    }\n    if (Number.isInteger(data.Sequence)) {\n        // sequence must be a BigInt, but DAG-CBOR doesn't preserve this for Numbers within the safe-integer range\n        data.Sequence = BigInt(data.Sequence);\n    }\n    if (Number.isInteger(data.TTL)) {\n        // ttl must be a BigInt, but DAG-CBOR doesn't preserve this for Numbers within the safe-integer range\n        data.TTL = BigInt(data.TTL);\n    }\n    return data;\n}\nexport function normalizeByteValue(value) {\n    const string = uint8ArrayToString(value).trim();\n    // if we have a path, check it is a valid path\n    if (string.startsWith('/')) {\n        return string;\n    }\n    // try parsing what we have as CID bytes or a CID string\n    try {\n        return `/ipfs/${CID.decode(value).toV1().toString()}`;\n    }\n    catch {\n        // fall through\n    }\n    try {\n        return `/ipfs/${CID.parse(string).toV1().toString()}`;\n    }\n    catch {\n        // fall through\n    }\n    throw new InvalidValueError('Value must be a valid content path starting with /');\n}\n/**\n * Normalizes the given record value. It ensures it is a PeerID, a CID or a\n * string starting with '/'. PeerIDs become `/ipns/${cidV1Libp2pKey}`,\n * CIDs become `/ipfs/${cidAsV1}`.\n */\nexport function normalizeValue(value) {\n    if (value != null) {\n        const cid = asCID(value);\n        // if we have a CID, turn it into an ipfs path\n        if (cid != null) {\n            // PeerID encoded as a CID\n            if (cid.code === LIBP2P_CID_CODEC) {\n                return `/ipns/${cid.toString(base36)}`;\n            }\n            return `/ipfs/${cid.toV1().toString()}`;\n        }\n        if (hasBytes(value)) {\n            return `/ipns/${base36.encode(value.bytes)}`;\n        }\n        // if we have a path, check it is a valid path\n        const string = value.toString().trim();\n        if (string.startsWith('/') && string.length > 1) {\n            return string;\n        }\n    }\n    throw new InvalidValueError('Value must be a valid content path starting with /');\n}\nfunction validateCborDataMatchesPbData(entry) {\n    if (entry.data == null) {\n        throw new InvalidRecordDataError('Record data is missing');\n    }\n    const data = parseCborData(entry.data);\n    if (!uint8ArrayEquals(data.Value, entry.value ?? new Uint8Array(0))) {\n        throw new SignatureVerificationError('Field \"value\" did not match between protobuf and CBOR');\n    }\n    if (!uint8ArrayEquals(data.Validity, entry.validity ?? new Uint8Array(0))) {\n        throw new SignatureVerificationError('Field \"validity\" did not match between protobuf and CBOR');\n    }\n    if (data.ValidityType !== entry.validityType) {\n        throw new SignatureVerificationError('Field \"validityType\" did not match between protobuf and CBOR');\n    }\n    if (data.Sequence !== entry.sequence) {\n        throw new SignatureVerificationError('Field \"sequence\" did not match between protobuf and CBOR');\n    }\n    if (data.TTL !== entry.ttl) {\n        throw new SignatureVerificationError('Field \"ttl\" did not match between protobuf and CBOR');\n    }\n}\nfunction hasBytes(obj) {\n    return obj.bytes instanceof Uint8Array;\n}\nfunction hasToCID(obj) {\n    return typeof obj?.toCID === 'function';\n}\nfunction asCID(obj) {\n    if (hasToCID(obj)) {\n        return obj.toCID();\n    }\n    // try parsing as a CID string\n    try {\n        return CID.parse(obj);\n    }\n    catch {\n        // fall through\n    }\n    return CID.asCID(obj);\n}\nexport function isCodec(digest, codec) {\n    return digest.code === codec;\n}\n//# sourceMappingURL=utils.js.map","import { publicKeyFromMultihash } from '@libp2p/crypto/keys';\nimport { logger } from '@libp2p/logger';\nimport NanoDate from 'timestamp-nano';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { InvalidEmbeddedPublicKeyError, RecordExpiredError, RecordTooLargeError, SignatureVerificationError, UnsupportedValidityError } from './errors.js';\nimport { IpnsEntry } from './pb/ipns.js';\nimport { extractPublicKeyFromIPNSRecord, ipnsRecordDataForV2Sig, isCodec, multihashFromIPNSRoutingKey, multihashToIPNSRoutingKey, unmarshalIPNSRecord } from './utils.js';\nconst log = logger('ipns:validator');\n/**\n * Limit valid IPNS record sizes to 10kb\n */\nconst MAX_RECORD_SIZE = 1024 * 10;\n/**\n * Validates the given IPNS Record against the given public key. We need a \"raw\"\n * record in order to be able to access to all of its fields.\n */\nexport const validate = async (publicKey, buf) => {\n    // unmarshal ensures that (1) SignatureV2 and Data are present, (2) that ValidityType\n    // and Validity are of valid types and have a value, (3) that CBOR data matches protobuf\n    // if it's a V1+V2 record.\n    const record = unmarshalIPNSRecord(buf);\n    // Validate Signature V2\n    let isValid;\n    try {\n        const dataForSignature = ipnsRecordDataForV2Sig(record.data);\n        isValid = await publicKey.verify(dataForSignature, record.signatureV2);\n    }\n    catch (err) {\n        isValid = false;\n    }\n    if (!isValid) {\n        log.error('record signature verification failed');\n        throw new SignatureVerificationError('Record signature verification failed');\n    }\n    // Validate according to the validity type\n    if (record.validityType === IpnsEntry.ValidityType.EOL) {\n        if (NanoDate.fromString(record.validity).toDate().getTime() < Date.now()) {\n            log.error('record has expired');\n            throw new RecordExpiredError('record has expired');\n        }\n    }\n    else if (record.validityType != null) {\n        log.error('the validity type is unsupported');\n        throw new UnsupportedValidityError('The validity type is unsupported');\n    }\n    log('ipns record for %s is valid', record.value);\n};\nexport async function ipnsValidator(key, marshalledData) {\n    if (marshalledData.byteLength > MAX_RECORD_SIZE) {\n        throw new RecordTooLargeError('The record is too large');\n    }\n    // try to extract public key from routing key\n    const routingMultihash = multihashFromIPNSRoutingKey(key);\n    let routingPubKey;\n    // identity hash\n    if (isCodec(routingMultihash, 0x0)) {\n        routingPubKey = publicKeyFromMultihash(routingMultihash);\n    }\n    // extract public key from record\n    const receivedRecord = unmarshalIPNSRecord(marshalledData);\n    const recordPubKey = extractPublicKeyFromIPNSRecord(receivedRecord) ?? routingPubKey;\n    if (recordPubKey == null) {\n        throw new InvalidEmbeddedPublicKeyError('Could not extract public key from IPNS record or routing key');\n    }\n    const routingKey = multihashToIPNSRoutingKey(recordPubKey.toMultihash());\n    if (!uint8ArrayEquals(key, routingKey)) {\n        throw new InvalidEmbeddedPublicKeyError('Embedded public key did not match routing key');\n    }\n    // Record validation\n    await validate(recordPubKey, marshalledData);\n}\n//# sourceMappingURL=validator.js.map","export default async function* parse(source) {\n    const matcher = /\\r?\\n/;\n    const decoder = new TextDecoder('utf8');\n    let buffer = '';\n    for await (let chunk of source) {\n        if (typeof chunk === 'string') {\n            chunk = new TextEncoder().encode(chunk);\n        }\n        buffer += decoder.decode(chunk, { stream: true });\n        const parts = buffer.split(matcher);\n        buffer = parts.pop() ?? '';\n        for (let i = 0; i < parts.length; i++) {\n            yield JSON.parse(parts[i]);\n        }\n    }\n    buffer += decoder.decode();\n    if (buffer !== '') {\n        yield JSON.parse(buffer);\n    }\n}\n//# sourceMappingURL=parse.js.map","export class TimeoutError extends Error {\n\tconstructor(message) {\n\t\tsuper(message);\n\t\tthis.name = 'TimeoutError';\n\t}\n}\n\n/**\nAn error to be thrown when the request is aborted by AbortController.\nDOMException is thrown instead of this Error when DOMException is available.\n*/\nexport class AbortError extends Error {\n\tconstructor(message) {\n\t\tsuper();\n\t\tthis.name = 'AbortError';\n\t\tthis.message = message;\n\t}\n}\n\n/**\nTODO: Remove AbortError and just throw DOMException when targeting Node 18.\n*/\nconst getDOMException = errorMessage => globalThis.DOMException === undefined\n\t? new AbortError(errorMessage)\n\t: new DOMException(errorMessage);\n\n/**\nTODO: Remove below function and just 'reject(signal.reason)' when targeting Node 18.\n*/\nconst getAbortedReason = signal => {\n\tconst reason = signal.reason === undefined\n\t\t? getDOMException('This operation was aborted.')\n\t\t: signal.reason;\n\n\treturn reason instanceof Error ? reason : getDOMException(reason);\n};\n\nexport default function pTimeout(promise, options) {\n\tconst {\n\t\tmilliseconds,\n\t\tfallback,\n\t\tmessage,\n\t\tcustomTimers = {setTimeout, clearTimeout},\n\t} = options;\n\n\tlet timer;\n\n\tconst wrappedPromise = new Promise((resolve, reject) => {\n\t\tif (typeof milliseconds !== 'number' || Math.sign(milliseconds) !== 1) {\n\t\t\tthrow new TypeError(`Expected \\`milliseconds\\` to be a positive number, got \\`${milliseconds}\\``);\n\t\t}\n\n\t\tif (options.signal) {\n\t\t\tconst {signal} = options;\n\t\t\tif (signal.aborted) {\n\t\t\t\treject(getAbortedReason(signal));\n\t\t\t}\n\n\t\t\tconst abortHandler = () => {\n\t\t\t\treject(getAbortedReason(signal));\n\t\t\t};\n\n\t\t\tsignal.addEventListener('abort', abortHandler, {once: true});\n\n\t\t\tpromise.finally(() => {\n\t\t\t\tsignal.removeEventListener('abort', abortHandler);\n\t\t\t});\n\t\t}\n\n\t\tif (milliseconds === Number.POSITIVE_INFINITY) {\n\t\t\tpromise.then(resolve, reject);\n\t\t\treturn;\n\t\t}\n\n\t\t// We create the error outside of `setTimeout` to preserve the stack trace.\n\t\tconst timeoutError = new TimeoutError();\n\n\t\ttimer = customTimers.setTimeout.call(undefined, () => {\n\t\t\tif (fallback) {\n\t\t\t\ttry {\n\t\t\t\t\tresolve(fallback());\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (typeof promise.cancel === 'function') {\n\t\t\t\tpromise.cancel();\n\t\t\t}\n\n\t\t\tif (message === false) {\n\t\t\t\tresolve();\n\t\t\t} else if (message instanceof Error) {\n\t\t\t\treject(message);\n\t\t\t} else {\n\t\t\t\ttimeoutError.message = message ?? `Promise timed out after ${milliseconds} milliseconds`;\n\t\t\t\treject(timeoutError);\n\t\t\t}\n\t\t}, milliseconds);\n\n\t\t(async () => {\n\t\t\ttry {\n\t\t\t\tresolve(await promise);\n\t\t\t} catch (error) {\n\t\t\t\treject(error);\n\t\t\t}\n\t\t})();\n\t});\n\n\tconst cancelablePromise = wrappedPromise.finally(() => {\n\t\tcancelablePromise.clear();\n\t});\n\n\tcancelablePromise.clear = () => {\n\t\tcustomTimers.clearTimeout.call(undefined, timer);\n\t\ttimer = undefined;\n\t};\n\n\treturn cancelablePromise;\n}\n","// Port of lower_bound from https://en.cppreference.com/w/cpp/algorithm/lower_bound\n// Used to compute insertion index to keep queue sorted after insertion\nexport default function lowerBound(array, value, comparator) {\n    let first = 0;\n    let count = array.length;\n    while (count > 0) {\n        const step = Math.trunc(count / 2);\n        let it = first + step;\n        if (comparator(array[it], value) <= 0) {\n            first = ++it;\n            count -= step + 1;\n        }\n        else {\n            count = step;\n        }\n    }\n    return first;\n}\n","import lowerBound from './lower-bound.js';\nexport default class PriorityQueue {\n    #queue = [];\n    enqueue(run, options) {\n        options = {\n            priority: 0,\n            ...options,\n        };\n        const element = {\n            priority: options.priority,\n            run,\n        };\n        if (this.size && this.#queue[this.size - 1].priority >= options.priority) {\n            this.#queue.push(element);\n            return;\n        }\n        const index = lowerBound(this.#queue, element, (a, b) => b.priority - a.priority);\n        this.#queue.splice(index, 0, element);\n    }\n    dequeue() {\n        const item = this.#queue.shift();\n        return item?.run;\n    }\n    filter(options) {\n        return this.#queue.filter((element) => element.priority === options.priority).map((element) => element.run);\n    }\n    get size() {\n        return this.#queue.length;\n    }\n}\n","import { EventEmitter } from 'eventemitter3';\nimport pTimeout, { TimeoutError } from 'p-timeout';\nimport PriorityQueue from './priority-queue.js';\n/**\nPromise queue with concurrency control.\n*/\nexport default class PQueue extends EventEmitter {\n    #carryoverConcurrencyCount;\n    #isIntervalIgnored;\n    #intervalCount = 0;\n    #intervalCap;\n    #interval;\n    #intervalEnd = 0;\n    #intervalId;\n    #timeoutId;\n    #queue;\n    #queueClass;\n    #pending = 0;\n    // The `!` is needed because of https://github.com/microsoft/TypeScript/issues/32194\n    #concurrency;\n    #isPaused;\n    #throwOnTimeout;\n    /**\n    Per-operation timeout in milliseconds. Operations fulfill once `timeout` elapses if they haven't already.\n\n    Applies to each future operation.\n    */\n    timeout;\n    // TODO: The `throwOnTimeout` option should affect the return types of `add()` and `addAll()`\n    constructor(options) {\n        super();\n        // eslint-disable-next-line @typescript-eslint/consistent-type-assertions\n        options = {\n            carryoverConcurrencyCount: false,\n            intervalCap: Number.POSITIVE_INFINITY,\n            interval: 0,\n            concurrency: Number.POSITIVE_INFINITY,\n            autoStart: true,\n            queueClass: PriorityQueue,\n            ...options,\n        };\n        if (!(typeof options.intervalCap === 'number' && options.intervalCap >= 1)) {\n            throw new TypeError(`Expected \\`intervalCap\\` to be a number from 1 and up, got \\`${options.intervalCap?.toString() ?? ''}\\` (${typeof options.intervalCap})`);\n        }\n        if (options.interval === undefined || !(Number.isFinite(options.interval) && options.interval >= 0)) {\n            throw new TypeError(`Expected \\`interval\\` to be a finite number >= 0, got \\`${options.interval?.toString() ?? ''}\\` (${typeof options.interval})`);\n        }\n        this.#carryoverConcurrencyCount = options.carryoverConcurrencyCount;\n        this.#isIntervalIgnored = options.intervalCap === Number.POSITIVE_INFINITY || options.interval === 0;\n        this.#intervalCap = options.intervalCap;\n        this.#interval = options.interval;\n        this.#queue = new options.queueClass();\n        this.#queueClass = options.queueClass;\n        this.concurrency = options.concurrency;\n        this.timeout = options.timeout;\n        this.#throwOnTimeout = options.throwOnTimeout === true;\n        this.#isPaused = options.autoStart === false;\n    }\n    get #doesIntervalAllowAnother() {\n        return this.#isIntervalIgnored || this.#intervalCount < this.#intervalCap;\n    }\n    get #doesConcurrentAllowAnother() {\n        return this.#pending < this.#concurrency;\n    }\n    #next() {\n        this.#pending--;\n        this.#tryToStartAnother();\n        this.emit('next');\n    }\n    #onResumeInterval() {\n        this.#onInterval();\n        this.#initializeIntervalIfNeeded();\n        this.#timeoutId = undefined;\n    }\n    get #isIntervalPaused() {\n        const now = Date.now();\n        if (this.#intervalId === undefined) {\n            const delay = this.#intervalEnd - now;\n            if (delay < 0) {\n                // Act as the interval was done\n                // We don't need to resume it here because it will be resumed on line 160\n                this.#intervalCount = (this.#carryoverConcurrencyCount) ? this.#pending : 0;\n            }\n            else {\n                // Act as the interval is pending\n                if (this.#timeoutId === undefined) {\n                    this.#timeoutId = setTimeout(() => {\n                        this.#onResumeInterval();\n                    }, delay);\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    #tryToStartAnother() {\n        if (this.#queue.size === 0) {\n            // We can clear the interval (\"pause\")\n            // Because we can redo it later (\"resume\")\n            if (this.#intervalId) {\n                clearInterval(this.#intervalId);\n            }\n            this.#intervalId = undefined;\n            this.emit('empty');\n            if (this.#pending === 0) {\n                this.emit('idle');\n            }\n            return false;\n        }\n        if (!this.#isPaused) {\n            const canInitializeInterval = !this.#isIntervalPaused;\n            if (this.#doesIntervalAllowAnother && this.#doesConcurrentAllowAnother) {\n                const job = this.#queue.dequeue();\n                if (!job) {\n                    return false;\n                }\n                this.emit('active');\n                job();\n                if (canInitializeInterval) {\n                    this.#initializeIntervalIfNeeded();\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    #initializeIntervalIfNeeded() {\n        if (this.#isIntervalIgnored || this.#intervalId !== undefined) {\n            return;\n        }\n        this.#intervalId = setInterval(() => {\n            this.#onInterval();\n        }, this.#interval);\n        this.#intervalEnd = Date.now() + this.#interval;\n    }\n    #onInterval() {\n        if (this.#intervalCount === 0 && this.#pending === 0 && this.#intervalId) {\n            clearInterval(this.#intervalId);\n            this.#intervalId = undefined;\n        }\n        this.#intervalCount = this.#carryoverConcurrencyCount ? this.#pending : 0;\n        this.#processQueue();\n    }\n    /**\n    Executes all queued functions until it reaches the limit.\n    */\n    #processQueue() {\n        // eslint-disable-next-line no-empty\n        while (this.#tryToStartAnother()) { }\n    }\n    get concurrency() {\n        return this.#concurrency;\n    }\n    set concurrency(newConcurrency) {\n        if (!(typeof newConcurrency === 'number' && newConcurrency >= 1)) {\n            throw new TypeError(`Expected \\`concurrency\\` to be a number from 1 and up, got \\`${newConcurrency}\\` (${typeof newConcurrency})`);\n        }\n        this.#concurrency = newConcurrency;\n        this.#processQueue();\n    }\n    async #throwOnAbort(signal) {\n        return new Promise((_resolve, reject) => {\n            signal.addEventListener('abort', () => {\n                reject(signal.reason);\n            }, { once: true });\n        });\n    }\n    async add(function_, options = {}) {\n        options = {\n            timeout: this.timeout,\n            throwOnTimeout: this.#throwOnTimeout,\n            ...options,\n        };\n        return new Promise((resolve, reject) => {\n            this.#queue.enqueue(async () => {\n                this.#pending++;\n                this.#intervalCount++;\n                try {\n                    options.signal?.throwIfAborted();\n                    let operation = function_({ signal: options.signal });\n                    if (options.timeout) {\n                        operation = pTimeout(Promise.resolve(operation), { milliseconds: options.timeout });\n                    }\n                    if (options.signal) {\n                        operation = Promise.race([operation, this.#throwOnAbort(options.signal)]);\n                    }\n                    const result = await operation;\n                    resolve(result);\n                    this.emit('completed', result);\n                }\n                catch (error) {\n                    if (error instanceof TimeoutError && !options.throwOnTimeout) {\n                        resolve();\n                        return;\n                    }\n                    reject(error);\n                    this.emit('error', error);\n                }\n                finally {\n                    this.#next();\n                }\n            }, options);\n            this.emit('add');\n            this.#tryToStartAnother();\n        });\n    }\n    async addAll(functions, options) {\n        return Promise.all(functions.map(async (function_) => this.add(function_, options)));\n    }\n    /**\n    Start (or resume) executing enqueued tasks within concurrency limit. No need to call this if queue is not paused (via `options.autoStart = false` or by `.pause()` method.)\n    */\n    start() {\n        if (!this.#isPaused) {\n            return this;\n        }\n        this.#isPaused = false;\n        this.#processQueue();\n        return this;\n    }\n    /**\n    Put queue execution on hold.\n    */\n    pause() {\n        this.#isPaused = true;\n    }\n    /**\n    Clear the queue.\n    */\n    clear() {\n        this.#queue = new this.#queueClass();\n    }\n    /**\n    Can be called multiple times. Useful if you for example add additional items at a later time.\n\n    @returns A promise that settles when the queue becomes empty.\n    */\n    async onEmpty() {\n        // Instantly resolve if the queue is empty\n        if (this.#queue.size === 0) {\n            return;\n        }\n        await this.#onEvent('empty');\n    }\n    /**\n    @returns A promise that settles when the queue size is less than the given limit: `queue.size < limit`.\n\n    If you want to avoid having the queue grow beyond a certain size you can `await queue.onSizeLessThan()` before adding a new item.\n\n    Note that this only limits the number of items waiting to start. There could still be up to `concurrency` jobs already running that this call does not include in its calculation.\n    */\n    async onSizeLessThan(limit) {\n        // Instantly resolve if the queue is empty.\n        if (this.#queue.size < limit) {\n            return;\n        }\n        await this.#onEvent('next', () => this.#queue.size < limit);\n    }\n    /**\n    The difference with `.onEmpty` is that `.onIdle` guarantees that all work from the queue has finished. `.onEmpty` merely signals that the queue is empty, but it could mean that some promises haven't completed yet.\n\n    @returns A promise that settles when the queue becomes empty, and all promises have completed; `queue.size === 0 && queue.pending === 0`.\n    */\n    async onIdle() {\n        // Instantly resolve if none pending and if nothing else is queued\n        if (this.#pending === 0 && this.#queue.size === 0) {\n            return;\n        }\n        await this.#onEvent('idle');\n    }\n    async #onEvent(event, filter) {\n        return new Promise(resolve => {\n            const listener = () => {\n                if (filter && !filter()) {\n                    return;\n                }\n                this.off(event, listener);\n                resolve();\n            };\n            this.on(event, listener);\n        });\n    }\n    /**\n    Size of the queue, the number of queued items waiting to run.\n    */\n    get size() {\n        return this.#queue.size;\n    }\n    /**\n    Size of the queue, filtered by the given options.\n\n    For example, this can be used to find the number of items remaining in the queue with a specific priority level.\n    */\n    sizeBy(options) {\n        // eslint-disable-next-line unicorn/no-array-callback-reference\n        return this.#queue.filter(options).length;\n    }\n    /**\n    Number of running items (no longer in the queue).\n    */\n    get pending() {\n        return this.#pending;\n    }\n    /**\n    Whether the queue is currently paused.\n    */\n    get isPaused() {\n        return this.#isPaused;\n    }\n}\n","export class InvalidRequestError extends Error {\n    static name = 'InvalidRequestError';\n    constructor(message = 'Invalid request') {\n        super(message);\n        this.name = 'InvalidRequestError';\n    }\n}\nexport class BadResponseError extends Error {\n    static name = 'BadResponseError';\n    constructor(message = 'Bad response') {\n        super(message);\n        this.name = 'BadResponseError';\n    }\n}\n//# sourceMappingURL=errors.js.map","/**\n * @packageDocumentation\n *\n * Return the first value in an (async)iterable\n *\n * @example\n *\n * ```javascript\n * import first from 'it-first'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * const res = first(values)\n *\n * console.info(res) // 0\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import first from 'it-first'\n *\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const res = await first(values())\n *\n * console.info(res) // 0\n * ```\n */\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction first(source) {\n    if (isAsyncIterable(source)) {\n        return (async () => {\n            for await (const entry of source) { // eslint-disable-line no-unreachable-loop\n                return entry;\n            }\n            return undefined;\n        })();\n    }\n    for (const entry of source) { // eslint-disable-line no-unreachable-loop\n        return entry;\n    }\n    return undefined;\n}\nexport default first;\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Lets you look at the contents of an async iterator and decide what to do\n *\n * @example\n *\n * ```javascript\n * import peekable from 'it-peekable'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * const it = peekable(value)\n *\n * const first = it.peek()\n *\n * console.info(first) // 0\n *\n * it.push(first)\n *\n * console.info([...it])\n * // [ 0, 1, 2, 3, 4 ]\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import peekable from 'it-peekable'\n *\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const it = peekable(values())\n *\n * const first = await it.peek()\n *\n * console.info(first) // 0\n *\n * it.push(first)\n *\n * console.info(await all(it))\n * // [ 0, 1, 2, 3, 4 ]\n * ```\n */\nfunction peekable(iterable) {\n    // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable\n    const [iterator, symbol] = iterable[Symbol.asyncIterator] != null\n        // @ts-expect-error can't use Symbol.asyncIterator to index iterable since it might be Iterable\n        ? [iterable[Symbol.asyncIterator](), Symbol.asyncIterator]\n        // @ts-expect-error can't use Symbol.iterator to index iterable since it might be AsyncIterable\n        : [iterable[Symbol.iterator](), Symbol.iterator];\n    const queue = [];\n    // @ts-expect-error can't use symbol to index peekable\n    return {\n        peek: () => {\n            return iterator.next();\n        },\n        push: (value) => {\n            queue.push(value);\n        },\n        next: () => {\n            if (queue.length > 0) {\n                return {\n                    done: false,\n                    value: queue.shift()\n                };\n            }\n            return iterator.next();\n        },\n        [symbol]() {\n            return this;\n        }\n    };\n}\nexport default peekable;\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Convert one value from an (async)iterator into another.\n *\n * @example\n *\n * ```javascript\n * import map from 'it-map'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * const result = map(values, (val, index) => val++)\n *\n * console.info(result) // [1, 2, 3, 4, 5]\n * ```\n *\n * Async sources and transforms must be awaited:\n *\n * ```javascript\n * import map from 'it-map'\n *\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const result = await map(values(), async (val, index) => val++)\n *\n * console.info(result) // [1, 2, 3, 4, 5]\n * ```\n */\nimport peek from 'it-peekable';\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction map(source, func) {\n    let index = 0;\n    if (isAsyncIterable(source)) {\n        return (async function* () {\n            for await (const val of source) {\n                yield func(val, index++);\n            }\n        })();\n    }\n    // if mapping function returns a promise we have to return an async generator\n    const peekable = peek(source);\n    const { value, done } = peekable.next();\n    if (done === true) {\n        return (function* () { }());\n    }\n    const res = func(value, index++);\n    // @ts-expect-error .then is not present on O\n    if (typeof res.then === 'function') {\n        return (async function* () {\n            yield await res;\n            for await (const val of peekable) {\n                yield func(val, index++);\n            }\n        })();\n    }\n    const fn = func;\n    return (function* () {\n        yield res;\n        for (const val of peekable) {\n            yield fn(val, index++);\n        }\n    })();\n}\nexport default map;\n//# sourceMappingURL=index.js.map","import { NotFoundError } from '@libp2p/interface';\nimport { marshalIPNSRecord, multihashFromIPNSRoutingKey, unmarshalIPNSRecord } from 'ipns';\nimport first from 'it-first';\nimport map from 'it-map';\nimport { CID } from 'multiformats/cid';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nconst IPNS_PREFIX = uint8ArrayFromString('/ipns/');\nfunction isIPNSKey(key) {\n    return uint8ArrayEquals(key.subarray(0, IPNS_PREFIX.byteLength), IPNS_PREFIX);\n}\n/**\n * Wrapper class to convert [http-routing-v1 content events](https://specs.ipfs.tech/routing/http-routing-v1/#response-body) into returned values\n */\nexport class DelegatedRoutingV1HttpApiClientContentRouting {\n    client;\n    constructor(client) {\n        this.client = client;\n    }\n    async *findProviders(cid, options = {}) {\n        yield* map(this.client.getProviders(cid, options), (record) => {\n            return {\n                id: record.ID,\n                multiaddrs: record.Addrs ?? []\n            };\n        });\n    }\n    async provide() {\n        // noop\n    }\n    async cancelReprovide() {\n        // noop\n    }\n    async put(key, value, options) {\n        if (!isIPNSKey(key)) {\n            return;\n        }\n        const digest = multihashFromIPNSRoutingKey(key);\n        const cid = CID.createV1(0x72, digest);\n        const record = unmarshalIPNSRecord(value);\n        await this.client.putIPNS(cid, record, options);\n    }\n    async get(key, options) {\n        if (!isIPNSKey(key)) {\n            throw new NotFoundError('Not found');\n        }\n        const digest = multihashFromIPNSRoutingKey(key);\n        const cid = CID.createV1(0x72, digest);\n        try {\n            const record = await this.client.getIPNS(cid, options);\n            return marshalIPNSRecord(record);\n        }\n        catch (err) {\n            // BadResponseError is thrown when the response had no body, which means\n            // the record couldn't be found\n            if (err.name === 'BadResponseError') {\n                throw new NotFoundError('Not found');\n            }\n            throw err;\n        }\n    }\n}\n/**\n * Wrapper class to convert [http-routing-v1](https://specs.ipfs.tech/routing/http-routing-v1/#response-body-0) events into expected libp2p values\n */\nexport class DelegatedRoutingV1HttpApiClientPeerRouting {\n    client;\n    constructor(client) {\n        this.client = client;\n    }\n    async findPeer(peerId, options = {}) {\n        const peer = await first(this.client.getPeers(peerId, options));\n        if (peer != null) {\n            return {\n                id: peer.ID,\n                multiaddrs: peer.Addrs ?? []\n            };\n        }\n        throw new NotFoundError('Not found');\n    }\n    async *getClosestPeers(key, options = {}) {\n        // noop\n    }\n}\n//# sourceMappingURL=routings.js.map","import { NotFoundError, contentRoutingSymbol, peerRoutingSymbol, setMaxListeners } from '@libp2p/interface';\nimport { logger } from '@libp2p/logger';\nimport { peerIdFromString } from '@libp2p/peer-id';\nimport { multiaddr } from '@multiformats/multiaddr';\nimport { anySignal } from 'any-signal';\nimport toIt from 'browser-readablestream-to-it';\nimport { unmarshalIPNSRecord, marshalIPNSRecord, multihashToIPNSRoutingKey } from 'ipns';\nimport { ipnsValidator } from 'ipns/validator';\nimport { parse as ndjson } from 'it-ndjson';\nimport defer from 'p-defer';\nimport PQueue from 'p-queue';\nimport { BadResponseError, InvalidRequestError } from './errors.js';\nimport { DelegatedRoutingV1HttpApiClientContentRouting, DelegatedRoutingV1HttpApiClientPeerRouting } from './routings.js';\nconst log = logger('delegated-routing-v1-http-api-client');\nconst defaultValues = {\n    concurrentRequests: 4,\n    timeout: 30e3\n};\nexport class DefaultDelegatedRoutingV1HttpApiClient {\n    started;\n    httpQueue;\n    shutDownController;\n    clientUrl;\n    timeout;\n    contentRouting;\n    peerRouting;\n    filterAddrs;\n    filterProtocols;\n    /**\n     * Create a new DelegatedContentRouting instance\n     */\n    constructor(url, init = {}) {\n        this.started = false;\n        this.shutDownController = new AbortController();\n        setMaxListeners(Infinity, this.shutDownController.signal);\n        this.httpQueue = new PQueue({\n            concurrency: init.concurrentRequests ?? defaultValues.concurrentRequests\n        });\n        this.clientUrl = url instanceof URL ? url : new URL(url);\n        this.timeout = init.timeout ?? defaultValues.timeout;\n        this.filterAddrs = init.filterAddrs;\n        this.filterProtocols = init.filterProtocols;\n        this.contentRouting = new DelegatedRoutingV1HttpApiClientContentRouting(this);\n        this.peerRouting = new DelegatedRoutingV1HttpApiClientPeerRouting(this);\n    }\n    get [contentRoutingSymbol]() {\n        return this.contentRouting;\n    }\n    get [peerRoutingSymbol]() {\n        return this.peerRouting;\n    }\n    isStarted() {\n        return this.started;\n    }\n    start() {\n        this.started = true;\n    }\n    stop() {\n        this.httpQueue.clear();\n        this.shutDownController.abort();\n        this.started = false;\n    }\n    async *getProviders(cid, options = {}) {\n        log('getProviders starts: %c', cid);\n        const timeoutSignal = AbortSignal.timeout(this.timeout);\n        const signal = anySignal([this.shutDownController.signal, timeoutSignal, options.signal]);\n        setMaxListeners(Infinity, timeoutSignal, signal);\n        const onStart = defer();\n        const onFinish = defer();\n        void this.httpQueue.add(async () => {\n            onStart.resolve();\n            return onFinish.promise;\n        });\n        try {\n            await onStart.promise;\n            // https://specs.ipfs.tech/routing/http-routing-v1/\n            const url = new URL(`${this.clientUrl}routing/v1/providers/${cid.toString()}`);\n            this.#addFilterParams(url, options.filterAddrs, options.filterProtocols);\n            const getOptions = { headers: { Accept: 'application/x-ndjson' }, signal };\n            const res = await fetch(url, getOptions);\n            if (res.status === 404) {\n                // https://specs.ipfs.tech/routing/http-routing-v1/#response-status-codes\n                // 404 (Not Found): must be returned if no matching records are found\n                throw new NotFoundError('No matching records found');\n            }\n            if (res.status === 422) {\n                // https://specs.ipfs.tech/routing/http-routing-v1/#response-status-codes\n                // 422 (Unprocessable Entity): request does not conform to schema or semantic constraints\n                throw new InvalidRequestError('Request does not conform to schema or semantic constraints');\n            }\n            if (res.body == null) {\n                throw new BadResponseError('Routing response had no body');\n            }\n            const contentType = res.headers.get('Content-Type');\n            if (contentType === 'application/json') {\n                const body = await res.json();\n                for (const provider of body.Providers) {\n                    const record = this.#conformToPeerSchema(provider);\n                    if (record != null) {\n                        yield record;\n                    }\n                }\n            }\n            else {\n                for await (const provider of ndjson(toIt(res.body))) {\n                    const record = this.#conformToPeerSchema(provider);\n                    if (record != null) {\n                        yield record;\n                    }\n                }\n            }\n        }\n        catch (err) {\n            log.error('getProviders errored:', err);\n        }\n        finally {\n            signal.clear();\n            onFinish.resolve();\n            log('getProviders finished: %c', cid);\n        }\n    }\n    async *getPeers(peerId, options = {}) {\n        log('getPeers starts: %c', peerId);\n        const timeoutSignal = AbortSignal.timeout(this.timeout);\n        const signal = anySignal([this.shutDownController.signal, timeoutSignal, options.signal]);\n        setMaxListeners(Infinity, timeoutSignal, signal);\n        const onStart = defer();\n        const onFinish = defer();\n        void this.httpQueue.add(async () => {\n            onStart.resolve();\n            return onFinish.promise;\n        });\n        try {\n            await onStart.promise;\n            // https://specs.ipfs.tech/routing/http-routing-v1/\n            const url = new URL(`${this.clientUrl}routing/v1/peers/${peerId.toCID().toString()}`);\n            this.#addFilterParams(url, options.filterAddrs, options.filterProtocols);\n            const getOptions = { headers: { Accept: 'application/x-ndjson' }, signal };\n            const res = await fetch(url, getOptions);\n            if (res.status === 404) {\n                // https://specs.ipfs.tech/routing/http-routing-v1/#response-status-codes\n                // 404 (Not Found): must be returned if no matching records are found.\n                throw new NotFoundError('No matching records found');\n            }\n            if (res.status === 422) {\n                // https://specs.ipfs.tech/routing/http-routing-v1/#response-status-codes\n                // 422 (Unprocessable Entity): request does not conform to schema or semantic constraints\n                throw new InvalidRequestError('Request does not conform to schema or semantic constraints');\n            }\n            if (res.body == null) {\n                throw new BadResponseError('Routing response had no body');\n            }\n            const contentType = res.headers.get('Content-Type');\n            if (contentType === 'application/json') {\n                const body = await res.json();\n                for (const peer of body.Peers) {\n                    const record = this.#conformToPeerSchema(peer);\n                    if (record != null) {\n                        yield record;\n                    }\n                }\n            }\n            else {\n                for await (const peer of ndjson(toIt(res.body))) {\n                    const record = this.#conformToPeerSchema(peer);\n                    if (record != null) {\n                        yield record;\n                    }\n                }\n            }\n        }\n        catch (err) {\n            log.error('getPeers errored:', err);\n        }\n        finally {\n            signal.clear();\n            onFinish.resolve();\n            log('getPeers finished: %c', peerId);\n        }\n    }\n    async getIPNS(libp2pKey, options = {}) {\n        log('getIPNS starts: %s', libp2pKey);\n        const timeoutSignal = AbortSignal.timeout(this.timeout);\n        const signal = anySignal([this.shutDownController.signal, timeoutSignal, options.signal]);\n        setMaxListeners(Infinity, timeoutSignal, signal);\n        const onStart = defer();\n        const onFinish = defer();\n        void this.httpQueue.add(async () => {\n            onStart.resolve();\n            return onFinish.promise;\n        });\n        // https://specs.ipfs.tech/routing/http-routing-v1/\n        const resource = `${this.clientUrl}routing/v1/ipns/${libp2pKey}`;\n        try {\n            await onStart.promise;\n            const getOptions = { headers: { Accept: 'application/vnd.ipfs.ipns-record' }, signal };\n            const res = await fetch(resource, getOptions);\n            log('getIPNS GET %s %d', resource, res.status);\n            if (res.status === 404) {\n                // https://specs.ipfs.tech/routing/http-routing-v1/#response-status-codes\n                // 404 (Not Found): must be returned if no matching records are found\n                throw new NotFoundError('No matching records found');\n            }\n            if (res.status === 422) {\n                // https://specs.ipfs.tech/routing/http-routing-v1/#response-status-codes\n                // 422 (Unprocessable Entity): request does not conform to schema or semantic constraints\n                throw new InvalidRequestError('Request does not conform to schema or semantic constraints');\n            }\n            if (res.body == null) {\n                throw new BadResponseError('GET ipns response had no body');\n            }\n            const buf = await res.arrayBuffer();\n            const body = new Uint8Array(buf, 0, buf.byteLength);\n            if (options.validate !== false) {\n                await ipnsValidator(multihashToIPNSRoutingKey(libp2pKey.multihash), body);\n            }\n            return unmarshalIPNSRecord(body);\n        }\n        catch (err) {\n            log.error('getIPNS GET %s error:', resource, err);\n            throw err;\n        }\n        finally {\n            signal.clear();\n            onFinish.resolve();\n            log('getIPNS finished: %s', libp2pKey);\n        }\n    }\n    async putIPNS(libp2pKey, record, options = {}) {\n        log('putIPNS starts: %c', libp2pKey);\n        const timeoutSignal = AbortSignal.timeout(this.timeout);\n        const signal = anySignal([this.shutDownController.signal, timeoutSignal, options.signal]);\n        setMaxListeners(Infinity, timeoutSignal, signal);\n        const onStart = defer();\n        const onFinish = defer();\n        void this.httpQueue.add(async () => {\n            onStart.resolve();\n            return onFinish.promise;\n        });\n        // https://specs.ipfs.tech/routing/http-routing-v1/\n        const resource = `${this.clientUrl}routing/v1/ipns/${libp2pKey}`;\n        try {\n            await onStart.promise;\n            const body = marshalIPNSRecord(record);\n            const getOptions = { method: 'PUT', headers: { 'Content-Type': 'application/vnd.ipfs.ipns-record' }, body, signal };\n            const res = await fetch(resource, getOptions);\n            log('putIPNS PUT %s %d', resource, res.status);\n            if (res.status !== 200) {\n                throw new BadResponseError('PUT ipns response had status other than 200');\n            }\n        }\n        catch (err) {\n            log.error('putIPNS PUT %s error:', resource, err.stack);\n            throw err;\n        }\n        finally {\n            signal.clear();\n            onFinish.resolve();\n            log('putIPNS finished: %c', libp2pKey);\n        }\n    }\n    #conformToPeerSchema(record) {\n        try {\n            const protocols = [];\n            const multiaddrs = record.Addrs?.map(multiaddr) ?? [];\n            if (record.Protocols != null) {\n                protocols.push(...record.Protocols);\n            }\n            if (record.Protocol != null) {\n                protocols.push(record.Protocol);\n                delete record.Protocol;\n            }\n            return {\n                ...record,\n                Schema: 'peer',\n                ID: peerIdFromString(record.ID),\n                Addrs: multiaddrs,\n                Protocols: protocols\n            };\n        }\n        catch (err) {\n            log.error('could not conform record to peer schema', err);\n        }\n    }\n    #addFilterParams(url, filterAddrs, filterProtocols) {\n        // IPIP-484 filtering. local options filter precedence over global filter\n        if (filterAddrs != null || this.filterAddrs != null) {\n            const adressFilter = filterAddrs?.join(',') ?? this.filterAddrs?.join(',') ?? '';\n            if (adressFilter !== '') {\n                url.searchParams.set('filter-addrs', adressFilter);\n            }\n        }\n        if (filterProtocols != null || this.filterProtocols != null) {\n            const protocolFilter = filterProtocols?.join(',') ?? this.filterProtocols?.join(',') ?? '';\n            if (protocolFilter !== '') {\n                url.searchParams.set('filter-protocols', protocolFilter);\n            }\n        }\n    }\n}\n//# sourceMappingURL=client.js.map","/**\n * @packageDocumentation\n *\n * A client implementation of the IPFS [Delegated Routing V1 HTTP API](https://specs.ipfs.tech/routing/http-routing-v1/) that can be used to interact with any compliant server implementation.\n *\n * @example\n *\n * ```typescript\n * import { createDelegatedRoutingV1HttpApiClient } from '@helia/delegated-routing-v1-http-api-client'\n * import { CID } from 'multiformats/cid'\n *\n * const client = createDelegatedRoutingV1HttpApiClient('https://example.org')\n *\n * for await (const prov of getProviders(CID.parse('QmFoo'))) {\n *   // ...\n * }\n * ```\n *\n * ### How to use with libp2p\n *\n * The client can be configured as a libp2p service, this will enable it as both a {@link https://libp2p.github.io/js-libp2p/interfaces/_libp2p_interface.content_routing.ContentRouting.html | ContentRouting} and a {@link https://libp2p.github.io/js-libp2p/interfaces/_libp2p_interface.peer_routing.PeerRouting.html | PeerRouting} implementation\n *\n * @example\n *\n * ```typescript\n * import { createDelegatedRoutingV1HttpApiClient } from '@helia/delegated-routing-v1-http-api-client'\n * import { createLibp2p } from 'libp2p'\n * import { peerIdFromString } from '@libp2p/peer-id'\n *\n * const client = createDelegatedRoutingV1HttpApiClient('https://example.org')\n * const libp2p = await createLibp2p({\n *   // other config here\n *   services: {\n *     delegatedRouting: client\n *   }\n * })\n *\n * // later this will use the configured HTTP gateway\n * await libp2p.peerRouting.findPeer(peerIdFromString('QmFoo'))\n * ```\n *\n * ### Filtering with IPIP-484\n *\n * The client can be configured to pass filter options to the delegated routing server as defined in IPIP-484.\n * The filter options be set globally, by passing them to the client constructor, or on a per-request basis.\n *\n * @see https://github.com/ipfs/specs/pull/484\n *\n * @example\n *\n * ```typescript\n * import { createDelegatedRoutingV1HttpApiClient } from '@helia/delegated-routing-v1-http-api-client'\n * import { createLibp2p } from 'libp2p'\n * import { peerIdFromString } from '@libp2p/peer-id'\n *\n * // globally set filter options\n * const client = createDelegatedRoutingV1HttpApiClient('https://delegated-ipfs.dev', {\n *   filterProtocols: ['transport-bitswap', 'unknown', 'transport-ipfs-gateway-http'],\n *   filterAddrs: ['webtransport', 'webrtc-direct', 'wss']\n * })\n *\n * // per-request filter options\n * for await (const prov of getProviders(CID.parse('bafy'), {\n *   filterProtocols: ['transport-ipfs-gateway-http'],\n *   filterAddrs: ['!p2p-circuit']\n * })) {\n *   // ...\n * }\n * ```\n */\nimport { DefaultDelegatedRoutingV1HttpApiClient } from './client.js';\n/**\n * Create and return a client to use with a Routing V1 HTTP API server\n */\nexport function createDelegatedRoutingV1HttpApiClient(url, init = {}) {\n    return new DefaultDelegatedRoutingV1HttpApiClient(new URL(url), init);\n}\n//# sourceMappingURL=index.js.map","export function delegatedHTTPRoutingDefaults() {\n    return {\n        filterProtocols: ['unknown', 'transport-bitswap', 'transport-ipfs-gateway-http'],\n        filterAddrs: ['https', 'webtransport', 'webrtc', 'webrtc-direct', 'wss']\n    };\n}\n//# sourceMappingURL=delegated-http-routing-defaults.browser.js.map","import { createDelegatedRoutingV1HttpApiClient } from '@helia/delegated-routing-v1-http-api-client';\nimport { NotFoundError } from '@libp2p/interface';\nimport { marshalIPNSRecord, multihashFromIPNSRoutingKey, unmarshalIPNSRecord } from 'ipns';\nimport first from 'it-first';\nimport map from 'it-map';\nimport { CID } from 'multiformats/cid';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { delegatedHTTPRoutingDefaults } from './utils/delegated-http-routing-defaults.js';\nconst IPNS_PREFIX = uint8ArrayFromString('/ipns/');\nfunction isIPNSKey(key) {\n    return uint8ArrayEquals(key.subarray(0, IPNS_PREFIX.byteLength), IPNS_PREFIX);\n}\nclass DelegatedHTTPRouter {\n    client;\n    constructor(url, init = {}) {\n        this.client = createDelegatedRoutingV1HttpApiClient(url, init);\n    }\n    async provide(cid, options) {\n        // noop\n    }\n    async *findProviders(cid, options) {\n        yield* map(this.client.getProviders(cid, options), (record) => {\n            return {\n                id: record.ID,\n                multiaddrs: record.Addrs,\n                protocols: record.Protocols\n            };\n        });\n    }\n    async put(key, value, options) {\n        if (!isIPNSKey(key)) {\n            return;\n        }\n        const digest = multihashFromIPNSRoutingKey(key);\n        const cid = CID.createV1(0x72, digest);\n        const record = unmarshalIPNSRecord(value);\n        await this.client.putIPNS(cid, record, options);\n    }\n    async get(key, options) {\n        if (!isIPNSKey(key)) {\n            throw new NotFoundError('Not found');\n        }\n        const digest = multihashFromIPNSRoutingKey(key);\n        const cid = CID.createV1(0x72, digest);\n        try {\n            const record = await this.client.getIPNS(cid, options);\n            return marshalIPNSRecord(record);\n        }\n        catch (err) {\n            // BadResponseError is thrown when the response had no body, which means\n            // the record couldn't be found\n            if (err.name === 'BadResponseError') {\n                throw new NotFoundError('Not found');\n            }\n            throw err;\n        }\n    }\n    async findPeer(peerId, options) {\n        const peer = await first(this.client.getPeers(peerId, options));\n        if (peer != null) {\n            return {\n                id: peer.ID,\n                multiaddrs: peer.Addrs ?? []\n            };\n        }\n        throw new NotFoundError('Not found');\n    }\n    async *getClosestPeers(key, options) {\n        // noop\n    }\n}\n/**\n * Creates a Helia Router that connects to an endpoint that supports the [Delegated Routing V1 HTTP API](https://specs.ipfs.tech/routing/http-routing-v1/) spec.\n */\nexport function delegatedHTTPRouting(url, init) {\n    const config = init ?? delegatedHTTPRoutingDefaults();\n    return new DelegatedHTTPRouter(new URL(url), config);\n}\n//# sourceMappingURL=delegated-http-routing.js.map","const word = '[a-fA-F\\\\d:]';\n\nconst boundry = options => options && options.includeBoundaries\n\t? `(?:(?<=\\\\s|^)(?=${word})|(?<=${word})(?=\\\\s|$))`\n\t: '';\n\nconst v4 = '(?:25[0-5]|2[0-4]\\\\d|1\\\\d\\\\d|[1-9]\\\\d|\\\\d)(?:\\\\.(?:25[0-5]|2[0-4]\\\\d|1\\\\d\\\\d|[1-9]\\\\d|\\\\d)){3}';\n\nconst v6segment = '[a-fA-F\\\\d]{1,4}';\n\nconst v6 = `\n(?:\n(?:${v6segment}:){7}(?:${v6segment}|:)|                                    // 1:2:3:4:5:6:7::  1:2:3:4:5:6:7:8\n(?:${v6segment}:){6}(?:${v4}|:${v6segment}|:)|                             // 1:2:3:4:5:6::    1:2:3:4:5:6::8   1:2:3:4:5:6::8  1:2:3:4:5:6::1.2.3.4\n(?:${v6segment}:){5}(?::${v4}|(?::${v6segment}){1,2}|:)|                   // 1:2:3:4:5::      1:2:3:4:5::7:8   1:2:3:4:5::8    1:2:3:4:5::7:1.2.3.4\n(?:${v6segment}:){4}(?:(?::${v6segment}){0,1}:${v4}|(?::${v6segment}){1,3}|:)| // 1:2:3:4::        1:2:3:4::6:7:8   1:2:3:4::8      1:2:3:4::6:7:1.2.3.4\n(?:${v6segment}:){3}(?:(?::${v6segment}){0,2}:${v4}|(?::${v6segment}){1,4}|:)| // 1:2:3::          1:2:3::5:6:7:8   1:2:3::8        1:2:3::5:6:7:1.2.3.4\n(?:${v6segment}:){2}(?:(?::${v6segment}){0,3}:${v4}|(?::${v6segment}){1,5}|:)| // 1:2::            1:2::4:5:6:7:8   1:2::8          1:2::4:5:6:7:1.2.3.4\n(?:${v6segment}:){1}(?:(?::${v6segment}){0,4}:${v4}|(?::${v6segment}){1,6}|:)| // 1::              1::3:4:5:6:7:8   1::8            1::3:4:5:6:7:1.2.3.4\n(?::(?:(?::${v6segment}){0,5}:${v4}|(?::${v6segment}){1,7}|:))             // ::2:3:4:5:6:7:8  ::2:3:4:5:6:7:8  ::8             ::1.2.3.4\n)(?:%[0-9a-zA-Z]{1,})?                                             // %eth0            %1\n`.replace(/\\s*\\/\\/.*$/gm, '').replace(/\\n/g, '').trim();\n\n// Pre-compile only the exact regexes because adding a global flag make regexes stateful\nconst v46Exact = new RegExp(`(?:^${v4}$)|(?:^${v6}$)`);\nconst v4exact = new RegExp(`^${v4}$`);\nconst v6exact = new RegExp(`^${v6}$`);\n\nconst ipRegex = options => options && options.exact\n\t? v46Exact\n\t: new RegExp(`(?:${boundry(options)}${v4}${boundry(options)})|(?:${boundry(options)}${v6}${boundry(options)})`, 'g');\n\nipRegex.v4 = options => options && options.exact ? v4exact : new RegExp(`${boundry(options)}${v4}${boundry(options)}`, 'g');\nipRegex.v6 = options => options && options.exact ? v6exact : new RegExp(`${boundry(options)}${v6}${boundry(options)}`, 'g');\n\nexport default ipRegex;\n","// Even though the browser version is a no-op, we wrap it to ensure consistent behavior.\nexport default function functionTimeout(function_) {\n\tconst wrappedFunction = (...arguments_) => function_(...arguments_);\n\n\tObject.defineProperty(wrappedFunction, 'name', {\n\t\tvalue: `functionTimeout(${function_.name || '<anonymous>'})`,\n\t\tconfigurable: true,\n\t});\n\n\treturn wrappedFunction;\n}\n\nexport function isTimeoutError() {\n\treturn false;\n}\n","const {toString} = Object.prototype;\n\nexport default function isRegexp(value) {\n\treturn toString.call(value) === '[object RegExp]';\n}\n","import isRegexp from 'is-regexp';\n\nconst flagMap = {\n\tglobal: 'g',\n\tignoreCase: 'i',\n\tmultiline: 'm',\n\tdotAll: 's',\n\tsticky: 'y',\n\tunicode: 'u'\n};\n\nexport default function clonedRegexp(regexp, options = {}) {\n\tif (!isRegexp(regexp)) {\n\t\tthrow new TypeError('Expected a RegExp instance');\n\t}\n\n\tconst flags = Object.keys(flagMap).map(flag => (\n\t\t(typeof options[flag] === 'boolean' ? options[flag] : regexp[flag]) ? flagMap[flag] : ''\n\t)).join('');\n\n\tconst clonedRegexp = new RegExp(options.source || regexp.source, flags);\n\n\tclonedRegexp.lastIndex = typeof options.lastIndex === 'number' ?\n\t\toptions.lastIndex :\n\t\tregexp.lastIndex;\n\n\treturn clonedRegexp;\n}\n","import functionTimeout, {isTimeoutError} from 'function-timeout';\nimport timeSpan from 'time-span';\nimport cloneRegexp from 'clone-regexp'; // TODO: Use `structuredClone` instead when targeting Node.js 18.\n\nconst resultToMatch = result => ({\n\tmatch: result[0],\n\tindex: result.index,\n\tgroups: result.slice(1),\n\tnamedGroups: result.groups ?? {},\n\tinput: result.input,\n});\n\nexport function isMatch(regex, string, {timeout} = {}) {\n\ttry {\n\t\treturn functionTimeout(() => cloneRegexp(regex).test(string), {timeout})();\n\t} catch (error) {\n\t\tif (isTimeoutError(error)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tthrow error;\n\t}\n}\n\nexport function firstMatch(regex, string, {timeout} = {}) {\n\ttry {\n\t\tconst result = functionTimeout(() => cloneRegexp(regex).exec(string), {timeout})();\n\n\t\tif (result === null) {\n\t\t\treturn;\n\t\t}\n\n\t\treturn resultToMatch(result);\n\t} catch (error) {\n\t\tif (isTimeoutError(error)) {\n\t\t\treturn;\n\t\t}\n\n\t\tthrow error;\n\t}\n}\n\nexport function matches(regex, string, {timeout = Number.POSITIVE_INFINITY, matchTimeout = Number.POSITIVE_INFINITY} = {}) {\n\tif (!regex.global) {\n\t\tthrow new Error('The regex must have the global flag, otherwise, use `firstMatch()` instead');\n\t}\n\n\treturn {\n\t\t* [Symbol.iterator]() {\n\t\t\ttry {\n\t\t\t\tconst matches = string.matchAll(regex); // The regex is only executed when iterated over.\n\n\t\t\t\twhile (true) {\n\t\t\t\t\tconst nextMatch = functionTimeout(() => matches.next(), {timeout: (timeout !== Number.POSITIVE_INFINITY || matchTimeout !== Number.POSITIVE_INFINITY) ? Math.min(timeout, matchTimeout) : undefined}); // `matches.next` must be called within an arrow function so that it doesn't loose its context.\n\n\t\t\t\t\tconst end = timeSpan();\n\t\t\t\t\tconst {value, done} = nextMatch();\n\t\t\t\t\ttimeout -= Math.ceil(end());\n\n\t\t\t\t\tif (done) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\n\t\t\t\t\tyield resultToMatch(value);\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\tif (!isTimeoutError(error)) {\n\t\t\t\t\tthrow error;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t};\n}\n","import ipRegex from 'ip-regex';\nimport {isMatch} from 'super-regex';\n\nconst maxIPv4Length = 15;\nconst maxIPv6Length = 45;\n\nconst options = {\n\ttimeout: 400,\n};\n\nexport function isIP(string) {\n\tif (string.length > maxIPv6Length) {\n\t\treturn false;\n\t}\n\n\treturn isMatch(ipRegex({exact: true}), string, options);\n}\n\nexport function isIPv6(string) {\n\tif (string.length > maxIPv6Length) {\n\t\treturn false;\n\t}\n\n\treturn isMatch(ipRegex.v6({exact: true}), string, options);\n}\n\nexport function isIPv4(string) {\n\tif (string.length > maxIPv4Length) {\n\t\treturn false;\n\t}\n\n\treturn isMatch(ipRegex.v4({exact: true}), string, options);\n}\n\nexport function ipVersion(string) {\n\tif (isIPv6(string)) {\n\t\treturn 6;\n\t}\n\n\tif (isIPv4(string)) {\n\t\treturn 4;\n\t}\n}\n","/**\n * @packageDocumentation\n *\n * ```typescript\n * import { uriToMultiaddr } from '@multiformats/uri-to-multiaddr'\n *\n * console.log(uriToMultiaddr('https://protocol.ai'))\n * // -> /dns4/protocol.ai/tcp/443/https\n * ```\n *\n * Domain names can represent one of\n *\n * - `/dns4` - domain resolves to an ipv4 address (**default**)\n * - `/dns6` - domain resolves to an ipv6 address\n * - `/dnsaddr` - domain has a [DNSLink](https://docs.ipfs.io/guides/concepts/dnslink/) TXT record pointing to an IPFS CID\n *\n * This library assumes `/dns4` when it finds a domain name in the input string.\n * It makes no attempt query DNS. To override the default assumption, you can pass\n * in an options object as the second parameter to override it:\n *\n * ```typescript\n * import { uriToMultiaddr } from '@multiformats/uri-to-multiaddr'\n *\n * console.log(uriToMultiaddr('https://protocol.ai'), { defaultDnsType: 'dns6' })\n * // -> /dns6/protocol.ai/tcp/443/https\n * ```\n *\n * See [test.js](./test.js) for the currently supported conversions.\n *\n * **Note**: `uri-to-multiaddr` will throw if the passed URI:\n *\n * - is not a valid, according the WHATWG URL spec implementation used.\n * - is not supported yet\n *\n * ## Related\n *\n * - [@multiformats/multiaddr-to-uri](https://github.com/multiformats/js-multiaddr-to-uri) - convert it back again\n */\nimport { multiaddr } from '@multiformats/multiaddr';\nimport { isIPv4, isIPv6 } from 'is-ip';\nconst portFor = {\n    http: '80',\n    https: '443',\n    ws: '80',\n    wss: '443'\n};\nconst BROWSER_SCHEMES = ['http', 'https', 'ws', 'wss'];\n/**\n * Convert a URI to a multiaddr\n *\n * http://foobar.com => /dns4/foobar.com/tcp/80/http\n * https://foobar.com => /dns4/foobar.com/tcp/443/https\n * https://foobar.com:5001 => /dns4/foobar.com/tcp/5001/https\n * https://127.0.0.1:8080 => /ip4/127.0.0.1/tcp/8080/https\n * http://[::1]:8080 => /ip6/::1/tcp/8080/http\n * tcp://foobar.com:8080 => /dns4/foobar.com/tcp/8080\n * udp://foobar.com:8080 => /dns4/foobar.com/udp/8080\n */\nexport function uriToMultiaddr(uriStr, opts) {\n    opts = opts ?? {};\n    const defaultDnsType = opts.defaultDnsType ?? 'dns4';\n    const { scheme, hostname, port } = parseUri(uriStr);\n    const parts = [\n        tupleForHostname(hostname, defaultDnsType),\n        tupleForPort(port, scheme),\n        tupleForScheme(scheme)\n    ];\n    const multiaddrStr = '/' + parts\n        .filter(x => Boolean(x))\n        // @ts-expect-error ts cannot see we filter falsy values\n        .reduce((a, b) => a.concat(b), [])\n        .join('/');\n    return multiaddr(multiaddrStr);\n}\nfunction parseUri(uriStr) {\n    const [scheme] = uriStr.split(':');\n    // browsers will only parse URLs with schemes they understand\n    if (!BROWSER_SCHEMES.includes(scheme)) {\n        uriStr = 'http' + uriStr.substring(scheme.length);\n    }\n    // Use the WHATWG URL global, in node >= 10 and the browser\n    let { protocol, hostname, port } = new URL(uriStr);\n    if (port == null || port === '') {\n        const protocolPort = portForProtocol(scheme);\n        if (protocolPort != null) {\n            port = protocolPort;\n        }\n        // browsers will omit the port when it's common\n        if (protocolPort == null && protocol === 'http:') {\n            // we overrode the protocol with http, set the port to 80\n            port = '80';\n        }\n    }\n    return { scheme, hostname, port };\n}\nfunction tupleForHostname(hostname, defaultDnsType) {\n    if (hostname == null || hostname === '') {\n        return undefined;\n    }\n    if (isIPv4(hostname)) {\n        return ['ip4', hostname];\n    }\n    if (isIPv6(hostname)) {\n        return ['ip6', hostname];\n    }\n    // literal ipv6 in url should be wrapped in square brackets [x:y:z]\n    // https://www.ietf.org/rfc/rfc2732.txt\n    if (hostname[0] === '[') {\n        const trimmed = hostname.substring(1, hostname.length - 1);\n        if (isIPv6(trimmed)) {\n            return ['ip6', trimmed];\n        }\n    }\n    // assumes that any non-ip hostname is a dns4 address.\n    return [defaultDnsType, hostname];\n}\nfunction tupleForPort(port, scheme) {\n    if (port == null || port === '') {\n        return undefined;\n    }\n    if (scheme === 'udp') {\n        return ['udp', port];\n    }\n    return ['tcp', port];\n}\nfunction tupleForScheme(scheme) {\n    if (scheme.match(/^tcp$|^udp$/) != null) {\n        return undefined;\n    }\n    return [scheme];\n}\nfunction portForProtocol(protocol) {\n    if (protocol == null || protocol === '' || portFor[protocol] == null) {\n        return undefined;\n    }\n    return portFor[protocol];\n}\n//# sourceMappingURL=index.js.map","import { peerIdFromCID } from '@libp2p/peer-id';\nimport { uriToMultiaddr } from '@multiformats/uri-to-multiaddr';\nimport { CID } from 'multiformats/cid';\nimport { identity } from 'multiformats/hashes/identity';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nexport const DEFAULT_TRUSTLESS_GATEWAYS = [\n    // 2023-10-03: IPNS, Origin, and Block/CAR support from https://ipfs-public-gateway-checker.on.fleek.co/\n    'https://trustless-gateway.link',\n    // 2023-10-03: IPNS, Origin, and Block/CAR support from https://ipfs-public-gateway-checker.on.fleek.co/\n    'https://4everland.io'\n];\n// this value is from https://github.com/multiformats/multicodec/blob/master/table.csv\nconst TRANSPORT_IPFS_GATEWAY_HTTP_CODE = 0x0920;\nfunction toPeerInfo(url) {\n    url = url.toString();\n    return {\n        id: peerIdFromCID(CID.createV1(TRANSPORT_IPFS_GATEWAY_HTTP_CODE, identity.digest(uint8ArrayFromString(url)))),\n        multiaddrs: [\n            uriToMultiaddr(url)\n        ]\n    };\n}\nclass HTTPGatwayRouter {\n    gateways;\n    constructor(init = {}) {\n        this.gateways = (init.gateways ?? DEFAULT_TRUSTLESS_GATEWAYS).map(url => toPeerInfo(url));\n    }\n    async *findProviders(cid, options) {\n        yield* this.gateways.toSorted(() => Math.random() > 0.5 ? 1 : -1).map(info => ({\n            ...info,\n            protocols: ['transport-ipfs-gateway-http']\n        }));\n    }\n}\n/**\n * Returns a static list of HTTP Gateways as providers\n */\nexport function httpGatewayRouting(init = {}) {\n    return new HTTPGatwayRouter(init);\n}\n//# sourceMappingURL=http-gateway-routing.js.map","export function isStartable(obj) {\n    return obj != null && typeof obj.start === 'function' && typeof obj.stop === 'function';\n}\nexport async function start(...objs) {\n    const startables = [];\n    for (const obj of objs) {\n        if (isStartable(obj)) {\n            startables.push(obj);\n        }\n    }\n    await Promise.all(startables.map(async (s) => {\n        if (s.beforeStart != null) {\n            await s.beforeStart();\n        }\n    }));\n    await Promise.all(startables.map(async (s) => {\n        await s.start();\n    }));\n    await Promise.all(startables.map(async (s) => {\n        if (s.afterStart != null) {\n            await s.afterStart();\n        }\n    }));\n}\nexport async function stop(...objs) {\n    const startables = [];\n    for (const obj of objs) {\n        if (isStartable(obj)) {\n            startables.push(obj);\n        }\n    }\n    await Promise.all(startables.map(async (s) => {\n        if (s.beforeStop != null) {\n            await s.beforeStop();\n        }\n    }));\n    await Promise.all(startables.map(async (s) => {\n        await s.stop();\n    }));\n    await Promise.all(startables.map(async (s) => {\n        if (s.afterStop != null) {\n            await s.afterStop();\n        }\n    }));\n}\n//# sourceMappingURL=startable.js.map","/**\n * An implementation of the ProgressEvent interface, this is essentially\n * a typed `CustomEvent` with a `type` property that lets us disambiguate\n * events passed to `progress` callbacks.\n */\nexport class CustomProgressEvent extends Event {\n    type;\n    detail;\n    constructor(type, detail) {\n        super(type);\n        this.type = type;\n        // @ts-expect-error detail may be undefined\n        this.detail = detail;\n    }\n}\n//# sourceMappingURL=index.js.map","import { RecordType } from '../index.js';\nexport function getTypes(types) {\n    const DEFAULT_TYPES = [\n        RecordType.A\n    ];\n    if (types == null) {\n        return DEFAULT_TYPES;\n    }\n    if (Array.isArray(types)) {\n        if (types.length === 0) {\n            return DEFAULT_TYPES;\n        }\n        return types;\n    }\n    return [\n        types\n    ];\n}\n//# sourceMappingURL=get-types.js.map","import { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport { RecordType } from '../index.js';\n/**\n * This TTL will be used if the remote service does not return one\n */\nexport const DEFAULT_TTL = 60;\nexport function toDNSResponse(obj) {\n    return {\n        Status: obj.Status ?? 0,\n        TC: obj.TC ?? obj.flag_tc ?? false,\n        RD: obj.RD ?? obj.flag_rd ?? false,\n        RA: obj.RA ?? obj.flag_ra ?? false,\n        AD: obj.AD ?? obj.flag_ad ?? false,\n        CD: obj.CD ?? obj.flag_cd ?? false,\n        Question: (obj.Question ?? obj.questions ?? []).map((question) => {\n            return {\n                name: question.name,\n                type: RecordType[question.type]\n            };\n        }),\n        Answer: (obj.Answer ?? obj.answers ?? []).map((answer) => {\n            return {\n                name: answer.name,\n                type: RecordType[answer.type],\n                TTL: (answer.TTL ?? answer.ttl ?? DEFAULT_TTL),\n                data: answer.data instanceof Uint8Array ? uint8ArrayToString(answer.data) : answer.data\n            };\n        })\n    };\n}\n//# sourceMappingURL=to-dns-response.js.map","/* eslint-env browser */\nimport PQueue from 'p-queue';\nimport { CustomProgressEvent } from 'progress-events';\nimport { RecordType } from '../index.js';\nimport { getTypes } from '../utils/get-types.js';\nimport { toDNSResponse } from '../utils/to-dns-response.js';\n/**\n * Browsers limit concurrent connections per host (~6), we don't want to exhaust\n * the limit so this value controls how many DNS queries can be in flight at\n * once.\n */\nexport const DEFAULT_QUERY_CONCURRENCY = 4;\n/**\n * Uses the RFC 8427 'application/dns-json' content-type to resolve DNS queries.\n *\n * Supports and server that uses the same schema as Google's DNS over HTTPS\n * resolver.\n *\n * This resolver needs fewer dependencies than the regular DNS-over-HTTPS\n * resolver so can result in a smaller bundle size and consequently is preferred\n * for browser use.\n *\n * @see https://developers.cloudflare.com/1.1.1.1/encryption/dns-over-https/make-api-requests/dns-json/\n * @see https://github.com/curl/curl/wiki/DNS-over-HTTPS#publicly-available-servers\n * @see https://dnsprivacy.org/public_resolvers/\n * @see https://datatracker.ietf.org/doc/html/rfc8427\n */\nexport function dnsJsonOverHttps(url, init = {}) {\n    const httpQueue = new PQueue({\n        concurrency: init.queryConcurrency ?? DEFAULT_QUERY_CONCURRENCY\n    });\n    return async (fqdn, options = {}) => {\n        const searchParams = new URLSearchParams();\n        searchParams.set('name', fqdn);\n        getTypes(options.types).forEach(type => {\n            // We pass record type as a string to the server because cloudflare DNS bug. see https://github.com/ipfs/helia/issues/474\n            searchParams.append('type', RecordType[type]);\n        });\n        options.onProgress?.(new CustomProgressEvent('dns:query', { detail: fqdn }));\n        // query DNS-JSON over HTTPS server\n        const response = await httpQueue.add(async () => {\n            const res = await fetch(`${url}?${searchParams}`, {\n                headers: {\n                    accept: 'application/dns-json'\n                },\n                signal: options?.signal\n            });\n            if (res.status !== 200) {\n                throw new Error(`Unexpected HTTP status: ${res.status} - ${res.statusText}`);\n            }\n            const response = toDNSResponse(await res.json());\n            options.onProgress?.(new CustomProgressEvent('dns:response', { detail: response }));\n            return response;\n        }, {\n            signal: options.signal\n        });\n        if (response == null) {\n            throw new Error('No DNS response received');\n        }\n        return response;\n    };\n}\n//# sourceMappingURL=dns-json-over-https.js.map","import { dnsJsonOverHttps } from './dns-json-over-https.js';\nexport function defaultResolver() {\n    return [\n        dnsJsonOverHttps('https://cloudflare-dns.com/dns-query'),\n        dnsJsonOverHttps('https://dns.google/resolve')\n    ];\n}\n//# sourceMappingURL=default.browser.js.map","import hashlru from 'hashlru';\nimport { RecordType } from '../index.js';\nimport { DEFAULT_TTL, toDNSResponse } from './to-dns-response.js';\n/**\n * Time Aware Least Recent Used Cache\n *\n * @see https://arxiv.org/pdf/1801.00390\n */\nclass CachedAnswers {\n    lru;\n    constructor(maxSize) {\n        this.lru = hashlru(maxSize);\n    }\n    get(fqdn, types) {\n        let foundAllAnswers = true;\n        const answers = [];\n        for (const type of types) {\n            const cached = this.getAnswers(fqdn, type);\n            if (cached.length === 0) {\n                foundAllAnswers = false;\n                break;\n            }\n            answers.push(...cached);\n        }\n        if (foundAllAnswers) {\n            return toDNSResponse({ answers });\n        }\n    }\n    getAnswers(domain, type) {\n        const key = `${domain.toLowerCase()}-${type}`;\n        const answers = this.lru.get(key);\n        if (answers != null) {\n            const cachedAnswers = answers\n                .filter((entry) => {\n                return entry.expires > Date.now();\n            })\n                .map(({ expires, value }) => ({\n                ...value,\n                TTL: Math.round((expires - Date.now()) / 1000),\n                type: RecordType[value.type]\n            }));\n            if (cachedAnswers.length === 0) {\n                this.lru.remove(key);\n            }\n            // @ts-expect-error hashlru stringifies stored types which turns enums\n            // into strings, we convert back into enums above but tsc doesn't know\n            return cachedAnswers;\n        }\n        return [];\n    }\n    add(domain, answer) {\n        const key = `${domain.toLowerCase()}-${answer.type}`;\n        const answers = this.lru.get(key) ?? [];\n        answers.push({\n            expires: Date.now() + ((answer.TTL ?? DEFAULT_TTL) * 1000),\n            value: answer\n        });\n        this.lru.set(key, answers);\n    }\n    remove(domain, type) {\n        const key = `${domain.toLowerCase()}-${type}`;\n        this.lru.remove(key);\n    }\n    clear() {\n        this.lru.clear();\n    }\n}\n/**\n * Avoid sending multiple queries for the same hostname by caching results\n */\nexport function cache(size) {\n    return new CachedAnswers(size);\n}\n//# sourceMappingURL=cache.js.map","import { CustomProgressEvent } from 'progress-events';\nimport { defaultResolver } from './resolvers/default.js';\nimport { cache } from './utils/cache.js';\nimport { getTypes } from './utils/get-types.js';\nconst DEFAULT_ANSWER_CACHE_SIZE = 1000;\nexport class DNS {\n    resolvers;\n    cache;\n    constructor(init) {\n        this.resolvers = {};\n        this.cache = cache(init.cacheSize ?? DEFAULT_ANSWER_CACHE_SIZE);\n        Object.entries(init.resolvers ?? {}).forEach(([tld, resolver]) => {\n            if (!Array.isArray(resolver)) {\n                resolver = [resolver];\n            }\n            // convert `com` -> `com.`\n            if (!tld.endsWith('.')) {\n                tld = `${tld}.`;\n            }\n            this.resolvers[tld] = resolver;\n        });\n        // configure default resolver if none specified\n        if (this.resolvers['.'] == null) {\n            this.resolvers['.'] = defaultResolver();\n        }\n    }\n    /**\n     * Queries DNS resolvers for the passed record types for the passed domain.\n     *\n     * If cached records exist for all desired types they will be returned\n     * instead.\n     *\n     * Any new responses will be added to the cache for subsequent requests.\n     */\n    async query(domain, options = {}) {\n        const types = getTypes(options.types);\n        const cached = options.cached !== false ? this.cache.get(domain, types) : undefined;\n        if (cached != null) {\n            options.onProgress?.(new CustomProgressEvent('dns:cache', { detail: cached }));\n            return cached;\n        }\n        const tld = `${domain.split('.').pop()}.`;\n        const resolvers = (this.resolvers[tld] ?? this.resolvers['.']).sort(() => {\n            return (Math.random() > 0.5) ? -1 : 1;\n        });\n        const errors = [];\n        for (const resolver of resolvers) {\n            // skip further resolutions if the user aborted the signal\n            if (options.signal?.aborted === true) {\n                break;\n            }\n            try {\n                const result = await resolver(domain, {\n                    ...options,\n                    types\n                });\n                for (const answer of result.Answer) {\n                    this.cache.add(domain, answer);\n                }\n                return result;\n            }\n            catch (err) {\n                errors.push(err);\n                options.onProgress?.(new CustomProgressEvent('dns:error', { detail: err }));\n            }\n        }\n        if (errors.length === 1) {\n            throw errors[0];\n        }\n        throw new AggregateError(errors, `DNS lookup of ${domain} ${types} failed`);\n    }\n}\n//# sourceMappingURL=dns.js.map","/**\n * @packageDocumentation\n *\n * Query DNS records using `node:dns`, DNS over HTTP and/or DNSJSON over HTTP.\n *\n * A list of publicly accessible servers can be found [here](https://github.com/curl/curl/wiki/DNS-over-HTTPS#publicly-available-servers).\n *\n * @example Using the default resolver\n *\n * ```TypeScript\n * import { dns } from '@multiformats/dns'\n *\n * const resolver = dns()\n *\n * // resolve A records with a 5s timeout\n * const result = await dns.query('google.com', {\n *   signal: AbortSignal.timeout(5000)\n * })\n * ```\n *\n * @example Using per-TLD resolvers\n *\n * ```TypeScript\n * import { dns } from '@multiformats/dns'\n * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'\n *\n * const resolver = dns({\n *   resolvers: {\n *     // will only be used to resolve `.com` addresses\n *     'com.': dnsJsonOverHttps('https://cloudflare-dns.com/dns-query'),\n *\n *     // this can also be an array, resolvers will be shuffled and tried in\n *     // series\n *     'net.': [\n *       dnsJsonOverHttps('https://dns.google/resolve'),\n *       dnsJsonOverHttps('https://dns.pub/dns-query')\n *     ],\n *\n *     // will only be used to resolve all other addresses\n *     '.': dnsJsonOverHttps('https://dnsforge.de/dns-query'),\n *   }\n * })\n * ```\n *\n * @example Query for specific record types\n *\n * ```TypeScript\n * import { dns, RecordType } from '@multiformats/dns'\n *\n * const resolver = dns()\n *\n * // resolve only TXT records\n * const result = await dns.query('google.com', {\n *   types: [\n *     RecordType.TXT\n *   ]\n * })\n * ```\n *\n * ## Caching\n *\n * Individual Aanswers are cached so. If you make a request, for which all\n * record types are cached, all values will be pulled from the cache.\n *\n * If any of the record types are not cached, a new request will be resolved as\n * if none of the records were cached, and the cache will be updated to include\n * the new results.\n *\n * @example Ignoring the cache\n *\n * ```TypeScript\n * import { dns, RecordType } from '@multiformats/dns'\n *\n * const resolver = dns()\n *\n * // do not used cached results, always resolve a new query\n * const result = await dns.query('google.com', {\n *   cached: false\n * })\n * ```\n */\nimport { DNS as DNSClass } from './dns.js';\n/**\n * A subset of DNS Record Types\n *\n * @see https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-4.\n */\nexport var RecordType;\n(function (RecordType) {\n    RecordType[RecordType[\"A\"] = 1] = \"A\";\n    RecordType[RecordType[\"CNAME\"] = 5] = \"CNAME\";\n    RecordType[RecordType[\"TXT\"] = 16] = \"TXT\";\n    RecordType[RecordType[\"AAAA\"] = 28] = \"AAAA\";\n})(RecordType || (RecordType = {}));\n/**\n * The default maximum amount of recursion allowed during a query\n */\nexport const MAX_RECURSIVE_DEPTH = 32;\nexport function dns(init = {}) {\n    return new DNSClass(init);\n}\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Mostly useful for tests or when you want to be explicit about consuming an iterable without doing anything with any yielded values.\n *\n * @example\n *\n * ```javascript\n * import drain from 'it-drain'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * drain(values)\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import drain from 'it-drain'\n *\n * const values = async function * {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * await drain(values())\n * ```\n */\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction drain(source) {\n    if (isAsyncIterable(source)) {\n        return (async () => {\n            for await (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars\n        })();\n    }\n    else {\n        for (const _ of source) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars\n    }\n}\nexport default drain;\n//# sourceMappingURL=index.js.map","import { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nconst pathSepS = '/';\nconst pathSepB = new TextEncoder().encode(pathSepS);\nconst pathSep = pathSepB[0];\n/**\n * A Key represents the unique identifier of an object.\n * Our Key scheme is inspired by file systems and Google App Engine key model.\n * Keys are meant to be unique across a system. Keys are hierarchical,\n * incorporating more and more specific namespaces. Thus keys can be deemed\n * 'children' or 'ancestors' of other keys:\n * - `new Key('/Comedy')`\n * - `new Key('/Comedy/MontyPython')`\n * Also, every namespace can be parametrized to embed relevant object\n * information. For example, the Key `name` (most specific namespace) could\n * include the object type:\n * - `new Key('/Comedy/MontyPython/Actor:JohnCleese')`\n * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop')`\n * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop/Character:Mousebender')`\n *\n */\nexport class Key {\n    _buf;\n    /**\n     * @param {string | Uint8Array} s\n     * @param {boolean} [clean]\n     */\n    constructor(s, clean) {\n        if (typeof s === 'string') {\n            this._buf = uint8ArrayFromString(s);\n        }\n        else if (s instanceof Uint8Array) {\n            this._buf = s;\n        }\n        else {\n            throw new Error('Invalid key, should be String of Uint8Array');\n        }\n        if (clean == null) {\n            clean = true;\n        }\n        if (clean) {\n            this.clean();\n        }\n        if (this._buf.byteLength === 0 || this._buf[0] !== pathSep) {\n            throw new Error('Invalid key');\n        }\n    }\n    /**\n     * Convert to the string representation\n     *\n     * @param {import('uint8arrays/to-string').SupportedEncodings} [encoding='utf8'] - The encoding to use.\n     * @returns {string}\n     */\n    toString(encoding = 'utf8') {\n        return uint8ArrayToString(this._buf, encoding);\n    }\n    /**\n     * Return the Uint8Array representation of the key\n     *\n     * @returns {Uint8Array}\n     */\n    uint8Array() {\n        return this._buf;\n    }\n    /**\n     * Return string representation of the key\n     *\n     * @returns {string}\n     */\n    get [Symbol.toStringTag]() {\n        return `Key(${this.toString()})`;\n    }\n    /**\n     * Constructs a key out of a namespace array.\n     *\n     * @param {Array<string>} list - The array of namespaces\n     * @returns {Key}\n     *\n     * @example\n     * ```js\n     * Key.withNamespaces(['one', 'two'])\n     * // => Key('/one/two')\n     * ```\n     */\n    static withNamespaces(list) {\n        return new Key(list.join(pathSepS));\n    }\n    /**\n     * Returns a randomly (uuid) generated key.\n     *\n     * @returns {Key}\n     *\n     * @example\n     * ```js\n     * Key.random()\n     * // => Key('/344502982398')\n     * ```\n     */\n    static random() {\n        return new Key(Math.random().toString().substring(2));\n    }\n    /**\n     * @param {*} other\n     */\n    static asKey(other) {\n        if (other instanceof Uint8Array || typeof other === 'string') {\n            // we can create a key from this\n            return new Key(other);\n        }\n        if (typeof other.uint8Array === 'function') {\n            // this is an older version or may have crossed the esm/cjs boundary\n            return new Key(other.uint8Array());\n        }\n        return null;\n    }\n    /**\n     * Cleanup the current key\n     *\n     * @returns {void}\n     */\n    clean() {\n        if (this._buf == null || this._buf.byteLength === 0) {\n            this._buf = pathSepB;\n        }\n        if (this._buf[0] !== pathSep) {\n            const bytes = new Uint8Array(this._buf.byteLength + 1);\n            bytes.fill(pathSep, 0, 1);\n            bytes.set(this._buf, 1);\n            this._buf = bytes;\n        }\n        // normalize does not remove trailing slashes\n        while (this._buf.byteLength > 1 && this._buf[this._buf.byteLength - 1] === pathSep) {\n            this._buf = this._buf.subarray(0, -1);\n        }\n    }\n    /**\n     * Check if the given key is sorted lower than ourself.\n     *\n     * @param {Key} key - The other Key to check against\n     * @returns {boolean}\n     */\n    less(key) {\n        const list1 = this.list();\n        const list2 = key.list();\n        for (let i = 0; i < list1.length; i++) {\n            if (list2.length < i + 1) {\n                return false;\n            }\n            const c1 = list1[i];\n            const c2 = list2[i];\n            if (c1 < c2) {\n                return true;\n            }\n            else if (c1 > c2) {\n                return false;\n            }\n        }\n        return list1.length < list2.length;\n    }\n    /**\n     * Returns the key with all parts in reversed order.\n     *\n     * @returns {Key}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython/Actor:JohnCleese').reverse()\n     * // => Key('/Actor:JohnCleese/MontyPython/Comedy')\n     * ```\n     */\n    reverse() {\n        return Key.withNamespaces(this.list().slice().reverse());\n    }\n    /**\n     * Returns the `namespaces` making up this Key.\n     *\n     * @returns {Array<string>}\n     */\n    namespaces() {\n        return this.list();\n    }\n    /** Returns the \"base\" namespace of this key.\n     *\n     * @returns {string}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython/Actor:JohnCleese').baseNamespace()\n     * // => 'Actor:JohnCleese'\n     * ```\n     */\n    baseNamespace() {\n        const ns = this.namespaces();\n        return ns[ns.length - 1];\n    }\n    /**\n     * Returns the `list` representation of this key.\n     *\n     * @returns {Array<string>}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython/Actor:JohnCleese').list()\n     * // => ['Comedy', 'MontyPythong', 'Actor:JohnCleese']\n     * ```\n     */\n    list() {\n        return this.toString().split(pathSepS).slice(1);\n    }\n    /**\n     * Returns the \"type\" of this key (value of last namespace).\n     *\n     * @returns {string}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython/Actor:JohnCleese').type()\n     * // => 'Actor'\n     * ```\n     */\n    type() {\n        return namespaceType(this.baseNamespace());\n    }\n    /**\n     * Returns the \"name\" of this key (field of last namespace).\n     *\n     * @returns {string}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython/Actor:JohnCleese').name()\n     * // => 'JohnCleese'\n     * ```\n     */\n    name() {\n        return namespaceValue(this.baseNamespace());\n    }\n    /**\n     * Returns an \"instance\" of this type key (appends value to namespace).\n     *\n     * @param {string} s - The string to append.\n     * @returns {Key}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython/Actor').instance('JohnClesse')\n     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')\n     * ```\n     */\n    instance(s) {\n        return new Key(this.toString() + ':' + s);\n    }\n    /**\n     * Returns the \"path\" of this key (parent + type).\n     *\n     * @returns {Key}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython/Actor:JohnCleese').path()\n     * // => Key('/Comedy/MontyPython/Actor')\n     * ```\n     */\n    path() {\n        let p = this.parent().toString();\n        if (!p.endsWith(pathSepS)) {\n            p += pathSepS;\n        }\n        p += this.type();\n        return new Key(p);\n    }\n    /**\n     * Returns the `parent` Key of this Key.\n     *\n     * @returns {Key}\n     *\n     * @example\n     * ```js\n     * new Key(\"/Comedy/MontyPython/Actor:JohnCleese\").parent()\n     * // => Key(\"/Comedy/MontyPython\")\n     * ```\n     */\n    parent() {\n        const list = this.list();\n        if (list.length === 1) {\n            return new Key(pathSepS);\n        }\n        return new Key(list.slice(0, -1).join(pathSepS));\n    }\n    /**\n     * Returns the `child` Key of this Key.\n     *\n     * @param {Key} key - The child Key to add\n     * @returns {Key}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython').child(new Key('Actor:JohnCleese'))\n     * // => Key('/Comedy/MontyPython/Actor:JohnCleese')\n     * ```\n     */\n    child(key) {\n        if (this.toString() === pathSepS) {\n            return key;\n        }\n        else if (key.toString() === pathSepS) {\n            return this;\n        }\n        return new Key(this.toString() + key.toString(), false);\n    }\n    /**\n     * Returns whether this key is a prefix of `other`\n     *\n     * @param {Key} other - The other key to test against\n     * @returns {boolean}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy').isAncestorOf('/Comedy/MontyPython')\n     * // => true\n     * ```\n     */\n    isAncestorOf(other) {\n        if (other.toString() === this.toString()) {\n            return false;\n        }\n        return other.toString().startsWith(this.toString());\n    }\n    /**\n     * Returns whether this key is a contains another as prefix.\n     *\n     * @param {Key} other - The other Key to test against\n     * @returns {boolean}\n     *\n     * @example\n     * ```js\n     * new Key('/Comedy/MontyPython').isDecendantOf('/Comedy')\n     * // => true\n     * ```\n     */\n    isDecendantOf(other) {\n        if (other.toString() === this.toString()) {\n            return false;\n        }\n        return this.toString().startsWith(other.toString());\n    }\n    /**\n     * Checks if this key has only one namespace.\n     *\n     * @returns {boolean}\n     */\n    isTopLevel() {\n        return this.list().length === 1;\n    }\n    /**\n     * Concats one or more Keys into one new Key.\n     *\n     * @param {Array<Key>} keys - The array of keys to concatenate\n     * @returns {Key}\n     */\n    concat(...keys) {\n        return Key.withNamespaces([...this.namespaces(), ...flatten(keys.map(key => key.namespaces()))]);\n    }\n}\n/**\n * The first component of a namespace. `foo` in `foo:bar`\n *\n * @param {string} ns\n * @returns {string}\n */\nfunction namespaceType(ns) {\n    const parts = ns.split(':');\n    if (parts.length < 2) {\n        return '';\n    }\n    return parts.slice(0, -1).join(':');\n}\n/**\n * The last component of a namespace, `baz` in `foo:bar:baz`.\n *\n * @param {string} ns\n * @returns {string}\n */\nfunction namespaceValue(ns) {\n    const parts = ns.split(':');\n    return parts[parts.length - 1];\n}\n/**\n * Flatten array of arrays (only one level)\n *\n * @template T\n * @param {Array<any>} arr\n * @returns {T[]}\n */\nfunction flatten(arr) {\n    return ([]).concat(...arr);\n}\n//# sourceMappingURL=key.js.map","/* eslint-disable @typescript-eslint/ban-types */\n// this ignore is so we can use {} as the default value for the options\n// extensions below - it normally means \"any non-nullish value\" but here\n// we are using it as an intersection type - see the aside at the bottom:\n// https://github.com/typescript-eslint/typescript-eslint/issues/2063#issuecomment-675156492\n/**\n * @packageDocumentation\n *\n * A Datastore is a key/value database that lets store/retrieve binary blobs using namespaced Keys.\n *\n * It is used by IPFS to store/retrieve arbitrary metadata needed to run the node - DHT provider records, signed peer records, etc.\n *\n * ## Backed Implementations\n *\n * - File System: [`datastore-fs`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-fs)\n * - IndexedDB: [`datastore-idb`](https://github.com/ipfs/js-stores/blob/main/packages/datastore-idb)\n * - level: [`datastore-level`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-level) (supports any levelup compatible backend)\n * - Memory: [`datastore-core/memory`](https://github.com/ipfs/js-stores/blob/main/packages/datastore-core/src/memory.ts)\n * - S3: [`datastore-s3`](https://github.com/ipfs/js-stores/tree/main/packages/datastore-s3)\n *\n * ## Wrapper Implementations\n *\n * - Keytransform: [`datstore-core/src/keytransform`](https://github.com/ipfs/js-stores/blob/main/packages/datastore-core/src/keytransform.ts)\n * - Mount: [`datastore-core/src/mount`](https://github.com/ipfs/js-stores/blob/main/packages/datastore-core/src/mount.ts)\n * - Namespace: [`datastore-core/src/namespace`](https://github.com/ipfs/js-stores/blob/main/packages/datastore-core/src/namespace.ts)\n * - Sharding: [`datastore-core/src/sharding`](https://github.com/ipfs/js-stores/blob/main/packages/datastore-core/src/sharding.ts)\n * - Tiered: [`datstore-core/src/tiered`](https://github.com/ipfs/js-stores/blob/main/packages/datastore-core/src/tiered.ts)\n *\n * If you want the same functionality as [go-ds-flatfs](https://github.com/ipfs/go-ds-flatfs), use sharding with fs.\n *\n * @example\n *\n * ```js\n * import FsStore from 'datastore-fs'\n * import { ShardingDataStore, shard } from 'datastore-core'\n *\n * const fs = new FsStore('path/to/store')\n *\n * // flatfs now works like go-flatfs\n * const flatfs = await ShardingStore.createOrOpen(fs, new shard.NextToLast(2))\n * ```\n *\n * ### Test suite\n *\n * Available via the [`interface-datastore-tests`](https://npmjs.com/package/interface-datastore-tests) module\n *\n * ```js\n * import { interfaceDatastoreTests } from 'interface-datastore-tests'\n *\n * describe('mystore', () => {\n *   interfaceDatastoreTests({\n *     async setup () {\n *       return instanceOfMyStore\n *     },\n *     async teardown () {\n *       // cleanup resources\n *     }\n *   })\n * })\n * ```\n *\n * ### Aborting requests\n *\n * Most API methods accept an \\[AbortSignal]\\[] as part of an options object.  Implementations may listen for an `abort` event emitted by this object, or test the `signal.aborted` property. When received implementations should tear down any long-lived requests or resources created.\n *\n * ### Concurrency\n *\n * The streaming `(put|get|delete)Many` methods are intended to be used with modules such as [it-parallel-batch](https://www.npmjs.com/package/it-parallel-batch) to allow calling code to control levels of parallelisation.  The batching method ensures results are returned in the correct order, but interface implementations should be thread safe.\n *\n * ```js\n * import batch from 'it-parallel-batch'\n * const source = [{\n *   key: ..,\n *   value: ..\n * }]\n *\n * // put values into the datastore concurrently, max 10 at a time\n * for await (const { key, data } of batch(store.putMany(source), 10)) {\n *   console.info(`Put ${key}`)\n * }\n * ```\n *\n * ### Keys\n *\n * To allow a better abstraction on how to address values, there is a `Key` class which is used as identifier. It's easy to create a key from a `Uint8Array` or a `string`.\n *\n * ```js\n * const a = new Key('a')\n * const b = new Key(new Uint8Array([0, 1, 2, 3]))\n * ```\n *\n * The key scheme is inspired by file systems and Google App Engine key model. Keys are meant to be unique across a system. They are typically hierarchical, incorporating more and more specific namespaces. Thus keys can be deemed 'children' or 'ancestors' of other keys:\n *\n * - `new Key('/Comedy')`\n * - `new Key('/Comedy/MontyPython')`\n *\n * Also, every namespace can be parameterized to embed relevant object information. For example, the Key `name` (most specific namespace) could include the object type:\n *\n * - `new Key('/Comedy/MontyPython/Actor:JohnCleese')`\n * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop')`\n * - `new Key('/Comedy/MontyPython/Sketch:CheeseShop/Character:Mousebender')`\n */\nimport { Key } from './key.js';\nexport { Key };\n//# sourceMappingURL=index.js.map","import { bytes as binary, CID } from './index.js';\nfunction readonly({ enumerable = true, configurable = false } = {}) {\n    return { enumerable, configurable, writable: false };\n}\nfunction* linksWithin(path, value) {\n    if (value != null && typeof value === 'object') {\n        if (Array.isArray(value)) {\n            for (const [index, element] of value.entries()) {\n                const elementPath = [...path, index];\n                const cid = CID.asCID(element);\n                if (cid != null) {\n                    yield [elementPath.join('/'), cid];\n                }\n                else if (typeof element === 'object') {\n                    yield* links(element, elementPath);\n                }\n            }\n        }\n        else {\n            const cid = CID.asCID(value);\n            if (cid != null) {\n                yield [path.join('/'), cid];\n            }\n            else {\n                yield* links(value, path);\n            }\n        }\n    }\n}\nfunction* links(source, base) {\n    if (source == null || source instanceof Uint8Array) {\n        return;\n    }\n    const cid = CID.asCID(source);\n    if (cid != null) {\n        yield [base.join('/'), cid];\n    }\n    for (const [key, value] of Object.entries(source)) {\n        const path = [...base, key];\n        yield* linksWithin(path, value);\n    }\n}\nfunction* treeWithin(path, value) {\n    if (Array.isArray(value)) {\n        for (const [index, element] of value.entries()) {\n            const elementPath = [...path, index];\n            yield elementPath.join('/');\n            if (typeof element === 'object' && (CID.asCID(element) == null)) {\n                yield* tree(element, elementPath);\n            }\n        }\n    }\n    else {\n        yield* tree(value, path);\n    }\n}\nfunction* tree(source, base) {\n    if (source == null || typeof source !== 'object') {\n        return;\n    }\n    for (const [key, value] of Object.entries(source)) {\n        const path = [...base, key];\n        yield path.join('/');\n        if (value != null && !(value instanceof Uint8Array) && typeof value === 'object' && (CID.asCID(value) == null)) {\n            yield* treeWithin(path, value);\n        }\n    }\n}\nfunction get(source, path) {\n    let node = source;\n    for (const [index, key] of path.entries()) {\n        node = node[key];\n        if (node == null) {\n            throw new Error(`Object has no property at ${path.slice(0, index + 1).map(part => `[${JSON.stringify(part)}]`).join('')}`);\n        }\n        const cid = CID.asCID(node);\n        if (cid != null) {\n            return { value: cid, remaining: path.slice(index + 1).join('/') };\n        }\n    }\n    return { value: node };\n}\n/**\n * @template T - Logical type of the data encoded in the block\n * @template C - multicodec code corresponding to codec used to encode the block\n * @template A - multicodec code corresponding to the hashing algorithm used in CID creation.\n * @template V - CID version\n */\nexport class Block {\n    cid;\n    bytes;\n    value;\n    asBlock;\n    constructor({ cid, bytes, value }) {\n        if (cid == null || bytes == null || typeof value === 'undefined') {\n            throw new Error('Missing required argument');\n        }\n        this.cid = cid;\n        this.bytes = bytes;\n        this.value = value;\n        this.asBlock = this;\n        // Mark all the properties immutable\n        Object.defineProperties(this, {\n            cid: readonly(),\n            bytes: readonly(),\n            value: readonly(),\n            asBlock: readonly()\n        });\n    }\n    links() {\n        return links(this.value, []);\n    }\n    tree() {\n        return tree(this.value, []);\n    }\n    get(path = '/') {\n        return get(this.value, path.split('/').filter(Boolean));\n    }\n}\n/**\n * @template T - Logical type of the data encoded in the block\n * @template Code - multicodec code corresponding to codec used to encode the block\n * @template Alg - multicodec code corresponding to the hashing algorithm used in CID creation.\n */\nexport async function encode({ value, codec, hasher }) {\n    if (typeof value === 'undefined')\n        throw new Error('Missing required argument \"value\"');\n    if (codec == null || hasher == null)\n        throw new Error('Missing required argument: codec or hasher');\n    const bytes = codec.encode(value);\n    const hash = await hasher.digest(bytes);\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-assertion\n    const cid = CID.create(1, codec.code, hash);\n    return new Block({ value, bytes, cid });\n}\n/**\n * @template T - Logical type of the data encoded in the block\n * @template Code - multicodec code corresponding to codec used to encode the block\n * @template Alg - multicodec code corresponding to the hashing algorithm used in CID creation.\n */\nexport async function decode({ bytes, codec, hasher }) {\n    if (bytes == null)\n        throw new Error('Missing required argument \"bytes\"');\n    if (codec == null || hasher == null)\n        throw new Error('Missing required argument: codec or hasher');\n    const value = codec.decode(bytes);\n    const hash = await hasher.digest(bytes);\n    // eslint-disable-next-line @typescript-eslint/no-unnecessary-type-assertion\n    const cid = CID.create(1, codec.code, hash);\n    return new Block({ value, bytes, cid });\n}\n/**\n * @template T - Logical type of the data encoded in the block\n * @template Code - multicodec code corresponding to codec used to encode the block\n * @template Alg - multicodec code corresponding to the hashing algorithm used in CID creation.\n * @template V - CID version\n */\nexport function createUnsafe({ bytes, cid, value: maybeValue, codec }) {\n    // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n    const value = maybeValue !== undefined\n        ? maybeValue\n        : (codec?.decode(bytes));\n    if (value === undefined)\n        throw new Error('Missing required argument, must either provide \"value\" or \"codec\"');\n    return new Block({\n        cid: cid,\n        bytes,\n        value\n    });\n}\n/**\n * @template T - Logical type of the data encoded in the block\n * @template Code - multicodec code corresponding to codec used to encode the block\n * @template Alg - multicodec code corresponding to the hashing algorithm used in CID creation.\n * @template V - CID version\n */\nexport async function create({ bytes, cid, hasher, codec }) {\n    if (bytes == null)\n        throw new Error('Missing required argument \"bytes\"');\n    if (hasher == null)\n        throw new Error('Missing required argument \"hasher\"');\n    const value = codec.decode(bytes);\n    const hash = await hasher.digest(bytes);\n    if (!binary.equals(cid.multihash.bytes, hash.bytes)) {\n        throw new Error('CID hash does not match bytes');\n    }\n    return createUnsafe({\n        bytes,\n        cid,\n        value,\n        codec\n    });\n}\n//# sourceMappingURL=block.js.map","import { Queue } from '@libp2p/utils/queue';\nimport * as cborg from 'cborg';\nimport { Key } from 'interface-datastore';\nimport { base36 } from 'multiformats/bases/base36';\nimport { createUnsafe } from 'multiformats/block';\nimport { CID } from 'multiformats/cid';\nimport { CustomProgressEvent } from 'progress-events';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nconst DATASTORE_PIN_PREFIX = '/pin/';\nconst DATASTORE_BLOCK_PREFIX = '/pinned-block/';\nconst DATASTORE_ENCODING = base36;\nconst DAG_WALK_QUEUE_CONCURRENCY = 1;\nfunction toDSKey(cid) {\n    if (cid.version === 0) {\n        cid = cid.toV1();\n    }\n    return new Key(`${DATASTORE_PIN_PREFIX}${cid.toString(DATASTORE_ENCODING)}`);\n}\nexport class PinsImpl {\n    datastore;\n    blockstore;\n    getCodec;\n    constructor(datastore, blockstore, getCodec) {\n        this.datastore = datastore;\n        this.blockstore = blockstore;\n        this.getCodec = getCodec;\n    }\n    async *add(cid, options = {}) {\n        const pinKey = toDSKey(cid);\n        if (await this.datastore.has(pinKey)) {\n            throw new Error('Already pinned');\n        }\n        const depth = Math.round(options.depth ?? Infinity);\n        if (depth < 0) {\n            throw new Error('Depth must be greater than or equal to 0');\n        }\n        // use a queue to walk the DAG instead of recursion so we can traverse very large DAGs\n        const queue = new Queue({\n            concurrency: DAG_WALK_QUEUE_CONCURRENCY\n        });\n        for await (const childCid of this.#walkDag(cid, queue, {\n            ...options,\n            depth\n        })) {\n            await this.#updatePinnedBlock(childCid, (pinnedBlock) => {\n                // do not update pinned block if this block is already pinned by this CID\n                if (pinnedBlock.pinnedBy.find(c => uint8ArrayEquals(c, cid.bytes)) != null) {\n                    return false;\n                }\n                pinnedBlock.pinCount++;\n                pinnedBlock.pinnedBy.push(cid.bytes);\n                return true;\n            }, options);\n            yield childCid;\n        }\n        const pin = {\n            depth,\n            metadata: options.metadata ?? {}\n        };\n        await this.datastore.put(pinKey, cborg.encode(pin), options);\n    }\n    /**\n     * Walk a DAG in an iterable fashion\n     */\n    async *#walkDag(cid, queue, options) {\n        if (options.depth === -1) {\n            return;\n        }\n        const codec = await this.getCodec(cid.code);\n        const bytes = await this.blockstore.get(cid, options);\n        const block = createUnsafe({ bytes, cid, codec });\n        yield cid;\n        // walk dag, ensure all blocks are present\n        for await (const [, cid] of block.links()) {\n            yield* await queue.add(async () => {\n                return this.#walkDag(cid, queue, {\n                    ...options,\n                    depth: options.depth - 1\n                });\n            });\n        }\n    }\n    /**\n     * Update the pin count for the CID\n     */\n    async #updatePinnedBlock(cid, withPinnedBlock, options) {\n        const blockKey = new Key(`${DATASTORE_BLOCK_PREFIX}${DATASTORE_ENCODING.encode(cid.multihash.bytes)}`);\n        let pinnedBlock = {\n            pinCount: 0,\n            pinnedBy: []\n        };\n        try {\n            pinnedBlock = cborg.decode(await this.datastore.get(blockKey, options));\n        }\n        catch (err) {\n            if (err.name !== 'NotFoundError') {\n                throw err;\n            }\n        }\n        const shouldContinue = withPinnedBlock(pinnedBlock);\n        if (!shouldContinue) {\n            return;\n        }\n        if (pinnedBlock.pinCount === 0) {\n            if (await this.datastore.has(blockKey)) {\n                await this.datastore.delete(blockKey);\n                return;\n            }\n        }\n        await this.datastore.put(blockKey, cborg.encode(pinnedBlock), options);\n        options.onProgress?.(new CustomProgressEvent('helia:pin:add', cid));\n    }\n    async *rm(cid, options = {}) {\n        const pinKey = toDSKey(cid);\n        const buf = await this.datastore.get(pinKey, options);\n        const pin = cborg.decode(buf);\n        await this.datastore.delete(pinKey, options);\n        // use a queue to walk the DAG instead of recursion so we can traverse very large DAGs\n        const queue = new Queue({\n            concurrency: DAG_WALK_QUEUE_CONCURRENCY\n        });\n        for await (const childCid of this.#walkDag(cid, queue, {\n            ...options,\n            depth: pin.depth\n        })) {\n            await this.#updatePinnedBlock(childCid, (pinnedBlock) => {\n                pinnedBlock.pinCount--;\n                pinnedBlock.pinnedBy = pinnedBlock.pinnedBy.filter(c => uint8ArrayEquals(c, cid.bytes));\n                return true;\n            }, {\n                ...options,\n                depth: pin.depth\n            });\n            yield childCid;\n        }\n    }\n    async *ls(options = {}) {\n        for await (const { key, value } of this.datastore.query({\n            prefix: DATASTORE_PIN_PREFIX + (options.cid != null ? `${options.cid.toString(base36)}` : '')\n        }, options)) {\n            const cid = CID.parse(key.toString().substring(5), base36);\n            const pin = cborg.decode(value);\n            yield {\n                cid,\n                ...pin\n            };\n        }\n    }\n    async isPinned(cid, options = {}) {\n        const blockKey = new Key(`${DATASTORE_BLOCK_PREFIX}${DATASTORE_ENCODING.encode(cid.multihash.bytes)}`);\n        return this.datastore.has(blockKey, options);\n    }\n    async get(cid, options) {\n        const pinKey = toDSKey(cid);\n        const buf = await this.datastore.get(pinKey, options);\n        return cborg.decode(buf);\n    }\n    async setMetadata(cid, metadata, options) {\n        const pinKey = toDSKey(cid);\n        const buf = await this.datastore.get(pinKey, options);\n        const pin = cborg.decode(buf);\n        pin.metadata = metadata ?? {};\n        await this.datastore.put(pinKey, cborg.encode(pin), options);\n    }\n}\n//# sourceMappingURL=pins.js.map","import { Queue } from './queue/index.js';\n/**\n * Extends Queue to add support for querying queued jobs by peer id\n */\nexport class PeerQueue extends Queue {\n    has(peerId) {\n        return this.find(peerId) != null;\n    }\n    find(peerId) {\n        return this.queue.find(job => {\n            return peerId.equals(job.options.peerId);\n        });\n    }\n}\n//# sourceMappingURL=peer-queue.js.map","/**\n * @packageDocumentation\n *\n * Merge several (async)iterables into one, yield values as they arrive.\n *\n * Nb. sources are iterated over in parallel so the order of emitted items is not guaranteed.\n *\n * @example\n *\n * ```javascript\n * import merge from 'it-merge'\n * import all from 'it-all'\n *\n * // This can also be an iterator, generator, etc\n * const values1 = [0, 1, 2, 3, 4]\n * const values2 = [5, 6, 7, 8, 9]\n *\n * const arr = all(merge(values1, values2))\n *\n * console.info(arr) // 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import merge from 'it-merge'\n * import all from 'it-all'\n *\n * // This can also be an iterator, async iterator, generator, etc\n * const values1 = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n * const values2 = async function * () {\n *   yield * [5, 6, 7, 8, 9]\n * }\n *\n * const arr = await all(merge(values1(), values2()))\n *\n * console.info(arr) // 0, 1, 5, 6, 2, 3, 4, 7, 8, 9  <- nb. order is not guaranteed\n * ```\n */\nimport { pushable } from 'it-pushable';\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction merge(...sources) {\n    const syncSources = [];\n    for (const source of sources) {\n        if (!isAsyncIterable(source)) {\n            syncSources.push(source);\n        }\n    }\n    if (syncSources.length === sources.length) {\n        // all sources are synchronous\n        return (function* () {\n            for (const source of syncSources) {\n                yield* source;\n            }\n        })();\n    }\n    return (async function* () {\n        const output = pushable({\n            objectMode: true\n        });\n        void Promise.resolve().then(async () => {\n            try {\n                await Promise.all(sources.map(async (source) => {\n                    for await (const item of source) {\n                        output.push(item);\n                    }\n                }));\n                output.end();\n            }\n            catch (err) {\n                output.end(err);\n            }\n        });\n        yield* output;\n    })();\n}\nexport default merge;\n//# sourceMappingURL=index.js.map","import { NoRoutersAvailableError } from '@helia/interface';\nimport { NotFoundError, start, stop } from '@libp2p/interface';\nimport { PeerQueue } from '@libp2p/utils/peer-queue';\nimport merge from 'it-merge';\nconst DEFAULT_PROVIDER_LOOKUP_CONCURRENCY = 5;\nexport class Routing {\n    log;\n    routers;\n    providerLookupConcurrency;\n    constructor(components, init) {\n        this.log = components.logger.forComponent('helia:routing');\n        this.routers = init.routers ?? [];\n        this.providerLookupConcurrency = init.providerLookupConcurrency ?? DEFAULT_PROVIDER_LOOKUP_CONCURRENCY;\n    }\n    async start() {\n        await start(...this.routers);\n    }\n    async stop() {\n        await stop(...this.routers);\n    }\n    /**\n     * Iterates over all content routers in parallel to find providers of the\n     * given key\n     */\n    async *findProviders(key, options = {}) {\n        if (this.routers.length === 0) {\n            throw new NoRoutersAvailableError('No content routers available');\n        }\n        // provider multiaddrs are only cached for a limited time, so they can come\n        // back as an empty array - when this happens we have to do a FIND_PEER\n        // query to get updated addresses, but we shouldn't block on this so use a\n        // separate bounded queue to perform this lookup\n        const queue = new PeerQueue({\n            concurrency: this.providerLookupConcurrency\n        });\n        queue.addEventListener('error', () => { });\n        for await (const peer of merge(queue.toGenerator(), ...supports(this.routers, 'findProviders')\n            .map(router => router.findProviders(key, options)))) {\n            // the peer was yielded by a content router without multiaddrs and we\n            // failed to load them\n            if (peer == null) {\n                continue;\n            }\n            // have to refresh peer info for this peer to get updated multiaddrs\n            if (peer.multiaddrs.length === 0) {\n                // already looking this peer up\n                if (queue.find(peer.id) != null) {\n                    continue;\n                }\n                queue.add(async () => {\n                    try {\n                        const provider = await this.findPeer(peer.id, options);\n                        if (provider.multiaddrs.length === 0) {\n                            return null;\n                        }\n                        return provider;\n                    }\n                    catch (err) {\n                        this.log.error('could not load multiaddrs for peer %p', peer.id, err);\n                        return null;\n                    }\n                }, {\n                    peerId: peer.id,\n                    signal: options.signal\n                })\n                    .catch(err => {\n                    this.log.error('could not load multiaddrs for peer %p', peer.id, err);\n                });\n            }\n            yield peer;\n        }\n    }\n    /**\n     * Iterates over all content routers in parallel to notify it is\n     * a provider of the given key\n     */\n    async provide(key, options = {}) {\n        if (this.routers.length === 0) {\n            throw new NoRoutersAvailableError('No content routers available');\n        }\n        await Promise.all(supports(this.routers, 'provide')\n            .map(async (router) => {\n            await router.provide(key, options);\n        }));\n    }\n    /**\n     * Store the given key/value pair in the available content routings\n     */\n    async put(key, value, options) {\n        await Promise.all(supports(this.routers, 'put')\n            .map(async (router) => {\n            await router.put(key, value, options);\n        }));\n    }\n    /**\n     * Get the value to the given key.\n     * Times out after 1 minute by default.\n     */\n    async get(key, options) {\n        return Promise.any(supports(this.routers, 'get')\n            .map(async (router) => {\n            return router.get(key, options);\n        }));\n    }\n    /**\n     * Iterates over all peer routers in parallel to find the given peer\n     */\n    async findPeer(id, options) {\n        if (this.routers.length === 0) {\n            throw new NoRoutersAvailableError('No peer routers available');\n        }\n        const self = this;\n        const source = merge(...supports(this.routers, 'findPeer')\n            .map(router => (async function* () {\n            try {\n                yield await router.findPeer(id, options);\n            }\n            catch (err) {\n                self.log.error(err);\n            }\n        })()));\n        for await (const peer of source) {\n            if (peer == null) {\n                continue;\n            }\n            return peer;\n        }\n        throw new NotFoundError('Could not find peer in routing');\n    }\n    /**\n     * Attempt to find the closest peers on the network to the given key\n     */\n    async *getClosestPeers(key, options = {}) {\n        if (this.routers.length === 0) {\n            throw new NoRoutersAvailableError('No peer routers available');\n        }\n        for await (const peer of merge(...supports(this.routers, 'getClosestPeers')\n            .map(router => router.getClosestPeers(key, options)))) {\n            if (peer == null) {\n                continue;\n            }\n            yield peer;\n        }\n    }\n}\nfunction supports(routers, key) {\n    return routers.filter(router => router[key] != null);\n}\n//# sourceMappingURL=routing.js.map","const events = {};\nconst observable = (worker) => {\n    worker.addEventListener('message', (event) => {\n        observable.dispatchEvent('message', worker, event);\n    });\n    if (worker.port != null) {\n        worker.port.addEventListener('message', (event) => {\n            observable.dispatchEvent('message', worker, event);\n        });\n    }\n};\nobservable.addEventListener = (type, fn) => {\n    if (events[type] == null) {\n        events[type] = [];\n    }\n    events[type].push(fn);\n};\nobservable.removeEventListener = (type, fn) => {\n    if (events[type] == null) {\n        return;\n    }\n    events[type] = events[type]\n        .filter(listener => listener === fn);\n};\nobservable.dispatchEvent = function (type, worker, event) {\n    if (events[type] == null) {\n        return;\n    }\n    events[type].forEach(fn => fn(worker, event));\n};\nexport default observable;\n//# sourceMappingURL=index.js.map","export const WORKER_REQUEST_READ_LOCK = 'lock:worker:request-read';\nexport const WORKER_RELEASE_READ_LOCK = 'lock:worker:release-read';\nexport const MASTER_GRANT_READ_LOCK = 'lock:master:grant-read';\nexport const WORKER_REQUEST_WRITE_LOCK = 'lock:worker:request-write';\nexport const WORKER_RELEASE_WRITE_LOCK = 'lock:worker:release-write';\nexport const MASTER_GRANT_WRITE_LOCK = 'lock:master:grant-write';\n//# sourceMappingURL=constants.js.map","export const nanoid = (size = 21) => {\n    return Math.random().toString().substring(2);\n};\n//# sourceMappingURL=utils.js.map","import observer from 'observable-webworkers';\nimport { WORKER_REQUEST_READ_LOCK, WORKER_RELEASE_READ_LOCK, MASTER_GRANT_READ_LOCK, WORKER_REQUEST_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK } from './constants.js';\nimport { nanoid } from './utils.js';\nconst handleWorkerLockRequest = (emitter, masterEvent, requestType, releaseType, grantType) => {\n    return (worker, event) => {\n        if (event.data.type !== requestType) {\n            return;\n        }\n        const requestEvent = {\n            type: event.data.type,\n            name: event.data.name,\n            identifier: event.data.identifier\n        };\n        emitter.dispatchEvent(new MessageEvent(masterEvent, {\n            data: {\n                name: requestEvent.name,\n                handler: async () => {\n                    // grant lock to worker\n                    worker.postMessage({\n                        type: grantType,\n                        name: requestEvent.name,\n                        identifier: requestEvent.identifier\n                    });\n                    // wait for worker to finish\n                    await new Promise((resolve) => {\n                        const releaseEventListener = (event) => {\n                            if (event?.data == null) {\n                                return;\n                            }\n                            const releaseEvent = {\n                                type: event.data.type,\n                                name: event.data.name,\n                                identifier: event.data.identifier\n                            };\n                            if (releaseEvent.type === releaseType && releaseEvent.identifier === requestEvent.identifier) {\n                                worker.removeEventListener('message', releaseEventListener);\n                                resolve();\n                            }\n                        };\n                        worker.addEventListener('message', releaseEventListener);\n                    });\n                }\n            }\n        }));\n    };\n};\nconst makeWorkerLockRequest = (name, requestType, grantType, releaseType) => {\n    return async () => {\n        const id = nanoid();\n        globalThis.postMessage({\n            type: requestType,\n            identifier: id,\n            name\n        });\n        return new Promise((resolve) => {\n            const listener = (event) => {\n                if (event?.data == null) {\n                    return;\n                }\n                const responseEvent = {\n                    type: event.data.type,\n                    identifier: event.data.identifier\n                };\n                if (responseEvent.type === grantType && responseEvent.identifier === id) {\n                    globalThis.removeEventListener('message', listener);\n                    // grant lock\n                    resolve(() => {\n                        // release lock\n                        globalThis.postMessage({\n                            type: releaseType,\n                            identifier: id,\n                            name\n                        });\n                    });\n                }\n            };\n            globalThis.addEventListener('message', listener);\n        });\n    };\n};\nconst defaultOptions = {\n    singleProcess: false\n};\nexport default (options) => {\n    options = Object.assign({}, defaultOptions, options);\n    const isPrimary = Boolean(globalThis.document) || options.singleProcess;\n    if (isPrimary) {\n        const emitter = new EventTarget();\n        observer.addEventListener('message', handleWorkerLockRequest(emitter, 'requestReadLock', WORKER_REQUEST_READ_LOCK, WORKER_RELEASE_READ_LOCK, MASTER_GRANT_READ_LOCK));\n        observer.addEventListener('message', handleWorkerLockRequest(emitter, 'requestWriteLock', WORKER_REQUEST_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK));\n        return emitter;\n    }\n    return {\n        isWorker: true,\n        readLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_READ_LOCK, MASTER_GRANT_READ_LOCK, WORKER_RELEASE_READ_LOCK),\n        writeLock: (name) => makeWorkerLockRequest(name, WORKER_REQUEST_WRITE_LOCK, MASTER_GRANT_WRITE_LOCK, WORKER_RELEASE_WRITE_LOCK)\n    };\n};\n//# sourceMappingURL=browser.js.map","/**\n * @packageDocumentation\n *\n * - Reads occur concurrently\n * - Writes occur one at a time\n * - No reads occur while a write operation is in progress\n * - Locks can be created with different names\n * - Reads/writes can time out\n *\n * ## Usage\n *\n * ```javascript\n * import mortice from 'mortice'\n * import delay from 'delay'\n *\n * // the lock name & options objects are both optional\n * const mutex = mortice('my-lock', {\n *\n *   // how long before write locks time out (default: 24 hours)\n *   timeout: 30000,\n *\n *    // control how many read operations are executed concurrently (default: Infinity)\n *   concurrency: 5,\n *\n *   // by default the the lock will be held on the main thread, set this to true if the\n *   // a lock should reside on each worker (default: false)\n *   singleProcess: false\n * })\n *\n * Promise.all([\n *   (async () => {\n *     const release = await mutex.readLock()\n *\n *     try {\n *       console.info('read 1')\n *     } finally {\n *       release()\n *     }\n *   })(),\n *   (async () => {\n *     const release = await mutex.readLock()\n *\n *     try {\n *       console.info('read 2')\n *     } finally {\n *       release()\n *     }\n *   })(),\n *   (async () => {\n *     const release = await mutex.writeLock()\n *\n *     try {\n *       await delay(1000)\n *\n *       console.info('write 1')\n *     } finally {\n *       release()\n *     }\n *   })(),\n *   (async () => {\n *     const release = await mutex.readLock()\n *\n *     try {\n *       console.info('read 3')\n *     } finally {\n *       release()\n *     }\n *   })()\n * ])\n * ```\n *\n *     read 1\n *     read 2\n *     <small pause>\n *     write 1\n *     read 3\n *\n * ## Browser\n *\n * Because there's no global way to evesdrop on messages sent by Web Workers, please pass all created Web Workers to the [`observable-webworkers`](https://npmjs.org/package/observable-webworkers) module:\n *\n * ```javascript\n * // main.js\n * import mortice from 'mortice'\n * import observe from 'observable-webworkers'\n *\n * // create our lock on the main thread, it will be held here\n * const mutex = mortice()\n *\n * const worker = new Worker('worker.js')\n *\n * observe(worker)\n * ```\n *\n * ```javascript\n * // worker.js\n * import mortice from 'mortice'\n * import delay from 'delay'\n *\n * const mutex = mortice()\n *\n * let release = await mutex.readLock()\n * // read something\n * release()\n *\n * release = await mutex.writeLock()\n * // write something\n * release()\n * ```\n */\nimport PQueue from 'p-queue';\nimport pTimeout from 'p-timeout';\nimport impl from './node.js';\nconst mutexes = {};\nlet implementation;\nasync function createReleaseable(queue, options) {\n    let res;\n    const p = new Promise((resolve) => {\n        res = resolve;\n    });\n    void queue.add(async () => pTimeout((async () => {\n        await new Promise((resolve) => {\n            res(() => {\n                resolve();\n            });\n        });\n    })(), {\n        milliseconds: options.timeout\n    }));\n    return p;\n}\nconst createMutex = (name, options) => {\n    if (implementation.isWorker === true) {\n        return {\n            readLock: implementation.readLock(name, options),\n            writeLock: implementation.writeLock(name, options)\n        };\n    }\n    const masterQueue = new PQueue({ concurrency: 1 });\n    let readQueue;\n    return {\n        async readLock() {\n            // If there's already a read queue, just add the task to it\n            if (readQueue != null) {\n                return createReleaseable(readQueue, options);\n            }\n            // Create a new read queue\n            readQueue = new PQueue({\n                concurrency: options.concurrency,\n                autoStart: false\n            });\n            const localReadQueue = readQueue;\n            // Add the task to the read queue\n            const readPromise = createReleaseable(readQueue, options);\n            void masterQueue.add(async () => {\n                // Start the task only once the master queue has completed processing\n                // any previous tasks\n                localReadQueue.start();\n                // Once all the tasks in the read queue have completed, remove it so\n                // that the next read lock will occur after any write locks that were\n                // started in the interim\n                await localReadQueue.onIdle()\n                    .then(() => {\n                    if (readQueue === localReadQueue) {\n                        readQueue = null;\n                    }\n                });\n            });\n            return readPromise;\n        },\n        async writeLock() {\n            // Remove the read queue reference, so that any later read locks will be\n            // added to a new queue that starts after this write lock has been\n            // released\n            readQueue = null;\n            return createReleaseable(masterQueue, options);\n        }\n    };\n};\nconst defaultOptions = {\n    name: 'lock',\n    concurrency: Infinity,\n    timeout: 84600000,\n    singleProcess: false\n};\nexport default function createMortice(options) {\n    const opts = Object.assign({}, defaultOptions, options);\n    if (implementation == null) {\n        implementation = impl(opts);\n        if (implementation.isWorker !== true) {\n            // we are master, set up worker requests\n            implementation.addEventListener('requestReadLock', (event) => {\n                if (mutexes[event.data.name] == null) {\n                    return;\n                }\n                void mutexes[event.data.name].readLock()\n                    .then(async (release) => event.data.handler().finally(() => { release(); }));\n            });\n            implementation.addEventListener('requestWriteLock', async (event) => {\n                if (mutexes[event.data.name] == null) {\n                    return;\n                }\n                void mutexes[event.data.name].writeLock()\n                    .then(async (release) => event.data.handler().finally(() => { release(); }));\n            });\n        }\n    }\n    if (mutexes[opts.name] == null) {\n        mutexes[opts.name] = createMutex(opts.name, opts);\n    }\n    return mutexes[opts.name];\n}\n//# sourceMappingURL=index.js.map","import { start, stop } from '@libp2p/interface';\nimport createMortice from 'mortice';\n/**\n * BlockStorage is a hybrid blockstore that puts/gets blocks from a configured\n * blockstore (that may be on disk, s3, or something else). If the blocks are\n * not present Bitswap will be used to fetch them from network peers.\n */\nexport class BlockStorage {\n    lock;\n    child;\n    pins;\n    started;\n    /**\n     * Create a new BlockStorage\n     */\n    constructor(blockstore, pins, options = {}) {\n        this.child = blockstore;\n        this.pins = pins;\n        this.lock = createMortice({\n            singleProcess: options.holdGcLock\n        });\n        this.started = false;\n    }\n    isStarted() {\n        return this.started;\n    }\n    async start() {\n        await start(this.child);\n        this.started = true;\n    }\n    async stop() {\n        await stop(this.child);\n        this.started = false;\n    }\n    unwrap() {\n        return this.child;\n    }\n    /**\n     * Put a block to the underlying datastore\n     */\n    async put(cid, block, options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.readLock();\n        try {\n            return await this.child.put(cid, block, options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    /**\n     * Put a multiple blocks to the underlying datastore\n     */\n    async *putMany(blocks, options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.readLock();\n        try {\n            yield* this.child.putMany(blocks, options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    /**\n     * Get a block by cid\n     */\n    async get(cid, options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.readLock();\n        try {\n            return await this.child.get(cid, options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    /**\n     * Get multiple blocks back from an (async) iterable of cids\n     */\n    async *getMany(cids, options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.readLock();\n        try {\n            yield* this.child.getMany(cids, options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    /**\n     * Delete a block from the blockstore\n     */\n    async delete(cid, options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.writeLock();\n        try {\n            if (await this.pins.isPinned(cid)) {\n                throw new Error('CID was pinned');\n            }\n            await this.child.delete(cid, options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    /**\n     * Delete multiple blocks from the blockstore\n     */\n    async *deleteMany(cids, options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.writeLock();\n        try {\n            const storage = this;\n            yield* this.child.deleteMany((async function* () {\n                for await (const cid of cids) {\n                    if (await storage.pins.isPinned(cid)) {\n                        throw new Error('CID was pinned');\n                    }\n                    yield cid;\n                }\n            }()), options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    async has(cid, options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.readLock();\n        try {\n            return await this.child.has(cid, options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    async *getAll(options = {}) {\n        options?.signal?.throwIfAborted();\n        const releaseLock = await this.lock.readLock();\n        try {\n            yield* this.child.getAll(options);\n        }\n        finally {\n            releaseLock();\n        }\n    }\n    createSession(root, options) {\n        options?.signal?.throwIfAborted();\n        return this.child.createSession(root, options);\n    }\n}\n//# sourceMappingURL=storage.js.map","import { Key } from 'interface-datastore';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nconst DS_VERSION_KEY = new Key('/version');\nconst CURRENT_VERSION = 1;\nexport async function assertDatastoreVersionIsCurrent(datastore) {\n    if (!(await datastore.has(DS_VERSION_KEY))) {\n        await datastore.put(DS_VERSION_KEY, uint8ArrayFromString(`${CURRENT_VERSION}`));\n        return;\n    }\n    const buf = await datastore.get(DS_VERSION_KEY);\n    const str = uint8ArrayToString(buf);\n    const version = parseInt(str, 10);\n    if (version !== CURRENT_VERSION) {\n        // TODO: write migrations when we break compatibility - for an example, see https://github.com/ipfs/js-ipfs-repo/tree/master/packages/ipfs-repo-migrations\n        throw new Error('Unknown datastore version, a datastore migration may be required');\n    }\n}\n//# sourceMappingURL=datastore-version.js.map","import * as cborg from 'cborg'\nimport { CID } from 'multiformats/cid'\n\n// https://github.com/ipfs/go-ipfs/issues/3570#issuecomment-273931692\nconst CID_CBOR_TAG = 42\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ByteView<T>} ByteView\n */\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ArrayBufferView<T>} ArrayBufferView\n */\n\n/**\n * @template T\n * @param {ByteView<T> | ArrayBufferView<T>} buf\n * @returns {ByteView<T>}\n */\nexport function toByteView (buf) {\n  if (buf instanceof ArrayBuffer) {\n    return new Uint8Array(buf, 0, buf.byteLength)\n  }\n\n  return buf\n}\n\n/**\n * cidEncoder will receive all Objects during encode, it needs to filter out\n * anything that's not a CID and return `null` for that so it's encoded as\n * normal.\n *\n * @param {any} obj\n * @returns {cborg.Token[]|null}\n */\nfunction cidEncoder (obj) {\n  if (obj.asCID !== obj && obj['/'] !== obj.bytes) {\n    return null // any other kind of object\n  }\n  const cid = CID.asCID(obj)\n  /* c8 ignore next 4 */\n  // very unlikely case, and it'll probably throw a recursion error in cborg\n  if (!cid) {\n    return null\n  }\n  const bytes = new Uint8Array(cid.bytes.byteLength + 1)\n  bytes.set(cid.bytes, 1) // prefix is 0x00, for historical reasons\n  return [\n    new cborg.Token(cborg.Type.tag, CID_CBOR_TAG),\n    new cborg.Token(cborg.Type.bytes, bytes)\n  ]\n}\n\n// eslint-disable-next-line jsdoc/require-returns-check\n/**\n * Intercept all `undefined` values from an object walk and reject the entire\n * object if we find one.\n *\n * @returns {null}\n */\nfunction undefinedEncoder () {\n  throw new Error('`undefined` is not supported by the IPLD Data Model and cannot be encoded')\n}\n\n/**\n * Intercept all `number` values from an object walk and reject the entire\n * object if we find something that doesn't fit the IPLD data model (NaN &\n * Infinity).\n *\n * @param {number} num\n * @returns {null}\n */\nfunction numberEncoder (num) {\n  if (Number.isNaN(num)) {\n    throw new Error('`NaN` is not supported by the IPLD Data Model and cannot be encoded')\n  }\n  if (num === Infinity || num === -Infinity) {\n    throw new Error('`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded')\n  }\n  return null\n}\n\nconst _encodeOptions = {\n  float64: true,\n  typeEncoders: {\n    Object: cidEncoder,\n    undefined: undefinedEncoder,\n    number: numberEncoder\n  }\n}\n\nexport const encodeOptions = {\n  ..._encodeOptions,\n  typeEncoders: {\n    ..._encodeOptions.typeEncoders\n  }\n}\n\n/**\n * @param {Uint8Array} bytes\n * @returns {CID}\n */\nfunction cidDecoder (bytes) {\n  if (bytes[0] !== 0) {\n    throw new Error('Invalid CID for CBOR tag 42; expected leading 0x00')\n  }\n  return CID.decode(bytes.subarray(1)) // ignore leading 0x00\n}\n\nconst _decodeOptions = {\n  allowIndefinite: false,\n  coerceUndefinedToNull: true,\n  allowNaN: false,\n  allowInfinity: false,\n  allowBigInt: true, // this will lead to BigInt for ints outside of\n  // safe-integer range, which may surprise users\n  strict: true,\n  useMaps: false,\n  rejectDuplicateMapKeys: true,\n  /** @type {import('cborg').TagDecoder[]} */\n  tags: []\n}\n_decodeOptions.tags[CID_CBOR_TAG] = cidDecoder\n\nexport const decodeOptions = {\n  ..._decodeOptions,\n  tags: _decodeOptions.tags.slice()\n}\n\nexport const name = 'dag-cbor'\nexport const code = 0x71\n\n/**\n * @template T\n * @param {T} node\n * @returns {ByteView<T>}\n */\nexport const encode = (node) => cborg.encode(node, _encodeOptions)\n\n/**\n * @template T\n * @param {ByteView<T> | ArrayBufferView<T>} data\n * @returns {T}\n */\nexport const decode = (data) => cborg.decode(toByteView(data), _decodeOptions)\n","import { Type } from '../token.js'\nimport { encodeCustom } from '../encode.js'\nimport { encodeErrPrefix } from '../common.js'\nimport { asU8A, fromString } from '../byte-utils.js'\n\n/**\n * @typedef {import('../../interface').EncodeOptions} EncodeOptions\n * @typedef {import('../token').Token} Token\n * @typedef {import('../bl').Bl} Bl\n */\n\nclass JSONEncoder extends Array {\n  constructor () {\n    super()\n    /** @type {{type:Type,elements:number}[]} */\n    this.inRecursive = []\n  }\n\n  /**\n   * @param {Bl} buf\n   */\n  prefix (buf) {\n    const recurs = this.inRecursive[this.inRecursive.length - 1]\n    if (recurs) {\n      if (recurs.type === Type.array) {\n        recurs.elements++\n        if (recurs.elements !== 1) { // >first\n          buf.push([44]) // ','\n        }\n      }\n      if (recurs.type === Type.map) {\n        recurs.elements++\n        if (recurs.elements !== 1) { // >first\n          if (recurs.elements % 2 === 1) { // key\n            buf.push([44]) // ','\n          } else {\n            buf.push([58]) // ':'\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * @param {Bl} buf\n   * @param {Token} token\n   */\n  [Type.uint.major] (buf, token) {\n    this.prefix(buf)\n    const is = String(token.value)\n    const isa = []\n    for (let i = 0; i < is.length; i++) {\n      isa[i] = is.charCodeAt(i)\n    }\n    buf.push(isa)\n  }\n\n  /**\n   * @param {Bl} buf\n   * @param {Token} token\n   */\n  [Type.negint.major] (buf, token) {\n    // @ts-ignore hack\n    this[Type.uint.major](buf, token)\n  }\n\n  /**\n   * @param {Bl} _buf\n   * @param {Token} _token\n   */\n  [Type.bytes.major] (_buf, _token) {\n    throw new Error(`${encodeErrPrefix} unsupported type: Uint8Array`)\n  }\n\n  /**\n   * @param {Bl} buf\n   * @param {Token} token\n   */\n  [Type.string.major] (buf, token) {\n    this.prefix(buf)\n    // buf.push(34) // '\"'\n    // encodeUtf8(token.value, byts)\n    // buf.push(34) // '\"'\n    const byts = fromString(JSON.stringify(token.value))\n    buf.push(byts.length > 32 ? asU8A(byts) : byts)\n  }\n\n  /**\n   * @param {Bl} buf\n   * @param {Token} _token\n   */\n  [Type.array.major] (buf, _token) {\n    this.prefix(buf)\n    this.inRecursive.push({ type: Type.array, elements: 0 })\n    buf.push([91]) // '['\n  }\n\n  /**\n   * @param {Bl} buf\n   * @param {Token} _token\n   */\n  [Type.map.major] (buf, _token) {\n    this.prefix(buf)\n    this.inRecursive.push({ type: Type.map, elements: 0 })\n    buf.push([123]) // '{'\n  }\n\n  /**\n   * @param {Bl} _buf\n   * @param {Token} _token\n   */\n  [Type.tag.major] (_buf, _token) {}\n\n  /**\n   * @param {Bl} buf\n   * @param {Token} token\n   */\n  [Type.float.major] (buf, token) {\n    if (token.type.name === 'break') {\n      const recurs = this.inRecursive.pop()\n      if (recurs) {\n        if (recurs.type === Type.array) {\n          buf.push([93]) // ']'\n        } else if (recurs.type === Type.map) {\n          buf.push([125]) // '}'\n        /* c8 ignore next 3 */\n        } else {\n          throw new Error('Unexpected recursive type; this should not happen!')\n        }\n        return\n      }\n      /* c8 ignore next 2 */\n      throw new Error('Unexpected break; this should not happen!')\n    }\n    if (token.value === undefined) {\n      throw new Error(`${encodeErrPrefix} unsupported type: undefined`)\n    }\n\n    this.prefix(buf)\n    if (token.type.name === 'true') {\n      buf.push([116, 114, 117, 101]) // 'true'\n      return\n    } else if (token.type.name === 'false') {\n      buf.push([102, 97, 108, 115, 101]) // 'false'\n      return\n    } else if (token.type.name === 'null') {\n      buf.push([110, 117, 108, 108]) // 'null'\n      return\n    }\n\n    // number\n    const is = String(token.value)\n    const isa = []\n    let dp = false\n    for (let i = 0; i < is.length; i++) {\n      isa[i] = is.charCodeAt(i)\n      if (!dp && (isa[i] === 46 || isa[i] === 101 || isa[i] === 69)) { // '[.eE]'\n        dp = true\n      }\n    }\n    if (!dp) { // need a decimal point for floats\n      isa.push(46) // '.'\n      isa.push(48) // '0'\n    }\n    buf.push(isa)\n  }\n}\n\n// The below code is mostly taken and modified from https://github.com/feross/buffer\n// Licensed MIT. Copyright (c) Feross Aboukhadijeh\n// function encodeUtf8 (string, byts) {\n//   let codePoint\n//   const length = string.length\n//   let leadSurrogate = null\n\n//   for (let i = 0; i < length; ++i) {\n//     codePoint = string.charCodeAt(i)\n\n//     // is surrogate component\n//     if (codePoint > 0xd7ff && codePoint < 0xe000) {\n//       // last char was a lead\n//       if (!leadSurrogate) {\n//         // no lead yet\n//         /* c8 ignore next 9 */\n//         if (codePoint > 0xdbff) {\n//           // unexpected trail\n//           byts.push(0xef, 0xbf, 0xbd)\n//           continue\n//         } else if (i + 1 === length) {\n//           // unpaired lead\n//           byts.push(0xef, 0xbf, 0xbd)\n//           continue\n//         }\n\n//         // valid lead\n//         leadSurrogate = codePoint\n\n//         continue\n//       }\n\n//       // 2 leads in a row\n//       /* c8 ignore next 5 */\n//       if (codePoint < 0xdc00) {\n//         byts.push(0xef, 0xbf, 0xbd)\n//         leadSurrogate = codePoint\n//         continue\n//       }\n\n//       // valid surrogate pair\n//       codePoint = (leadSurrogate - 0xd800 << 10 | codePoint - 0xdc00) + 0x10000\n//     /* c8 ignore next 4 */\n//     } else if (leadSurrogate) {\n//       // valid bmp char, but last char was a lead\n//       byts.push(0xef, 0xbf, 0xbd)\n//     }\n\n//     leadSurrogate = null\n\n//     // encode utf8\n//     if (codePoint < 0x80) {\n//       // special JSON escapes\n//       switch (codePoint) {\n//         case 8: // '\\b'\n//           byts.push(92, 98) // '\\\\b'\n//           continue\n//         case 9: // '\\t'\n//           byts.push(92, 116) // '\\\\t'\n//           continue\n//         case 10: // '\\n'\n//           byts.push(92, 110) // '\\\\n'\n//           continue\n//         case 12: // '\\f'\n//           byts.push(92, 102) // '\\\\f'\n//           continue\n//         case 13: // '\\r'\n//           byts.push(92, 114) // '\\\\r'\n//           continue\n//         case 34: // '\"'\n//           byts.push(92, 34) // '\\\\\"'\n//           continue\n//         case 92: // '\\\\'\n//           byts.push(92, 92) // '\\\\\\\\'\n//           continue\n//       }\n\n//       byts.push(codePoint)\n//     } else if (codePoint < 0x800) {\n//       /* c8 ignore next 1 */\n//       byts.push(\n//         codePoint >> 0x6 | 0xc0,\n//         codePoint & 0x3f | 0x80\n//       )\n//     } else if (codePoint < 0x10000) {\n//       /* c8 ignore next 1 */\n//       byts.push(\n//         codePoint >> 0xc | 0xe0,\n//         codePoint >> 0x6 & 0x3f | 0x80,\n//         codePoint & 0x3f | 0x80\n//       )\n//     /* c8 ignore next 9 */\n//     } else if (codePoint < 0x110000) {\n//       byts.push(\n//         codePoint >> 0x12 | 0xf0,\n//         codePoint >> 0xc & 0x3f | 0x80,\n//         codePoint >> 0x6 & 0x3f | 0x80,\n//         codePoint & 0x3f | 0x80\n//       )\n//     } else {\n//       /* c8 ignore next 2 */\n//       throw new Error('Invalid code point')\n//     }\n//   }\n// }\n\n/**\n * @param {(Token|Token[])[]} e1\n * @param {(Token|Token[])[]} e2\n * @returns {number}\n */\nfunction mapSorter (e1, e2) {\n  if (Array.isArray(e1[0]) || Array.isArray(e2[0])) {\n    throw new Error(`${encodeErrPrefix} complex map keys are not supported`)\n  }\n  const keyToken1 = e1[0]\n  const keyToken2 = e2[0]\n  if (keyToken1.type !== Type.string || keyToken2.type !== Type.string) {\n    throw new Error(`${encodeErrPrefix} non-string map keys are not supported`)\n  }\n  if (keyToken1 < keyToken2) {\n    return -1\n  }\n  if (keyToken1 > keyToken2) {\n    return 1\n  }\n  /* c8 ignore next 1 */\n  throw new Error(`${encodeErrPrefix} unexpected duplicate map keys, this is not supported`)\n}\n\nconst defaultEncodeOptions = { addBreakTokens: true, mapSorter }\n\n/**\n * @param {any} data\n * @param {EncodeOptions} [options]\n * @returns {Uint8Array}\n */\nfunction encode (data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options)\n  return encodeCustom(data, new JSONEncoder(), options)\n}\n\nexport { encode }\n","import { decode as _decode, decodeFirst as _decodeFirst } from '../decode.js'\nimport { Token, Type } from '../token.js'\nimport { decodeCodePointsArray } from '../byte-utils.js'\nimport { decodeErrPrefix } from '../common.js'\n\n/**\n * @typedef {import('../../interface').DecodeOptions} DecodeOptions\n * @typedef {import('../../interface').DecodeTokenizer} DecodeTokenizer\n */\n\n/**\n * @implements {DecodeTokenizer}\n */\nclass Tokenizer {\n  /**\n   * @param {Uint8Array} data\n   * @param {DecodeOptions} options\n   */\n  constructor (data, options = {}) {\n    this._pos = 0\n    this.data = data\n    this.options = options\n    /** @type {string[]} */\n    this.modeStack = ['value']\n    this.lastToken = ''\n  }\n\n  pos () {\n    return this._pos\n  }\n\n  /**\n   * @returns {boolean}\n   */\n  done () {\n    return this._pos >= this.data.length\n  }\n\n  /**\n   * @returns {number}\n   */\n  ch () {\n    return this.data[this._pos]\n  }\n\n  /**\n   * @returns {string}\n   */\n  currentMode () {\n    return this.modeStack[this.modeStack.length - 1]\n  }\n\n  skipWhitespace () {\n    let c = this.ch()\n    // @ts-ignore\n    while (c === 32 /* ' ' */ || c === 9 /* '\\t' */ || c === 13 /* '\\r' */ || c === 10 /* '\\n' */) {\n      c = this.data[++this._pos]\n    }\n  }\n\n  /**\n   * @param {number[]} str\n   */\n  expect (str) {\n    if (this.data.length - this._pos < str.length) {\n      throw new Error(`${decodeErrPrefix} unexpected end of input at position ${this._pos}`)\n    }\n    for (let i = 0; i < str.length; i++) {\n      if (this.data[this._pos++] !== str[i]) {\n        throw new Error(`${decodeErrPrefix} unexpected token at position ${this._pos}, expected to find '${String.fromCharCode(...str)}'`)\n      }\n    }\n  }\n\n  parseNumber () {\n    const startPos = this._pos\n    let negative = false\n    let float = false\n\n    /**\n     * @param {number[]} chars\n     */\n    const swallow = (chars) => {\n      while (!this.done()) {\n        const ch = this.ch()\n        if (chars.includes(ch)) {\n          this._pos++\n        } else {\n          break\n        }\n      }\n    }\n\n    // lead\n    if (this.ch() === 45) { // '-'\n      negative = true\n      this._pos++\n    }\n    if (this.ch() === 48) { // '0'\n      this._pos++\n      if (this.ch() === 46) { // '.'\n        this._pos++\n        float = true\n      } else {\n        return new Token(Type.uint, 0, this._pos - startPos)\n      }\n    }\n    swallow([48, 49, 50, 51, 52, 53, 54, 55, 56, 57]) // DIGIT\n    if (negative && this._pos === startPos + 1) {\n      throw new Error(`${decodeErrPrefix} unexpected token at position ${this._pos}`)\n    }\n    if (!this.done() && this.ch() === 46) { // '.'\n      if (float) {\n        throw new Error(`${decodeErrPrefix} unexpected token at position ${this._pos}`)\n      }\n      float = true\n      this._pos++\n      swallow([48, 49, 50, 51, 52, 53, 54, 55, 56, 57]) // DIGIT\n    }\n    if (!this.done() && (this.ch() === 101 || this.ch() === 69)) { // '[eE]'\n      float = true\n      this._pos++\n      if (!this.done() && (this.ch() === 43 || this.ch() === 45)) { // '+', '-'\n        this._pos++\n      }\n      swallow([48, 49, 50, 51, 52, 53, 54, 55, 56, 57]) // DIGIT\n    }\n    // @ts-ignore\n    const numStr = String.fromCharCode.apply(null, this.data.subarray(startPos, this._pos))\n    const num = parseFloat(numStr)\n    if (float) {\n      return new Token(Type.float, num, this._pos - startPos)\n    }\n    if (this.options.allowBigInt !== true || Number.isSafeInteger(num)) {\n      return new Token(num >= 0 ? Type.uint : Type.negint, num, this._pos - startPos)\n    }\n    return new Token(num >= 0 ? Type.uint : Type.negint, BigInt(numStr), this._pos - startPos)\n  }\n\n  /**\n   * @returns {Token}\n   */\n  parseString () {\n    /* c8 ignore next 4 */\n    if (this.ch() !== 34) { // '\"'\n      // this would be a programming error\n      throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}; this shouldn't happen`)\n    }\n    this._pos++\n\n    // check for simple fast-path, all printable ascii, no escapes\n    // >0x10000 elements may fail fn.apply() (http://stackoverflow.com/a/22747272/680742)\n    for (let i = this._pos, l = 0; i < this.data.length && l < 0x10000; i++, l++) {\n      const ch = this.data[i]\n      if (ch === 92 || ch < 32 || ch >= 128) { // '\\', ' ', control-chars or non-trivial\n        break\n      }\n      if (ch === 34) { // '\"'\n        // @ts-ignore\n        const str = String.fromCharCode.apply(null, this.data.subarray(this._pos, i))\n        this._pos = i + 1\n        return new Token(Type.string, str, l)\n      }\n    }\n\n    const startPos = this._pos\n    const chars = []\n\n    const readu4 = () => {\n      if (this._pos + 4 >= this.data.length) {\n        throw new Error(`${decodeErrPrefix} unexpected end of unicode escape sequence at position ${this._pos}`)\n      }\n      let u4 = 0\n      for (let i = 0; i < 4; i++) {\n        let ch = this.ch()\n        if (ch >= 48 && ch <= 57) { // '0' && '9'\n          ch -= 48\n        } else if (ch >= 97 && ch <= 102) { // 'a' && 'f'\n          ch = ch - 97 + 10\n        } else if (ch >= 65 && ch <= 70) { // 'A' && 'F'\n          ch = ch - 65 + 10\n        } else {\n          throw new Error(`${decodeErrPrefix} unexpected unicode escape character at position ${this._pos}`)\n        }\n        u4 = u4 * 16 + ch\n        this._pos++\n      }\n      return u4\n    }\n\n    // mostly taken from feross/buffer and adjusted to fit\n    const readUtf8Char = () => {\n      const firstByte = this.ch()\n      let codePoint = null\n      /* c8 ignore next 1 */\n      let bytesPerSequence = (firstByte > 0xef) ? 4 : (firstByte > 0xdf) ? 3 : (firstByte > 0xbf) ? 2 : 1\n\n      if (this._pos + bytesPerSequence > this.data.length) {\n        throw new Error(`${decodeErrPrefix} unexpected unicode sequence at position ${this._pos}`)\n      }\n\n      let secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        /* c8 ignore next 6 */\n        // this case is dealt with by the caller function\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = this.data[this._pos + 1]\n          if ((secondByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1f) << 0x6 | (secondByte & 0x3f)\n            if (tempCodePoint > 0x7f) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = this.data[this._pos + 1]\n          thirdByte = this.data[this._pos + 2]\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0xc | (secondByte & 0x3f) << 0x6 | (thirdByte & 0x3f)\n            /* c8 ignore next 3 */\n            if (tempCodePoint > 0x7ff && (tempCodePoint < 0xd800 || tempCodePoint > 0xdfff)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = this.data[this._pos + 1]\n          thirdByte = this.data[this._pos + 2]\n          fourthByte = this.data[this._pos + 3]\n          if ((secondByte & 0xc0) === 0x80 && (thirdByte & 0xc0) === 0x80 && (fourthByte & 0xc0) === 0x80) {\n            tempCodePoint = (firstByte & 0xf) << 0x12 | (secondByte & 0x3f) << 0xc | (thirdByte & 0x3f) << 0x6 | (fourthByte & 0x3f)\n            if (tempCodePoint > 0xffff && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n\n      /* c8 ignore next 5 */\n      if (codePoint === null) {\n        // we did not generate a valid codePoint so insert a\n        // replacement char (U+FFFD) and advance only 1 byte\n        codePoint = 0xfffd\n        bytesPerSequence = 1\n      } else if (codePoint > 0xffff) {\n        // encode to utf16 (surrogate pair dance)\n        codePoint -= 0x10000\n        chars.push(codePoint >>> 10 & 0x3ff | 0xd800)\n        codePoint = 0xdc00 | codePoint & 0x3ff\n      }\n\n      chars.push(codePoint)\n      this._pos += bytesPerSequence\n    }\n\n    // TODO: could take the approach of a quick first scan for special chars like encoding/json/decode.go#unquoteBytes\n    // and converting all of the ascii chars from the base array in bulk\n    while (!this.done()) {\n      const ch = this.ch()\n      let ch1\n      switch (ch) {\n        case 92: // '\\'\n          this._pos++\n          if (this.done()) {\n            throw new Error(`${decodeErrPrefix} unexpected string termination at position ${this._pos}`)\n          }\n          ch1 = this.ch()\n          this._pos++\n          switch (ch1) {\n            case 34: // '\"'\n            case 39: // '\\''\n            case 92: // '\\'\n            case 47: // '/'\n              chars.push(ch1)\n              break\n            case 98: // 'b'\n              chars.push(8)\n              break\n            case 116: // 't'\n              chars.push(9)\n              break\n            case 110: // 'n'\n              chars.push(10)\n              break\n            case 102: // 'f'\n              chars.push(12)\n              break\n            case 114: // 'r'\n              chars.push(13)\n              break\n            case 117: // 'u'\n              chars.push(readu4())\n              break\n            default:\n              throw new Error(`${decodeErrPrefix} unexpected string escape character at position ${this._pos}`)\n          }\n          break\n        case 34: // '\"'\n          this._pos++\n          return new Token(Type.string, decodeCodePointsArray(chars), this._pos - startPos)\n        default:\n          if (ch < 32) { // ' '\n            throw new Error(`${decodeErrPrefix} invalid control character at position ${this._pos}`)\n          } else if (ch < 0x80) {\n            chars.push(ch)\n            this._pos++\n          } else {\n            readUtf8Char()\n          }\n      }\n    }\n\n    throw new Error(`${decodeErrPrefix} unexpected end of string at position ${this._pos}`)\n  }\n\n  /**\n   * @returns {Token}\n   */\n  parseValue () {\n    switch (this.ch()) {\n      case 123: // '{'\n        this.modeStack.push('obj-start')\n        this._pos++\n        return new Token(Type.map, Infinity, 1)\n      case 91: // '['\n        this.modeStack.push('array-start')\n        this._pos++\n        return new Token(Type.array, Infinity, 1)\n      case 34: { // '\"'\n        return this.parseString()\n      }\n      case 110: // 'n' / null\n        this.expect([110, 117, 108, 108]) // 'null'\n        return new Token(Type.null, null, 4)\n      case 102: // 'f' / // false\n        this.expect([102, 97, 108, 115, 101]) // 'false'\n        return new Token(Type.false, false, 5)\n      case 116: // 't' / // true\n        this.expect([116, 114, 117, 101]) // 'true'\n        return new Token(Type.true, true, 4)\n      case 45: // '-'\n      case 48: // '0'\n      case 49: // '1'\n      case 50: // '2'\n      case 51: // '3'\n      case 52: // '4'\n      case 53: // '5'\n      case 54: // '6'\n      case 55: // '7'\n      case 56: // '8'\n      case 57: // '9'\n        return this.parseNumber()\n      default:\n        throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}`)\n    }\n  }\n\n  /**\n   * @returns {Token}\n   */\n  next () {\n    this.skipWhitespace()\n    switch (this.currentMode()) {\n      case 'value':\n        this.modeStack.pop()\n        return this.parseValue()\n      case 'array-value': {\n        this.modeStack.pop()\n        if (this.ch() === 93) { // ']'\n          this._pos++\n          this.skipWhitespace()\n          return new Token(Type.break, undefined, 1)\n        }\n        if (this.ch() !== 44) { // ','\n          throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}, was expecting array delimiter but found '${String.fromCharCode(this.ch())}'`)\n        }\n        this._pos++\n        this.modeStack.push('array-value')\n        this.skipWhitespace()\n        return this.parseValue()\n      }\n      case 'array-start': {\n        this.modeStack.pop()\n        if (this.ch() === 93) { // ']'\n          this._pos++\n          this.skipWhitespace()\n          return new Token(Type.break, undefined, 1)\n        }\n        this.modeStack.push('array-value')\n        this.skipWhitespace()\n        return this.parseValue()\n      }\n      // @ts-ignore\n      case 'obj-key':\n        if (this.ch() === 125) { // '}'\n          this.modeStack.pop()\n          this._pos++\n          this.skipWhitespace()\n          return new Token(Type.break, undefined, 1)\n        }\n        if (this.ch() !== 44) { // ','\n          throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}, was expecting object delimiter but found '${String.fromCharCode(this.ch())}'`)\n        }\n        this._pos++\n        this.skipWhitespace()\n      case 'obj-start': { // eslint-disable-line no-fallthrough\n        this.modeStack.pop()\n        if (this.ch() === 125) { // '}'\n          this._pos++\n          this.skipWhitespace()\n          return new Token(Type.break, undefined, 1)\n        }\n        const token = this.parseString()\n        this.skipWhitespace()\n        if (this.ch() !== 58) { // ':'\n          throw new Error(`${decodeErrPrefix} unexpected character at position ${this._pos}, was expecting key/value delimiter ':' but found '${String.fromCharCode(this.ch())}'`)\n        }\n        this._pos++\n        this.modeStack.push('obj-value')\n        return token\n      }\n      case 'obj-value': {\n        this.modeStack.pop()\n        this.modeStack.push('obj-key')\n        this.skipWhitespace()\n        return this.parseValue()\n      }\n      /* c8 ignore next 2 */\n      default:\n        throw new Error(`${decodeErrPrefix} unexpected parse state at position ${this._pos}; this shouldn't happen`)\n    }\n  }\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {any}\n */\nfunction decode (data, options) {\n  options = Object.assign({ tokenizer: new Tokenizer(data, options) }, options)\n  return _decode(data, options)\n}\n\n/**\n * @param {Uint8Array} data\n * @param {DecodeOptions} [options]\n * @returns {[any, Uint8Array]}\n */\nfunction decodeFirst (data, options) {\n  options = Object.assign({ tokenizer: new Tokenizer(data, options) }, options)\n  return _decodeFirst(data, options)\n}\n\nexport { decode, decodeFirst, Tokenizer }\n","import { encode } from './encode.js'\nimport { decode, decodeFirst, Tokenizer } from './decode.js'\n\nexport { encode, decode, decodeFirst, Tokenizer }\n","/* eslint max-depth: [\"error\", 7] */\nimport { Token, Type } from 'cborg'\nimport * as cborgJson from 'cborg/json'\nimport { CID } from 'multiformats'\nimport { base64 } from 'multiformats/bases/base64'\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ByteView<T>} ByteView\n */\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ArrayBufferView<T>} ArrayBufferView\n */\n/**\n * @template T\n * @typedef {import('multiformats').ToString<T>} ToString\n */\n/**\n * @typedef {import('cborg/interface').DecodeTokenizer} DecodeTokenizer\n */\n\n/**\n * @template T\n * @param {ByteView<T> | ArrayBufferView<T>} buf\n * @returns {ByteView<T>}\n */\nfunction toByteView (buf) {\n  if (buf instanceof ArrayBuffer) {\n    return new Uint8Array(buf, 0, buf.byteLength)\n  }\n\n  return buf\n}\n\n/**\n * cidEncoder will receive all Objects during encode, it needs to filter out\n * anything that's not a CID and return `null` for that so it's encoded as\n * normal. Encoding a CID means replacing it with a `{\"/\":\"<CidString>}`\n * object as per the DAG-JSON spec.\n *\n * @param {any} obj\n * @returns {Token[]|null}\n */\nfunction cidEncoder (obj) {\n  if (obj.asCID !== obj && obj['/'] !== obj.bytes) {\n    return null // any other kind of object\n  }\n  const cid = CID.asCID(obj)\n  /* c8 ignore next 4 */\n  // very unlikely case, and it'll probably throw a recursion error in cborg\n  if (!cid) {\n    return null\n  }\n  const cidString = cid.toString()\n\n  return [\n    new Token(Type.map, Infinity, 1),\n    new Token(Type.string, '/', 1), // key\n    new Token(Type.string, cidString, cidString.length), // value\n    new Token(Type.break, undefined, 1)\n  ]\n}\n\n/**\n * bytesEncoder will receive all Uint8Arrays (and friends) during encode, it\n * needs to replace it with a `{\"/\":{\"bytes\":\"Base64ByteString\"}}` object as\n * per the DAG-JSON spec.\n *\n * @param {Uint8Array} bytes\n * @returns {Token[]|null}\n */\nfunction bytesEncoder (bytes) {\n  const bytesString = base64.encode(bytes).slice(1) // no mbase prefix\n  return [\n    new Token(Type.map, Infinity, 1),\n    new Token(Type.string, '/', 1), // key\n    new Token(Type.map, Infinity, 1), // value\n    new Token(Type.string, 'bytes', 5), // inner key\n    new Token(Type.string, bytesString, bytesString.length), // inner value\n    new Token(Type.break, undefined, 1),\n    new Token(Type.break, undefined, 1)\n  ]\n}\n\n/**\n * taBytesEncoder wraps bytesEncoder() but for the more exotic typed arrays so\n * that we access the underlying ArrayBuffer data\n *\n * @param {Int8Array|Uint16Array|Int16Array|Uint32Array|Int32Array|Float32Array|Float64Array|Uint8ClampedArray|BigInt64Array|BigUint64Array} obj\n * @returns {Token[]|null}\n */\nfunction taBytesEncoder (obj) {\n  return bytesEncoder(new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength))\n}\n\n/**\n * abBytesEncoder wraps bytesEncoder() but for plain ArrayBuffers\n *\n * @param {ArrayBuffer} ab\n * @returns {Token[]|null}\n */\nfunction abBytesEncoder (ab) {\n  return bytesEncoder(new Uint8Array(ab))\n}\n\n// eslint-disable-next-line jsdoc/require-returns-check\n/**\n * Intercept all `undefined` values from an object walk and reject the entire\n * object if we find one.\n *\n * @returns {null}\n */\nfunction undefinedEncoder () {\n  throw new Error('`undefined` is not supported by the IPLD Data Model and cannot be encoded')\n}\n\n/**\n * Intercept all `number` values from an object walk and reject the entire\n * object if we find something that doesn't fit the IPLD data model (NaN &\n * Infinity).\n *\n * @param {number} num\n * @returns {null}\n */\nfunction numberEncoder (num) {\n  if (Number.isNaN(num)) {\n    throw new Error('`NaN` is not supported by the IPLD Data Model and cannot be encoded')\n  }\n  if (num === Infinity || num === -Infinity) {\n    throw new Error('`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded')\n  }\n  return null // process with standard number encoder\n}\n\nconst encodeOptions = {\n  typeEncoders: {\n    Object: cidEncoder,\n    Buffer: bytesEncoder,\n    Uint8Array: bytesEncoder,\n    Int8Array: taBytesEncoder,\n    Uint16Array: taBytesEncoder,\n    Int16Array: taBytesEncoder,\n    Uint32Array: taBytesEncoder,\n    Int32Array: taBytesEncoder,\n    Float32Array: taBytesEncoder,\n    Float64Array: taBytesEncoder,\n    Uint8ClampedArray: taBytesEncoder,\n    BigInt64Array: taBytesEncoder,\n    BigUint64Array: taBytesEncoder,\n    DataView: taBytesEncoder,\n    ArrayBuffer: abBytesEncoder,\n    undefined: undefinedEncoder,\n    number: numberEncoder\n  }\n}\n\n/**\n * @implements {DecodeTokenizer}\n */\nclass DagJsonTokenizer extends cborgJson.Tokenizer {\n  /**\n   * @param {Uint8Array} data\n   * @param {object} [options]\n   */\n  constructor (data, options) {\n    super(data, options)\n    /** @type {Token[]} */\n    this.tokenBuffer = []\n  }\n\n  /**\n   * @returns {boolean}\n   */\n  done () {\n    return this.tokenBuffer.length === 0 && super.done()\n  }\n\n  /**\n   * @returns {Token}\n   */\n  _next () {\n    if (this.tokenBuffer.length > 0) {\n      // @ts-ignore https://github.com/Microsoft/TypeScript/issues/30406\n      return this.tokenBuffer.pop()\n    }\n    return super.next()\n  }\n\n  /**\n   * Implements rules outlined in https://github.com/ipld/specs/pull/356\n   *\n   * @returns {Token}\n   */\n  next () {\n    const token = this._next()\n\n    if (token.type === Type.map) {\n      const keyToken = this._next()\n      if (keyToken.type === Type.string && keyToken.value === '/') {\n        const valueToken = this._next()\n        if (valueToken.type === Type.string) { // *must* be a CID\n          const breakToken = this._next() // swallow the end-of-map token\n          if (breakToken.type !== Type.break) {\n            throw new Error('Invalid encoded CID form')\n          }\n          this.tokenBuffer.push(valueToken) // CID.parse will pick this up after our tag token\n          return new Token(Type.tag, 42, 0)\n        }\n        if (valueToken.type === Type.map) {\n          const innerKeyToken = this._next()\n          if (innerKeyToken.type === Type.string && innerKeyToken.value === 'bytes') {\n            const innerValueToken = this._next()\n            if (innerValueToken.type === Type.string) { // *must* be Bytes\n              for (let i = 0; i < 2; i++) {\n                const breakToken = this._next() // swallow two end-of-map tokens\n                if (breakToken.type !== Type.break) {\n                  throw new Error('Invalid encoded Bytes form')\n                }\n              }\n              const bytes = base64.decode(`m${innerValueToken.value}`)\n              return new Token(Type.bytes, bytes, innerValueToken.value.length)\n            }\n            this.tokenBuffer.push(innerValueToken) // bail\n          }\n          this.tokenBuffer.push(innerKeyToken) // bail\n        }\n        this.tokenBuffer.push(valueToken) // bail\n      }\n      this.tokenBuffer.push(keyToken) // bail\n    }\n    return token\n  }\n}\n\nconst decodeOptions = {\n  allowIndefinite: false,\n  allowUndefined: false,\n  allowNaN: false,\n  allowInfinity: false,\n  allowBigInt: true, // this will lead to BigInt for ints outside of\n  // safe-integer range, which may surprise users\n  strict: true,\n  useMaps: false,\n  rejectDuplicateMapKeys: true,\n  /** @type {import('cborg').TagDecoder[]} */\n  tags: []\n}\n\n// we're going to get TAG(42)STRING(\"bafy...\") from the tokenizer so we only need\n// to deal with the STRING(\"bafy...\") at this point\ndecodeOptions.tags[42] = CID.parse\n\nexport const name = 'dag-json'\nexport const code = 0x0129\n\n/**\n * @template T\n * @param {T} node\n * @returns {ByteView<T>}\n */\nexport const encode = (node) => cborgJson.encode(node, encodeOptions)\n\n/**\n * @template T\n * @param {ByteView<T> | ArrayBufferView<T>} data\n * @returns {T}\n */\nexport const decode = (data) => {\n  const buf = toByteView(data)\n  // the tokenizer is stateful so we need a single instance of it\n  const options = Object.assign(decodeOptions, { tokenizer: new DagJsonTokenizer(buf, decodeOptions) })\n  return cborgJson.decode(buf, options)\n}\n\n/**\n * @template T\n * @param {T} node\n * @returns {ToString<T>}\n */\nexport const format = (node) => utf8Decoder.decode(encode(node))\nexport { format as stringify }\nconst utf8Decoder = new TextDecoder()\n\n/**\n * @template T\n * @param {ToString<T>} data\n * @returns {T}\n */\nexport const parse = (data) => decode(utf8Encoder.encode(data))\nconst utf8Encoder = new TextEncoder()\n","const textDecoder = new TextDecoder()\n\n/**\n * @typedef {import('./interface.js').RawPBLink} RawPBLink\n */\n\n/**\n * @typedef {import('./interface.js').RawPBNode} RawPBNode\n */\n\n/**\n * @param {Uint8Array} bytes\n * @param {number} offset\n * @returns {[number, number]}\n */\nfunction decodeVarint (bytes, offset) {\n  let v = 0\n\n  for (let shift = 0; ; shift += 7) {\n    /* c8 ignore next 3 */\n    if (shift >= 64) {\n      throw new Error('protobuf: varint overflow')\n    }\n    /* c8 ignore next 3 */\n    if (offset >= bytes.length) {\n      throw new Error('protobuf: unexpected end of data')\n    }\n\n    const b = bytes[offset++]\n    v += shift < 28 ? (b & 0x7f) << shift : (b & 0x7f) * (2 ** shift)\n    if (b < 0x80) {\n      break\n    }\n  }\n  return [v, offset]\n}\n\n/**\n * @param {Uint8Array} bytes\n * @param {number} offset\n * @returns {[Uint8Array, number]}\n */\nfunction decodeBytes (bytes, offset) {\n  let byteLen\n  ;[byteLen, offset] = decodeVarint(bytes, offset)\n  const postOffset = offset + byteLen\n\n  /* c8 ignore next 3 */\n  if (byteLen < 0 || postOffset < 0) {\n    throw new Error('protobuf: invalid length')\n  }\n  /* c8 ignore next 3 */\n  if (postOffset > bytes.length) {\n    throw new Error('protobuf: unexpected end of data')\n  }\n\n  return [bytes.subarray(offset, postOffset), postOffset]\n}\n\n/**\n * @param {Uint8Array} bytes\n * @param {number} index\n * @returns {[number, number, number]}\n */\nfunction decodeKey (bytes, index) {\n  let wire\n  ;[wire, index] = decodeVarint(bytes, index)\n  // [wireType, fieldNum, newIndex]\n  return [wire & 0x7, wire >> 3, index]\n}\n\n/**\n * @param {Uint8Array} bytes\n * @returns {RawPBLink}\n */\nfunction decodeLink (bytes) {\n  /** @type {RawPBLink} */\n  const link = {}\n  const l = bytes.length\n  let index = 0\n\n  while (index < l) {\n    let wireType, fieldNum\n    ;[wireType, fieldNum, index] = decodeKey(bytes, index)\n\n    if (fieldNum === 1) {\n      if (link.Hash) {\n        throw new Error('protobuf: (PBLink) duplicate Hash section')\n      }\n      if (wireType !== 2) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Hash`)\n      }\n      if (link.Name !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Name before Hash')\n      }\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Tsize before Hash')\n      }\n\n      [link.Hash, index] = decodeBytes(bytes, index)\n    } else if (fieldNum === 2) {\n      if (link.Name !== undefined) {\n        throw new Error('protobuf: (PBLink) duplicate Name section')\n      }\n      if (wireType !== 2) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Name`)\n      }\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) invalid order, found Tsize before Name')\n      }\n\n      let byts\n      ;[byts, index] = decodeBytes(bytes, index)\n      link.Name = textDecoder.decode(byts)\n    } else if (fieldNum === 3) {\n      if (link.Tsize !== undefined) {\n        throw new Error('protobuf: (PBLink) duplicate Tsize section')\n      }\n      if (wireType !== 0) {\n        throw new Error(`protobuf: (PBLink) wrong wireType (${wireType}) for Tsize`)\n      }\n\n      [link.Tsize, index] = decodeVarint(bytes, index)\n    } else {\n      throw new Error(`protobuf: (PBLink) invalid fieldNumber, expected 1, 2 or 3, got ${fieldNum}`)\n    }\n  }\n\n  /* c8 ignore next 3 */\n  if (index > l) {\n    throw new Error('protobuf: (PBLink) unexpected end of data')\n  }\n\n  return link\n}\n\n/**\n * @param {Uint8Array} bytes\n * @returns {RawPBNode}\n */\nexport function decodeNode (bytes) {\n  const l = bytes.length\n  let index = 0\n  /** @type {RawPBLink[]|void} */\n  let links = undefined // eslint-disable-line no-undef-init\n  let linksBeforeData = false\n  /** @type {Uint8Array|void} */\n  let data = undefined // eslint-disable-line no-undef-init\n\n  while (index < l) {\n    let wireType, fieldNum\n    ;[wireType, fieldNum, index] = decodeKey(bytes, index)\n\n    if (wireType !== 2) {\n      throw new Error(`protobuf: (PBNode) invalid wireType, expected 2, got ${wireType}`)\n    }\n\n    if (fieldNum === 1) {\n      if (data) {\n        throw new Error('protobuf: (PBNode) duplicate Data section')\n      }\n\n      [data, index] = decodeBytes(bytes, index)\n      if (links) {\n        linksBeforeData = true\n      }\n    } else if (fieldNum === 2) {\n      if (linksBeforeData) { // interleaved Links/Data/Links\n        throw new Error('protobuf: (PBNode) duplicate Links section')\n      } else if (!links) {\n        links = []\n      }\n      let byts\n      ;[byts, index] = decodeBytes(bytes, index)\n      links.push(decodeLink(byts))\n    } else {\n      throw new Error(`protobuf: (PBNode) invalid fieldNumber, expected 1 or 2, got ${fieldNum}`)\n    }\n  }\n\n  /* c8 ignore next 3 */\n  if (index > l) {\n    throw new Error('protobuf: (PBNode) unexpected end of data')\n  }\n\n  /** @type {RawPBNode} */\n  const node = {}\n  if (data) {\n    node.Data = data\n  }\n  node.Links = links || []\n  return node\n}\n","const textEncoder = new TextEncoder()\nconst maxInt32 = 2 ** 32\nconst maxUInt32 = 2 ** 31\n\n/**\n * @typedef {import('./interface.js').RawPBLink} RawPBLink\n */\n\n/**\n * @typedef {import('./interface.js').RawPBNode} RawPBNode\n */\n\n// the encoders work backward from the end of the bytes array\n\n/**\n * encodeLink() is passed a slice of the parent byte array that ends where this\n * link needs to end, so it packs to the right-most part of the passed `bytes`\n *\n * @param {RawPBLink} link\n * @param {Uint8Array} bytes\n * @returns {number}\n */\nfunction encodeLink (link, bytes) {\n  let i = bytes.length\n\n  if (typeof link.Tsize === 'number') {\n    if (link.Tsize < 0) {\n      throw new Error('Tsize cannot be negative')\n    }\n    if (!Number.isSafeInteger(link.Tsize)) {\n      throw new Error('Tsize too large for encoding')\n    }\n    i = encodeVarint(bytes, i, link.Tsize) - 1\n    bytes[i] = 0x18\n  }\n\n  if (typeof link.Name === 'string') {\n    const nameBytes = textEncoder.encode(link.Name)\n    i -= nameBytes.length\n    bytes.set(nameBytes, i)\n    i = encodeVarint(bytes, i, nameBytes.length) - 1\n    bytes[i] = 0x12\n  }\n\n  if (link.Hash) {\n    i -= link.Hash.length\n    bytes.set(link.Hash, i)\n    i = encodeVarint(bytes, i, link.Hash.length) - 1\n    bytes[i] = 0xa\n  }\n\n  return bytes.length - i\n}\n\n/**\n * Encodes a PBNode into a new byte array of precisely the correct size\n *\n * @param {RawPBNode} node\n * @returns {Uint8Array}\n */\nexport function encodeNode (node) {\n  const size = sizeNode(node)\n  const bytes = new Uint8Array(size)\n  let i = size\n\n  if (node.Data) {\n    i -= node.Data.length\n    bytes.set(node.Data, i)\n    i = encodeVarint(bytes, i, node.Data.length) - 1\n    bytes[i] = 0xa\n  }\n\n  if (node.Links) {\n    for (let index = node.Links.length - 1; index >= 0; index--) {\n      const size = encodeLink(node.Links[index], bytes.subarray(0, i))\n      i -= size\n      i = encodeVarint(bytes, i, size) - 1\n      bytes[i] = 0x12\n    }\n  }\n\n  return bytes\n}\n\n/**\n * work out exactly how many bytes this link takes up\n *\n * @param {RawPBLink} link\n * @returns\n */\nfunction sizeLink (link) {\n  let n = 0\n\n  if (link.Hash) {\n    const l = link.Hash.length\n    n += 1 + l + sov(l)\n  }\n\n  if (typeof link.Name === 'string') {\n    const l = textEncoder.encode(link.Name).length\n    n += 1 + l + sov(l)\n  }\n\n  if (typeof link.Tsize === 'number') {\n    n += 1 + sov(link.Tsize)\n  }\n\n  return n\n}\n\n/**\n * Work out exactly how many bytes this node takes up\n *\n * @param {RawPBNode} node\n * @returns {number}\n */\nfunction sizeNode (node) {\n  let n = 0\n\n  if (node.Data) {\n    const l = node.Data.length\n    n += 1 + l + sov(l)\n  }\n\n  if (node.Links) {\n    for (const link of node.Links) {\n      const l = sizeLink(link)\n      n += 1 + l + sov(l)\n    }\n  }\n\n  return n\n}\n\n/**\n * @param {Uint8Array} bytes\n * @param {number} offset\n * @param {number} v\n * @returns {number}\n */\nfunction encodeVarint (bytes, offset, v) {\n  offset -= sov(v)\n  const base = offset\n\n  while (v >= maxUInt32) {\n    bytes[offset++] = (v & 0x7f) | 0x80\n    v /= 128\n  }\n\n  while (v >= 128) {\n    bytes[offset++] = (v & 0x7f) | 0x80\n    v >>>= 7\n  }\n\n  bytes[offset] = v\n\n  return base\n}\n\n/**\n * size of varint\n *\n * @param {number} x\n * @returns {number}\n */\nfunction sov (x) {\n  if (x % 2 === 0) {\n    x++\n  }\n  return Math.floor((len64(x) + 6) / 7)\n}\n\n/**\n * golang math/bits, how many bits does it take to represent this integer?\n *\n * @param {number} x\n * @returns {number}\n */\nfunction len64 (x) {\n  let n = 0\n  if (x >= maxInt32) {\n    x = Math.floor(x / maxInt32)\n    n = 32\n  }\n  if (x >= (1 << 16)) {\n    x >>>= 16\n    n += 16\n  }\n  if (x >= (1 << 8)) {\n    x >>>= 8\n    n += 8\n  }\n  return n + len8tab[x]\n}\n\n// golang math/bits\nconst len8tab = [\n  0, 1, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n  5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n  6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n  6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n  7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n  7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n  7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n  7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n  8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n]\n","import { CID } from 'multiformats/cid'\n\n/**\n * @typedef {import('./interface.js').PBLink} PBLink\n * @typedef {import('./interface.js').PBNode} PBNode\n */\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ByteView<T>} ByteView\n */\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ArrayBufferView<T>} ArrayBufferView\n */\n\nconst pbNodeProperties = ['Data', 'Links']\nconst pbLinkProperties = ['Hash', 'Name', 'Tsize']\n\nconst textEncoder = new TextEncoder()\n\n/**\n * @param {PBLink} a\n * @param {PBLink} b\n * @returns {number}\n */\nfunction linkComparator (a, b) {\n  if (a === b) {\n    return 0\n  }\n\n  const abuf = a.Name ? textEncoder.encode(a.Name) : []\n  const bbuf = b.Name ? textEncoder.encode(b.Name) : []\n\n  let x = abuf.length\n  let y = bbuf.length\n\n  for (let i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (abuf[i] !== bbuf[i]) {\n      x = abuf[i]\n      y = bbuf[i]\n      break\n    }\n  }\n\n  return x < y ? -1 : y < x ? 1 : 0\n}\n\n/**\n * @param {any} node\n * @param {string[]} properties\n * @returns {boolean}\n */\nfunction hasOnlyProperties (node, properties) {\n  return !Object.keys(node).some((p) => !properties.includes(p))\n}\n\n/**\n * Converts a CID, or a PBLink-like object to a PBLink\n *\n * @param {any} link\n * @returns {PBLink}\n */\nfunction asLink (link) {\n  if (typeof link.asCID === 'object') {\n    const Hash = CID.asCID(link)\n    if (!Hash) {\n      throw new TypeError('Invalid DAG-PB form')\n    }\n    return { Hash }\n  }\n\n  if (typeof link !== 'object' || Array.isArray(link)) {\n    throw new TypeError('Invalid DAG-PB form')\n  }\n\n  const pbl = {}\n\n  if (link.Hash) {\n    let cid = CID.asCID(link.Hash)\n    try {\n      if (!cid) {\n        if (typeof link.Hash === 'string') {\n          cid = CID.parse(link.Hash)\n        } else if (link.Hash instanceof Uint8Array) {\n          cid = CID.decode(link.Hash)\n        }\n      }\n    } catch (/** @type {any} */ e) {\n      throw new TypeError(`Invalid DAG-PB form: ${e.message}`)\n    }\n\n    if (cid) {\n      pbl.Hash = cid\n    }\n  }\n\n  if (!pbl.Hash) {\n    throw new TypeError('Invalid DAG-PB form')\n  }\n\n  if (typeof link.Name === 'string') {\n    pbl.Name = link.Name\n  }\n\n  if (typeof link.Tsize === 'number') {\n    pbl.Tsize = link.Tsize\n  }\n\n  return pbl\n}\n\n/**\n * @param {any} node\n * @returns {PBNode}\n */\nexport function prepare (node) {\n  if (node instanceof Uint8Array || typeof node === 'string') {\n    node = { Data: node }\n  }\n\n  if (typeof node !== 'object' || Array.isArray(node)) {\n    throw new TypeError('Invalid DAG-PB form')\n  }\n\n  /** @type {PBNode} */\n  const pbn = {}\n\n  if (node.Data !== undefined) {\n    if (typeof node.Data === 'string') {\n      pbn.Data = textEncoder.encode(node.Data)\n    } else if (node.Data instanceof Uint8Array) {\n      pbn.Data = node.Data\n    } else {\n      throw new TypeError('Invalid DAG-PB form')\n    }\n  }\n\n  if (node.Links !== undefined) {\n    if (Array.isArray(node.Links)) {\n      pbn.Links = node.Links.map(asLink)\n      pbn.Links.sort(linkComparator)\n    } else {\n      throw new TypeError('Invalid DAG-PB form')\n    }\n  } else {\n    pbn.Links = []\n  }\n\n  return pbn\n}\n\n/**\n * @param {PBNode} node\n */\nexport function validate (node) {\n  /*\n  type PBLink struct {\n    Hash optional Link\n    Name optional String\n    Tsize optional Int\n  }\n\n  type PBNode struct {\n    Links [PBLink]\n    Data optional Bytes\n  }\n  */\n  // @ts-ignore private property for TS\n  if (!node || typeof node !== 'object' || Array.isArray(node) || node instanceof Uint8Array || (node['/'] && node['/'] === node.bytes)) {\n    throw new TypeError('Invalid DAG-PB form')\n  }\n\n  if (!hasOnlyProperties(node, pbNodeProperties)) {\n    throw new TypeError('Invalid DAG-PB form (extraneous properties)')\n  }\n\n  if (node.Data !== undefined && !(node.Data instanceof Uint8Array)) {\n    throw new TypeError('Invalid DAG-PB form (Data must be bytes)')\n  }\n\n  if (!Array.isArray(node.Links)) {\n    throw new TypeError('Invalid DAG-PB form (Links must be a list)')\n  }\n\n  for (let i = 0; i < node.Links.length; i++) {\n    const link = node.Links[i]\n    // @ts-ignore private property for TS\n    if (!link || typeof link !== 'object' || Array.isArray(link) || link instanceof Uint8Array || (link['/'] && link['/'] === link.bytes)) {\n      throw new TypeError('Invalid DAG-PB form (bad link)')\n    }\n\n    if (!hasOnlyProperties(link, pbLinkProperties)) {\n      throw new TypeError('Invalid DAG-PB form (extraneous properties on link)')\n    }\n\n    if (link.Hash === undefined) {\n      throw new TypeError('Invalid DAG-PB form (link must have a Hash)')\n    }\n\n    // @ts-ignore private property for TS\n    if (link.Hash == null || !link.Hash['/'] || link.Hash['/'] !== link.Hash.bytes) {\n      throw new TypeError('Invalid DAG-PB form (link Hash must be a CID)')\n    }\n\n    if (link.Name !== undefined && typeof link.Name !== 'string') {\n      throw new TypeError('Invalid DAG-PB form (link Name must be a string)')\n    }\n\n    if (link.Tsize !== undefined) {\n      if (typeof link.Tsize !== 'number' || link.Tsize % 1 !== 0) {\n        throw new TypeError('Invalid DAG-PB form (link Tsize must be an integer)')\n      }\n      if (link.Tsize < 0) {\n        throw new TypeError('Invalid DAG-PB form (link Tsize cannot be negative)')\n      }\n    }\n\n    if (i > 0 && linkComparator(link, node.Links[i - 1]) === -1) {\n      throw new TypeError('Invalid DAG-PB form (links must be sorted by Name bytes)')\n    }\n  }\n}\n\n/**\n * @param {Uint8Array} data\n * @param {PBLink[]} [links=[]]\n * @returns {PBNode}\n */\nexport function createNode (data, links = []) {\n  return prepare({ Data: data, Links: links })\n}\n\n/**\n * @param {string} name\n * @param {number} size\n * @param {CID} cid\n * @returns {PBLink}\n */\nexport function createLink (name, size, cid) {\n  return asLink({ Hash: cid, Name: name, Tsize: size })\n}\n\n/**\n * @template T\n * @param {ByteView<T> | ArrayBufferView<T>} buf\n * @returns {ByteView<T>}\n */\nexport function toByteView (buf) {\n  if (buf instanceof ArrayBuffer) {\n    return new Uint8Array(buf, 0, buf.byteLength)\n  }\n\n  return buf\n}\n","import { CID } from 'multiformats/cid'\nimport { decodeNode } from './pb-decode.js'\nimport { encodeNode } from './pb-encode.js'\nimport { prepare, validate, createNode, createLink, toByteView } from './util.js'\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ByteView<T>} ByteView\n */\n\n/**\n * @template T\n * @typedef {import('multiformats/codecs/interface').ArrayBufferView<T>} ArrayBufferView\n */\n\n/**\n * @typedef {import('./interface.js').PBLink} PBLink\n * @typedef {import('./interface.js').PBNode} PBNode\n */\n\nexport const name = 'dag-pb'\nexport const code = 0x70\n\n/**\n * @param {PBNode} node\n * @returns {ByteView<PBNode>}\n */\nexport function encode (node) {\n  validate(node)\n\n  const pbn = {}\n  if (node.Links) {\n    pbn.Links = node.Links.map((l) => {\n      const link = {}\n      if (l.Hash) {\n        link.Hash = l.Hash.bytes // cid -> bytes\n      }\n      if (l.Name !== undefined) {\n        link.Name = l.Name\n      }\n      if (l.Tsize !== undefined) {\n        link.Tsize = l.Tsize\n      }\n      return link\n    })\n  }\n  if (node.Data) {\n    pbn.Data = node.Data\n  }\n\n  return encodeNode(pbn)\n}\n\n/**\n * @param {ByteView<PBNode> | ArrayBufferView<PBNode>} bytes\n * @returns {PBNode}\n */\nexport function decode (bytes) {\n  const buf = toByteView(bytes)\n  const pbn = decodeNode(buf)\n\n  const node = {}\n\n  if (pbn.Data) {\n    node.Data = pbn.Data\n  }\n\n  if (pbn.Links) {\n    node.Links = pbn.Links.map((l) => {\n      const link = {}\n      try {\n        link.Hash = CID.decode(l.Hash)\n      } catch (e) {}\n      if (!link.Hash) {\n        throw new Error('Invalid Hash field found in link, expected CID')\n      }\n      if (l.Name !== undefined) {\n        link.Name = l.Name\n      }\n      if (l.Tsize !== undefined) {\n        link.Tsize = l.Tsize\n      }\n      return link\n    })\n  }\n\n  return node\n}\n\nexport { prepare, validate, createNode, createLink }\n","export function isPromise(p) {\n    return p?.then != null;\n}\n//# sourceMappingURL=is-promise.js.map","/* eslint max-depth: [\"error\", 7] */\nimport { UnknownCodecError } from '@helia/interface';\nimport * as dagCbor from '@ipld/dag-cbor';\nimport * as dagJson from '@ipld/dag-json';\nimport * as dagPb from '@ipld/dag-pb';\nimport * as json from 'multiformats/codecs/json';\nimport * as raw from 'multiformats/codecs/raw';\nimport { isPromise } from './is-promise.js';\nexport function getCodec(initialCodecs = [], loadCodec) {\n    const codecs = {\n        [dagPb.code]: dagPb,\n        [raw.code]: raw,\n        [dagCbor.code]: dagCbor,\n        [dagJson.code]: dagJson,\n        [json.code]: json\n    };\n    initialCodecs.forEach(codec => {\n        codecs[codec.code] = codec;\n    });\n    return async (code) => {\n        let codec = codecs[code];\n        if (codec == null && loadCodec != null) {\n            const res = loadCodec(code);\n            if (isPromise(res)) {\n                codec = await res;\n            }\n            else {\n                codec = res;\n            }\n            codecs[codec.code] = codec;\n        }\n        if (codec != null) {\n            return codec;\n        }\n        throw new UnknownCodecError(`Could not load codec for ${code}`);\n    };\n}\n//# sourceMappingURL=get-codec.js.map","import { UnknownHashAlgorithmError } from '@helia/interface';\nimport { identity } from 'multiformats/hashes/identity';\nimport { sha256, sha512 } from 'multiformats/hashes/sha2';\nimport { isPromise } from './is-promise.js';\nexport function getHasher(initialHashers = [], loadHasher) {\n    const hashers = {\n        [sha256.code]: sha256,\n        [sha512.code]: sha512,\n        [identity.code]: identity\n    };\n    initialHashers.forEach(hasher => {\n        hashers[hasher.code] = hasher;\n    });\n    return async (code) => {\n        let hasher = hashers[code];\n        if (hasher == null && loadHasher != null) {\n            const res = loadHasher(code);\n            if (isPromise(res)) {\n                hasher = await res;\n            }\n            else {\n                hasher = res;\n            }\n            hashers[hasher.code] = hasher;\n        }\n        if (hasher != null) {\n            return hasher;\n        }\n        throw new UnknownHashAlgorithmError(`No hasher configured for multihash code 0x${code.toString(16)}, please configure one. You can look up which hash this is at https://github.com/multiformats/multicodec/blob/master/table.csv`);\n    };\n}\n//# sourceMappingURL=get-hasher.js.map","export class OpenFailedError extends Error {\n    static name = 'OpenFailedError';\n    static code = 'ERR_OPEN_FAILED';\n    name = OpenFailedError.name;\n    code = OpenFailedError.code;\n    constructor(message = 'Open failed') {\n        super(message);\n    }\n}\nexport class CloseFailedError extends Error {\n    static name = 'CloseFailedError';\n    static code = 'ERR_CLOSE_FAILED';\n    name = CloseFailedError.name;\n    code = CloseFailedError.code;\n    constructor(message = 'Close failed') {\n        super(message);\n    }\n}\nexport class PutFailedError extends Error {\n    static name = 'PutFailedError';\n    static code = 'ERR_PUT_FAILED';\n    name = PutFailedError.name;\n    code = PutFailedError.code;\n    constructor(message = 'Put failed') {\n        super(message);\n    }\n}\nexport class GetFailedError extends Error {\n    static name = 'GetFailedError';\n    static code = 'ERR_GET_FAILED';\n    name = GetFailedError.name;\n    code = GetFailedError.code;\n    constructor(message = 'Get failed') {\n        super(message);\n    }\n}\nexport class DeleteFailedError extends Error {\n    static name = 'DeleteFailedError';\n    static code = 'ERR_DELETE_FAILED';\n    name = DeleteFailedError.name;\n    code = DeleteFailedError.code;\n    constructor(message = 'Delete failed') {\n        super(message);\n    }\n}\nexport class HasFailedError extends Error {\n    static name = 'HasFailedError';\n    static code = 'ERR_HAS_FAILED';\n    name = HasFailedError.name;\n    code = HasFailedError.code;\n    constructor(message = 'Has failed') {\n        super(message);\n    }\n}\nexport class NotFoundError extends Error {\n    static name = 'NotFoundError';\n    static code = 'ERR_NOT_FOUND';\n    name = NotFoundError.name;\n    code = NotFoundError.code;\n    constructor(message = 'Not Found') {\n        super(message);\n    }\n}\nexport class AbortError extends Error {\n    static name = 'AbortError';\n    static code = 'ERR_ABORTED';\n    name = AbortError.name;\n    code = AbortError.code;\n    constructor(message = 'Aborted') {\n        super(message);\n    }\n}\n//# sourceMappingURL=errors.js.map","/* eslint-disable @typescript-eslint/ban-types */\n// this ignore is so we can use {} as the default value for the options\n// extensions below - it normally means \"any non-nullish value\" but here\n// we are using it as an intersection type - see the aside at the bottom:\n// https://github.com/typescript-eslint/typescript-eslint/issues/2063#issuecomment-675156492\nexport * from './errors.js';\n//# sourceMappingURL=index.js.map","export class BaseBlockstore {\n    has(key, options) {\n        return Promise.reject(new Error('.has is not implemented'));\n    }\n    put(key, val, options) {\n        return Promise.reject(new Error('.put is not implemented'));\n    }\n    async *putMany(source, options) {\n        for await (const { cid, block } of source) {\n            await this.put(cid, block, options);\n            yield cid;\n        }\n    }\n    get(key, options) {\n        return Promise.reject(new Error('.get is not implemented'));\n    }\n    async *getMany(source, options) {\n        for await (const key of source) {\n            yield {\n                cid: key,\n                block: await this.get(key, options)\n            };\n        }\n    }\n    delete(key, options) {\n        return Promise.reject(new Error('.delete is not implemented'));\n    }\n    async *deleteMany(source, options) {\n        for await (const key of source) {\n            await this.delete(key, options);\n            yield key;\n        }\n    }\n    /**\n     * Extending classes should override `query` or implement this method\n     */\n    async *getAll(options) {\n        throw new Error('.getAll is not implemented');\n    }\n}\n//# sourceMappingURL=base.js.map","import { NotFoundError } from 'interface-store';\nimport { BaseBlockstore } from './base.js';\n// https://github.com/multiformats/multicodec/blob/d06fc6194710e8909bac64273c43f16b56ca4c34/table.csv#L2\nconst IDENTITY_CODEC = 0x00;\nexport class IdentityBlockstore extends BaseBlockstore {\n    child;\n    constructor(child) {\n        super();\n        this.child = child;\n    }\n    put(key, block) {\n        if (key.multihash.code === IDENTITY_CODEC) {\n            return key;\n        }\n        if (this.child == null) {\n            return key;\n        }\n        return this.child.put(key, block);\n    }\n    get(key) {\n        if (key.multihash.code === IDENTITY_CODEC) {\n            return key.multihash.digest;\n        }\n        if (this.child == null) {\n            throw new NotFoundError();\n        }\n        return this.child.get(key);\n    }\n    has(key) {\n        if (key.multihash.code === IDENTITY_CODEC) {\n            return true;\n        }\n        if (this.child == null) {\n            return false;\n        }\n        return this.child.has(key);\n    }\n    delete(key) {\n        if (key.code === IDENTITY_CODEC) {\n            return;\n        }\n        if (this.child != null) {\n            return this.child.delete(key);\n        }\n    }\n    getAll(options) {\n        if (this.child != null) {\n            return this.child.getAll(options);\n        }\n        return [];\n    }\n}\n//# sourceMappingURL=identity.js.map","/**\n * @packageDocumentation\n *\n * Filter values out of an (async)iterable\n *\n * @example\n *\n * ```javascript\n * import all from 'it-all'\n * import filter from 'it-filter'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * const fn = (val, index) => val > 2 // Return boolean to keep item\n *\n * const arr = all(filter(values, fn))\n *\n * console.info(arr) // 3, 4\n * ```\n *\n * Async sources and filter functions must be awaited:\n *\n * ```javascript\n * import all from 'it-all'\n * import filter from 'it-filter'\n *\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const fn = async val => (val, index) > 2 // Return boolean or promise of boolean to keep item\n *\n * const arr = await all(filter(values, fn))\n *\n * console.info(arr) // 3, 4\n * ```\n */\nimport peek from 'it-peekable';\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction filter(source, fn) {\n    let index = 0;\n    if (isAsyncIterable(source)) {\n        return (async function* () {\n            for await (const entry of source) {\n                if (await fn(entry, index++)) {\n                    yield entry;\n                }\n            }\n        })();\n    }\n    // if mapping function returns a promise we have to return an async generator\n    const peekable = peek(source);\n    const { value, done } = peekable.next();\n    if (done === true) {\n        return (function* () { }());\n    }\n    const res = fn(value, index++);\n    // @ts-expect-error .then is not present on O\n    if (typeof res.then === 'function') {\n        return (async function* () {\n            if (await res) {\n                yield value;\n            }\n            for await (const entry of peekable) {\n                if (await fn(entry, index++)) {\n                    yield entry;\n                }\n            }\n        })();\n    }\n    const func = fn;\n    return (function* () {\n        if (res === true) {\n            yield value;\n        }\n        for (const entry of peekable) {\n            if (func(entry, index++)) {\n                yield entry;\n            }\n        }\n    })();\n}\nexport default filter;\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Calls a function for each value in an (async)iterable.\n *\n * The function can be sync or async.\n *\n * Async functions can be awaited on so may slow down processing of the (async)iterable.\n *\n * @example\n *\n * ```javascript\n * import each from 'it-foreach'\n * import drain from 'it-drain'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * // prints [0, 0], [1, 1], [2, 2], [3, 3], [4, 4]\n * const arr = drain(\n *   each(values, console.info)\n * )\n * ```\n *\n * Async sources and callbacks must be awaited:\n *\n * ```javascript\n * import each from 'it-foreach'\n * import drain from 'it-drain'\n *\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * // prints [0, 0], [1, 1], [2, 2], [3, 3], [4, 4]\n * const arr = await drain(\n *   each(values(), console.info)\n * )\n * ```\n */\nimport peek from 'it-peekable';\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction isPromise(thing) {\n    return thing?.then != null;\n}\nfunction forEach(source, fn) {\n    let index = 0;\n    if (isAsyncIterable(source)) {\n        return (async function* () {\n            for await (const val of source) {\n                const res = fn(val, index++);\n                if (isPromise(res)) {\n                    await res;\n                }\n                yield val;\n            }\n        })();\n    }\n    // if fn function returns a promise we have to return an async generator\n    const peekable = peek(source);\n    const { value, done } = peekable.next();\n    if (done === true) {\n        return (function* () { }());\n    }\n    const res = fn(value, index++);\n    if (typeof res?.then === 'function') {\n        return (async function* () {\n            yield value;\n            for await (const val of peekable) {\n                const res = fn(val, index++);\n                if (isPromise(res)) {\n                    await res;\n                }\n                yield val;\n            }\n        })();\n    }\n    const func = fn;\n    return (function* () {\n        yield value;\n        for (const val of peekable) {\n            func(val, index++);\n            yield val;\n        }\n    })();\n}\nexport default forEach;\n//# sourceMappingURL=index.js.map","import { InvalidMultihashError, InvalidParametersError, setMaxListeners, start, stop } from '@libp2p/interface';\nimport { anySignal } from 'any-signal';\nimport { IdentityBlockstore } from 'blockstore-core/identity';\nimport filter from 'it-filter';\nimport forEach from 'it-foreach';\nimport { CustomProgressEvent } from 'progress-events';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { isPromise } from './is-promise.js';\nclass Storage {\n    child;\n    getHasher;\n    log;\n    logger;\n    components;\n    /**\n     * Create a new BlockStorage\n     */\n    constructor(components) {\n        this.log = components.logger.forComponent('helia:networked-storage');\n        this.logger = components.logger;\n        this.components = components;\n        this.child = new IdentityBlockstore(components.blockstore);\n        this.getHasher = components.getHasher;\n    }\n    /**\n     * Put a block to the underlying datastore\n     */\n    async put(cid, block, options = {}) {\n        if (await this.child.has(cid, options)) {\n            options.onProgress?.(new CustomProgressEvent('blocks:put:duplicate', cid));\n            return cid;\n        }\n        options.onProgress?.(new CustomProgressEvent('blocks:put:providers:notify', cid));\n        await Promise.all(this.components.blockBrokers.map(async (broker) => broker.announce?.(cid, block, options)));\n        options.onProgress?.(new CustomProgressEvent('blocks:put:blockstore:put', cid));\n        return this.child.put(cid, block, options);\n    }\n    /**\n     * Put a multiple blocks to the underlying datastore\n     */\n    async *putMany(blocks, options = {}) {\n        const missingBlocks = filter(blocks, async ({ cid }) => {\n            const has = await this.child.has(cid, options);\n            if (has) {\n                options.onProgress?.(new CustomProgressEvent('blocks:put-many:duplicate', cid));\n            }\n            return !has;\n        });\n        const notifyEach = forEach(missingBlocks, async ({ cid, block }) => {\n            options.onProgress?.(new CustomProgressEvent('blocks:put-many:providers:notify', cid));\n            await Promise.all(this.components.blockBrokers.map(async (broker) => broker.announce?.(cid, block, options)));\n        });\n        options.onProgress?.(new CustomProgressEvent('blocks:put-many:blockstore:put-many'));\n        yield* this.child.putMany(notifyEach, options);\n    }\n    /**\n     * Get a block by cid\n     */\n    async get(cid, options = {}) {\n        if (options.offline !== true && !(await this.child.has(cid, options))) {\n            const hasher = await this.getHasher(cid.multihash.code);\n            // we do not have the block locally, get it from a block provider\n            options.onProgress?.(new CustomProgressEvent('blocks:get:providers:get', cid));\n            const block = await raceBlockRetrievers(cid, this.components.blockBrokers, hasher, {\n                ...options,\n                log: this.log\n            });\n            options.onProgress?.(new CustomProgressEvent('blocks:get:blockstore:put', cid));\n            await this.child.put(cid, block, options);\n            // notify other block providers of the new block\n            options.onProgress?.(new CustomProgressEvent('blocks:get:providers:notify', cid));\n            await Promise.all(this.components.blockBrokers.map(async (broker) => broker.announce?.(cid, block, options)));\n            return block;\n        }\n        options.onProgress?.(new CustomProgressEvent('blocks:get:blockstore:get', cid));\n        return this.child.get(cid, options);\n    }\n    /**\n     * Get multiple blocks back from an (async) iterable of cids\n     */\n    async *getMany(cids, options = {}) {\n        options.onProgress?.(new CustomProgressEvent('blocks:get-many:blockstore:get-many'));\n        yield* this.child.getMany(forEach(cids, async (cid) => {\n            if (options.offline !== true && !(await this.child.has(cid, options))) {\n                const hasher = await this.getHasher(cid.multihash.code);\n                // we do not have the block locally, get it from a block provider\n                options.onProgress?.(new CustomProgressEvent('blocks:get-many:providers:get', cid));\n                const block = await raceBlockRetrievers(cid, this.components.blockBrokers, hasher, {\n                    ...options,\n                    log: this.log\n                });\n                options.onProgress?.(new CustomProgressEvent('blocks:get-many:blockstore:put', cid));\n                await this.child.put(cid, block, options);\n                // notify other block providers of the new block\n                options.onProgress?.(new CustomProgressEvent('blocks:get-many:providers:notify', cid));\n                await Promise.all(this.components.blockBrokers.map(async (broker) => broker.announce?.(cid, block, options)));\n            }\n        }));\n    }\n    /**\n     * Delete a block from the blockstore\n     */\n    async delete(cid, options = {}) {\n        options.onProgress?.(new CustomProgressEvent('blocks:delete:blockstore:delete', cid));\n        await this.child.delete(cid, options);\n    }\n    /**\n     * Delete multiple blocks from the blockstore\n     */\n    async *deleteMany(cids, options = {}) {\n        options.onProgress?.(new CustomProgressEvent('blocks:delete-many:blockstore:delete-many'));\n        yield* this.child.deleteMany((async function* () {\n            for await (const cid of cids) {\n                yield cid;\n            }\n        }()), options);\n    }\n    async has(cid, options = {}) {\n        return this.child.has(cid, options);\n    }\n    async *getAll(options = {}) {\n        options.onProgress?.(new CustomProgressEvent('blocks:get-all:blockstore:get-many'));\n        yield* this.child.getAll(options);\n    }\n}\n/**\n * Networked storage wraps a regular blockstore - when getting blocks if the\n * blocks are not present, the configured BlockBrokers will be used to fetch them.\n */\nexport class NetworkedStorage extends Storage {\n    started;\n    /**\n     * Create a new BlockStorage\n     */\n    constructor(components) {\n        super(components);\n        this.started = false;\n    }\n    isStarted() {\n        return this.started;\n    }\n    async start() {\n        await start(this.child, ...this.components.blockBrokers);\n        this.started = true;\n    }\n    async stop() {\n        await stop(this.child, ...this.components.blockBrokers);\n        this.started = false;\n    }\n    unwrap() {\n        return this.child;\n    }\n    createSession(root, options) {\n        const blockBrokers = this.components.blockBrokers.map(broker => {\n            if (broker.createSession == null) {\n                return broker;\n            }\n            return broker.createSession(options);\n        });\n        return new SessionStorage({\n            blockstore: this.child,\n            blockBrokers,\n            getHasher: this.getHasher,\n            logger: this.logger\n        }, {\n            root\n        });\n    }\n}\n/**\n * Storage subclass that can cancel any ongoing operation at any point.\n */\nclass SessionStorage extends Storage {\n    closeController;\n    constructor(components, init) {\n        super(components);\n        // because brokers are allowed to continue searching for providers after the\n        // session has been created, we need a way to tell them that the user has\n        // finished using the session any in-flight requests should be cancelled\n        this.closeController = new AbortController();\n        setMaxListeners(Infinity, this.closeController.signal);\n        this.log = components.logger.forComponent(`helia:session-storage:${init.root}`);\n    }\n    close() {\n        this.closeController.abort();\n    }\n    /**\n     * Put a block to the underlying datastore\n     */\n    async put(cid, block, options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            return await super.put(cid, block, {\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n    /**\n     * Put a multiple blocks to the underlying datastore\n     */\n    async *putMany(blocks, options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            yield* super.putMany(blocks, {\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n    /**\n     * Get a block by cid\n     */\n    async get(cid, options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            return await super.get(cid, {\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n    /**\n     * Get multiple blocks back from an (async) iterable of cids\n     */\n    async *getMany(cids, options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            yield* super.getMany(cids, {\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n    /**\n     * Delete a block from the blockstore\n     */\n    async delete(cid, options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            await super.delete(cid, {\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n    /**\n     * Delete multiple blocks from the blockstore\n     */\n    async *deleteMany(cids, options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            yield* super.deleteMany(cids, {\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n    async has(cid, options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            return await super.has(cid, {\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n    async *getAll(options = {}) {\n        const signal = anySignal([this.closeController.signal, options.signal]);\n        setMaxListeners(Infinity, signal);\n        try {\n            yield* super.getAll({\n                ...options,\n                signal\n            });\n        }\n        finally {\n            signal.clear();\n        }\n    }\n}\nfunction isRetrievingBlockBroker(broker) {\n    return typeof broker.retrieve === 'function';\n}\nexport const getCidBlockVerifierFunction = (cid, hasher) => {\n    if (hasher == null) {\n        throw new InvalidParametersError(`No hasher configured for multihash code 0x${cid.multihash.code.toString(16)}, please configure one. You can look up which hash this is at https://github.com/multiformats/multicodec/blob/master/table.csv`);\n    }\n    return async (block) => {\n        // verify block\n        let hash;\n        const res = hasher.digest(block);\n        if (isPromise(res)) {\n            hash = await res;\n        }\n        else {\n            hash = res;\n        }\n        if (!uint8ArrayEquals(hash.digest, cid.multihash.digest)) {\n            // if a hash mismatch occurs for a TrustlessGatewayBlockBroker, we should try another gateway\n            throw new InvalidMultihashError('Hash of downloaded block did not match multihash from passed CID');\n        }\n    };\n};\n/**\n * Race block providers cancelling any pending requests once the block has been\n * found.\n */\nasync function raceBlockRetrievers(cid, blockBrokers, hasher, options) {\n    const validateFn = getCidBlockVerifierFunction(cid, hasher);\n    const controller = new AbortController();\n    const signal = anySignal([controller.signal, options.signal]);\n    setMaxListeners(Infinity, controller.signal, signal);\n    const retrievers = [];\n    for (const broker of blockBrokers) {\n        if (isRetrievingBlockBroker(broker)) {\n            retrievers.push(broker);\n        }\n    }\n    try {\n        return await Promise.any(retrievers\n            .map(async (retriever) => {\n            try {\n                let blocksWereValidated = false;\n                const block = await retriever.retrieve(cid, {\n                    ...options,\n                    signal,\n                    validateFn: async (block) => {\n                        await validateFn(block);\n                        blocksWereValidated = true;\n                    }\n                });\n                if (!blocksWereValidated) {\n                    // the blockBroker either did not throw an error when attempting to validate the block\n                    // or did not call the validateFn at all. We should validate the block ourselves\n                    await validateFn(block);\n                }\n                return block;\n            }\n            catch (err) {\n                options.log.error('could not retrieve verified block for %c', cid, err);\n                throw err;\n            }\n        }));\n    }\n    finally {\n        // we have the block from the fastest block retriever, abort any still\n        // in-flight retrieve attempts\n        controller.abort();\n        signal.clear();\n    }\n}\n//# sourceMappingURL=networked-storage.js.map","/**\n * @packageDocumentation\n *\n * Exports a `Helia` class that implements the Helia API.\n *\n * In general you should use the `helia` or `@helia/http` modules instead which\n * pre-configure Helia for certain use-cases (p2p or pure-HTTP).\n *\n * @example\n *\n * ```typescript\n * import { Helia } from '@helia/utils'\n * import type { HeliaInit } from '@helia/utils'\n *\n * const node = new Helia({\n *   // ...options\n * } as HeliaInit)\n * ```\n */\nimport { contentRoutingSymbol, peerRoutingSymbol, start, stop } from '@libp2p/interface';\nimport { defaultLogger } from '@libp2p/logger';\nimport { dns } from '@multiformats/dns';\nimport drain from 'it-drain';\nimport { CustomProgressEvent } from 'progress-events';\nimport { PinsImpl } from './pins.js';\nimport { Routing as RoutingClass } from './routing.js';\nimport { BlockStorage } from './storage.js';\nimport { assertDatastoreVersionIsCurrent } from './utils/datastore-version.js';\nimport { getCodec } from './utils/get-codec.js';\nimport { getHasher } from './utils/get-hasher.js';\nimport { NetworkedStorage } from './utils/networked-storage.js';\nexport { AbstractSession } from './abstract-session.js';\nexport class Helia {\n    blockstore;\n    datastore;\n    pins;\n    logger;\n    routing;\n    getCodec;\n    getHasher;\n    dns;\n    metrics;\n    log;\n    constructor(init) {\n        this.logger = init.logger ?? defaultLogger();\n        this.log = this.logger.forComponent('helia');\n        this.getHasher = getHasher(init.hashers, init.loadHasher);\n        this.getCodec = getCodec(init.codecs, init.loadCodec);\n        this.dns = init.dns ?? dns();\n        this.metrics = init.metrics;\n        // @ts-expect-error routing is not set\n        const components = {\n            blockstore: init.blockstore,\n            datastore: init.datastore,\n            logger: this.logger,\n            blockBrokers: [],\n            getHasher: this.getHasher,\n            getCodec: this.getCodec,\n            dns: this.dns,\n            metrics: this.metrics,\n            ...(init.components ?? {})\n        };\n        this.routing = components.routing = new RoutingClass(components, {\n            routers: (init.routers ?? []).flatMap((router) => {\n                // if the router itself is a router\n                const routers = [\n                    router\n                ];\n                // if the router provides a libp2p-style ContentRouter\n                if (router[contentRoutingSymbol] != null) {\n                    routers.push(router[contentRoutingSymbol]);\n                }\n                // if the router provides a libp2p-style PeerRouter\n                if (router[peerRoutingSymbol] != null) {\n                    routers.push(router[peerRoutingSymbol]);\n                }\n                return routers;\n            }),\n            providerLookupConcurrency: init.providerLookupConcurrency\n        });\n        const networkedStorage = new NetworkedStorage(components);\n        this.pins = new PinsImpl(init.datastore, networkedStorage, this.getCodec);\n        this.blockstore = new BlockStorage(networkedStorage, this.pins, {\n            holdGcLock: init.holdGcLock ?? true\n        });\n        this.datastore = init.datastore;\n        components.blockBrokers = init.blockBrokers.map((fn) => {\n            return fn(components);\n        });\n    }\n    async start() {\n        await assertDatastoreVersionIsCurrent(this.datastore);\n        await start(this.blockstore, this.datastore, this.routing);\n    }\n    async stop() {\n        await stop(this.blockstore, this.datastore, this.routing);\n    }\n    async gc(options = {}) {\n        const releaseLock = await this.blockstore.lock.writeLock();\n        try {\n            const helia = this;\n            const blockstore = this.blockstore.unwrap();\n            this.log('gc start');\n            await drain(blockstore.deleteMany((async function* () {\n                for await (const { cid } of blockstore.getAll()) {\n                    try {\n                        if (await helia.pins.isPinned(cid, options)) {\n                            continue;\n                        }\n                        yield cid;\n                        options.onProgress?.(new CustomProgressEvent('helia:gc:deleted', cid));\n                    }\n                    catch (err) {\n                        helia.log.error('Error during gc', err);\n                        options.onProgress?.(new CustomProgressEvent('helia:gc:error', err));\n                    }\n                }\n            }())));\n        }\n        finally {\n            releaseLock();\n        }\n        this.log('gc finished');\n    }\n}\n//# sourceMappingURL=index.js.map","import { NotFoundError } from 'interface-store';\nimport { base32 } from 'multiformats/bases/base32';\nimport { CID } from 'multiformats/cid';\nimport * as raw from 'multiformats/codecs/raw';\nimport * as Digest from 'multiformats/hashes/digest';\nimport { BaseBlockstore } from './base.js';\nexport class MemoryBlockstore extends BaseBlockstore {\n    data;\n    constructor() {\n        super();\n        this.data = new Map();\n    }\n    put(key, val) {\n        this.data.set(base32.encode(key.multihash.bytes), val);\n        return key;\n    }\n    get(key) {\n        const buf = this.data.get(base32.encode(key.multihash.bytes));\n        if (buf == null) {\n            throw new NotFoundError();\n        }\n        return buf;\n    }\n    has(key) {\n        return this.data.has(base32.encode(key.multihash.bytes));\n    }\n    async delete(key) {\n        this.data.delete(base32.encode(key.multihash.bytes));\n    }\n    async *getAll() {\n        for (const [key, value] of this.data.entries()) {\n            yield {\n                cid: CID.createV1(raw.code, Digest.decode(base32.decode(key))),\n                block: value\n            };\n        }\n    }\n}\n//# sourceMappingURL=memory.js.map","import { NotFoundError } from 'interface-store';\nimport { BaseBlockstore } from './base.js';\nexport class BlackHoleBlockstore extends BaseBlockstore {\n    put(key) {\n        return key;\n    }\n    get() {\n        throw new NotFoundError();\n    }\n    has() {\n        return false;\n    }\n    async delete() {\n    }\n    async *getAll() {\n    }\n}\n//# sourceMappingURL=black-hole.js.map","import { logger } from '@libp2p/logger';\nimport { DeleteFailedError, NotFoundError, PutFailedError } from 'interface-store';\nimport drain from 'it-drain';\nimport filter from 'it-filter';\nimport merge from 'it-merge';\nimport { pushable } from 'it-pushable';\nimport { BaseBlockstore } from './base.js';\nconst log = logger('blockstore:core:tiered');\n/**\n * A blockstore that can combine multiple stores. Puts and deletes\n * will write through to all blockstores. Has and get will\n * try each store sequentially. getAll will use every store but also\n * deduplicate any yielded pairs.\n */\nexport class TieredBlockstore extends BaseBlockstore {\n    stores;\n    constructor(stores) {\n        super();\n        this.stores = stores.slice();\n    }\n    async put(key, value, options) {\n        try {\n            await Promise.all(this.stores.map(async (store) => { await store.put(key, value, options); }));\n            return key;\n        }\n        catch (err) {\n            throw new PutFailedError(String(err));\n        }\n    }\n    async get(key, options) {\n        for (const store of this.stores) {\n            try {\n                const res = await store.get(key, options);\n                if (res != null)\n                    return res;\n            }\n            catch (err) {\n                log.error(err);\n            }\n        }\n        throw new NotFoundError();\n    }\n    async has(key, options) {\n        for (const s of this.stores) {\n            if (await s.has(key, options)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    async delete(key, options) {\n        try {\n            await Promise.all(this.stores.map(async (store) => { await store.delete(key, options); }));\n        }\n        catch (err) {\n            throw new DeleteFailedError(String(err));\n        }\n    }\n    async *putMany(source, options = {}) {\n        let error;\n        const pushables = this.stores.map(store => {\n            const source = pushable({\n                objectMode: true\n            });\n            drain(store.putMany(source, options))\n                .catch(err => {\n                // store threw while putting, make sure we bubble the error up\n                error = err;\n            });\n            return source;\n        });\n        try {\n            for await (const pair of source) {\n                if (error != null) {\n                    throw error;\n                }\n                pushables.forEach(p => p.push(pair));\n                yield pair.cid;\n            }\n        }\n        finally {\n            pushables.forEach(p => p.end());\n        }\n    }\n    async *deleteMany(source, options = {}) {\n        let error;\n        const pushables = this.stores.map(store => {\n            const source = pushable({\n                objectMode: true\n            });\n            drain(store.deleteMany(source, options))\n                .catch(err => {\n                // store threw while deleting, make sure we bubble the error up\n                error = err;\n            });\n            return source;\n        });\n        try {\n            for await (const key of source) {\n                if (error != null) {\n                    throw error;\n                }\n                pushables.forEach(p => p.push(key));\n                yield key;\n            }\n        }\n        finally {\n            pushables.forEach(p => p.end());\n        }\n    }\n    async *getAll(options) {\n        // deduplicate yielded pairs\n        const seen = new Set();\n        yield* filter(merge(...this.stores.map(s => s.getAll(options))), (pair) => {\n            const cidStr = pair.cid.toString();\n            if (seen.has(cidStr)) {\n                return false;\n            }\n            seen.add(cidStr);\n            return true;\n        });\n    }\n}\n//# sourceMappingURL=tiered.js.map","/**\n * @packageDocumentation\n *\n * Various Blockstore implementations are available.\n *\n * ## Implementations\n *\n * - Base: [`src/base`](src/base.ts)\n * - Memory: [`src/memory`](src/memory.ts)\n * - BlackHole: ['src/black-hole](src/black-hole.ts)\n * - Tiered: ['src/tiered](src/tiered.ts)\n *\n * @example BaseBlockstore\n *\n * Provides a complete implementation of the Blockstore interface.  You must implement `.get`, `.put`, etc.\n *\n * ```js\n * import { BaseBlockstore } from 'blockstore-core/base'\n *\n * class MyCustomBlockstore extends BaseBlockstore {\n *   put (key, val, options) {\n *     // store a block\n *   }\n *\n *   get (key, options) {\n *     // retrieve a block\n *   }\n *\n *   // ...etc\n * }\n * ```\n *\n * @example MemoryBlockstore\n *\n * A simple Blockstore that stores blocks in memory.\n *\n * ```js\n * import { MemoryBlockstore } from 'blockstore-core/memory'\n *\n * const store = new MemoryBlockstore()\n * ```\n *\n * @example BlackHoleBlockstore\n *\n * A Blockstore that does not store any blocks.\n *\n * ```js\n * import { BlackHoleBlockstore } from 'blockstore-core/black-hole'\n *\n * const store = new BlackHoleBlockstore()\n * ```\n *\n * @example TieredBlockstore\n *\n * A tiered blockstore wraps one or more blockstores and will query each in parallel to retrieve a block - the operation will succeed if any wrapped store has the block.\n *\n * Writes are invoked on all wrapped blockstores.\n *\n * ```js\n * import { TieredBlockstore } from 'blockstore-core/tiered'\n *\n * const store = new TieredBlockstore([\n *   store1,\n *   store2,\n *   // ...etc\n * ])\n * ```\n *\n * @example IdentityBlockstore\n *\n * An identity blockstore is one that deals exclusively in Identity CIDs - this is a special CID with the codec [0x00](https://github.com/multiformats/multicodec/blob/d06fc6194710e8909bac64273c43f16b56ca4c34/table.csv#L2) where the multihash digest is the data that makes up the block.\n *\n * ```TypeScript\n * import { IdentityBlockstore } from 'blockstore-core/identity'\n * import { CID } from 'multiformats/cid'\n *\n * const blockstore = new IdentityBlockstore()\n *\n * blockstore.has(CID.parse('QmFoo')) // false\n *\n * blockstore.has(CID.parse('bafkqac3imvwgy3zao5xxe3de')) // true\n * ```\n */\nexport { BaseBlockstore } from './base.js';\nexport { MemoryBlockstore } from './memory.js';\nexport { BlackHoleBlockstore } from './black-hole.js';\nexport { TieredBlockstore } from './tiered.js';\n//# sourceMappingURL=index.js.map","import { Key } from 'interface-datastore/key';\nexport const PREFIX = '/repo/flatfs/shard/';\nexport const SHARDING_FN = 'SHARDING';\nexport class ShardBase {\n    param;\n    name;\n    _padding;\n    constructor(param) {\n        this.param = param;\n        this.name = 'base';\n        this._padding = '';\n    }\n    fun(s) {\n        return 'implement me';\n    }\n    toString() {\n        return `${PREFIX}v1/${this.name}/${this.param}`;\n    }\n}\nexport class Prefix extends ShardBase {\n    constructor(prefixLen) {\n        super(prefixLen);\n        this._padding = ''.padStart(prefixLen, '_');\n        this.name = 'prefix';\n    }\n    fun(noslash) {\n        return (noslash + this._padding).slice(0, this.param);\n    }\n}\nexport class Suffix extends ShardBase {\n    constructor(suffixLen) {\n        super(suffixLen);\n        this._padding = ''.padStart(suffixLen, '_');\n        this.name = 'suffix';\n    }\n    fun(noslash) {\n        const s = this._padding + noslash;\n        return s.slice(s.length - this.param);\n    }\n}\nexport class NextToLast extends ShardBase {\n    constructor(suffixLen) {\n        super(suffixLen);\n        this._padding = ''.padStart(suffixLen + 1, '_');\n        this.name = 'next-to-last';\n    }\n    fun(noslash) {\n        const s = this._padding + noslash;\n        const offset = s.length - this.param - 1;\n        return s.slice(offset, offset + this.param);\n    }\n}\n/**\n * Convert a given string to the matching sharding function\n */\nexport function parseShardFun(str) {\n    str = str.trim();\n    if (str.length === 0) {\n        throw new Error('empty shard string');\n    }\n    if (!str.startsWith(PREFIX)) {\n        throw new Error(`invalid or no path prefix: ${str}`);\n    }\n    const parts = str.slice(PREFIX.length).split('/');\n    const version = parts[0];\n    if (version !== 'v1') {\n        throw new Error(`expect 'v1' version, got '${version}'`);\n    }\n    const name = parts[1];\n    if (parts[2] == null || parts[2] === '') {\n        throw new Error('missing param');\n    }\n    const param = parseInt(parts[2], 10);\n    switch (name) {\n        case 'prefix':\n            return new Prefix(param);\n        case 'suffix':\n            return new Suffix(param);\n        case 'next-to-last':\n            return new NextToLast(param);\n        default:\n            throw new Error(`unkown sharding function: ${name}`);\n    }\n}\nexport const readShardFun = async (path, store) => {\n    const key = new Key(path).child(new Key(SHARDING_FN));\n    // @ts-expect-error not all stores have this\n    const get = typeof store.getRaw === 'function' ? store.getRaw.bind(store) : store.get.bind(store);\n    const res = await get(key);\n    return parseShardFun(new TextDecoder().decode(res ?? '').trim());\n};\n//# sourceMappingURL=shard.js.map","/**\n * @packageDocumentation\n *\n * For when you need a one-liner to collect iterable values.\n *\n * @example\n *\n * ```javascript\n * import all from 'it-all'\n *\n * // This can also be an iterator, etc\n * const values = function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const arr = all(values)\n *\n * console.info(arr) // 0, 1, 2, 3, 4\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const arr = await all(values())\n *\n * console.info(arr) // 0, 1, 2, 3, 4\n * ```\n */\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction all(source) {\n    if (isAsyncIterable(source)) {\n        return (async () => {\n            const arr = [];\n            for await (const entry of source) {\n                arr.push(entry);\n            }\n            return arr;\n        })();\n    }\n    const arr = [];\n    for (const entry of source) {\n        arr.push(entry);\n    }\n    return arr;\n}\nexport default all;\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Consumes all values from an (async)iterable and returns them sorted by the passed sort function.\n *\n * @example\n *\n * ```javascript\n * import sort from 'it-sort'\n * import all from 'it-all'\n *\n * const sorter = (a, b) => {\n *   return a.localeCompare(b)\n * }\n *\n * // This can also be an iterator, generator, etc\n * const values = ['foo', 'bar']\n *\n * const arr = all(sort(values, sorter))\n *\n * console.info(arr) // 'bar', 'foo'\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import sort from 'it-sort'\n * import all from 'it-all'\n *\n * const sorter = (a, b) => {\n *   return a.localeCompare(b)\n * }\n *\n * const values = async function * () {\n *   yield * ['foo', 'bar']\n * }\n *\n * const arr = await all(sort(values, sorter))\n *\n * console.info(arr) // 'bar', 'foo'\n * ```\n */\nimport all from 'it-all';\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction sort(source, sorter) {\n    if (isAsyncIterable(source)) {\n        return (async function* () {\n            const arr = await all(source);\n            yield* arr.sort(sorter);\n        })();\n    }\n    return (function* () {\n        const arr = all(source);\n        yield* arr.sort(sorter);\n    })();\n}\nexport default sort;\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * For when you only want a few values out of an (async)iterable.\n *\n * @example\n *\n * ```javascript\n * import take from 'it-take'\n * import all from 'it-all'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * const arr = all(take(values, 2))\n *\n * console.info(arr) // 0, 1\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import take from 'it-take'\n * import all from 'it-all'\n *\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const arr = await all(take(values(), 2))\n *\n * console.info(arr) // 0, 1\n * ```\n */\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction take(source, limit) {\n    if (isAsyncIterable(source)) {\n        return (async function* () {\n            let items = 0;\n            if (limit < 1) {\n                return;\n            }\n            for await (const entry of source) {\n                yield entry;\n                items++;\n                if (items === limit) {\n                    return;\n                }\n            }\n        })();\n    }\n    return (function* () {\n        let items = 0;\n        if (limit < 1) {\n            return;\n        }\n        for (const entry of source) {\n            yield entry;\n            items++;\n            if (items === limit) {\n                return;\n            }\n        }\n    })();\n}\nexport default take;\n//# sourceMappingURL=index.js.map","import drain from 'it-drain';\nimport filter from 'it-filter';\nimport sort from 'it-sort';\nimport take from 'it-take';\nexport class BaseDatastore {\n    put(key, val, options) {\n        return Promise.reject(new Error('.put is not implemented'));\n    }\n    get(key, options) {\n        return Promise.reject(new Error('.get is not implemented'));\n    }\n    has(key, options) {\n        return Promise.reject(new Error('.has is not implemented'));\n    }\n    delete(key, options) {\n        return Promise.reject(new Error('.delete is not implemented'));\n    }\n    async *putMany(source, options = {}) {\n        for await (const { key, value } of source) {\n            await this.put(key, value, options);\n            yield key;\n        }\n    }\n    async *getMany(source, options = {}) {\n        for await (const key of source) {\n            yield {\n                key,\n                value: await this.get(key, options)\n            };\n        }\n    }\n    async *deleteMany(source, options = {}) {\n        for await (const key of source) {\n            await this.delete(key, options);\n            yield key;\n        }\n    }\n    batch() {\n        let puts = [];\n        let dels = [];\n        return {\n            put(key, value) {\n                puts.push({ key, value });\n            },\n            delete(key) {\n                dels.push(key);\n            },\n            commit: async (options) => {\n                await drain(this.putMany(puts, options));\n                puts = [];\n                await drain(this.deleteMany(dels, options));\n                dels = [];\n            }\n        };\n    }\n    /**\n     * Extending classes should override `query` or implement this method\n     */\n    // eslint-disable-next-line require-yield\n    async *_all(q, options) {\n        throw new Error('._all is not implemented');\n    }\n    /**\n     * Extending classes should override `queryKeys` or implement this method\n     */\n    // eslint-disable-next-line require-yield\n    async *_allKeys(q, options) {\n        throw new Error('._allKeys is not implemented');\n    }\n    query(q, options) {\n        let it = this._all(q, options);\n        if (q.prefix != null) {\n            const prefix = q.prefix;\n            it = filter(it, (e) => e.key.toString().startsWith(prefix));\n        }\n        if (Array.isArray(q.filters)) {\n            it = q.filters.reduce((it, f) => filter(it, f), it);\n        }\n        if (Array.isArray(q.orders)) {\n            it = q.orders.reduce((it, f) => sort(it, f), it);\n        }\n        if (q.offset != null) {\n            let i = 0;\n            const offset = q.offset;\n            it = filter(it, () => i++ >= offset);\n        }\n        if (q.limit != null) {\n            it = take(it, q.limit);\n        }\n        return it;\n    }\n    queryKeys(q, options) {\n        let it = this._allKeys(q, options);\n        if (q.prefix != null) {\n            const prefix = q.prefix;\n            it = filter(it, (key) => key.toString().startsWith(prefix));\n        }\n        if (Array.isArray(q.filters)) {\n            it = q.filters.reduce((it, f) => filter(it, f), it);\n        }\n        if (Array.isArray(q.orders)) {\n            it = q.orders.reduce((it, f) => sort(it, f), it);\n        }\n        if (q.offset != null) {\n            const offset = q.offset;\n            let i = 0;\n            it = filter(it, () => i++ >= offset);\n        }\n        if (q.limit != null) {\n            it = take(it, q.limit);\n        }\n        return it;\n    }\n}\n//# sourceMappingURL=base.js.map","import { Key } from 'interface-datastore/key';\nimport { NotFoundError } from 'interface-store';\nimport { BaseDatastore } from './base.js';\nexport class MemoryDatastore extends BaseDatastore {\n    data;\n    constructor() {\n        super();\n        this.data = new Map();\n    }\n    put(key, val) {\n        this.data.set(key.toString(), val);\n        return key;\n    }\n    get(key) {\n        const result = this.data.get(key.toString());\n        if (result == null) {\n            throw new NotFoundError();\n        }\n        return result;\n    }\n    has(key) {\n        return this.data.has(key.toString());\n    }\n    delete(key) {\n        this.data.delete(key.toString());\n    }\n    *_all() {\n        for (const [key, value] of this.data.entries()) {\n            yield { key: new Key(key), value };\n        }\n    }\n    *_allKeys() {\n        for (const key of this.data.keys()) {\n            yield new Key(key);\n        }\n    }\n}\n//# sourceMappingURL=memory.js.map","import { pushable } from 'it-pushable';\nimport merge from 'it-merge';\nexport function pipe(first, ...rest) {\n    if (first == null) {\n        throw new Error('Empty pipeline');\n    }\n    // Duplex at start: wrap in function and return duplex source\n    if (isDuplex(first)) {\n        const duplex = first;\n        first = () => duplex.source;\n        // Iterable at start: wrap in function\n    }\n    else if (isIterable(first) || isAsyncIterable(first)) {\n        const source = first;\n        first = () => source;\n    }\n    const fns = [first, ...rest];\n    if (fns.length > 1) {\n        // Duplex at end: use duplex sink\n        if (isDuplex(fns[fns.length - 1])) {\n            fns[fns.length - 1] = fns[fns.length - 1].sink;\n        }\n    }\n    if (fns.length > 2) {\n        // Duplex in the middle, consume source with duplex sink and return duplex source\n        for (let i = 1; i < fns.length - 1; i++) {\n            if (isDuplex(fns[i])) {\n                fns[i] = duplexPipelineFn(fns[i]);\n            }\n        }\n    }\n    return rawPipe(...fns);\n}\nexport const rawPipe = (...fns) => {\n    let res;\n    while (fns.length > 0) {\n        res = fns.shift()(res);\n    }\n    return res;\n};\nconst isAsyncIterable = (obj) => {\n    return obj?.[Symbol.asyncIterator] != null;\n};\nconst isIterable = (obj) => {\n    return obj?.[Symbol.iterator] != null;\n};\nconst isDuplex = (obj) => {\n    if (obj == null) {\n        return false;\n    }\n    return obj.sink != null && obj.source != null;\n};\nconst duplexPipelineFn = (duplex) => {\n    return (source) => {\n        const p = duplex.sink(source);\n        if (p?.then != null) {\n            const stream = pushable({\n                objectMode: true\n            });\n            p.then(() => {\n                stream.end();\n            }, (err) => {\n                stream.end(err);\n            });\n            let sourceWrap;\n            const source = duplex.source;\n            if (isAsyncIterable(source)) {\n                sourceWrap = async function* () {\n                    yield* source;\n                    stream.end();\n                };\n            }\n            else if (isIterable(source)) {\n                sourceWrap = function* () {\n                    yield* source;\n                    stream.end();\n                };\n            }\n            else {\n                throw new Error('Unknown duplex source type - must be Iterable or AsyncIterable');\n            }\n            return merge(stream, sourceWrap());\n        }\n        return duplex.source;\n    };\n};\n//# sourceMappingURL=index.js.map","import map from 'it-map';\nimport { pipe } from 'it-pipe';\nimport { BaseDatastore } from './base.js';\n/**\n * A datastore shim, that wraps around a given datastore, changing\n * the way keys look to the user, for example namespacing\n * keys, reversing them, etc.\n */\nexport class KeyTransformDatastore extends BaseDatastore {\n    child;\n    transform;\n    constructor(child, transform) {\n        super();\n        this.child = child;\n        this.transform = transform;\n    }\n    async put(key, val, options) {\n        await this.child.put(this.transform.convert(key), val, options);\n        return key;\n    }\n    async get(key, options) {\n        return this.child.get(this.transform.convert(key), options);\n    }\n    async has(key, options) {\n        return this.child.has(this.transform.convert(key), options);\n    }\n    async delete(key, options) {\n        await this.child.delete(this.transform.convert(key), options);\n    }\n    async *putMany(source, options = {}) {\n        const transform = this.transform;\n        const child = this.child;\n        yield* pipe(source, async function* (source) {\n            yield* map(source, ({ key, value }) => ({\n                key: transform.convert(key),\n                value\n            }));\n        }, async function* (source) {\n            yield* child.putMany(source, options);\n        }, async function* (source) {\n            yield* map(source, key => transform.invert(key));\n        });\n    }\n    async *getMany(source, options = {}) {\n        const transform = this.transform;\n        const child = this.child;\n        yield* pipe(source, async function* (source) {\n            yield* map(source, key => transform.convert(key));\n        }, async function* (source) {\n            yield* child.getMany(source, options);\n        }, async function* (source) {\n            yield* map(source, ({ key, value }) => ({\n                key: transform.invert(key),\n                value\n            }));\n        });\n    }\n    async *deleteMany(source, options = {}) {\n        const transform = this.transform;\n        const child = this.child;\n        yield* pipe(source, async function* (source) {\n            yield* map(source, key => transform.convert(key));\n        }, async function* (source) {\n            yield* child.deleteMany(source, options);\n        }, async function* (source) {\n            yield* map(source, key => transform.invert(key));\n        });\n    }\n    batch() {\n        const b = this.child.batch();\n        return {\n            put: (key, value) => {\n                b.put(this.transform.convert(key), value);\n            },\n            delete: (key) => {\n                b.delete(this.transform.convert(key));\n            },\n            commit: async (options) => {\n                await b.commit(options);\n            }\n        };\n    }\n    query(q, options) {\n        const query = {\n            ...q\n        };\n        query.filters = (query.filters ?? []).map(filter => {\n            return ({ key, value }) => filter({ key: this.transform.convert(key), value });\n        });\n        const { prefix } = q;\n        if (prefix != null && prefix !== '/') {\n            delete query.prefix;\n            query.filters.push(({ key }) => {\n                return this.transform.invert(key).toString().startsWith(prefix);\n            });\n        }\n        if (query.orders != null) {\n            query.orders = query.orders.map(order => {\n                return (a, b) => order({ key: this.transform.invert(a.key), value: a.value }, { key: this.transform.invert(b.key), value: b.value });\n            });\n        }\n        return map(this.child.query(query, options), ({ key, value }) => {\n            return {\n                key: this.transform.invert(key),\n                value\n            };\n        });\n    }\n    queryKeys(q, options) {\n        const query = {\n            ...q\n        };\n        query.filters = (query.filters ?? []).map(filter => {\n            return (key) => filter(this.transform.convert(key));\n        });\n        const { prefix } = q;\n        if (prefix != null && prefix !== '/') {\n            delete query.prefix;\n            query.filters.push((key) => {\n                return this.transform.invert(key).toString().startsWith(prefix);\n            });\n        }\n        if (query.orders != null) {\n            query.orders = query.orders.map(order => {\n                return (a, b) => order(this.transform.invert(a), this.transform.invert(b));\n            });\n        }\n        return map(this.child.queryKeys(query, options), key => {\n            return this.transform.invert(key);\n        });\n    }\n}\n//# sourceMappingURL=keytransform.js.map","import { Key } from 'interface-datastore';\nimport { OpenFailedError } from 'interface-store';\nimport { BaseDatastore } from './base.js';\nimport { KeyTransformDatastore } from './keytransform.js';\nimport { readShardFun, SHARDING_FN } from './shard.js';\nconst shardKey = new Key(SHARDING_FN);\n/**\n * Backend independent abstraction of go-ds-flatfs.\n *\n * Wraps another datastore such that all values are stored\n * sharded according to the given sharding function.\n */\nexport class ShardingDatastore extends BaseDatastore {\n    child;\n    shard;\n    constructor(store, shard) {\n        super();\n        this.child = new KeyTransformDatastore(store, {\n            convert: this._convertKey.bind(this),\n            invert: this._invertKey.bind(this)\n        });\n        this.shard = shard;\n    }\n    async open() {\n        this.shard = await ShardingDatastore.create(this.child, this.shard);\n    }\n    _convertKey(key) {\n        const s = key.toString();\n        if (s === shardKey.toString()) {\n            return key;\n        }\n        const parent = new Key(this.shard.fun(s));\n        return parent.child(key);\n    }\n    _invertKey(key) {\n        const s = key.toString();\n        if (s === shardKey.toString()) {\n            return key;\n        }\n        return Key.withNamespaces(key.list().slice(1));\n    }\n    static async create(store, shard) {\n        const hasShard = await store.has(shardKey);\n        if (!hasShard) {\n            if (shard == null) {\n                throw new OpenFailedError('Shard is required when datastore doesn\\'t have a shard key already');\n            }\n            await store.put(shardKey, new TextEncoder().encode(shard.toString() + '\\n'));\n        }\n        if (shard == null) {\n            shard = await readShardFun('/', store);\n        }\n        // test shards\n        const diskShard = await readShardFun('/', store);\n        const a = diskShard.toString();\n        const b = shard.toString();\n        if (a !== b) {\n            throw new Error(`specified fun ${b} does not match repo shard fun ${a}`);\n        }\n        return diskShard;\n    }\n    async put(key, val, options) {\n        await this.child.put(key, val, options);\n        return key;\n    }\n    async get(key, options) {\n        return this.child.get(key, options);\n    }\n    async has(key, options) {\n        return this.child.has(key, options);\n    }\n    async delete(key, options) {\n        await this.child.delete(key, options);\n    }\n    async *putMany(source, options = {}) {\n        yield* this.child.putMany(source, options);\n    }\n    async *getMany(source, options = {}) {\n        yield* this.child.getMany(source, options);\n    }\n    async *deleteMany(source, options = {}) {\n        yield* this.child.deleteMany(source, options);\n    }\n    batch() {\n        return this.child.batch();\n    }\n    query(q, options) {\n        const omitShard = ({ key }) => key.toString() !== shardKey.toString();\n        const tq = {\n            ...q,\n            filters: [\n                omitShard\n            ].concat(q.filters ?? [])\n        };\n        return this.child.query(tq, options);\n    }\n    queryKeys(q, options) {\n        const omitShard = (key) => key.toString() !== shardKey.toString();\n        const tq = {\n            ...q,\n            filters: [\n                omitShard\n            ].concat(q.filters ?? [])\n        };\n        return this.child.queryKeys(tq, options);\n    }\n}\n//# sourceMappingURL=sharding.js.map","import { DeleteFailedError, NotFoundError, PutFailedError } from 'interface-store';\nimport filter from 'it-filter';\nimport merge from 'it-merge';\nimport sort from 'it-sort';\nimport take from 'it-take';\nimport { BaseDatastore } from './base.js';\n/**\n * A datastore that can combine multiple stores inside various\n * key prefixes\n */\nexport class MountDatastore extends BaseDatastore {\n    mounts;\n    constructor(mounts) {\n        super();\n        this.mounts = mounts.slice();\n    }\n    /**\n     * Lookup the matching datastore for the given key\n     */\n    _lookup(key) {\n        for (const mount of this.mounts) {\n            if (mount.prefix.toString() === key.toString() || mount.prefix.isAncestorOf(key)) {\n                return {\n                    datastore: mount.datastore,\n                    mountpoint: mount.prefix\n                };\n            }\n        }\n    }\n    async put(key, value, options) {\n        const match = this._lookup(key);\n        if (match == null) {\n            throw new PutFailedError('No datastore mounted for this key');\n        }\n        await match.datastore.put(key, value, options);\n        return key;\n    }\n    /**\n     * @param {Key} key\n     * @param {Options} [options]\n     */\n    async get(key, options = {}) {\n        const match = this._lookup(key);\n        if (match == null) {\n            throw new NotFoundError('No datastore mounted for this key');\n        }\n        return match.datastore.get(key, options);\n    }\n    async has(key, options) {\n        const match = this._lookup(key);\n        if (match == null) {\n            return Promise.resolve(false);\n        }\n        return match.datastore.has(key, options);\n    }\n    async delete(key, options) {\n        const match = this._lookup(key);\n        if (match == null) {\n            throw new DeleteFailedError('No datastore mounted for this key');\n        }\n        await match.datastore.delete(key, options);\n    }\n    batch() {\n        const batchMounts = {};\n        const lookup = (key) => {\n            const match = this._lookup(key);\n            if (match == null) {\n                throw new Error('No datastore mounted for this key');\n            }\n            const m = match.mountpoint.toString();\n            if (batchMounts[m] == null) {\n                batchMounts[m] = match.datastore.batch();\n            }\n            return {\n                batch: batchMounts[m]\n            };\n        };\n        return {\n            put: (key, value) => {\n                const match = lookup(key);\n                match.batch.put(key, value);\n            },\n            delete: (key) => {\n                const match = lookup(key);\n                match.batch.delete(key);\n            },\n            commit: async (options) => {\n                await Promise.all(Object.keys(batchMounts).map(async (p) => { await batchMounts[p].commit(options); }));\n            }\n        };\n    }\n    query(q, options) {\n        const qs = this.mounts.map(m => {\n            return m.datastore.query({\n                prefix: q.prefix,\n                filters: q.filters\n            }, options);\n        });\n        let it = merge(...qs);\n        if (q.filters != null)\n            q.filters.forEach(f => { it = filter(it, f); });\n        if (q.orders != null)\n            q.orders.forEach(o => { it = sort(it, o); });\n        if (q.offset != null) {\n            let i = 0;\n            const offset = q.offset;\n            it = filter(it, () => i++ >= offset);\n        }\n        if (q.limit != null)\n            it = take(it, q.limit);\n        return it;\n    }\n    queryKeys(q, options) {\n        const qs = this.mounts.map(m => {\n            return m.datastore.queryKeys({\n                prefix: q.prefix,\n                filters: q.filters\n            }, options);\n        });\n        /** @type AsyncIterable<Key> */\n        let it = merge(...qs);\n        if (q.filters != null)\n            q.filters.forEach(f => { it = filter(it, f); });\n        if (q.orders != null)\n            q.orders.forEach(o => { it = sort(it, o); });\n        if (q.offset != null) {\n            let i = 0;\n            const offset = q.offset;\n            it = filter(it, () => i++ >= offset);\n        }\n        if (q.limit != null)\n            it = take(it, q.limit);\n        return it;\n    }\n}\n//# sourceMappingURL=mount.js.map","import { logger } from '@libp2p/logger';\nimport { PutFailedError, NotFoundError, DeleteFailedError } from 'interface-store';\nimport drain from 'it-drain';\nimport { pushable } from 'it-pushable';\nimport { BaseDatastore } from './base.js';\nconst log = logger('datastore:core:tiered');\n/**\n * A datastore that can combine multiple stores. Puts and deletes\n * will write through to all datastores. Has and get will\n * try each store sequentially. Query will always try the\n * last one first.\n *\n */\nexport class TieredDatastore extends BaseDatastore {\n    stores;\n    constructor(stores) {\n        super();\n        this.stores = stores.slice();\n    }\n    async put(key, value, options) {\n        try {\n            await Promise.all(this.stores.map(async (store) => { await store.put(key, value, options); }));\n            return key;\n        }\n        catch (err) {\n            throw new PutFailedError(err.message);\n        }\n    }\n    async get(key, options) {\n        for (const store of this.stores) {\n            try {\n                const res = await store.get(key, options);\n                if (res != null)\n                    return res;\n            }\n            catch (err) {\n                log.error(err);\n            }\n        }\n        throw new NotFoundError();\n    }\n    async has(key, options) {\n        for (const s of this.stores) {\n            if (await s.has(key, options)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    async delete(key, options) {\n        try {\n            await Promise.all(this.stores.map(async (store) => { await store.delete(key, options); }));\n        }\n        catch (err) {\n            throw new DeleteFailedError(err.message);\n        }\n    }\n    async *putMany(source, options = {}) {\n        let error;\n        const pushables = this.stores.map(store => {\n            const source = pushable({\n                objectMode: true\n            });\n            drain(store.putMany(source, options))\n                .catch(err => {\n                // store threw while putting, make sure we bubble the error up\n                error = err;\n            });\n            return source;\n        });\n        try {\n            for await (const pair of source) {\n                if (error != null) {\n                    throw error;\n                }\n                pushables.forEach(p => p.push(pair));\n                yield pair.key;\n            }\n        }\n        finally {\n            pushables.forEach(p => p.end());\n        }\n    }\n    async *deleteMany(source, options = {}) {\n        let error;\n        const pushables = this.stores.map(store => {\n            const source = pushable({\n                objectMode: true\n            });\n            drain(store.deleteMany(source, options))\n                .catch(err => {\n                // store threw while deleting, make sure we bubble the error up\n                error = err;\n            });\n            return source;\n        });\n        try {\n            for await (const key of source) {\n                if (error != null) {\n                    throw error;\n                }\n                pushables.forEach(p => p.push(key));\n                yield key;\n            }\n        }\n        finally {\n            pushables.forEach(p => p.end());\n        }\n    }\n    batch() {\n        const batches = this.stores.map(store => store.batch());\n        return {\n            put: (key, value) => {\n                batches.forEach(b => { b.put(key, value); });\n            },\n            delete: (key) => {\n                batches.forEach(b => { b.delete(key); });\n            },\n            commit: async (options) => {\n                for (const batch of batches) {\n                    await batch.commit(options);\n                }\n            }\n        };\n    }\n    query(q, options) {\n        return this.stores[this.stores.length - 1].query(q, options);\n    }\n    queryKeys(q, options) {\n        return this.stores[this.stores.length - 1].queryKeys(q, options);\n    }\n}\n//# sourceMappingURL=tiered.js.map","import { Key } from 'interface-datastore';\nimport map from 'it-map';\nimport { KeyTransformDatastore } from './keytransform.js';\n/**\n * Wraps a given datastore into a keytransform which\n * makes a given prefix transparent.\n *\n * For example, if the prefix is `new Key(/hello)` a call\n * to `store.put(new Key('/world'), mydata)` would store the data under\n * `/hello/world`.\n */\nexport class NamespaceDatastore extends KeyTransformDatastore {\n    iChild;\n    iKey;\n    constructor(child, prefix) {\n        super(child, {\n            convert(key) {\n                return prefix.child(key);\n            },\n            invert(key) {\n                if (prefix.toString() === '/') {\n                    return key;\n                }\n                if (!prefix.isAncestorOf(key)) {\n                    throw new Error(`Expected prefix: (${prefix.toString()}) in key: ${key.toString()}`);\n                }\n                return new Key(key.toString().slice(prefix.toString().length), false);\n            }\n        });\n        this.iChild = child;\n        this.iKey = prefix;\n    }\n    query(q, options) {\n        const query = {\n            ...q\n        };\n        query.filters = (query.filters ?? []).map(filter => {\n            return ({ key, value }) => filter({ key: this.transform.invert(key), value });\n        });\n        const { prefix } = q;\n        if (prefix != null && prefix !== '/') {\n            delete query.prefix;\n            query.filters.push(({ key }) => {\n                return this.transform.invert(key).toString().startsWith(prefix);\n            });\n        }\n        if (query.orders != null) {\n            query.orders = query.orders.map(order => {\n                return (a, b) => order({ key: this.transform.invert(a.key), value: a.value }, { key: this.transform.invert(b.key), value: b.value });\n            });\n        }\n        query.filters.unshift(({ key }) => this.iKey.isAncestorOf(key));\n        return map(this.iChild.query(query, options), ({ key, value }) => {\n            return {\n                key: this.transform.invert(key),\n                value\n            };\n        });\n    }\n    queryKeys(q, options) {\n        const query = {\n            ...q\n        };\n        query.filters = (query.filters ?? []).map(filter => {\n            return (key) => filter(this.transform.invert(key));\n        });\n        const { prefix } = q;\n        if (prefix != null && prefix !== '/') {\n            delete query.prefix;\n            query.filters.push((key) => {\n                return this.transform.invert(key).toString().startsWith(prefix);\n            });\n        }\n        if (query.orders != null) {\n            query.orders = query.orders.map(order => {\n                return (a, b) => order(this.transform.invert(a), this.transform.invert(b));\n            });\n        }\n        query.filters.unshift(key => this.iKey.isAncestorOf(key));\n        return map(this.iChild.queryKeys(query, options), key => {\n            return this.transform.invert(key);\n        });\n    }\n}\n//# sourceMappingURL=namespace.js.map","/**\n * @packageDocumentation\n *\n * Various Datastore implementations are available.\n *\n * ## Implementations\n *\n * - Mount: [`src/mount`](src/mount.ts)\n * - Keytransform: [`src/keytransform`](src/keytransform.ts)\n * - Sharding: [`src/sharding`](src/sharding.ts)\n * - Tiered: [`src/tiered`](src/tirered.ts)\n * - Namespace: [`src/namespace`](src/namespace.ts)\n * - BlackHole: [`src/black-hole`](src/black-hole.ts)\n *\n * @example BaseDatastore\n *\n * An base store is made available to make implementing your own datastore easier:\n *\n * ```javascript\n * import { BaseDatastore } from 'datastore-core'\n *\n * class MyDatastore extends BaseDatastore {\n *   constructor () {\n *     super()\n *   }\n *\n *   async put (key, val) {\n *     // your implementation here\n *   }\n *\n *   async get (key) {\n *     // your implementation here\n *   }\n *\n *   // etc...\n * }\n * ```\n *\n * See the [MemoryDatastore](./src/memory.js) for an example of how it is used.\n *\n * @example Wrapping Stores\n *\n * ```js\n * import { Key } from 'interface-datastore'\n * import {\n *   MemoryStore,\n *   MountStore\n * } from 'datastore-core'\n *\n * const store = new MountStore({prefix: new Key('/a'), datastore: new MemoryStore()})\n * ```\n *\n * @example BlackHoleDatastore\n *\n * A datastore that does not store any data.\n *\n * ```js\n * import { BlackHoleDatastore } from 'datastore-core/black-hole'\n *\n * const store = new BlackHoleDatastore()\n * ```\n */\nimport * as shard from './shard.js';\nexport { BaseDatastore } from './base.js';\nexport { MemoryDatastore } from './memory.js';\nexport { KeyTransformDatastore } from './keytransform.js';\nexport { ShardingDatastore } from './sharding.js';\nexport { MountDatastore } from './mount.js';\nexport { TieredDatastore } from './tiered.js';\nexport { NamespaceDatastore } from './namespace.js';\nexport { shard };\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Exports a `createHeliaHTTP` function that returns an object that implements a lightweight version of the {@link Helia} API that functions only over HTTP.\n *\n * By default, content and peer routing are requests are resolved using the [Delegated HTTP Routing API](https://specs.ipfs.tech/routing/http-routing-v1/) and blocks are fetched from [Trustless Gateways](https://specs.ipfs.tech/http-gateways/trustless-gateway/).\n *\n * Pass it to other modules like {@link https://www.npmjs.com/package/@helia/unixfs | @helia/unixfs} to fetch files from the distributed web.\n *\n * @example\n *\n * ```typescript\n * import { createHeliaHTTP } from '@helia/http'\n * import { unixfs } from '@helia/unixfs'\n * import { CID } from 'multiformats/cid'\n *\n * const helia = await createHeliaHTTP()\n *\n * const fs = unixfs(helia)\n * fs.cat(CID.parse('bafyFoo'))\n * ```\n * @example with custom gateways and delegated routing endpoints\n * ```typescript\n * import { createHeliaHTTP } from '@helia/http'\n * import { trustlessGateway } from '@helia/block-brokers'\n * import { delegatedHTTPRouting, httpGatewayRouting } from '@helia/routers'\n * import { unixfs } from '@helia/unixfs'\n * import { CID } from 'multiformats/cid'\n *\n * const helia = await createHeliaHTTP({\n *   blockBrokers: [\n *     trustlessGateway()\n *   ],\n *   routers: [\n *     delegatedHTTPRouting('https://delegated-ipfs.dev'),\n *     httpGatewayRouting({\n *       gateways: ['https://cloudflare-ipfs.com', 'https://ipfs.io']\n *     })\n *   ]\n * })\n *\n * const fs = unixfs(helia)\n * fs.cat(CID.parse('bafyFoo'))\n * ```\n */\nimport { trustlessGateway } from '@helia/block-brokers';\nimport { delegatedHTTPRouting, httpGatewayRouting } from '@helia/routers';\nimport { Helia as HeliaClass } from '@helia/utils';\nimport { MemoryBlockstore } from 'blockstore-core';\nimport { MemoryDatastore } from 'datastore-core';\n// re-export interface types so people don't have to depend on @helia/interface\n// if they don't want to\nexport * from '@helia/interface';\n/**\n * Create and return a Helia node\n */\nexport async function createHeliaHTTP(init = {}) {\n    const datastore = init.datastore ?? new MemoryDatastore();\n    const blockstore = init.blockstore ?? new MemoryBlockstore();\n    const helia = new HeliaClass({\n        ...init,\n        datastore,\n        blockstore,\n        blockBrokers: init.blockBrokers ?? [\n            trustlessGateway()\n        ],\n        routers: init.routers ?? [\n            delegatedHTTPRouting('https://delegated-ipfs.dev'),\n            httpGatewayRouting()\n        ]\n    });\n    if (init.start !== false) {\n        await helia.start();\n    }\n    return helia;\n}\n//# sourceMappingURL=index.js.map","import varint from 'varint'\n\nexport const CIDV0_BYTES = {\n  SHA2_256: 0x12,\n  LENGTH: 0x20,\n  DAG_PB: 0x70\n}\n\nexport const V2_HEADER_LENGTH = /* characteristics */ 16 /* v1 offset */ + 8 /* v1 size */ + 8 /* index offset */ + 8\n\n/**\n * Decodes varint and seeks the buffer\n *\n * ```js\n * // needs bytes to be read first\n * const bytes = reader.upTo(8) // maybe async\n * ```\n *\n * @param {Uint8Array} bytes\n * @param {import('./coding').Seekable} seeker\n * @returns {number}\n */\nexport function decodeVarint (bytes, seeker) {\n  if (!bytes.length) {\n    throw new Error('Unexpected end of data')\n  }\n  const i = varint.decode(bytes)\n  seeker.seek(/** @type {number} */(varint.decode.bytes))\n  return i\n}\n\n/**\n * Decode v2 header\n *\n * ```js\n * // needs bytes to be read first\n * const bytes = reader.exactly(V2_HEADER_LENGTH, true) // maybe async\n * ```\n *\n * @param {Uint8Array} bytes\n * @returns {import('./coding').CarV2FixedHeader}\n */\nexport function decodeV2Header (bytes) {\n  const dv = new DataView(bytes.buffer, bytes.byteOffset, bytes.byteLength)\n  let offset = 0\n  const header = {\n    version: 2,\n    /** @type {[bigint, bigint]} */\n    characteristics: [\n      dv.getBigUint64(offset, true),\n      dv.getBigUint64(offset += 8, true)\n    ],\n    dataOffset: Number(dv.getBigUint64(offset += 8, true)),\n    dataSize: Number(dv.getBigUint64(offset += 8, true)),\n    indexOffset: Number(dv.getBigUint64(offset += 8, true))\n  }\n  return header\n}\n\n/**\n * Checks the length of the multihash to be read afterwards\n *\n * ```js\n * // needs bytes to be read first\n * const bytes = reader.upTo(8) // maybe async\n * ```\n *\n * @param {Uint8Array} bytes\n */\nexport function getMultihashLength (bytes) {\n  // | code | length | .... |\n  // where both code and length are varints, so we have to decode\n  // them first before we can know total length\n\n  varint.decode(bytes) // code\n  const codeLength = /** @type {number} */(varint.decode.bytes)\n  const length = varint.decode(bytes.subarray(varint.decode.bytes))\n  const lengthLength = /** @type {number} */(varint.decode.bytes)\n  const mhLength = codeLength + lengthLength + length\n\n  return mhLength\n}\n","/** Auto-generated with @ipld/schema@v4.2.0 at Thu Sep 14 2023 from IPLD Schema:\n *\n * # CarV1HeaderOrV2Pragma is a more relaxed form, and can parse {version:x} where\n * # roots are optional. This is typically useful for the {verison:2} CARv2\n * # pragma.\n *\n * type CarV1HeaderOrV2Pragma struct {\n * \troots optional [&Any]\n * \t# roots is _not_ optional for CarV1 but we defer that check within code to\n * \t# gracefully handle the V2 case where it's just {version:X}\n * \tversion Int\n * }\n *\n * # CarV1Header is the strict form of the header, and requires roots to be\n * # present. This is compatible with the CARv1 specification.\n *\n * # type CarV1Header struct {\n * # \troots [&Any]\n * # \tversion Int\n * # }\n *\n */\n\nconst Kinds = {\n  Null: /** @returns {undefined|null} */ (/** @type {any} */ obj) => obj === null ? obj : undefined,\n  Int: /** @returns {undefined|number} */ (/** @type {any} */ obj) => Number.isInteger(obj) ? obj : undefined,\n  Float: /** @returns {undefined|number} */ (/** @type {any} */ obj) => typeof obj === 'number' && Number.isFinite(obj) ? obj : undefined,\n  String: /** @returns {undefined|string} */ (/** @type {any} */ obj) => typeof obj === 'string' ? obj : undefined,\n  Bool: /** @returns {undefined|boolean} */ (/** @type {any} */ obj) => typeof obj === 'boolean' ? obj : undefined,\n  Bytes: /** @returns {undefined|Uint8Array} */ (/** @type {any} */ obj) => obj instanceof Uint8Array ? obj : undefined,\n  Link: /** @returns {undefined|object} */ (/** @type {any} */ obj) => obj !== null && typeof obj === 'object' && obj.asCID === obj ? obj : undefined,\n  List: /** @returns {undefined|Array<any>} */ (/** @type {any} */ obj) => Array.isArray(obj) ? obj : undefined,\n  Map: /** @returns {undefined|object} */ (/** @type {any} */ obj) => obj !== null && typeof obj === 'object' && obj.asCID !== obj && !Array.isArray(obj) && !(obj instanceof Uint8Array) ? obj : undefined\n}\n/** @type {{ [k in string]: (obj:any)=>undefined|any}} */\nconst Types = {\n  'CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)': Kinds.Link,\n  'CarV1HeaderOrV2Pragma > roots (anon)': /** @returns {undefined|any} */ (/** @type {any} */ obj) => {\n    if (Kinds.List(obj) === undefined) {\n      return undefined\n    }\n    for (let i = 0; i < obj.length; i++) {\n      let v = obj[i]\n      v = Types['CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)'](v)\n      if (v === undefined) {\n        return undefined\n      }\n      if (v !== obj[i]) {\n        const ret = obj.slice(0, i)\n        for (let j = i; j < obj.length; j++) {\n          let v = obj[j]\n          v = Types['CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)'](v)\n          if (v === undefined) {\n            return undefined\n          }\n          ret.push(v)\n        }\n        return ret\n      }\n    }\n    return obj\n  },\n  Int: Kinds.Int,\n  CarV1HeaderOrV2Pragma: /** @returns {undefined|any} */ (/** @type {any} */ obj) => {\n    if (Kinds.Map(obj) === undefined) {\n      return undefined\n    }\n    const entries = Object.entries(obj)\n    /** @type {{[k in string]: any}} */\n    let ret = obj\n    let requiredCount = 1\n    for (let i = 0; i < entries.length; i++) {\n      const [key, value] = entries[i]\n      switch (key) {\n        case 'roots':\n          {\n            const v = Types['CarV1HeaderOrV2Pragma > roots (anon)'](obj[key])\n            if (v === undefined) {\n              return undefined\n            }\n            if (v !== value || ret !== obj) {\n              if (ret === obj) {\n                /** @type {{[k in string]: any}} */\n                ret = {}\n                for (let j = 0; j < i; j++) {\n                  ret[entries[j][0]] = entries[j][1]\n                }\n              }\n              ret.roots = v\n            }\n          }\n          break\n        case 'version':\n          {\n            requiredCount--\n            const v = Types.Int(obj[key])\n            if (v === undefined) {\n              return undefined\n            }\n            if (v !== value || ret !== obj) {\n              if (ret === obj) {\n                /** @type {{[k in string]: any}} */\n                ret = {}\n                for (let j = 0; j < i; j++) {\n                  ret[entries[j][0]] = entries[j][1]\n                }\n              }\n              ret.version = v\n            }\n          }\n          break\n        default:\n          return undefined\n      }\n    }\n\n    if (requiredCount > 0) {\n      return undefined\n    }\n    return ret\n  }\n}\n/** @type {{ [k in string]: (obj:any)=>undefined|any}} */\nconst Reprs = {\n  'CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)': Kinds.Link,\n  'CarV1HeaderOrV2Pragma > roots (anon)': /** @returns {undefined|any} */ (/** @type {any} */ obj) => {\n    if (Kinds.List(obj) === undefined) {\n      return undefined\n    }\n    for (let i = 0; i < obj.length; i++) {\n      let v = obj[i]\n      v = Reprs['CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)'](v)\n      if (v === undefined) {\n        return undefined\n      }\n      if (v !== obj[i]) {\n        const ret = obj.slice(0, i)\n        for (let j = i; j < obj.length; j++) {\n          let v = obj[j]\n          v = Reprs['CarV1HeaderOrV2Pragma > roots (anon) > valueType (anon)'](v)\n          if (v === undefined) {\n            return undefined\n          }\n          ret.push(v)\n        }\n        return ret\n      }\n    }\n    return obj\n  },\n  Int: Kinds.Int,\n  CarV1HeaderOrV2Pragma: /** @returns {undefined|any} */ (/** @type {any} */ obj) => {\n    if (Kinds.Map(obj) === undefined) {\n      return undefined\n    }\n    const entries = Object.entries(obj)\n    /** @type {{[k in string]: any}} */\n    let ret = obj\n    let requiredCount = 1\n    for (let i = 0; i < entries.length; i++) {\n      const [key, value] = entries[i]\n      switch (key) {\n        case 'roots':\n          {\n            const v = Reprs['CarV1HeaderOrV2Pragma > roots (anon)'](value)\n            if (v === undefined) {\n              return undefined\n            }\n            if (v !== value || ret !== obj) {\n              if (ret === obj) {\n                /** @type {{[k in string]: any}} */\n                ret = {}\n                for (let j = 0; j < i; j++) {\n                  ret[entries[j][0]] = entries[j][1]\n                }\n              }\n              ret.roots = v\n            }\n          }\n          break\n        case 'version':\n          {\n            requiredCount--\n            const v = Reprs.Int(value)\n            if (v === undefined) {\n              return undefined\n            }\n            if (v !== value || ret !== obj) {\n              if (ret === obj) {\n                /** @type {{[k in string]: any}} */\n                ret = {}\n                for (let j = 0; j < i; j++) {\n                  ret[entries[j][0]] = entries[j][1]\n                }\n              }\n              ret.version = v\n            }\n          }\n          break\n        default:\n          return undefined\n      }\n    }\n    if (requiredCount > 0) {\n      return undefined\n    }\n    return ret\n  }\n}\n\nexport const CarV1HeaderOrV2Pragma = {\n  toTyped: Types.CarV1HeaderOrV2Pragma,\n  toRepresentation: Reprs.CarV1HeaderOrV2Pragma\n}\n","import { decode as decodeDagCbor } from '@ipld/dag-cbor'\nimport { CID } from 'multiformats/cid'\nimport * as Digest from 'multiformats/hashes/digest'\nimport { CIDV0_BYTES, decodeV2Header, decodeVarint, getMultihashLength, V2_HEADER_LENGTH } from './decoder-common.js'\nimport { CarV1HeaderOrV2Pragma } from './header-validator.js'\n\n/**\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').BlockHeader} BlockHeader\n * @typedef {import('./api').BlockIndex} BlockIndex\n * @typedef {import('./coding').BytesBufferReader} BytesBufferReader\n * @typedef {import('./coding').CarHeader} CarHeader\n * @typedef {import('./coding').CarV2Header} CarV2Header\n * @typedef {import('./coding').CarV2FixedHeader} CarV2FixedHeader\n */\n\n/**\n * Reads header data from a `BytesReader`. The header may either be in the form\n * of a `CarHeader` or `CarV2Header` depending on the CAR being read.\n *\n * @name decoder.readHeader(reader)\n * @param {BytesBufferReader} reader\n * @param {number} [strictVersion]\n * @returns {CarHeader | CarV2Header}\n */\nexport function readHeader (reader, strictVersion) {\n  const length = decodeVarint(reader.upTo(8), reader)\n  if (length === 0) {\n    throw new Error('Invalid CAR header (zero length)')\n  }\n  const header = reader.exactly(length, true)\n  const block = decodeDagCbor(header)\n  if (CarV1HeaderOrV2Pragma.toTyped(block) === undefined) {\n    throw new Error('Invalid CAR header format')\n  }\n  if ((block.version !== 1 && block.version !== 2) || (strictVersion !== undefined && block.version !== strictVersion)) {\n    throw new Error(`Invalid CAR version: ${block.version}${strictVersion !== undefined ? ` (expected ${strictVersion})` : ''}`)\n  }\n  if (block.version === 1) {\n    // CarV1HeaderOrV2Pragma makes roots optional, let's make it mandatory\n    if (!Array.isArray(block.roots)) {\n      throw new Error('Invalid CAR header format')\n    }\n    return block\n  }\n  // version 2\n  if (block.roots !== undefined) {\n    throw new Error('Invalid CAR header format')\n  }\n  const v2Header = decodeV2Header(reader.exactly(V2_HEADER_LENGTH, true))\n  reader.seek(v2Header.dataOffset - reader.pos)\n  const v1Header = readHeader(reader, 1)\n  return Object.assign(v1Header, v2Header)\n}\n\n/**\n * Reads CID sync\n *\n * @param {BytesBufferReader} reader\n * @returns {CID}\n */\nfunction readCid (reader) {\n  const first = reader.exactly(2, false)\n  if (first[0] === CIDV0_BYTES.SHA2_256 && first[1] === CIDV0_BYTES.LENGTH) {\n    // cidv0 32-byte sha2-256\n    const bytes = reader.exactly(34, true)\n    const multihash = Digest.decode(bytes)\n    return CID.create(0, CIDV0_BYTES.DAG_PB, multihash)\n  }\n\n  const version = decodeVarint(reader.upTo(8), reader)\n  if (version !== 1) {\n    throw new Error(`Unexpected CID version (${version})`)\n  }\n  const codec = decodeVarint(reader.upTo(8), reader)\n  const bytes = reader.exactly(getMultihashLength(reader.upTo(8)), true)\n  const multihash = Digest.decode(bytes)\n  return CID.create(version, codec, multihash)\n}\n\n/**\n * Reads the leading data of an individual block from CAR data from a\n * `BytesBufferReader`. Returns a `BlockHeader` object which contains\n * `{ cid, length, blockLength }` which can be used to either index the block\n * or read the block binary data.\n *\n * @name async decoder.readBlockHead(reader)\n * @param {BytesBufferReader} reader\n * @returns {BlockHeader}\n */\nexport function readBlockHead (reader) {\n  // length includes a CID + Binary, where CID has a variable length\n  // we have to deal with\n  const start = reader.pos\n  let length = decodeVarint(reader.upTo(8), reader)\n  if (length === 0) {\n    throw new Error('Invalid CAR section (zero length)')\n  }\n  length += (reader.pos - start)\n  const cid = readCid(reader)\n  const blockLength = length - Number(reader.pos - start) // subtract CID length\n\n  return { cid, length, blockLength }\n}\n\n/**\n * Returns Car header and blocks from a Uint8Array\n *\n * @param {Uint8Array} bytes\n * @returns {{ header : CarHeader | CarV2Header , blocks: Block[]}}\n */\nexport function fromBytes (bytes) {\n  let reader = bytesReader(bytes)\n  const header = readHeader(reader)\n  if (header.version === 2) {\n    const v1length = reader.pos - header.dataOffset\n    reader = limitReader(reader, header.dataSize - v1length)\n  }\n\n  const blocks = []\n  while (reader.upTo(8).length > 0) {\n    const { cid, blockLength } = readBlockHead(reader)\n\n    blocks.push({ cid, bytes: reader.exactly(blockLength, true) })\n  }\n\n  return {\n    header, blocks\n  }\n}\n\n/**\n * Creates a `BytesBufferReader` from a `Uint8Array`.\n *\n * @name decoder.bytesReader(bytes)\n * @param {Uint8Array} bytes\n * @returns {BytesBufferReader}\n */\nexport function bytesReader (bytes) {\n  let pos = 0\n\n  /** @type {BytesBufferReader} */\n  return {\n    upTo (length) {\n      return bytes.subarray(pos, pos + Math.min(length, bytes.length - pos))\n    },\n\n    exactly (length, seek = false) {\n      if (length > bytes.length - pos) {\n        throw new Error('Unexpected end of data')\n      }\n\n      const out = bytes.subarray(pos, pos + length)\n      if (seek) {\n        pos += length\n      }\n      return out\n    },\n\n    seek (length) {\n      pos += length\n    },\n\n    get pos () {\n      return pos\n    }\n  }\n}\n\n/**\n * Wraps a `BytesBufferReader` in a limiting `BytesBufferReader` which limits maximum read\n * to `byteLimit` bytes. It _does not_ update `pos` of the original\n * `BytesBufferReader`.\n *\n * @name decoder.limitReader(reader, byteLimit)\n * @param {BytesBufferReader} reader\n * @param {number} byteLimit\n * @returns {BytesBufferReader}\n */\nexport function limitReader (reader, byteLimit) {\n  let bytesRead = 0\n\n  /** @type {BytesBufferReader} */\n  return {\n    upTo (length) {\n      let bytes = reader.upTo(length)\n      if (bytes.length + bytesRead > byteLimit) {\n        bytes = bytes.subarray(0, byteLimit - bytesRead)\n      }\n      return bytes\n    },\n\n    exactly (length, seek = false) {\n      const bytes = reader.exactly(length, seek)\n      if (bytes.length + bytesRead > byteLimit) {\n        throw new Error('Unexpected end of data')\n      }\n      if (seek) {\n        bytesRead += length\n      }\n      return bytes\n    },\n\n    seek (length) {\n      bytesRead += length\n      reader.seek(length)\n    },\n\n    get pos () {\n      return reader.pos\n    }\n  }\n}\n","import * as BufferDecoder from './buffer-decoder.js'\n\n/**\n * @typedef {import('multiformats').CID} CID\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').CarBufferReader} ICarBufferReader\n * @typedef {import('./coding').CarHeader} CarHeader\n * @typedef {import('./coding').CarV2Header} CarV2Header\n */\n\n/**\n * Provides blockstore-like access to a CAR.\n *\n * Implements the `RootsBufferReader` interface:\n * {@link ICarBufferReader.getRoots `getRoots()`}. And the `BlockBufferReader` interface:\n * {@link ICarBufferReader.get `get()`}, {@link ICarBufferReader.has `has()`},\n * {@link ICarBufferReader.blocks `blocks()`} and\n * {@link ICarBufferReader.cids `cids()`}.\n *\n * Load this class with either `import { CarBufferReader } from '@ipld/car/buffer-reader'`\n * (`const { CarBufferReader } = require('@ipld/car/buffer-reader')`). Or\n * `import { CarBufferReader } from '@ipld/car'` (`const { CarBufferReader } = require('@ipld/car')`).\n * The former will likely result in smaller bundle sizes where this is\n * important.\n *\n * @name CarBufferReader\n * @class\n * @implements {ICarBufferReader}\n * @property {number} version The version number of the CAR referenced by this\n * reader (should be `1` or `2`).\n */\nexport class CarBufferReader {\n  /**\n   * @constructs CarBufferReader\n   * @param {CarHeader|CarV2Header} header\n   * @param {Block[]} blocks\n   */\n  constructor (header, blocks) {\n    this._header = header\n    this._blocks = blocks\n    this._cids = undefined\n  }\n\n  /**\n   * @property version\n   * @memberof CarBufferReader\n   * @instance\n   */\n  get version () {\n    return this._header.version\n  }\n\n  /**\n   * Get the list of roots defined by the CAR referenced by this reader. May be\n   * zero or more `CID`s.\n   *\n   * @function\n   * @memberof CarBufferReader\n   * @instance\n   * @returns {CID[]}\n   */\n  getRoots () {\n    return this._header.roots\n  }\n\n  /**\n   * Check whether a given `CID` exists within the CAR referenced by this\n   * reader.\n   *\n   * @function\n   * @memberof CarBufferReader\n   * @instance\n   * @param {CID} key\n   * @returns {boolean}\n   */\n  has (key) {\n    return this._blocks.some(b => b.cid.equals(key))\n  }\n\n  /**\n   * Fetch a `Block` (a `{ cid:CID, bytes:Uint8Array }` pair) from the CAR\n   * referenced by this reader matching the provided `CID`. In the case where\n   * the provided `CID` doesn't exist within the CAR, `undefined` will be\n   * returned.\n   *\n   * @function\n   * @memberof CarBufferReader\n   * @instance\n   * @param {CID} key\n   * @returns {Block | undefined}\n   */\n  get (key) {\n    return this._blocks.find(b => b.cid.equals(key))\n  }\n\n  /**\n   * Returns a `Block[]` of the `Block`s (`{ cid:CID, bytes:Uint8Array }` pairs) contained within\n   * the CAR referenced by this reader.\n   *\n   * @function\n   * @memberof CarBufferReader\n   * @instance\n   * @returns {Block[]}\n   */\n  blocks () {\n    return this._blocks\n  }\n\n  /**\n   * Returns a `CID[]` of the `CID`s contained within the CAR referenced by this reader.\n   *\n   * @function\n   * @memberof CarBufferReader\n   * @instance\n   * @returns {CID[]}\n   */\n  cids () {\n    if (!this._cids) {\n      this._cids = this._blocks.map(b => b.cid)\n    }\n    return this._cids\n  }\n\n  /**\n   * Instantiate a {@link CarBufferReader} from a `Uint8Array` blob. This performs a\n   * decode fully in memory and maintains the decoded state in memory for full\n   * access to the data via the `CarReader` API.\n   *\n   * @static\n   * @memberof CarBufferReader\n   * @param {Uint8Array} bytes\n   * @returns {CarBufferReader}\n   */\n  static fromBytes (bytes) {\n    if (!(bytes instanceof Uint8Array)) {\n      throw new TypeError('fromBytes() requires a Uint8Array')\n    }\n\n    const { header, blocks } = BufferDecoder.fromBytes(bytes)\n    return new CarBufferReader(header, blocks)\n  }\n}\n\nexport const __browser = true\n","import { makeCborEncoders, objectToTokens } from './encode.js'\nimport { quickEncodeToken } from './jump.js'\n\n/**\n * @typedef {import('../interface').EncodeOptions} EncodeOptions\n * @typedef {import('../interface').TokenTypeEncoder} TokenTypeEncoder\n * @typedef {import('../interface').TokenOrNestedTokens} TokenOrNestedTokens\n */\n\nconst cborEncoders = makeCborEncoders()\n\n/** @type {EncodeOptions} */\nconst defaultEncodeOptions = {\n  float64: false,\n  quickEncodeToken\n}\n\n/**\n * Calculate the byte length of the given data when encoded as CBOR with the\n * options provided.\n * This calculation will be accurate if the same options are used as when\n * performing a normal encode. Some encode options can change the encoding\n * output length.\n *\n * @param {any} data\n * @param {EncodeOptions} [options]\n * @returns {number}\n */\nexport function encodedLength (data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options)\n  options.mapSorter = undefined // won't change the length\n  const tokens = objectToTokens(data, options)\n  return tokensToLength(tokens, cborEncoders, options)\n}\n\n/**\n * Calculate the byte length of the data as represented by the given tokens when\n * encoded as CBOR with the options provided.\n * This function is for advanced users and would not normally be called\n * directly. See `encodedLength()` for appropriate use.\n *\n * @param {TokenOrNestedTokens} tokens\n * @param {TokenTypeEncoder[]} [encoders]\n * @param {EncodeOptions} [options]\n */\nexport function tokensToLength (tokens, encoders = cborEncoders, options = defaultEncodeOptions) {\n  if (Array.isArray(tokens)) {\n    let len = 0\n    for (const token of tokens) {\n      len += tokensToLength(token, encoders, options)\n    }\n    return len\n  } else {\n    const encoder = encoders[tokens.type.major]\n    /* c8 ignore next 3 */\n    if (encoder.encodedSize === undefined || typeof encoder.encodedSize !== 'function') {\n      throw new Error(`Encoder for ${tokens.type.name} does not have an encodedSize()`)\n    }\n    return encoder.encodedSize(tokens, options)\n  }\n}\n","import * as CBOR from '@ipld/dag-cbor'\nimport { Token, Type } from 'cborg'\nimport { tokensToLength } from 'cborg/length'\nimport varint from 'varint'\n\n/**\n * @typedef {import('./api').CID} CID\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').CarBufferWriter} Writer\n * @typedef {import('./api').CarBufferWriterOptions} Options\n * @typedef {import('./coding').CarEncoder} CarEncoder\n */\n\n/**\n * A simple CAR writer that writes to a pre-allocated buffer.\n *\n * @class\n * @name CarBufferWriter\n * @implements {Writer}\n */\nclass CarBufferWriter {\n  /**\n   * @param {Uint8Array} bytes\n   * @param {number} headerSize\n   */\n  constructor (bytes, headerSize) {\n    /** @readonly */\n    this.bytes = bytes\n    this.byteOffset = headerSize\n\n    /**\n     * @readonly\n     * @type {CID[]}\n     */\n    this.roots = []\n    this.headerSize = headerSize\n  }\n\n  /**\n   * Add a root to this writer, to be used to create a header when the CAR is\n   * finalized with {@link CarBufferWriter.close `close()`}\n   *\n   * @param {CID} root\n   * @param {{resize?:boolean}} [options]\n   * @returns {CarBufferWriter}\n   */\n  addRoot (root, options) {\n    addRoot(this, root, options)\n    return this\n  }\n\n  /**\n   * Write a `Block` (a `{ cid:CID, bytes:Uint8Array }` pair) to the archive.\n   * Throws if there is not enough capacity.\n   *\n   * @param {Block} block - A `{ cid:CID, bytes:Uint8Array }` pair.\n   * @returns {CarBufferWriter}\n   */\n  write (block) {\n    addBlock(this, block)\n    return this\n  }\n\n  /**\n   * Finalize the CAR and return it as a `Uint8Array`.\n   *\n   * @param {object} [options]\n   * @param {boolean} [options.resize]\n   * @returns {Uint8Array}\n   */\n  close (options) {\n    return close(this, options)\n  }\n}\n\n/**\n * @param {CarBufferWriter} writer\n * @param {CID} root\n * @param {{resize?:boolean}} [options]\n */\nexport const addRoot = (writer, root, options = {}) => {\n  const { resize = false } = options\n  const { bytes, headerSize, byteOffset, roots } = writer\n  writer.roots.push(root)\n  const size = headerLength(writer)\n  // If there is not enough space for the new root\n  if (size > headerSize) {\n    // Check if we root would fit if we were to resize the head.\n    if (size - headerSize + byteOffset < bytes.byteLength) {\n      // If resize is enabled resize head\n      if (resize) {\n        resizeHeader(writer, size)\n      // otherwise remove head and throw an error suggesting to resize\n      } else {\n        roots.pop()\n        throw new RangeError(`Header of size ${headerSize} has no capacity for new root ${root}.\n  However there is a space in the buffer and you could call addRoot(root, { resize: root }) to resize header to make a space for this root.`)\n      }\n    // If head would not fit even with resize pop new root and throw error\n    } else {\n      roots.pop()\n      throw new RangeError(`Buffer has no capacity for a new root ${root}`)\n    }\n  }\n}\n\n/**\n * Calculates number of bytes required for storing given block in CAR. Useful in\n * estimating size of an `ArrayBuffer` for the `CarBufferWriter`.\n *\n * @name CarBufferWriter.blockLength(Block)\n * @param {Block} block\n * @returns {number}\n */\nexport const blockLength = ({ cid, bytes }) => {\n  const size = cid.bytes.byteLength + bytes.byteLength\n  return varint.encodingLength(size) + size\n}\n\n/**\n * @param {CarBufferWriter} writer\n * @param {Block} block\n */\nexport const addBlock = (writer, { cid, bytes }) => {\n  const byteLength = cid.bytes.byteLength + bytes.byteLength\n  const size = varint.encode(byteLength)\n  if (writer.byteOffset + size.length + byteLength > writer.bytes.byteLength) {\n    throw new RangeError('Buffer has no capacity for this block')\n  } else {\n    writeBytes(writer, size)\n    writeBytes(writer, cid.bytes)\n    writeBytes(writer, bytes)\n  }\n}\n\n/**\n * @param {CarBufferWriter} writer\n * @param {object} [options]\n * @param {boolean} [options.resize]\n */\nexport const close = (writer, options = {}) => {\n  const { resize = false } = options\n  const { roots, bytes, byteOffset, headerSize } = writer\n\n  const headerBytes = CBOR.encode({ version: 1, roots })\n  const varintBytes = varint.encode(headerBytes.length)\n\n  const size = varintBytes.length + headerBytes.byteLength\n  const offset = headerSize - size\n\n  // If header size estimate was accurate we just write header and return\n  // view into buffer.\n  if (offset === 0) {\n    writeHeader(writer, varintBytes, headerBytes)\n    return bytes.subarray(0, byteOffset)\n    // If header was overestimated and `{resize: true}` is passed resize header\n  } else if (resize) {\n    resizeHeader(writer, size)\n    writeHeader(writer, varintBytes, headerBytes)\n    return bytes.subarray(0, writer.byteOffset)\n  } else {\n    throw new RangeError(`Header size was overestimated.\nYou can use close({ resize: true }) to resize header`)\n  }\n}\n\n/**\n * @param {CarBufferWriter} writer\n * @param {number} byteLength\n */\nexport const resizeHeader = (writer, byteLength) => {\n  const { bytes, headerSize } = writer\n  // Move data section to a new offset\n  bytes.set(bytes.subarray(headerSize, writer.byteOffset), byteLength)\n  // Update header size & byteOffset\n  writer.byteOffset += byteLength - headerSize\n  writer.headerSize = byteLength\n}\n\n/**\n * @param {CarBufferWriter} writer\n * @param {number[]|Uint8Array} bytes\n */\n\nconst writeBytes = (writer, bytes) => {\n  writer.bytes.set(bytes, writer.byteOffset)\n  writer.byteOffset += bytes.length\n}\n/**\n * @param {{bytes:Uint8Array}} writer\n * @param {number[]} varint\n * @param {Uint8Array} header\n */\nconst writeHeader = ({ bytes }, varint, header) => {\n  bytes.set(varint)\n  bytes.set(header, varint.length)\n}\n\nconst headerPreludeTokens = [\n  new Token(Type.map, 2),\n  new Token(Type.string, 'version'),\n  new Token(Type.uint, 1),\n  new Token(Type.string, 'roots')\n]\n\nconst CID_TAG = new Token(Type.tag, 42)\n\n/**\n * Calculates header size given the array of byteLength for roots.\n *\n * @name CarBufferWriter.calculateHeaderLength(rootLengths)\n * @param {number[]} rootLengths\n * @returns {number}\n */\nexport const calculateHeaderLength = (rootLengths) => {\n  const tokens = [...headerPreludeTokens]\n  tokens.push(new Token(Type.array, rootLengths.length))\n  for (const rootLength of rootLengths) {\n    tokens.push(CID_TAG)\n    tokens.push(new Token(Type.bytes, { length: rootLength + 1 }))\n  }\n  const length = tokensToLength(tokens) // no options needed here because we have simple tokens\n  return varint.encodingLength(length) + length\n}\n\n/**\n * Calculates header size given the array of roots.\n *\n * @name CarBufferWriter.headerLength({ roots })\n * @param {object} options\n * @param {CID[]} options.roots\n * @returns {number}\n */\nexport const headerLength = ({ roots }) =>\n  calculateHeaderLength(roots.map(cid => cid.bytes.byteLength))\n\n/**\n * Estimates header size given a count of the roots and the expected byte length\n * of the root CIDs. The default length works for a standard CIDv1 with a\n * single-byte multihash code, such as SHA2-256 (i.e. the most common CIDv1).\n *\n * @name CarBufferWriter.estimateHeaderLength(rootCount[, rootByteLength])\n * @param {number} rootCount\n * @param {number} [rootByteLength]\n * @returns {number}\n */\nexport const estimateHeaderLength = (rootCount, rootByteLength = 36) =>\n  calculateHeaderLength(new Array(rootCount).fill(rootByteLength))\n\n/**\n * Creates synchronous CAR writer that can be used to encode blocks into a given\n * buffer. Optionally you could pass `byteOffset` and `byteLength` to specify a\n * range inside buffer to write into. If car file is going to have `roots` you\n * need to either pass them under `options.roots` (from which header size will\n * be calculated) or provide `options.headerSize` to allocate required space\n * in the buffer. You may also provide known `roots` and `headerSize` to\n * allocate space for the roots that may not be known ahead of time.\n *\n * Note: Incorrect `headerSize` may lead to copying bytes inside a buffer\n * which will have a negative impact on performance.\n *\n * @name CarBufferWriter.createWriter(buffer[, options])\n * @param {ArrayBuffer} buffer\n * @param {object} [options]\n * @param {CID[]} [options.roots]\n * @param {number} [options.byteOffset]\n * @param {number} [options.byteLength]\n * @param {number} [options.headerSize]\n * @returns {CarBufferWriter}\n */\nexport const createWriter = (buffer, options = {}) => {\n  const {\n    roots = [],\n    byteOffset = 0,\n    byteLength = buffer.byteLength,\n    headerSize = headerLength({ roots })\n  } = options\n  const bytes = new Uint8Array(buffer, byteOffset, byteLength)\n\n  const writer = new CarBufferWriter(bytes, headerSize)\n  for (const root of roots) {\n    writer.addRoot(root)\n  }\n\n  return writer\n}\n","import { decode as decodeDagCbor } from '@ipld/dag-cbor'\nimport { CID } from 'multiformats/cid'\nimport * as Digest from 'multiformats/hashes/digest'\nimport { CIDV0_BYTES, decodeV2Header, decodeVarint, getMultihashLength, V2_HEADER_LENGTH } from './decoder-common.js'\nimport { CarV1HeaderOrV2Pragma } from './header-validator.js'\n\n/**\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').BlockHeader} BlockHeader\n * @typedef {import('./api').BlockIndex} BlockIndex\n * @typedef {import('./coding').BytesReader} BytesReader\n * @typedef {import('./coding').CarHeader} CarHeader\n * @typedef {import('./coding').CarV2Header} CarV2Header\n * @typedef {import('./coding').CarV2FixedHeader} CarV2FixedHeader\n * @typedef {import('./coding').CarDecoder} CarDecoder\n */\n\n/**\n * Reads header data from a `BytesReader`. The header may either be in the form\n * of a `CarHeader` or `CarV2Header` depending on the CAR being read.\n *\n * @name async decoder.readHeader(reader)\n * @param {BytesReader} reader\n * @param {number} [strictVersion]\n * @returns {Promise<CarHeader|CarV2Header>}\n */\nexport async function readHeader (reader, strictVersion) {\n  const length = decodeVarint(await reader.upTo(8), reader)\n  if (length === 0) {\n    throw new Error('Invalid CAR header (zero length)')\n  }\n  const header = await reader.exactly(length, true)\n  const block = decodeDagCbor(header)\n  if (CarV1HeaderOrV2Pragma.toTyped(block) === undefined) {\n    throw new Error('Invalid CAR header format')\n  }\n  if ((block.version !== 1 && block.version !== 2) || (strictVersion !== undefined && block.version !== strictVersion)) {\n    throw new Error(`Invalid CAR version: ${block.version}${strictVersion !== undefined ? ` (expected ${strictVersion})` : ''}`)\n  }\n  if (block.version === 1) {\n    // CarV1HeaderOrV2Pragma makes roots optional, let's make it mandatory\n    if (!Array.isArray(block.roots)) {\n      throw new Error('Invalid CAR header format')\n    }\n    return block\n  }\n  // version 2\n  if (block.roots !== undefined) {\n    throw new Error('Invalid CAR header format')\n  }\n  const v2Header = decodeV2Header(await reader.exactly(V2_HEADER_LENGTH, true))\n  reader.seek(v2Header.dataOffset - reader.pos)\n  const v1Header = await readHeader(reader, 1)\n  return Object.assign(v1Header, v2Header)\n}\n\n/**\n * @param {BytesReader} reader\n * @returns {Promise<CID>}\n */\nasync function readCid (reader) {\n  const first = await reader.exactly(2, false)\n  if (first[0] === CIDV0_BYTES.SHA2_256 && first[1] === CIDV0_BYTES.LENGTH) {\n    // cidv0 32-byte sha2-256\n    const bytes = await reader.exactly(34, true)\n    const multihash = Digest.decode(bytes)\n    return CID.create(0, CIDV0_BYTES.DAG_PB, multihash)\n  }\n\n  const version = decodeVarint(await reader.upTo(8), reader)\n  if (version !== 1) {\n    throw new Error(`Unexpected CID version (${version})`)\n  }\n  const codec = decodeVarint(await reader.upTo(8), reader)\n  const bytes = await reader.exactly(getMultihashLength(await reader.upTo(8)), true)\n  const multihash = Digest.decode(bytes)\n  return CID.create(version, codec, multihash)\n}\n\n/**\n * Reads the leading data of an individual block from CAR data from a\n * `BytesReader`. Returns a `BlockHeader` object which contains\n * `{ cid, length, blockLength }` which can be used to either index the block\n * or read the block binary data.\n *\n * @name async decoder.readBlockHead(reader)\n * @param {BytesReader} reader\n * @returns {Promise<BlockHeader>}\n */\nexport async function readBlockHead (reader) {\n  // length includes a CID + Binary, where CID has a variable length\n  // we have to deal with\n  const start = reader.pos\n  let length = decodeVarint(await reader.upTo(8), reader)\n  if (length === 0) {\n    throw new Error('Invalid CAR section (zero length)')\n  }\n  length += (reader.pos - start)\n  const cid = await readCid(reader)\n  const blockLength = length - Number(reader.pos - start) // subtract CID length\n\n  return { cid, length, blockLength }\n}\n\n/**\n * @param {BytesReader} reader\n * @returns {Promise<Block>}\n */\nasync function readBlock (reader) {\n  const { cid, blockLength } = await readBlockHead(reader)\n  const bytes = await reader.exactly(blockLength, true)\n  return { bytes, cid }\n}\n\n/**\n * @param {BytesReader} reader\n * @returns {Promise<BlockIndex>}\n */\nasync function readBlockIndex (reader) {\n  const offset = reader.pos\n  const { cid, length, blockLength } = await readBlockHead(reader)\n  const index = { cid, length, blockLength, offset, blockOffset: reader.pos }\n  reader.seek(index.blockLength)\n  return index\n}\n\n/**\n * Creates a `CarDecoder` from a `BytesReader`. The `CarDecoder` is as async\n * interface that will consume the bytes from the `BytesReader` to yield a\n * `header()` and either `blocks()` or `blocksIndex()` data.\n *\n * @name decoder.createDecoder(reader)\n * @param {BytesReader} reader\n * @returns {CarDecoder}\n */\nexport function createDecoder (reader) {\n  const headerPromise = (async () => {\n    const header = await readHeader(reader)\n    if (header.version === 2) {\n      const v1length = reader.pos - header.dataOffset\n      reader = limitReader(reader, header.dataSize - v1length)\n    }\n    return header\n  })()\n\n  return {\n    header: () => headerPromise,\n\n    async * blocks () {\n      await headerPromise\n      while ((await reader.upTo(8)).length > 0) {\n        yield await readBlock(reader)\n      }\n    },\n\n    async * blocksIndex () {\n      await headerPromise\n      while ((await reader.upTo(8)).length > 0) {\n        yield await readBlockIndex(reader)\n      }\n    }\n  }\n}\n\n/**\n * Creates a `BytesReader` from a `Uint8Array`.\n *\n * @name decoder.bytesReader(bytes)\n * @param {Uint8Array} bytes\n * @returns {BytesReader}\n */\nexport function bytesReader (bytes) {\n  let pos = 0\n\n  /** @type {BytesReader} */\n  return {\n    async upTo (length) {\n      const out = bytes.subarray(pos, pos + Math.min(length, bytes.length - pos))\n      return out\n    },\n\n    async exactly (length, seek = false) {\n      if (length > bytes.length - pos) {\n        throw new Error('Unexpected end of data')\n      }\n      const out = bytes.subarray(pos, pos + length)\n      if (seek) {\n        pos += length\n      }\n      return out\n    },\n\n    seek (length) {\n      pos += length\n    },\n\n    get pos () {\n      return pos\n    }\n  }\n}\n\n/**\n * @ignore\n * reusable reader for streams and files, we just need a way to read an\n * additional chunk (of some undetermined size) and a way to close the\n * reader when finished\n * @param {() => Promise<Uint8Array|null>} readChunk\n * @returns {BytesReader}\n */\nexport function chunkReader (readChunk /*, closer */) {\n  let pos = 0\n  let have = 0\n  let offset = 0\n  let currentChunk = new Uint8Array(0)\n\n  const read = async (/** @type {number} */ length) => {\n    have = currentChunk.length - offset\n    const bufa = [currentChunk.subarray(offset)]\n    while (have < length) {\n      const chunk = await readChunk()\n      if (chunk == null) {\n        break\n      }\n      /* c8 ignore next 8 */\n      // undo this ignore ^ when we have a fd implementation that can seek()\n      if (have < 0) { // because of a seek()\n        /* c8 ignore next 4 */\n        // toohard to test the else\n        if (chunk.length > have) {\n          bufa.push(chunk.subarray(-have))\n        } // else discard\n      } else {\n        bufa.push(chunk)\n      }\n      have += chunk.length\n    }\n    currentChunk = new Uint8Array(bufa.reduce((p, c) => p + c.length, 0))\n    let off = 0\n    for (const b of bufa) {\n      currentChunk.set(b, off)\n      off += b.length\n    }\n    offset = 0\n  }\n\n  /** @type {BytesReader} */\n  return {\n    async upTo (length) {\n      if (currentChunk.length - offset < length) {\n        await read(length)\n      }\n      return currentChunk.subarray(offset, offset + Math.min(currentChunk.length - offset, length))\n    },\n\n    async exactly (length, seek = false) {\n      if (currentChunk.length - offset < length) {\n        await read(length)\n      }\n      if (currentChunk.length - offset < length) {\n        throw new Error('Unexpected end of data')\n      }\n      const out = currentChunk.subarray(offset, offset + length)\n      if (seek) {\n        pos += length\n        offset += length\n      }\n      return out\n    },\n\n    seek (length) {\n      pos += length\n      offset += length\n    },\n\n    get pos () {\n      return pos\n    }\n  }\n}\n\n/**\n * Creates a `BytesReader` from an `AsyncIterable<Uint8Array>`, which allows for\n * consumption of CAR data from a streaming source.\n *\n * @name decoder.asyncIterableReader(asyncIterable)\n * @param {AsyncIterable<Uint8Array>} asyncIterable\n * @returns {BytesReader}\n */\nexport function asyncIterableReader (asyncIterable) {\n  const iterator = asyncIterable[Symbol.asyncIterator]()\n\n  async function readChunk () {\n    const next = await iterator.next()\n    if (next.done) {\n      return null\n    }\n    return next.value\n  }\n\n  return chunkReader(readChunk)\n}\n\n/**\n * Wraps a `BytesReader` in a limiting `BytesReader` which limits maximum read\n * to `byteLimit` bytes. It _does not_ update `pos` of the original\n * `BytesReader`.\n *\n * @name decoder.limitReader(reader, byteLimit)\n * @param {BytesReader} reader\n * @param {number} byteLimit\n * @returns {BytesReader}\n */\nexport function limitReader (reader, byteLimit) {\n  let bytesRead = 0\n\n  /** @type {BytesReader} */\n  return {\n    async upTo (length) {\n      let bytes = await reader.upTo(length)\n      if (bytes.length + bytesRead > byteLimit) {\n        bytes = bytes.subarray(0, byteLimit - bytesRead)\n      }\n      return bytes\n    },\n\n    async exactly (length, seek = false) {\n      const bytes = await reader.exactly(length, seek)\n      if (bytes.length + bytesRead > byteLimit) {\n        throw new Error('Unexpected end of data')\n      }\n      if (seek) {\n        bytesRead += length\n      }\n      return bytes\n    },\n\n    seek (length) {\n      bytesRead += length\n      reader.seek(length)\n    },\n\n    get pos () {\n      return reader.pos\n    }\n  }\n}\n","import {\n  asyncIterableReader,\n  bytesReader,\n  createDecoder\n} from './decoder.js'\n\n/**\n * @typedef {import('multiformats').CID} CID\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').RootsReader} RootsReader\n * @typedef {import('./api').BlockIndex} BlockIndex\n * @typedef {import('./coding').BytesReader} BytesReader\n */\n\n/**\n * Provides an iterator over all of the `Block`s in a CAR, returning their CIDs\n * and byte-location information. Implements an `AsyncIterable<BlockIndex>`.\n * Where a `BlockIndex` is a\n * `{ cid:CID, length:number, offset:number, blockLength:number, blockOffset:number }`.\n *\n * As an implementer of `AsyncIterable`, this class can be used directly in a\n * `for await (const blockIndex of iterator) {}` loop. Where the `iterator` is\n * constructed using {@link CarIndexer.fromBytes} or\n * {@link CarIndexer.fromIterable}.\n *\n * An iteration can only be performce _once_ per instantiation.\n *\n * `CarIndexer` also implements the `RootsReader` interface and provides\n * the {@link CarIndexer.getRoots `getRoots()`} method.\n *\n * Load this class with either\n * `import { CarIndexer } from '@ipld/car/indexer'`\n * (`const { CarIndexer } = require('@ipld/car/indexer')`). Or\n * `import { CarIndexer } from '@ipld/car'`\n * (`const { CarIndexer } = require('@ipld/car')`). The former will likely\n * result in smaller bundle sizes where this is important.\n *\n * @name CarIndexer\n * @class\n * @implements {RootsReader}\n * @implements {AsyncIterable<BlockIndex>}\n * @property {number} version The version number of the CAR referenced by this\n * reader (should be `1`).\n */\nexport class CarIndexer {\n  /**\n   * @param {number} version\n   * @param {CID[]} roots\n   * @param {AsyncGenerator<BlockIndex>} iterator\n   */\n  constructor (version, roots, iterator) {\n    this._version = version\n    this._roots = roots\n    this._iterator = iterator\n  }\n\n  get version () {\n    return this._version\n  }\n\n  /**\n   * Get the list of roots defined by the CAR referenced by this indexer. May be\n   * zero or more `CID`s.\n   *\n   * @function\n   * @memberof CarIndexer\n   * @instance\n   * @async\n   * @returns {Promise<CID[]>}\n   */\n  async getRoots () {\n    return this._roots\n  }\n\n  /**\n   * @returns {AsyncIterator<BlockIndex>}\n   */\n  [Symbol.asyncIterator] () {\n    return this._iterator\n  }\n\n  /**\n   * Instantiate a {@link CarIndexer} from a `Uint8Array` blob. Only the header\n   * is decoded initially, the remainder is processed and emitted via the\n   * iterator as it is consumed.\n   *\n   * @async\n   * @static\n   * @memberof CarIndexer\n   * @param {Uint8Array} bytes\n   * @returns {Promise<CarIndexer>}\n   */\n  static async fromBytes (bytes) {\n    if (!(bytes instanceof Uint8Array)) {\n      throw new TypeError('fromBytes() requires a Uint8Array')\n    }\n    return decodeIndexerComplete(bytesReader(bytes))\n  }\n\n  /**\n   * Instantiate a {@link CarIndexer} from a `AsyncIterable<Uint8Array>`,\n   * such as a [modern Node.js stream](https://nodejs.org/api/stream.html#stream_streams_compatibility_with_async_generators_and_async_iterators).\n   * is decoded initially, the remainder is processed and emitted via the\n   * iterator as it is consumed.\n   *\n   * @async\n   * @static\n   * @memberof CarIndexer\n   * @param {AsyncIterable<Uint8Array>} asyncIterable\n   * @returns {Promise<CarIndexer>}\n   */\n  static async fromIterable (asyncIterable) {\n    if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n      throw new TypeError('fromIterable() requires an async iterable')\n    }\n    return decodeIndexerComplete(asyncIterableReader(asyncIterable))\n  }\n}\n\n/**\n * @private\n * @param {BytesReader} reader\n * @returns {Promise<CarIndexer>}\n */\nasync function decodeIndexerComplete (reader) {\n  const decoder = createDecoder(reader)\n  const { version, roots } = await decoder.header()\n\n  return new CarIndexer(version, roots, decoder.blocksIndex())\n}\n","import {\n  asyncIterableReader,\n  bytesReader,\n  createDecoder\n} from './decoder.js'\n\n/**\n * @typedef {import('multiformats').CID} CID\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').RootsReader} RootsReader\n * @typedef {import('./coding').BytesReader} BytesReader\n */\n\n/**\n * @class\n * @implements {RootsReader}\n * @property {number} version The version number of the CAR referenced by this reader (should be `1`).\n */\nexport class CarIteratorBase {\n  /**\n   * @param {number} version\n   * @param {CID[]} roots\n   * @param {AsyncIterable<Block>|void} iterable\n   */\n  constructor (version, roots, iterable) {\n    this._version = version\n    this._roots = roots\n    this._iterable = iterable\n    this._decoded = false\n  }\n\n  get version () {\n    return this._version\n  }\n\n  /**\n   * @returns {Promise<CID[]>}\n   */\n  async getRoots () {\n    return this._roots\n  }\n}\n\n/**\n * Provides an iterator over all of the `Block`s in a CAR. Implements a\n * `BlockIterator` interface, or `AsyncIterable<Block>`. Where a `Block` is\n * a `{ cid:CID, bytes:Uint8Array }` pair.\n *\n * As an implementer of `AsyncIterable`, this class can be used directly in a\n * `for await (const block of iterator) {}` loop. Where the `iterator` is\n * constructed using {@link CarBlockiterator.fromBytes} or\n * {@link CarBlockiterator.fromIterable}.\n *\n * An iteration can only be performce _once_ per instantiation.\n *\n * `CarBlockIterator` also implements the `RootsReader` interface and provides\n * the {@link CarBlockiterator.getRoots `getRoots()`} method.\n *\n * Load this class with either\n * `import { CarBlockIterator } from '@ipld/car/iterator'`\n * (`const { CarBlockIterator } = require('@ipld/car/iterator')`). Or\n * `import { CarBlockIterator } from '@ipld/car'`\n * (`const { CarBlockIterator } = require('@ipld/car')`).\n *\n * @name CarBlockIterator\n * @class\n * @implements {RootsReader}\n * @implements {AsyncIterable<Block>}\n * @property {number} version The version number of the CAR referenced by this\n * iterator (should be `1`).\n */\nexport class CarBlockIterator extends CarIteratorBase {\n  // inherited method\n  /**\n   * Get the list of roots defined by the CAR referenced by this iterator. May be\n   * zero or more `CID`s.\n   *\n   * @function getRoots\n   * @memberof CarBlockIterator\n   * @instance\n   * @async\n   * @returns {Promise<CID[]>}\n   */\n\n  /**\n   * @returns {AsyncIterator<Block>}\n   */\n  [Symbol.asyncIterator] () {\n    if (this._decoded) {\n      throw new Error('Cannot decode more than once')\n    }\n    /* c8 ignore next 3 */\n    if (!this._iterable) {\n      throw new Error('Block iterable not found')\n    }\n    this._decoded = true\n    return this._iterable[Symbol.asyncIterator]()\n  }\n\n  /**\n   * Instantiate a {@link CarBlockIterator} from a `Uint8Array` blob. Rather\n   * than decoding the entire byte array prior to returning the iterator, as in\n   * {@link CarReader.fromBytes}, only the header is decoded and the remainder\n   * of the CAR is parsed as the `Block`s as yielded.\n   *\n   * @async\n   * @static\n   * @memberof CarBlockIterator\n   * @param {Uint8Array} bytes\n   * @returns {Promise<CarBlockIterator>}\n   */\n  static async fromBytes (bytes) {\n    const { version, roots, iterator } = await fromBytes(bytes)\n    return new CarBlockIterator(version, roots, iterator)\n  }\n\n  /**\n   * Instantiate a {@link CarBlockIterator} from a `AsyncIterable<Uint8Array>`,\n   * such as a [modern Node.js stream](https://nodejs.org/api/stream.html#stream_streams_compatibility_with_async_generators_and_async_iterators).\n   * Rather than decoding the entire byte array prior to returning the iterator,\n   * as in {@link CarReader.fromIterable}, only the header is decoded and the\n   * remainder of the CAR is parsed as the `Block`s as yielded.\n   *\n   * @async\n   * @static\n   * @param {AsyncIterable<Uint8Array>} asyncIterable\n   * @returns {Promise<CarBlockIterator>}\n   */\n  static async fromIterable (asyncIterable) {\n    const { version, roots, iterator } = await fromIterable(asyncIterable)\n    return new CarBlockIterator(version, roots, iterator)\n  }\n}\n\n/**\n * Provides an iterator over all of the `CID`s in a CAR. Implements a\n * `CIDIterator` interface, or `AsyncIterable<CID>`. Similar to\n * {@link CarBlockIterator} but only yields the CIDs in the CAR.\n *\n * As an implementer of `AsyncIterable`, this class can be used directly in a\n * `for await (const cid of iterator) {}` loop. Where the `iterator` is\n * constructed using {@link CarCIDiterator.fromBytes} or\n * {@link CarCIDiterator.fromIterable}.\n *\n * An iteration can only be performce _once_ per instantiation.\n *\n * `CarCIDIterator` also implements the `RootsReader` interface and provides\n * the {@link CarCIDiterator.getRoots `getRoots()`} method.\n *\n * Load this class with either\n * `import { CarCIDIterator } from '@ipld/car/iterator'`\n * (`const { CarCIDIterator } = require('@ipld/car/iterator')`). Or\n * `import { CarCIDIterator } from '@ipld/car'`\n * (`const { CarCIDIterator } = require('@ipld/car')`).\n *\n * @name CarCIDIterator\n * @class\n * @implements {RootsReader}\n * @implements {AsyncIterable<CID>}\n * @property {number} version The version number of the CAR referenced by this\n * iterator (should be `1`).\n */\nexport class CarCIDIterator extends CarIteratorBase {\n  // inherited method\n  /**\n   * Get the list of roots defined by the CAR referenced by this iterator. May be\n   * zero or more `CID`s.\n   *\n   * @function getRoots\n   * @memberof CarCIDIterator\n   * @instance\n   * @async\n   * @returns {Promise<CID[]>}\n   */\n\n  /**\n   * @returns {AsyncIterator<CID>}\n   */\n  [Symbol.asyncIterator] () {\n    if (this._decoded) {\n      throw new Error('Cannot decode more than once')\n    }\n    /* c8 ignore next 3 */\n    if (!this._iterable) {\n      throw new Error('Block iterable not found')\n    }\n    this._decoded = true\n    const iterable = this._iterable[Symbol.asyncIterator]()\n    return {\n      async next () {\n        const next = await iterable.next()\n        if (next.done) {\n          return next\n        }\n        return { done: false, value: next.value.cid }\n      }\n    }\n  }\n\n  /**\n   * Instantiate a {@link CarCIDIterator} from a `Uint8Array` blob. Rather\n   * than decoding the entire byte array prior to returning the iterator, as in\n   * {@link CarReader.fromBytes}, only the header is decoded and the remainder\n   * of the CAR is parsed as the `CID`s as yielded.\n   *\n   * @async\n   * @static\n   * @memberof CarCIDIterator\n   * @param {Uint8Array} bytes\n   * @returns {Promise<CarCIDIterator>}\n   */\n  static async fromBytes (bytes) {\n    const { version, roots, iterator } = await fromBytes(bytes)\n    return new CarCIDIterator(version, roots, iterator)\n  }\n\n  /**\n   * Instantiate a {@link CarCIDIterator} from a `AsyncIterable<Uint8Array>`,\n   * such as a [modern Node.js stream](https://nodejs.org/api/stream.html#stream_streams_compatibility_with_async_generators_and_async_iterators).\n   * Rather than decoding the entire byte array prior to returning the iterator,\n   * as in {@link CarReader.fromIterable}, only the header is decoded and the\n   * remainder of the CAR is parsed as the `CID`s as yielded.\n   *\n   * @async\n   * @static\n   * @memberof CarCIDIterator\n   * @param {AsyncIterable<Uint8Array>} asyncIterable\n   * @returns {Promise<CarCIDIterator>}\n   */\n  static async fromIterable (asyncIterable) {\n    const { version, roots, iterator } = await fromIterable(asyncIterable)\n    return new CarCIDIterator(version, roots, iterator)\n  }\n}\n\n/**\n * @param {Uint8Array} bytes\n * @returns {Promise<{ version:number, roots:CID[], iterator:AsyncIterable<Block>}>}\n */\nasync function fromBytes (bytes) {\n  if (!(bytes instanceof Uint8Array)) {\n    throw new TypeError('fromBytes() requires a Uint8Array')\n  }\n  return decodeIterator(bytesReader(bytes))\n}\n\n/**\n * @param {AsyncIterable<Uint8Array>} asyncIterable\n * @returns {Promise<{ version:number, roots:CID[], iterator:AsyncIterable<Block>}>}\n */\nasync function fromIterable (asyncIterable) {\n  if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n    throw new TypeError('fromIterable() requires an async iterable')\n  }\n  return decodeIterator(asyncIterableReader(asyncIterable))\n}\n\n/**\n * @private\n * @param {BytesReader} reader\n * @returns {Promise<{ version:number, roots:CID[], iterator:AsyncIterable<Block>}>}\n */\nasync function decodeIterator (reader) {\n  const decoder = createDecoder(reader)\n  const { version, roots } = await decoder.header()\n  return { version, roots, iterator: decoder.blocks() }\n}\n","import { asyncIterableReader, bytesReader, createDecoder } from './decoder.js'\n\n/**\n * @typedef {import('multiformats').CID} CID\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').CarReader} CarReaderIface\n * @typedef {import('./coding').BytesReader} BytesReader\n * @typedef {import('./coding').CarHeader} CarHeader\n * @typedef {import('./coding').CarV2Header} CarV2Header\n */\n\n/**\n * Provides blockstore-like access to a CAR.\n *\n * Implements the `RootsReader` interface:\n * {@link CarReader.getRoots `getRoots()`}. And the `BlockReader` interface:\n * {@link CarReader.get `get()`}, {@link CarReader.has `has()`},\n * {@link CarReader.blocks `blocks()`} (defined as a `BlockIterator`) and\n * {@link CarReader.cids `cids()`} (defined as a `CIDIterator`).\n *\n * Load this class with either `import { CarReader } from '@ipld/car/reader'`\n * (`const { CarReader } = require('@ipld/car/reader')`). Or\n * `import { CarReader } from '@ipld/car'` (`const { CarReader } = require('@ipld/car')`).\n * The former will likely result in smaller bundle sizes where this is\n * important.\n *\n * @name CarReader\n * @class\n * @implements {CarReaderIface}\n * @property {number} version The version number of the CAR referenced by this\n * reader (should be `1` or `2`).\n */\nexport class CarReader {\n  /**\n   * @constructs CarReader\n   * @param {CarHeader|CarV2Header} header\n   * @param {Block[]} blocks\n   */\n  constructor (header, blocks) {\n    this._header = header\n    this._blocks = blocks\n    this._keys = blocks.map((b) => b.cid.toString())\n  }\n\n  /**\n   * @property\n   * @memberof CarReader\n   * @instance\n   */\n  get version () {\n    return this._header.version\n  }\n\n  /**\n   * Get the list of roots defined by the CAR referenced by this reader. May be\n   * zero or more `CID`s.\n   *\n   * @function\n   * @memberof CarReader\n   * @instance\n   * @async\n   * @returns {Promise<CID[]>}\n   */\n  async getRoots () {\n    return this._header.roots\n  }\n\n  /**\n   * Check whether a given `CID` exists within the CAR referenced by this\n   * reader.\n   *\n   * @function\n   * @memberof CarReader\n   * @instance\n   * @async\n   * @param {CID} key\n   * @returns {Promise<boolean>}\n   */\n  async has (key) {\n    return this._keys.indexOf(key.toString()) > -1\n  }\n\n  /**\n   * Fetch a `Block` (a `{ cid:CID, bytes:Uint8Array }` pair) from the CAR\n   * referenced by this reader matching the provided `CID`. In the case where\n   * the provided `CID` doesn't exist within the CAR, `undefined` will be\n   * returned.\n   *\n   * @function\n   * @memberof CarReader\n   * @instance\n   * @async\n   * @param {CID} key\n   * @returns {Promise<Block | undefined>}\n   */\n  async get (key) {\n    const index = this._keys.indexOf(key.toString())\n    return index > -1 ? this._blocks[index] : undefined\n  }\n\n  /**\n   * Returns a `BlockIterator` (`AsyncIterable<Block>`) that iterates over all\n   * of the `Block`s (`{ cid:CID, bytes:Uint8Array }` pairs) contained within\n   * the CAR referenced by this reader.\n   *\n   * @function\n   * @memberof CarReader\n   * @instance\n   * @async\n   * @generator\n   * @returns {AsyncGenerator<Block>}\n   */\n  async * blocks () {\n    for (const block of this._blocks) {\n      yield block\n    }\n  }\n\n  /**\n   * Returns a `CIDIterator` (`AsyncIterable<CID>`) that iterates over all of\n   * the `CID`s contained within the CAR referenced by this reader.\n   *\n   * @function\n   * @memberof CarReader\n   * @instance\n   * @async\n   * @generator\n   * @returns {AsyncGenerator<CID>}\n   */\n  async * cids () {\n    for (const block of this._blocks) {\n      yield block.cid\n    }\n  }\n\n  /**\n   * Instantiate a {@link CarReader} from a `Uint8Array` blob. This performs a\n   * decode fully in memory and maintains the decoded state in memory for full\n   * access to the data via the `CarReader` API.\n   *\n   * @async\n   * @static\n   * @memberof CarReader\n   * @param {Uint8Array} bytes\n   * @returns {Promise<CarReader>}\n   */\n  static async fromBytes (bytes) {\n    if (!(bytes instanceof Uint8Array)) {\n      throw new TypeError('fromBytes() requires a Uint8Array')\n    }\n    return decodeReaderComplete(bytesReader(bytes))\n  }\n\n  /**\n   * Instantiate a {@link CarReader} from a `AsyncIterable<Uint8Array>`, such as\n   * a [modern Node.js stream](https://nodejs.org/api/stream.html#stream_streams_compatibility_with_async_generators_and_async_iterators).\n   * This performs a decode fully in memory and maintains the decoded state in\n   * memory for full access to the data via the `CarReader` API.\n   *\n   * Care should be taken for large archives; this API may not be appropriate\n   * where memory is a concern or the archive is potentially larger than the\n   * amount of memory that the runtime can handle.\n   *\n   * @async\n   * @static\n   * @memberof CarReader\n   * @param {AsyncIterable<Uint8Array>} asyncIterable\n   * @returns {Promise<CarReader>}\n   */\n  static async fromIterable (asyncIterable) {\n    if (!asyncIterable || !(typeof asyncIterable[Symbol.asyncIterator] === 'function')) {\n      throw new TypeError('fromIterable() requires an async iterable')\n    }\n    return decodeReaderComplete(asyncIterableReader(asyncIterable))\n  }\n}\n\n/**\n * @private\n * @param {BytesReader} reader\n * @returns {Promise<CarReader>}\n */\nexport async function decodeReaderComplete (reader) {\n  const decoder = createDecoder(reader)\n  const header = await decoder.header()\n  const blocks = []\n  for await (const block of decoder.blocks()) {\n    blocks.push(block)\n  }\n\n  return new CarReader(header, blocks)\n}\n\nexport const __browser = true\n","import { encode as dagCborEncode } from '@ipld/dag-cbor'\nimport varint from 'varint'\n\n/**\n * @typedef {import('multiformats').CID} CID\n * @typedef {import('./api').Block} Block\n * @typedef {import('./coding').CarEncoder} CarEncoder\n * @typedef {import('./coding').IteratorChannel_Writer<Uint8Array>} IteratorChannel_Writer\n */\n\nconst CAR_V1_VERSION = 1\n\n/**\n * Create a header from an array of roots.\n *\n * @param {CID[]} roots\n * @returns {Uint8Array}\n */\nexport function createHeader (roots) {\n  const headerBytes = dagCborEncode({ version: CAR_V1_VERSION, roots })\n  const varintBytes = varint.encode(headerBytes.length)\n  const header = new Uint8Array(varintBytes.length + headerBytes.length)\n  header.set(varintBytes, 0)\n  header.set(headerBytes, varintBytes.length)\n  return header\n}\n\n/**\n * @param {IteratorChannel_Writer} writer\n * @returns {CarEncoder}\n */\nfunction createEncoder (writer) {\n  // none of this is wrapped in a mutex, that needs to happen above this to\n  // avoid overwrites\n\n  return {\n    /**\n     * @param {CID[]} roots\n     * @returns {Promise<void>}\n     */\n    async setRoots (roots) {\n      const bytes = createHeader(roots)\n      await writer.write(bytes)\n    },\n\n    /**\n     * @param {Block} block\n     * @returns {Promise<void>}\n     */\n    async writeBlock (block) {\n      const { cid, bytes } = block\n      await writer.write(new Uint8Array(varint.encode(cid.bytes.length + bytes.length)))\n      await writer.write(cid.bytes)\n      if (bytes.length) {\n        // zero-length blocks are valid, but it'd be safer if we didn't write them\n        await writer.write(bytes)\n      }\n    },\n\n    /**\n     * @returns {Promise<void>}\n     */\n    async close () {\n      await writer.end()\n    },\n\n    /**\n     * @returns {number}\n     */\n    version () {\n      return CAR_V1_VERSION\n    }\n  }\n}\n\nexport { createEncoder }\n","/**\n * @template {any} T\n * @typedef {import('./coding').IteratorChannel<T>} IteratorChannel\n */\n\nfunction noop () {}\n\n/**\n * @template {any} T\n * @returns {IteratorChannel<T>}\n */\nexport function create () {\n  /** @type {T[]} */\n  const chunkQueue = []\n  /** @type {Promise<void> | null} */\n  let drainer = null\n  let drainerResolver = noop\n  let ended = false\n  /** @type {Promise<IteratorResult<T>> | null} */\n  let outWait = null\n  let outWaitResolver = noop\n\n  const makeDrainer = () => {\n    if (!drainer) {\n      drainer = new Promise((resolve) => {\n        drainerResolver = () => {\n          drainer = null\n          drainerResolver = noop\n          resolve()\n        }\n      })\n    }\n    return drainer\n  }\n\n  /**\n   * @returns {IteratorChannel<T>}\n   */\n  const writer = {\n    /**\n     * @param {T} chunk\n     * @returns {Promise<void>}\n     */\n    write (chunk) {\n      chunkQueue.push(chunk)\n      const drainer = makeDrainer()\n      outWaitResolver()\n      return drainer\n    },\n\n    async end () {\n      ended = true\n      const drainer = makeDrainer()\n      outWaitResolver()\n      await drainer\n    }\n  }\n\n  /** @type {AsyncIterator<T>} */\n  const iterator = {\n    /** @returns {Promise<IteratorResult<T>>} */\n    async next () {\n      const chunk = chunkQueue.shift()\n      if (chunk) {\n        if (chunkQueue.length === 0) {\n          drainerResolver()\n        }\n        return { done: false, value: chunk }\n      }\n\n      if (ended) {\n        drainerResolver()\n        return { done: true, value: undefined }\n      }\n\n      if (!outWait) {\n        outWait = new Promise((resolve) => {\n          outWaitResolver = () => {\n            outWait = null\n            outWaitResolver = noop\n            return resolve(iterator.next())\n          }\n        })\n      }\n\n      return outWait\n    }\n  }\n\n  return { writer, iterator }\n}\n","import { CID } from 'multiformats/cid'\nimport { bytesReader, readHeader } from './decoder.js'\nimport { createEncoder, createHeader } from './encoder.js'\nimport { create as iteratorChannel } from './iterator-channel.js'\n\n/**\n * @typedef {import('./api').Block} Block\n * @typedef {import('./api').BlockWriter} BlockWriter\n * @typedef {import('./api').WriterChannel} WriterChannel\n * @typedef {import('./coding').CarEncoder} CarEncoder\n * @typedef {import('./coding').IteratorChannel<Uint8Array>} IteratorChannel\n */\n\n/**\n * Provides a writer interface for the creation of CAR files.\n *\n * Creation of a `CarWriter` involves the instatiation of an input / output pair\n * in the form of a `WriterChannel`, which is a\n * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }` pair. These two\n * components form what can be thought of as a stream-like interface. The\n * `writer` component (an instantiated `CarWriter`), has methods to\n * {@link CarWriter.put `put()`} new blocks and {@link CarWriter.put `close()`}\n * the writing operation (finalising the CAR archive). The `out` component is\n * an `AsyncIterable` that yields the bytes of the archive. This can be\n * redirected to a file or other sink. In Node.js, you can use the\n * [`Readable.from()`](https://nodejs.org/api/stream.html#stream_stream_readable_from_iterable_options)\n * API to convert this to a standard Node.js stream, or it can be directly fed\n * to a\n * [`stream.pipeline()`](https://nodejs.org/api/stream.html#stream_stream_pipeline_source_transforms_destination_callback).\n *\n * The channel will provide a form of backpressure. The `Promise` from a\n * `write()` won't resolve until the resulting data is drained from the `out`\n * iterable.\n *\n * It is also possible to ignore the `Promise` from `write()` calls and allow\n * the generated data to queue in memory. This should be avoided for large CAR\n * archives of course due to the memory costs and potential for memory overflow.\n *\n * Load this class with either\n * `import { CarWriter } from '@ipld/car/writer'`\n * (`const { CarWriter } = require('@ipld/car/writer')`). Or\n * `import { CarWriter } from '@ipld/car'`\n * (`const { CarWriter } = require('@ipld/car')`). The former will likely\n * result in smaller bundle sizes where this is important.\n *\n * @name CarWriter\n * @class\n * @implements {BlockWriter}\n */\nexport class CarWriter {\n  /**\n   * @param {CID[]} roots\n   * @param {CarEncoder} encoder\n   */\n  constructor (roots, encoder) {\n    this._encoder = encoder\n    /** @type {Promise<void>} */\n    this._mutex = encoder.setRoots(roots)\n    this._ended = false\n  }\n\n  /**\n   * Write a `Block` (a `{ cid:CID, bytes:Uint8Array }` pair) to the archive.\n   *\n   * @function\n   * @memberof CarWriter\n   * @instance\n   * @async\n   * @param {Block} block - A `{ cid:CID, bytes:Uint8Array }` pair.\n   * @returns {Promise<void>} The returned promise will only resolve once the\n   * bytes this block generates are written to the `out` iterable.\n   */\n  async put (block) {\n    if (!(block.bytes instanceof Uint8Array) || !block.cid) {\n      throw new TypeError('Can only write {cid, bytes} objects')\n    }\n    if (this._ended) {\n      throw new Error('Already closed')\n    }\n    const cid = CID.asCID(block.cid)\n    if (!cid) {\n      throw new TypeError('Can only write {cid, bytes} objects')\n    }\n    this._mutex = this._mutex.then(() => this._encoder.writeBlock({ cid, bytes: block.bytes }))\n    return this._mutex\n  }\n\n  /**\n   * Finalise the CAR archive and signal that the `out` iterable should end once\n   * any remaining bytes are written.\n   *\n   * @function\n   * @memberof CarWriter\n   * @instance\n   * @async\n   * @returns {Promise<void>}\n   */\n  async close () {\n    if (this._ended) {\n      throw new Error('Already closed')\n    }\n    await this._mutex\n    this._ended = true\n    return this._encoder.close()\n  }\n\n  /**\n   * Returns the version number of the CAR file being written\n   *\n   * @returns {number}\n   */\n  version () {\n    return this._encoder.version()\n  }\n\n  /**\n   * Create a new CAR writer \"channel\" which consists of a\n   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }` pair.\n   *\n   * @async\n   * @static\n   * @memberof CarWriter\n   * @param {CID[] | CID | void} roots\n   * @returns {WriterChannel} The channel takes the form of\n   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }`.\n   */\n  static create (roots) {\n    roots = toRoots(roots)\n    const { encoder, iterator } = encodeWriter()\n    const writer = new CarWriter(roots, encoder)\n    const out = new CarWriterOut(iterator)\n    return { writer, out }\n  }\n\n  /**\n   * Create a new CAR appender \"channel\" which consists of a\n   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }` pair.\n   * This appender does not consider roots and does not produce a CAR header.\n   * It is designed to append blocks to an _existing_ CAR archive. It is\n   * expected that `out` will be concatenated onto the end of an existing\n   * archive that already has a properly formatted header.\n   *\n   * @async\n   * @static\n   * @memberof CarWriter\n   * @returns {WriterChannel} The channel takes the form of\n   * `{ writer:CarWriter, out:AsyncIterable<Uint8Array> }`.\n   */\n  static createAppender () {\n    const { encoder, iterator } = encodeWriter()\n    encoder.setRoots = () => Promise.resolve()\n    const writer = new CarWriter([], encoder)\n    const out = new CarWriterOut(iterator)\n    return { writer, out }\n  }\n\n  /**\n   * Update the list of roots in the header of an existing CAR as represented\n   * in a Uint8Array.\n   *\n   * This operation is an _overwrite_, the total length of the CAR will not be\n   * modified. A rejection will occur if the new header will not be the same\n   * length as the existing header, in which case the CAR will not be modified.\n   * It is the responsibility of the user to ensure that the roots being\n   * replaced encode as the same length as the new roots.\n   *\n   * The byte array passed in an argument will be modified and also returned\n   * upon successful modification.\n   *\n   * @async\n   * @static\n   * @memberof CarWriter\n   * @param {Uint8Array} bytes\n   * @param {CID[]} roots - A new list of roots to replace the existing list in\n   * the CAR header. The new header must take up the same number of bytes as the\n   * existing header, so the roots should collectively be the same byte length\n   * as the existing roots.\n   * @returns {Promise<Uint8Array>}\n   */\n  static async updateRootsInBytes (bytes, roots) {\n    const reader = bytesReader(bytes)\n    await readHeader(reader)\n    const newHeader = createHeader(roots)\n    if (Number(reader.pos) !== newHeader.length) {\n      throw new Error(`updateRoots() can only overwrite a header of the same length (old header is ${reader.pos} bytes, new header is ${newHeader.length} bytes)`)\n    }\n    bytes.set(newHeader, 0)\n    return bytes\n  }\n}\n\n/**\n * @class\n * @implements {AsyncIterable<Uint8Array>}\n */\nexport class CarWriterOut {\n  /**\n   * @param {AsyncIterator<Uint8Array>} iterator\n   */\n  constructor (iterator) {\n    this._iterator = iterator\n  }\n\n  [Symbol.asyncIterator] () {\n    if (this._iterating) {\n      throw new Error('Multiple iterator not supported')\n    }\n    this._iterating = true\n    return this._iterator\n  }\n}\n\nfunction encodeWriter () {\n  /** @type {IteratorChannel} */\n  const iw = iteratorChannel()\n  const { writer, iterator } = iw\n  const encoder = createEncoder(writer)\n  return { encoder, iterator }\n}\n\n/**\n * @private\n * @param {CID[] | CID | void} roots\n * @returns {CID[]}\n */\nfunction toRoots (roots) {\n  if (roots === undefined) {\n    return []\n  }\n\n  if (!Array.isArray(roots)) {\n    const cid = CID.asCID(roots)\n    if (!cid) {\n      throw new TypeError('roots must be a single CID or an array of CIDs')\n    }\n    return [cid]\n  }\n\n  const _roots = []\n  for (const root of roots) {\n    const _root = CID.asCID(root)\n    if (!_root) {\n      throw new TypeError('roots must be a single CID or an array of CIDs')\n    }\n    _roots.push(_root)\n  }\n  return _roots\n}\n\nexport const __browser = true\n","import { CarBufferReader } from './buffer-reader.js'\nimport * as CarBufferWriter from './buffer-writer.js'\nimport { CarIndexedReader } from './indexed-reader-browser.js'\nimport { CarIndexer } from './indexer.js'\nimport { CarBlockIterator, CarCIDIterator } from './iterator.js'\nimport { CarReader } from './reader-browser.js'\nimport { CarWriter } from './writer-browser.js'\n\nexport {\n  CarReader,\n  CarIndexer,\n  CarBlockIterator,\n  CarCIDIterator,\n  CarWriter,\n  CarIndexedReader,\n  CarBufferReader,\n  CarBufferWriter\n}\n","/**\n * @packageDocumentation\n *\n * `@helia/car` provides `import` and `export` methods to read/write Car files to {@link https://github.com/ipfs/helia Helia}'s blockstore.\n *\n * See the {@link Car} interface for all available operations.\n *\n * By default it supports `dag-pb`, `dag-cbor`, `dag-json` and `raw` CIDs, more esoteric DAG walkers can be passed as an init option.\n *\n * @example Exporting a DAG as a CAR file\n *\n * ```typescript\n * import { createHelia } from 'helia'\n * import { unixfs } from '@helia/unixfs'\n * import { car } from '@helia/car'\n * import { CarWriter } from '@ipld/car'\n * import { Readable } from 'node:stream'\n * import nodeFs from 'node:fs'\n *\n * const helia = await createHelia({\n *   // ... helia config\n * })\n * const fs = unixfs(helia)\n *\n * // add some UnixFS data\n * const cid = await fs.addBytes(Uint8Array.from([0, 1, 2, 3, 4]))\n *\n * // export it as a Car\n * const c = car(helia)\n * const { writer, out } = await CarWriter.create(cid)\n *\n * // `out` needs to be directed somewhere, see the @ipld/car docs for more information\n * Readable.from(out).pipe(nodeFs.createWriteStream('example.car'))\n *\n * // write the DAG behind `cid` into the writer\n * await c.export(cid, writer)\n * ```\n *\n * @example Importing all blocks from a CAR file\n *\n * ```typescript\n * import { createHelia } from 'helia'\n * import { unixfs } from '@helia/unixfs'\n * import { car } from '@helia/car'\n * import { CarReader } from '@ipld/car'\n * import { Readable } from 'node:stream'\n * import nodeFs from 'node:fs'\n *\n * const helia = await createHelia({\n *   // ... helia config\n * })\n *\n * // import the car\n * const inStream = nodeFs.createReadStream('example.car')\n * const reader = await CarReader.fromIterable(inStream)\n *\n * const c = car(helia)\n * await c.import(reader)\n * ```\n */\nimport { CarWriter } from '@ipld/car';\nimport drain from 'it-drain';\nimport map from 'it-map';\nimport { createUnsafe } from 'multiformats/block';\nimport defer from 'p-defer';\nimport PQueue from 'p-queue';\nconst DAG_WALK_QUEUE_CONCURRENCY = 1;\nclass DefaultCar {\n    components;\n    constructor(components, init) {\n        this.components = components;\n    }\n    async import(reader, options) {\n        await drain(this.components.blockstore.putMany(map(reader.blocks(), ({ cid, bytes }) => ({ cid, block: bytes })), options));\n    }\n    async export(root, writer, options) {\n        const deferred = defer();\n        const roots = Array.isArray(root) ? root : [root];\n        // use a queue to walk the DAG instead of recursion so we can traverse very large DAGs\n        const queue = new PQueue({\n            concurrency: DAG_WALK_QUEUE_CONCURRENCY\n        });\n        queue.on('idle', () => {\n            deferred.resolve();\n        });\n        queue.on('error', (err) => {\n            queue.clear();\n            deferred.reject(err);\n        });\n        for (const root of roots) {\n            void queue.add(async () => {\n                await this.#walkDag(root, queue, async (cid, bytes) => {\n                    // if a filter has been passed, skip blocks that have already been written\n                    if (options?.blockFilter?.has(cid.multihash.bytes) === true) {\n                        return;\n                    }\n                    options?.blockFilter?.add(cid.multihash.bytes);\n                    await writer.put({ cid, bytes });\n                }, options);\n            })\n                .catch(() => { });\n        }\n        // wait for the writer to end\n        try {\n            await deferred.promise;\n        }\n        finally {\n            await writer.close();\n        }\n    }\n    async *stream(root, options) {\n        const { writer, out } = CarWriter.create(root);\n        // has to be done async so we write to `writer` and read from `out` at the\n        // same time\n        this.export(root, writer, options)\n            .catch(() => { });\n        for await (const buf of out) {\n            yield buf;\n        }\n    }\n    /**\n     * Walk the DAG behind the passed CID, ensure all blocks are present in the blockstore\n     * and update the pin count for them\n     */\n    async #walkDag(cid, queue, withBlock, options) {\n        const codec = await this.components.getCodec(cid.code);\n        const bytes = await this.components.blockstore.get(cid, options);\n        await withBlock(cid, bytes);\n        const block = createUnsafe({ bytes, cid, codec });\n        // walk dag, ensure all blocks are present\n        for await (const [, cid] of block.links()) {\n            void queue.add(async () => {\n                await this.#walkDag(cid, queue, withBlock, options);\n            });\n        }\n    }\n}\n/**\n * Create a {@link Car} instance for use with {@link https://github.com/ipfs/helia Helia}\n */\nexport function car(helia, init = {}) {\n    return new DefaultCar(helia, init);\n}\n//# sourceMappingURL=index.js.map","/**\n * Returns true if the passed argument has type overlap with the `PublicKey`\n * interface. Can be used to disambiguate object types.\n */\nexport function isPublicKey(key) {\n    if (key == null) {\n        return false;\n    }\n    return (key.type === 'RSA' || key.type === 'Ed25519' || key.type === 'secp256k1') &&\n        key.raw instanceof Uint8Array &&\n        typeof key.equals === 'function' &&\n        typeof key.toMultihash === 'function' &&\n        typeof key.toCID === 'function' &&\n        typeof key.verify === 'function';\n}\n/**\n * Returns true if the passed argument has type overlap with the `PrivateKey`\n * interface. Can be used to disambiguate object types.\n */\nexport function isPrivateKey(key) {\n    if (key == null) {\n        return false;\n    }\n    return (key.type === 'RSA' || key.type === 'Ed25519' || key.type === 'secp256k1') &&\n        isPublicKey(key.publicKey) &&\n        key.raw instanceof Uint8Array &&\n        typeof key.equals === 'function' &&\n        typeof key.sign === 'function';\n}\n//# sourceMappingURL=index.js.map","import { publicKeyToProtobuf } from '@libp2p/crypto/keys';\nimport { logger } from '@libp2p/logger';\nimport {} from 'interface-datastore/key';\nimport NanoDate from 'timestamp-nano';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { SignatureCreationError } from './errors.js';\nimport { IpnsEntry } from './pb/ipns.js';\nimport { createCborData, ipnsRecordDataForV1Sig, ipnsRecordDataForV2Sig, normalizeValue } from './utils.js';\nconst log = logger('ipns');\nconst DEFAULT_TTL_NS = 60 * 60 * 1e+9; // 1 Hour or 3600 Seconds\nexport const namespace = '/ipns/';\nexport const namespaceLength = namespace.length;\nconst defaultCreateOptions = {\n    v1Compatible: true,\n    ttlNs: DEFAULT_TTL_NS\n};\nexport async function createIPNSRecord(privateKey, value, seq, lifetime, options = defaultCreateOptions) {\n    // Validity in ISOString with nanoseconds precision and validity type EOL\n    const expirationDate = new NanoDate(Date.now() + Number(lifetime));\n    const validityType = IpnsEntry.ValidityType.EOL;\n    const ttlNs = BigInt(options.ttlNs ?? DEFAULT_TTL_NS);\n    return _create(privateKey, value, seq, validityType, expirationDate.toString(), ttlNs, options);\n}\nexport async function createIPNSRecordWithExpiration(privateKey, value, seq, expiration, options = defaultCreateOptions) {\n    const expirationDate = NanoDate.fromString(expiration);\n    const validityType = IpnsEntry.ValidityType.EOL;\n    const ttlNs = BigInt(options.ttlNs ?? DEFAULT_TTL_NS);\n    return _create(privateKey, value, seq, validityType, expirationDate.toString(), ttlNs, options);\n}\nconst _create = async (privateKey, value, seq, validityType, validity, ttl, options = defaultCreateOptions) => {\n    seq = BigInt(seq);\n    const isoValidity = uint8ArrayFromString(validity);\n    const normalizedValue = normalizeValue(value);\n    const encodedValue = uint8ArrayFromString(normalizedValue);\n    const data = createCborData(encodedValue, validityType, isoValidity, seq, ttl);\n    const sigData = ipnsRecordDataForV2Sig(data);\n    const signatureV2 = await privateKey.sign(sigData);\n    let pubKey;\n    // if we cannot derive the public key from the PeerId (e.g. RSA PeerIDs),\n    // we have to embed it in the IPNS record\n    if (privateKey.type === 'RSA') {\n        pubKey = publicKeyToProtobuf(privateKey.publicKey);\n    }\n    if (options.v1Compatible === true) {\n        const signatureV1 = await signLegacyV1(privateKey, encodedValue, validityType, isoValidity);\n        const record = {\n            value: normalizedValue,\n            signatureV1,\n            validity,\n            validityType,\n            sequence: seq,\n            ttl,\n            signatureV2,\n            data\n        };\n        if (pubKey != null) {\n            record.pubKey = pubKey;\n        }\n        return record;\n    }\n    else {\n        const record = {\n            value: normalizedValue,\n            validity,\n            validityType,\n            sequence: seq,\n            ttl,\n            signatureV2,\n            data\n        };\n        if (pubKey != null) {\n            record.pubKey = pubKey;\n        }\n        return record;\n    }\n};\nexport { unmarshalIPNSRecord } from './utils.js';\nexport { marshalIPNSRecord } from './utils.js';\nexport { multihashToIPNSRoutingKey } from './utils.js';\nexport { multihashFromIPNSRoutingKey } from './utils.js';\nexport { extractPublicKeyFromIPNSRecord } from './utils.js';\n/**\n * Sign ipns record data using the legacy V1 signature scheme\n */\nconst signLegacyV1 = async (privateKey, value, validityType, validity) => {\n    try {\n        const dataForSignature = ipnsRecordDataForV1Sig(value, validityType, validity);\n        return await privateKey.sign(dataForSignature);\n    }\n    catch (error) {\n        log.error('record signature creation failed', error);\n        throw new SignatureCreationError('Record signature creation failed');\n    }\n};\n//# sourceMappingURL=index.js.map","import NanoDate from 'timestamp-nano';\nimport { IpnsEntry } from './pb/ipns.js';\nimport { unmarshalIPNSRecord } from './utils.js';\nexport function ipnsSelector(key, data) {\n    const entries = data.map((buf, index) => ({\n        record: unmarshalIPNSRecord(buf),\n        index\n    }));\n    entries.sort((a, b) => {\n        // Before we'd sort based on the signature version. Unmarshal now fails if\n        // a record does not have SignatureV2, so that is no longer needed. V1-only\n        // records haven't been issues in a long time.\n        const aSeq = a.record.sequence;\n        const bSeq = b.record.sequence;\n        // choose later sequence number\n        if (aSeq > bSeq) {\n            return -1;\n        }\n        else if (aSeq < bSeq) {\n            return 1;\n        }\n        if (a.record.validityType === IpnsEntry.ValidityType.EOL && b.record.validityType === IpnsEntry.ValidityType.EOL) {\n            // choose longer lived record if sequence numbers the same\n            const recordAValidityDate = NanoDate.fromString(a.record.validity).toDate();\n            const recordBValidityDate = NanoDate.fromString(b.record.validity).toDate();\n            if (recordAValidityDate.getTime() > recordBValidityDate.getTime()) {\n                return -1;\n            }\n            if (recordAValidityDate.getTime() < recordBValidityDate.getTime()) {\n                return 1;\n            }\n        }\n        return 0;\n    });\n    return entries[0].index;\n}\n//# sourceMappingURL=selector.js.map","export class DNSLinkNotFoundError extends Error {\n    static name = 'DNSLinkNotFoundError';\n    constructor(message = 'DNSLink not found') {\n        super(message);\n        this.name = 'DNSLinkNotFoundError';\n    }\n}\nexport class RecordsFailedValidationError extends Error {\n    static name = 'RecordsFailedValidationError';\n    constructor(message = 'Records failed validation') {\n        super(message);\n        this.name = 'RecordsFailedValidationError';\n    }\n}\nexport class UnsupportedMultibasePrefixError extends Error {\n    static name = 'UnsupportedMultibasePrefixError';\n    constructor(message = 'Unsupported multibase prefix') {\n        super(message);\n        this.name = 'UnsupportedMultibasePrefixError';\n    }\n}\nexport class UnsupportedMultihashCodecError extends Error {\n    static name = 'UnsupportedMultihashCodecError';\n    constructor(message = 'Unsupported multihash codec') {\n        super(message);\n        this.name = 'UnsupportedMultihashCodecError';\n    }\n}\nexport class InvalidValueError extends Error {\n    static name = 'InvalidValueError';\n    constructor(message = 'Invalid value') {\n        super(message);\n        this.name = 'InvalidValueError';\n    }\n}\nexport class InvalidTopicError extends Error {\n    static name = 'InvalidTopicError';\n    constructor(message = 'Invalid topic') {\n        super(message);\n        this.name = 'InvalidTopicError';\n    }\n}\n//# sourceMappingURL=errors.js.map","import {} from '@libp2p/interface';\nimport { peerIdFromString } from '@libp2p/peer-id';\nimport { RecordType } from '@multiformats/dns';\nimport { CID } from 'multiformats/cid';\nimport { DNSLinkNotFoundError } from './errors.js';\nconst MAX_RECURSIVE_DEPTH = 32;\nasync function recursiveResolveDnslink(domain, depth, dns, log, options = {}) {\n    if (depth === 0) {\n        throw new Error('recursion limit exceeded');\n    }\n    log('query %s for TXT and CNAME records', domain);\n    const txtRecordsResponse = await dns.query(domain, {\n        ...options,\n        types: [\n            RecordType.TXT\n        ]\n    });\n    // sort the TXT records to ensure deterministic processing\n    const txtRecords = (txtRecordsResponse?.Answer ?? [])\n        .sort((a, b) => a.data.localeCompare(b.data));\n    log('found %d TXT records for %s', txtRecords.length, domain);\n    for (const answer of txtRecords) {\n        try {\n            let result = answer.data;\n            // strip leading and trailing \" characters\n            if (result.startsWith('\"') && result.endsWith('\"')) {\n                result = result.substring(1, result.length - 1);\n            }\n            if (!result.startsWith('dnslink=')) {\n                // invalid record?\n                continue;\n            }\n            log('%s TXT %s', answer.name, result);\n            result = result.replace('dnslink=', '');\n            // result is now a `/ipfs/<cid>` or `/ipns/<cid>` string\n            const [, protocol, domainOrCID, ...rest] = result.split('/'); // e.g. [\"\", \"ipfs\", \"<cid>\"]\n            if (protocol === 'ipfs') {\n                try {\n                    const cid = CID.parse(domainOrCID);\n                    // if the result is a CID, we've reached the end of the recursion\n                    return {\n                        value: `/ipfs/${cid}${rest.length > 0 ? `/${rest.join('/')}` : ''}`,\n                        answer\n                    };\n                }\n                catch { }\n            }\n            else if (protocol === 'ipns') {\n                try {\n                    const peerId = peerIdFromString(domainOrCID);\n                    // if the result is a PeerId, we've reached the end of the recursion\n                    return {\n                        value: `/ipns/${peerId}${rest.length > 0 ? `/${rest.join('/')}` : ''}`,\n                        answer\n                    };\n                }\n                catch { }\n                // if the result was another IPNS domain, try to follow it\n                return await recursiveResolveDomain(domainOrCID, depth - 1, dns, log, options);\n            }\n            else if (protocol === 'dnslink') {\n                // if the result was another DNSLink domain, try to follow it\n                return await recursiveResolveDomain(domainOrCID, depth - 1, dns, log, options);\n            }\n            else {\n                log('unknown protocol \"%s\" in DNSLink record for domain: %s', protocol, domain);\n                continue;\n            }\n        }\n        catch (err) {\n            log.error('could not parse DNS link record for domain %s, %s', domain, answer.data, err);\n        }\n    }\n    // no dnslink records found, try CNAMEs\n    log('no DNSLink records found for %s, falling back to CNAME', domain);\n    const cnameRecordsResponse = await dns.query(domain, {\n        ...options,\n        types: [\n            RecordType.CNAME\n        ]\n    });\n    // sort the CNAME records to ensure deterministic processing\n    const cnameRecords = (cnameRecordsResponse?.Answer ?? [])\n        .sort((a, b) => a.data.localeCompare(b.data));\n    log('found %d CNAME records for %s', cnameRecords.length, domain);\n    for (const cname of cnameRecords) {\n        try {\n            return await recursiveResolveDomain(cname.data, depth - 1, dns, log, options);\n        }\n        catch (err) {\n            log.error('domain %s cname %s had no DNSLink records', domain, cname.data, err);\n        }\n    }\n    throw new DNSLinkNotFoundError(`No DNSLink records found for domain: ${domain}`);\n}\nasync function recursiveResolveDomain(domain, depth, dns, log, options = {}) {\n    if (depth === 0) {\n        throw new Error('recursion limit exceeded');\n    }\n    // the DNSLink spec says records MUST be stored on the `_dnslink.` subdomain\n    // so start looking for records there, we will fall back to the bare domain\n    // if none are found\n    if (!domain.startsWith('_dnslink.')) {\n        domain = `_dnslink.${domain}`;\n    }\n    try {\n        return await recursiveResolveDnslink(domain, depth, dns, log, options);\n    }\n    catch (err) {\n        // If the code is not ENOTFOUND or ERR_DNSLINK_NOT_FOUND or ENODATA then throw the error\n        if (err.code !== 'ENOTFOUND' && err.code !== 'ENODATA' && err.name !== 'DNSLinkNotFoundError' && err.name !== 'NotFoundError') {\n            throw err;\n        }\n        if (domain.startsWith('_dnslink.')) {\n            // The supplied domain contains a _dnslink component\n            // Check the non-_dnslink domain\n            domain = domain.replace('_dnslink.', '');\n        }\n        else {\n            // Check the _dnslink subdomain\n            domain = `_dnslink.${domain}`;\n        }\n        // If this throws then we propagate the error\n        return recursiveResolveDnslink(domain, depth, dns, log, options);\n    }\n}\nexport async function resolveDNSLink(domain, dns, log, options = {}) {\n    return recursiveResolveDomain(domain, options.maxRecursiveDepth ?? MAX_RECURSIVE_DEPTH, dns, log, options);\n}\n//# sourceMappingURL=dnslink.js.map","import { CustomProgressEvent } from 'progress-events';\nexport class HeliaRouting {\n    routing;\n    constructor(routing) {\n        this.routing = routing;\n    }\n    async put(routingKey, marshaledRecord, options = {}) {\n        try {\n            await this.routing.put(routingKey, marshaledRecord, options);\n        }\n        catch (err) {\n            options.onProgress?.(new CustomProgressEvent('ipns:routing:helia:error', err));\n        }\n    }\n    async get(routingKey, options = {}) {\n        try {\n            return await this.routing.get(routingKey, options);\n        }\n        catch (err) {\n            options.onProgress?.(new CustomProgressEvent('ipns:routing:helia:error', err));\n        }\n        throw new Error('Not found');\n    }\n}\n/**\n * The helia routing uses any available Routers configured on the passed Helia\n * node. This could be libp2p, HTTP API Delegated Routing, etc.\n */\nexport function helia(routing) {\n    return new HeliaRouting(routing);\n}\n//# sourceMappingURL=helia.js.map","/* eslint-disable import/export */\n/* eslint-disable complexity */\n/* eslint-disable @typescript-eslint/no-namespace */\n/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */\n/* eslint-disable @typescript-eslint/no-empty-interface */\nimport { decodeMessage, encodeMessage, message } from 'protons-runtime';\nimport { alloc as uint8ArrayAlloc } from 'uint8arrays/alloc';\nexport var Record;\n(function (Record) {\n    let _codec;\n    Record.codec = () => {\n        if (_codec == null) {\n            _codec = message((obj, w, opts = {}) => {\n                if (opts.lengthDelimited !== false) {\n                    w.fork();\n                }\n                if ((obj.key != null && obj.key.byteLength > 0)) {\n                    w.uint32(10);\n                    w.bytes(obj.key);\n                }\n                if ((obj.value != null && obj.value.byteLength > 0)) {\n                    w.uint32(18);\n                    w.bytes(obj.value);\n                }\n                if ((obj.timeReceived != null && obj.timeReceived !== '')) {\n                    w.uint32(42);\n                    w.string(obj.timeReceived);\n                }\n                if (opts.lengthDelimited !== false) {\n                    w.ldelim();\n                }\n            }, (reader, length, opts = {}) => {\n                const obj = {\n                    key: uint8ArrayAlloc(0),\n                    value: uint8ArrayAlloc(0),\n                    timeReceived: ''\n                };\n                const end = length == null ? reader.len : reader.pos + length;\n                while (reader.pos < end) {\n                    const tag = reader.uint32();\n                    switch (tag >>> 3) {\n                        case 1: {\n                            obj.key = reader.bytes();\n                            break;\n                        }\n                        case 2: {\n                            obj.value = reader.bytes();\n                            break;\n                        }\n                        case 5: {\n                            obj.timeReceived = reader.string();\n                            break;\n                        }\n                        default: {\n                            reader.skipType(tag & 7);\n                            break;\n                        }\n                    }\n                }\n                return obj;\n            });\n        }\n        return _codec;\n    };\n    Record.encode = (obj) => {\n        return encodeMessage(obj, Record.codec());\n    };\n    Record.decode = (buf, opts) => {\n        return decodeMessage(buf, Record.codec(), opts);\n    };\n})(Record || (Record = {}));\n//# sourceMappingURL=record.js.map","/**\n * Convert a JavaScript date into an `RFC3339Nano` formatted\n * string\n */\nexport function toRFC3339(time) {\n    const year = time.getUTCFullYear();\n    const month = String(time.getUTCMonth() + 1).padStart(2, '0');\n    const day = String(time.getUTCDate()).padStart(2, '0');\n    const hour = String(time.getUTCHours()).padStart(2, '0');\n    const minute = String(time.getUTCMinutes()).padStart(2, '0');\n    const seconds = String(time.getUTCSeconds()).padStart(2, '0');\n    const milliseconds = time.getUTCMilliseconds();\n    const nanoseconds = String(milliseconds * 1000 * 1000).padStart(9, '0');\n    return `${year}-${month}-${day}T${hour}:${minute}:${seconds}.${nanoseconds}Z`;\n}\n/**\n * Parses a date string formatted as `RFC3339Nano` into a\n * JavaScript Date object\n */\nexport function parseRFC3339(time) {\n    const rfc3339Matcher = new RegExp(\n    // 2006-01-02T\n    '(\\\\d{4})-(\\\\d{2})-(\\\\d{2})T' +\n        // 15:04:05\n        '(\\\\d{2}):(\\\\d{2}):(\\\\d{2})' +\n        // .999999999Z\n        '\\\\.(\\\\d+)Z');\n    const m = String(time).trim().match(rfc3339Matcher);\n    if (m == null) {\n        throw new Error('Invalid format');\n    }\n    const year = parseInt(m[1], 10);\n    const month = parseInt(m[2], 10) - 1;\n    const date = parseInt(m[3], 10);\n    const hour = parseInt(m[4], 10);\n    const minute = parseInt(m[5], 10);\n    const second = parseInt(m[6], 10);\n    const millisecond = parseInt(m[7].slice(0, -6), 10);\n    return new Date(Date.UTC(year, month, date, hour, minute, second, millisecond));\n}\n//# sourceMappingURL=utils.js.map","/**\n * @packageDocumentation\n *\n * This is an implementation of the [routing record format](https://github.com/libp2p/specs/blob/b9efe152c29f93f7a87931c14d78ae11e7924d5a/kad-dht/README.md?plain=1#L408-L425) used by libp2p to store data in the datastore passed to the libp2p constructor.\n *\n * @example Deserialization\n *\n * ```TypeScript\n * import { Libp2pRecord } from '@libp2p/record'\n *\n * const buf = Uint8Array.from([0, 1, 2, 3])\n * const record = Libp2pRecord.deserialize(buf)\n * ```\n *\n * @example Serialization\n *\n * ```TypeScript\n * import { Libp2pRecord } from '@libp2p/record'\n *\n * const key = Uint8Array.from([0, 1, 2, 3])\n * const value = Uint8Array.from([0, 1, 2, 3])\n * const timeReceived = new Date()\n *\n * const record = new Libp2pRecord(key, value, timeReceived)\n * const buf = record.serialize()\n * ```\n */\nimport { Record } from './record.js';\nimport * as utils from './utils.js';\nexport class Libp2pRecord {\n    key;\n    value;\n    timeReceived;\n    constructor(key, value, timeReceived) {\n        if (!(key instanceof Uint8Array)) {\n            throw new Error('key must be a Uint8Array');\n        }\n        if (!(value instanceof Uint8Array)) {\n            throw new Error('value must be a Uint8Array');\n        }\n        this.key = key;\n        this.value = value;\n        this.timeReceived = timeReceived;\n    }\n    serialize() {\n        return Record.encode(this.prepareSerialize());\n    }\n    /**\n     * Return the object format ready to be given to the protobuf library.\n     */\n    prepareSerialize() {\n        return {\n            key: this.key,\n            value: this.value,\n            timeReceived: utils.toRFC3339(this.timeReceived)\n        };\n    }\n    /**\n     * Decode a protobuf encoded record\n     */\n    static deserialize(raw) {\n        const rec = Record.decode(raw);\n        return new Libp2pRecord(rec.key, rec.value, new Date(rec.timeReceived));\n    }\n    /**\n     * Create a record from the raw object returned from the protobuf library\n     */\n    static fromDeserialized(obj) {\n        const recvtime = utils.parseRFC3339(obj.timeReceived);\n        if (obj.key == null) {\n            throw new Error('key missing from deserialized object');\n        }\n        if (obj.value == null) {\n            throw new Error('value missing from deserialized object');\n        }\n        const rec = new Libp2pRecord(obj.key, obj.value, recvtime);\n        return rec;\n    }\n}\n//# sourceMappingURL=index.js.map","import { Record } from '@libp2p/kad-dht';\nimport { Key } from 'interface-datastore';\nimport { CustomProgressEvent } from 'progress-events';\nimport { equals as uint8ArrayEquals } from 'uint8arrays/equals';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nfunction dhtRoutingKey(key) {\n    return new Key('/dht/record/' + uint8ArrayToString(key, 'base32'), false);\n}\n/**\n * Returns an IPNSRouting implementation that reads/writes IPNS records to the\n * datastore as DHT records. This lets us publish IPNS records offline then\n * serve them to the network later in response to DHT queries.\n */\nexport function localStore(datastore) {\n    return {\n        async put(routingKey, marshalledRecord, options = {}) {\n            try {\n                const key = dhtRoutingKey(routingKey);\n                // don't overwrite existing, identical records as this will affect the\n                // TTL\n                try {\n                    const existingBuf = await datastore.get(key);\n                    const existingRecord = Record.deserialize(existingBuf);\n                    if (uint8ArrayEquals(existingRecord.value, marshalledRecord)) {\n                        return;\n                    }\n                }\n                catch (err) {\n                    if (err.name !== 'NotFoundError') {\n                        throw err;\n                    }\n                }\n                // Marshal to libp2p record as the DHT does\n                const record = new Record(routingKey, marshalledRecord, new Date());\n                options.onProgress?.(new CustomProgressEvent('ipns:routing:datastore:put'));\n                await datastore.put(key, record.serialize(), options);\n            }\n            catch (err) {\n                options.onProgress?.(new CustomProgressEvent('ipns:routing:datastore:error', err));\n                throw err;\n            }\n        },\n        async get(routingKey, options = {}) {\n            try {\n                const key = dhtRoutingKey(routingKey);\n                options.onProgress?.(new CustomProgressEvent('ipns:routing:datastore:get'));\n                const buf = await datastore.get(key, options);\n                // Unmarshal libp2p record as the DHT does\n                const record = Record.deserialize(buf);\n                return {\n                    record: record.value,\n                    created: record.timeReceived\n                };\n            }\n            catch (err) {\n                options.onProgress?.(new CustomProgressEvent('ipns:routing:datastore:error', err));\n                throw err;\n            }\n        },\n        async has(routingKey, options = {}) {\n            const key = dhtRoutingKey(routingKey);\n            return datastore.has(key, options);\n        },\n        async delete(routingKey, options) {\n            const key = dhtRoutingKey(routingKey);\n            return datastore.delete(key, options);\n        }\n    };\n}\n//# sourceMappingURL=local-store.js.map","export const IDENTITY_CODEC = 0x0;\nexport const SHA2_256_CODEC = 0x12;\nexport function isCodec(digest, codec) {\n    return digest.code === codec;\n}\n//# sourceMappingURL=utils.js.map","/**\n * @packageDocumentation\n *\n * IPNS operations using a Helia node\n *\n * @example Getting started\n *\n * With {@link IPNSRouting} routers:\n *\n * ```TypeScript\n * import { createHelia } from 'helia'\n * import { ipns } from '@helia/ipns'\n * import { unixfs } from '@helia/unixfs'\n * import { generateKeyPair } from '@libp2p/crypto/keys'\n *\n * const helia = await createHelia()\n * const name = ipns(helia)\n *\n * // create a keypair to publish an IPNS name\n * const privateKey = await generateKeyPair('Ed25519')\n *\n * // store some data to publish\n * const fs = unixfs(helia)\n * const cid = await fs.addBytes(Uint8Array.from([0, 1, 2, 3, 4]))\n *\n * // publish the name\n * await name.publish(privateKey, cid)\n *\n * // resolve the name\n * const result = await name.resolve(privateKey.publicKey)\n *\n * console.info(result.cid, result.path)\n * ```\n *\n * @example Publishing a recursive record\n *\n * A recursive record is a one that points to another record rather than to a\n * value.\n *\n * ```TypeScript\n * import { createHelia } from 'helia'\n * import { ipns } from '@helia/ipns'\n * import { unixfs } from '@helia/unixfs'\n * import { generateKeyPair } from '@libp2p/crypto/keys'\n *\n * const helia = await createHelia()\n * const name = ipns(helia)\n *\n * // create a keypair to publish an IPNS name\n * const privateKey = await generateKeyPair('Ed25519')\n *\n * // store some data to publish\n * const fs = unixfs(helia)\n * const cid = await fs.addBytes(Uint8Array.from([0, 1, 2, 3, 4]))\n *\n * // publish the name\n * await name.publish(privateKey, cid)\n *\n * // create another keypair to re-publish the original record\n * const recursivePrivateKey = await generateKeyPair('Ed25519')\n *\n * // publish the recursive name\n * await name.publish(recursivePrivateKey, privateKey.publicKey)\n *\n * // resolve the name recursively - it resolves until a CID is found\n * const result = await name.resolve(recursivePrivateKey.publicKey)\n * console.info(result.cid.toString() === cid.toString()) // true\n * ```\n *\n * @example Publishing a record with a path\n *\n * It is possible to publish CIDs with an associated path.\n *\n * ```TypeScript\n * import { createHelia } from 'helia'\n * import { ipns } from '@helia/ipns'\n * import { unixfs } from '@helia/unixfs'\n * import { generateKeyPair } from '@libp2p/crypto/keys'\n *\n * const helia = await createHelia()\n * const name = ipns(helia)\n *\n * // create a keypair to publish an IPNS name\n * const privateKey = await generateKeyPair('Ed25519')\n *\n * // store some data to publish\n * const fs = unixfs(helia)\n * const fileCid = await fs.addBytes(Uint8Array.from([0, 1, 2, 3, 4]))\n *\n * // store the file in a directory\n * const dirCid = await fs.addDirectory()\n * const finalDirCid = await fs.cp(fileCid, dirCid, '/foo.txt')\n *\n * // publish the name\n * await name.publish(privateKey, `/ipfs/${finalDirCid}/foo.txt`)\n *\n * // resolve the name\n * const result = await name.resolve(privateKey.publicKey)\n *\n * console.info(result.cid, result.path) // QmFoo.. 'foo.txt'\n * ```\n *\n * @example Using custom PubSub router\n *\n * Additional IPNS routers can be configured - these enable alternative means to\n * publish and resolve IPNS names.\n *\n * One example is the PubSub router - this requires an instance of Helia with\n * libp2p PubSub configured.\n *\n * It works by subscribing to a pubsub topic for each IPNS name that we try to\n * resolve. Updated IPNS records are shared on these topics so an update must\n * occur before the name is resolvable.\n *\n * This router is only suitable for networks where IPNS updates are frequent\n * and multiple peers are listening on the topic(s), otherwise update messages\n * may fail to be published with \"Insufficient peers\" errors.\n *\n * ```TypeScript\n * import { createHelia, libp2pDefaults } from 'helia'\n * import { ipns } from '@helia/ipns'\n * import { pubsub } from '@helia/ipns/routing'\n * import { unixfs } from '@helia/unixfs'\n * import { gossipsub } from '@chainsafe/libp2p-gossipsub'\n * import { generateKeyPair } from '@libp2p/crypto/keys'\n * import type { Libp2p, PubSub } from '@libp2p/interface'\n * import type { DefaultLibp2pServices } from 'helia'\n *\n * const libp2pOptions = libp2pDefaults()\n * libp2pOptions.services.pubsub = gossipsub()\n *\n * const helia = await createHelia<Libp2p<DefaultLibp2pServices & { pubsub: PubSub }>>({\n *   libp2p: libp2pOptions\n * })\n * const name = ipns(helia, {\n *  routers: [\n *    pubsub(helia)\n *  ]\n * })\n *\n * // create a keypair to publish an IPNS name\n * const privateKey = await generateKeyPair('Ed25519')\n *\n * // store some data to publish\n * const fs = unixfs(helia)\n * const cid = await fs.addBytes(Uint8Array.from([0, 1, 2, 3, 4]))\n *\n * // publish the name\n * await name.publish(privateKey, cid)\n *\n * // resolve the name\n * const result = await name.resolve(privateKey.publicKey)\n * ```\n *\n * @example Using custom DNS over HTTPS resolvers\n *\n * To use custom resolvers, configure Helia's `dns` option:\n *\n * ```TypeScript\n * import { createHelia } from 'helia'\n * import { ipns } from '@helia/ipns'\n * import { dns } from '@multiformats/dns'\n * import { dnsOverHttps } from '@multiformats/dns/resolvers'\n * import { helia } from '@helia/ipns/routing'\n *\n * const node = await createHelia({\n *   dns: dns({\n *     resolvers: {\n *       '.': dnsOverHttps('https://private-dns-server.me/dns-query')\n *     }\n *   })\n * })\n * const name = ipns(node, {\n *  routers: [\n *    helia(node.routing)\n *  ]\n * })\n *\n * const result = name.resolveDNSLink('some-domain-with-dnslink-entry.com')\n * ```\n *\n * @example Resolving a domain with a dnslink entry\n *\n * Calling `resolveDNSLink` with the `@helia/ipns` instance:\n *\n * ```TypeScript\n * // resolve a CID from a TXT record in a DNS zone file, using the default\n * // resolver for the current platform eg:\n * // > dig _dnslink.ipfs.io TXT\n * // ;; ANSWER SECTION:\n * // _dnslink.ipfs.io.          60     IN      TXT     \"dnslink=/ipns/website.ipfs.io\"\n * // > dig _dnslink.website.ipfs.io TXT\n * // ;; ANSWER SECTION:\n * // _dnslink.website.ipfs.io.  60     IN      TXT     \"dnslink=/ipfs/QmWebsite\"\n *\n * import { createHelia } from 'helia'\n * import { ipns } from '@helia/ipns'\n *\n * const node = await createHelia()\n * const name = ipns(node)\n *\n * const { answer } = await name.resolveDNSLink('ipfs.io')\n *\n * console.info(answer)\n * // { data: '/ipfs/QmWebsite' }\n * ```\n *\n * @example Using DNS-Over-HTTPS\n *\n * This example uses the Mozilla provided RFC 1035 DNS over HTTPS service. This\n * uses binary DNS records so requires extra dependencies to process the\n * response which can increase browser bundle sizes.\n *\n * If this is a concern, use the DNS-JSON-Over-HTTPS resolver instead.\n *\n * ```TypeScript\n * import { createHelia } from 'helia'\n * import { ipns } from '@helia/ipns'\n * import { dns } from '@multiformats/dns'\n * import { dnsOverHttps } from '@multiformats/dns/resolvers'\n *\n * const node = await createHelia({\n *   dns: dns({\n *     resolvers: {\n *       '.': dnsOverHttps('https://mozilla.cloudflare-dns.com/dns-query')\n *     }\n *   })\n * })\n * const name = ipns(node)\n *\n * const result = await name.resolveDNSLink('ipfs.io')\n * ```\n *\n * @example Using DNS-JSON-Over-HTTPS\n *\n * DNS-JSON-Over-HTTPS resolvers use the RFC 8427 `application/dns-json` and can\n * result in a smaller browser bundle due to the response being plain JSON.\n *\n * ```TypeScript\n * import { createHelia } from 'helia'\n * import { ipns } from '@helia/ipns'\n * import { dns } from '@multiformats/dns'\n * import { dnsJsonOverHttps } from '@multiformats/dns/resolvers'\n *\n * const node = await createHelia({\n *   dns: dns({\n *     resolvers: {\n *       '.': dnsJsonOverHttps('https://mozilla.cloudflare-dns.com/dns-query')\n *     }\n *   })\n * })\n * const name = ipns(node)\n *\n * const result = await name.resolveDNSLink('ipfs.io')\n * ```\n */\nimport { NotFoundError, isPublicKey } from '@libp2p/interface';\nimport { logger } from '@libp2p/logger';\nimport { createIPNSRecord, marshalIPNSRecord, multihashToIPNSRoutingKey, unmarshalIPNSRecord } from 'ipns';\nimport { ipnsSelector } from 'ipns/selector';\nimport { ipnsValidator } from 'ipns/validator';\nimport { base36 } from 'multiformats/bases/base36';\nimport { base58btc } from 'multiformats/bases/base58';\nimport { CID } from 'multiformats/cid';\nimport * as Digest from 'multiformats/hashes/digest';\nimport { CustomProgressEvent } from 'progress-events';\nimport { resolveDNSLink } from './dnslink.js';\nimport { InvalidValueError, RecordsFailedValidationError, UnsupportedMultibasePrefixError, UnsupportedMultihashCodecError } from './errors.js';\nimport { helia } from './routing/helia.js';\nimport { localStore } from './routing/local-store.js';\nimport { isCodec, IDENTITY_CODEC, SHA2_256_CODEC } from './utils.js';\nconst log = logger('helia:ipns');\nconst MINUTE = 60 * 1000;\nconst HOUR = 60 * MINUTE;\nconst DEFAULT_LIFETIME_MS = 24 * HOUR;\nconst DEFAULT_REPUBLISH_INTERVAL_MS = 23 * HOUR;\nconst DEFAULT_TTL_NS = BigInt(HOUR) * 1000000n;\nconst bases = {\n    [base36.prefix]: base36,\n    [base58btc.prefix]: base58btc\n};\nclass DefaultIPNS {\n    routers;\n    localStore;\n    timeout;\n    dns;\n    log;\n    constructor(components, routers = []) {\n        this.routers = [\n            helia(components.routing),\n            ...routers\n        ];\n        this.localStore = localStore(components.datastore);\n        this.dns = components.dns;\n        this.log = components.logger.forComponent('helia:ipns');\n    }\n    async publish(key, value, options = {}) {\n        try {\n            let sequenceNumber = 1n;\n            const routingKey = multihashToIPNSRoutingKey(key.publicKey.toMultihash());\n            if (await this.localStore.has(routingKey, options)) {\n                // if we have published under this key before, increment the sequence number\n                const { record } = await this.localStore.get(routingKey, options);\n                const existingRecord = unmarshalIPNSRecord(record);\n                sequenceNumber = existingRecord.sequence + 1n;\n            }\n            // create record\n            const record = await createIPNSRecord(key, value, sequenceNumber, options.lifetime ?? DEFAULT_LIFETIME_MS, options);\n            const marshaledRecord = marshalIPNSRecord(record);\n            await this.localStore.put(routingKey, marshaledRecord, options);\n            if (options.offline !== true) {\n                // publish record to routing\n                await Promise.all(this.routers.map(async (r) => { await r.put(routingKey, marshaledRecord, options); }));\n            }\n            return record;\n        }\n        catch (err) {\n            options.onProgress?.(new CustomProgressEvent('ipns:publish:error', err));\n            throw err;\n        }\n    }\n    async resolve(key, options = {}) {\n        const digest = isPublicKey(key) ? key.toMultihash() : key;\n        const routingKey = multihashToIPNSRoutingKey(digest);\n        const record = await this.#findIpnsRecord(routingKey, options);\n        return {\n            ...(await this.#resolve(record.value, options)),\n            record\n        };\n    }\n    async resolveDNSLink(domain, options = {}) {\n        const dnslink = await resolveDNSLink(domain, this.dns, this.log, options);\n        return {\n            ...(await this.#resolve(dnslink.value, options)),\n            answer: dnslink.answer\n        };\n    }\n    republish(options = {}) {\n        if (this.timeout != null) {\n            throw new Error('Republish is already running');\n        }\n        options.signal?.addEventListener('abort', () => {\n            clearTimeout(this.timeout);\n        });\n        async function republish() {\n            const startTime = Date.now();\n            options.onProgress?.(new CustomProgressEvent('ipns:republish:start'));\n            const finishType = Date.now();\n            const timeTaken = finishType - startTime;\n            let nextInterval = DEFAULT_REPUBLISH_INTERVAL_MS - timeTaken;\n            if (nextInterval < 0) {\n                nextInterval = options.interval ?? DEFAULT_REPUBLISH_INTERVAL_MS;\n            }\n            setTimeout(() => {\n                republish().catch(err => {\n                    log.error('error republishing', err);\n                });\n            }, nextInterval);\n        }\n        this.timeout = setTimeout(() => {\n            republish().catch(err => {\n                log.error('error republishing', err);\n            });\n        }, options.interval ?? DEFAULT_REPUBLISH_INTERVAL_MS);\n    }\n    async #resolve(ipfsPath, options = {}) {\n        const parts = ipfsPath.split('/');\n        try {\n            const scheme = parts[1];\n            if (scheme === 'ipns') {\n                const str = parts[2];\n                const prefix = str.substring(0, 1);\n                let buf;\n                if (prefix === '1' || prefix === 'Q') {\n                    buf = base58btc.decode(`z${str}`);\n                }\n                else if (bases[prefix] != null) {\n                    buf = bases[prefix].decode(str);\n                }\n                else {\n                    throw new UnsupportedMultibasePrefixError(`Unsupported multibase prefix \"${prefix}\"`);\n                }\n                let digest;\n                try {\n                    digest = Digest.decode(buf);\n                }\n                catch {\n                    digest = CID.decode(buf).multihash;\n                }\n                if (!isCodec(digest, IDENTITY_CODEC) && !isCodec(digest, SHA2_256_CODEC)) {\n                    throw new UnsupportedMultihashCodecError(`Unsupported multihash codec \"${digest.code}\"`);\n                }\n                const { cid } = await this.resolve(digest, options);\n                const path = parts.slice(3).join('/');\n                return {\n                    cid,\n                    path\n                };\n            }\n            else if (scheme === 'ipfs') {\n                const cid = CID.parse(parts[2]);\n                const path = parts.slice(3).join('/');\n                return {\n                    cid,\n                    path\n                };\n            }\n        }\n        catch (err) {\n            log.error('error parsing ipfs path', err);\n        }\n        log.error('invalid ipfs path %s', ipfsPath);\n        throw new InvalidValueError('Invalid value');\n    }\n    async #findIpnsRecord(routingKey, options = {}) {\n        const records = [];\n        const cached = await this.localStore.has(routingKey, options);\n        if (cached) {\n            log('record is present in the cache');\n            if (options.nocache !== true) {\n                try {\n                    // check the local cache first\n                    const { record, created } = await this.localStore.get(routingKey, options);\n                    this.log('record retrieved from cache');\n                    // validate the record\n                    await ipnsValidator(routingKey, record);\n                    this.log('record was valid');\n                    // check the TTL\n                    const ipnsRecord = unmarshalIPNSRecord(record);\n                    // IPNS TTL is in nanoseconds, convert to milliseconds, default to one\n                    // hour\n                    const ttlMs = Number((ipnsRecord.ttl ?? DEFAULT_TTL_NS) / 1000000n);\n                    const ttlExpires = created.getTime() + ttlMs;\n                    if (ttlExpires > Date.now()) {\n                        // the TTL has not yet expired, return the cached record\n                        this.log('record TTL was valid');\n                        return ipnsRecord;\n                    }\n                    if (options.offline === true) {\n                        // the TTL has expired but we are skipping the routing search\n                        this.log('record TTL has been reached but we are resolving offline-only, returning record');\n                        return ipnsRecord;\n                    }\n                    this.log('record TTL has been reached, searching routing for updates');\n                    // add the local record to our list of resolved record, and also\n                    // search the routing for updates - the most up to date record will be\n                    // returned\n                    records.push(record);\n                }\n                catch (err) {\n                    this.log('cached record was invalid', err);\n                    await this.localStore.delete(routingKey, options);\n                }\n            }\n            else {\n                log('ignoring local cache due to nocache=true option');\n            }\n        }\n        if (options.offline === true) {\n            throw new NotFoundError('Record was not present in the cache or has expired');\n        }\n        log('did not have record locally');\n        let foundInvalid = 0;\n        await Promise.all(this.routers.map(async (router) => {\n            let record;\n            try {\n                record = await router.get(routingKey, {\n                    ...options,\n                    validate: false\n                });\n            }\n            catch (err) {\n                log.error('error finding IPNS record', err);\n                return;\n            }\n            try {\n                await ipnsValidator(routingKey, record);\n                records.push(record);\n            }\n            catch (err) {\n                // we found a record, but the validator rejected it\n                foundInvalid++;\n                log.error('error finding IPNS record', err);\n            }\n        }));\n        if (records.length === 0) {\n            if (foundInvalid > 0) {\n                throw new RecordsFailedValidationError(`${foundInvalid > 1 ? `${foundInvalid} records` : 'Record'} found for routing key ${foundInvalid > 1 ? 'were' : 'was'} invalid`);\n            }\n            throw new NotFoundError('Could not find record for routing key');\n        }\n        const record = records[ipnsSelector(routingKey, records)];\n        await this.localStore.put(routingKey, record, options);\n        return unmarshalIPNSRecord(record);\n    }\n}\nexport function ipns(components, { routers = [] } = {}) {\n    return new DefaultIPNS(components, routers);\n}\nexport { ipnsValidator };\nexport { ipnsSelector } from 'ipns/selector';\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Return the last value from an (async)iterable.\n *\n * @example\n *\n * ```javascript\n * import last from 'it-last'\n *\n * // This can also be an iterator, generator, etc\n * const values = [0, 1, 2, 3, 4]\n *\n * const res = last(values)\n *\n * console.info(res) // 4\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import last from 'it-last'\n *\n * const values = async function * () {\n *   yield * [0, 1, 2, 3, 4]\n * }\n *\n * const res = await last(values())\n *\n * console.info(res) // 4\n * ```\n */\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction last(source) {\n    if (isAsyncIterable(source)) {\n        return (async () => {\n            let res;\n            for await (const entry of source) {\n                res = entry;\n            }\n            return res;\n        })();\n    }\n    let res;\n    for (const entry of source) {\n        res = entry;\n    }\n    return res;\n}\nexport default last;\n//# sourceMappingURL=index.js.map","export class BadPathError extends Error {\n    static name = 'BadPathError';\n    static code = 'ERR_BAD_PATH';\n    name = BadPathError.name;\n    code = BadPathError.code;\n    constructor(message = 'Bad path') {\n        super(message);\n    }\n}\nexport class NotFoundError extends Error {\n    static name = 'NotFoundError';\n    static code = 'ERR_NOT_FOUND';\n    name = NotFoundError.name;\n    code = NotFoundError.code;\n    constructor(message = 'Not found') {\n        super(message);\n    }\n}\nexport class NoResolverError extends Error {\n    static name = 'NoResolverError';\n    static code = 'ERR_NO_RESOLVER';\n    name = NoResolverError.name;\n    code = NoResolverError.code;\n    constructor(message = 'No resolver') {\n        super(message);\n    }\n}\nexport class NotUnixFSError extends Error {\n    static name = 'NotUnixFSError';\n    static code = 'ERR_NOT_UNIXFS';\n    name = NotUnixFSError.name;\n    code = NotUnixFSError.code;\n    constructor(message = 'Not UnixFS') {\n        super(message);\n    }\n}\nexport class OverReadError extends Error {\n    static name = 'OverReadError';\n    static code = 'ERR_OVER_READ';\n    name = OverReadError.name;\n    code = OverReadError.code;\n    constructor(message = 'Over read') {\n        super(message);\n    }\n}\nexport class UnderReadError extends Error {\n    static name = 'UnderReadError';\n    static code = 'ERR_UNDER_READ';\n    name = UnderReadError.name;\n    code = UnderReadError.code;\n    constructor(message = 'Under read') {\n        super(message);\n    }\n}\nexport class NoPropError extends Error {\n    static name = 'NoPropError';\n    static code = 'ERR_NO_PROP';\n    name = NoPropError.name;\n    code = NoPropError.code;\n    constructor(message = 'No Property found') {\n        super(message);\n    }\n}\nexport class InvalidParametersError extends Error {\n    static name = 'InvalidParametersError';\n    static code = 'ERR_INVALID_PARAMS';\n    name = InvalidParametersError.name;\n    code = InvalidParametersError.code;\n    constructor(message = 'Invalid parameters') {\n        super(message);\n    }\n}\n//# sourceMappingURL=errors.js.map","import { CID } from 'multiformats/cid';\nimport { NoPropError } from '../errors.js';\nexport function resolveObjectPath(object, block, cid, name, path, toResolve, depth) {\n    let subObject = object;\n    let subPath = path;\n    while (toResolve.length > 0) {\n        const prop = toResolve[0];\n        if (prop in subObject) {\n            // remove the bit of the path we have resolved\n            toResolve.shift();\n            subPath = `${subPath}/${prop}`;\n            const subObjectCid = CID.asCID(subObject[prop]);\n            if (subObjectCid != null) {\n                return {\n                    entry: {\n                        type: 'object',\n                        name,\n                        path,\n                        cid,\n                        node: block,\n                        depth,\n                        size: BigInt(block.length),\n                        content: async function* () {\n                            yield object;\n                        }\n                    },\n                    next: {\n                        cid: subObjectCid,\n                        name: prop,\n                        path: subPath,\n                        toResolve\n                    }\n                };\n            }\n            subObject = subObject[prop];\n        }\n        else {\n            // cannot resolve further\n            throw new NoPropError(`No property named ${prop} found in node ${cid}`);\n        }\n    }\n    return {\n        entry: {\n            type: 'object',\n            name,\n            path,\n            cid,\n            node: block,\n            depth,\n            size: BigInt(block.length),\n            content: async function* () {\n                yield object;\n            }\n        }\n    };\n}\n//# sourceMappingURL=resolve-object-path.js.map","import * as dagCbor from '@ipld/dag-cbor';\nimport { resolveObjectPath } from '../utils/resolve-object-path.js';\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n    const block = await blockstore.get(cid, options);\n    const object = dagCbor.decode(block);\n    return resolveObjectPath(object, block, cid, name, path, toResolve, depth);\n};\nexport default resolve;\n//# sourceMappingURL=dag-cbor.js.map","import * as dagJson from '@ipld/dag-json';\nimport { resolveObjectPath } from '../utils/resolve-object-path.js';\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n    const block = await blockstore.get(cid, options);\n    const object = dagJson.decode(block);\n    return resolveObjectPath(object, block, cid, name, path, toResolve, depth);\n};\nexport default resolve;\n//# sourceMappingURL=dag-json.js.map","function extractDataFromBlock(block, blockStart, requestedStart, requestedEnd) {\n    const blockLength = BigInt(block.length);\n    const blockEnd = BigInt(blockStart + blockLength);\n    if (requestedStart >= blockEnd || requestedEnd < blockStart) {\n        // If we are looking for a byte range that is starts after the start of the block,\n        // return an empty block.  This can happen when internal nodes contain data\n        return new Uint8Array(0);\n    }\n    if (requestedEnd >= blockStart && requestedEnd < blockEnd) {\n        // If the end byte is in the current block, truncate the block to the end byte\n        block = block.subarray(0, Number(requestedEnd - blockStart));\n    }\n    if (requestedStart >= blockStart && requestedStart < blockEnd) {\n        // If the start byte is in the current block, skip to the start byte\n        block = block.subarray(Number(requestedStart - blockStart));\n    }\n    return block;\n}\nexport default extractDataFromBlock;\n//# sourceMappingURL=extract-data-from-block.js.map","import { InvalidParametersError } from '../errors.js';\nconst validateOffsetAndLength = (size, offset = 0, length = size) => {\n    const fileSize = BigInt(size);\n    const start = BigInt(offset ?? 0);\n    let end = BigInt(length);\n    if (end !== fileSize) {\n        end = start + end;\n    }\n    if (end > fileSize) {\n        end = fileSize;\n    }\n    if (start < 0n) {\n        throw new InvalidParametersError('Offset must be greater than or equal to 0');\n    }\n    if (start > fileSize) {\n        throw new InvalidParametersError('Offset must be less than the file size');\n    }\n    if (end < 0n) {\n        throw new InvalidParametersError('Length must be greater than or equal to 0');\n    }\n    if (end > fileSize) {\n        throw new InvalidParametersError('Length must be less than the file size');\n    }\n    return {\n        start,\n        end\n    };\n};\nexport default validateOffsetAndLength;\n//# sourceMappingURL=validate-offset-and-length.js.map","import * as mh from 'multiformats/hashes/digest';\nimport { CustomProgressEvent } from 'progress-events';\nimport { NotFoundError } from '../errors.js';\nimport extractDataFromBlock from '../utils/extract-data-from-block.js';\nimport validateOffsetAndLength from '../utils/validate-offset-and-length.js';\nconst rawContent = (node) => {\n    async function* contentGenerator(options = {}) {\n        const { start, end } = validateOffsetAndLength(node.length, options.offset, options.length);\n        const buf = extractDataFromBlock(node, 0n, start, end);\n        options.onProgress?.(new CustomProgressEvent('unixfs:exporter:progress:identity', {\n            bytesRead: BigInt(buf.byteLength),\n            totalBytes: end - start,\n            fileSize: BigInt(node.byteLength)\n        }));\n        yield buf;\n    }\n    return contentGenerator;\n};\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n    if (toResolve.length > 0) {\n        throw new NotFoundError(`No link named ${path} found in raw node ${cid}`);\n    }\n    const buf = mh.decode(cid.multihash.bytes);\n    return {\n        entry: {\n            type: 'identity',\n            name,\n            path,\n            cid,\n            content: rawContent(buf.digest),\n            depth,\n            size: BigInt(buf.digest.length),\n            node: buf.digest\n        }\n    };\n};\nexport default resolve;\n//# sourceMappingURL=identity.js.map","import * as json from 'multiformats/codecs/json';\nimport { resolveObjectPath } from '../utils/resolve-object-path.js';\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n    const block = await blockstore.get(cid, options);\n    const object = json.decode(block);\n    return resolveObjectPath(object, block, cid, name, path, toResolve, depth);\n};\nexport default resolve;\n//# sourceMappingURL=json.js.map","import { CustomProgressEvent } from 'progress-events';\nimport { NotFoundError } from '../errors.js';\nimport extractDataFromBlock from '../utils/extract-data-from-block.js';\nimport validateOffsetAndLength from '../utils/validate-offset-and-length.js';\nconst rawContent = (node) => {\n    async function* contentGenerator(options = {}) {\n        const { start, end } = validateOffsetAndLength(node.length, options.offset, options.length);\n        const buf = extractDataFromBlock(node, 0n, start, end);\n        options.onProgress?.(new CustomProgressEvent('unixfs:exporter:progress:raw', {\n            bytesRead: BigInt(buf.byteLength),\n            totalBytes: end - start,\n            fileSize: BigInt(node.byteLength)\n        }));\n        yield buf;\n    }\n    return contentGenerator;\n};\nconst resolve = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n    if (toResolve.length > 0) {\n        throw new NotFoundError(`No link named ${path} found in raw node ${cid}`);\n    }\n    const block = await blockstore.get(cid, options);\n    return {\n        entry: {\n            type: 'raw',\n            name,\n            path,\n            cid,\n            content: rawContent(block),\n            depth,\n            size: BigInt(block.length),\n            node: block\n        }\n    };\n};\nexport default resolve;\n//# sourceMappingURL=raw.js.map","export class InvalidTypeError extends Error {\n    static name = 'InvalidTypeError';\n    static code = 'ERR_INVALID_TYPE';\n    name = InvalidTypeError.name;\n    code = InvalidTypeError.code;\n    constructor(message = 'Invalid type') {\n        super(message);\n    }\n}\n//# sourceMappingURL=errors.js.map","/* eslint-disable import/export */\n/* eslint-disable complexity */\n/* eslint-disable @typescript-eslint/no-namespace */\n/* eslint-disable @typescript-eslint/no-unnecessary-boolean-literal-compare */\n/* eslint-disable @typescript-eslint/no-empty-interface */\nimport { enumeration, encodeMessage, decodeMessage, message } from 'protons-runtime';\nexport var Data;\n(function (Data) {\n    let DataType;\n    (function (DataType) {\n        DataType[\"Raw\"] = \"Raw\";\n        DataType[\"Directory\"] = \"Directory\";\n        DataType[\"File\"] = \"File\";\n        DataType[\"Metadata\"] = \"Metadata\";\n        DataType[\"Symlink\"] = \"Symlink\";\n        DataType[\"HAMTShard\"] = \"HAMTShard\";\n    })(DataType = Data.DataType || (Data.DataType = {}));\n    let __DataTypeValues;\n    (function (__DataTypeValues) {\n        __DataTypeValues[__DataTypeValues[\"Raw\"] = 0] = \"Raw\";\n        __DataTypeValues[__DataTypeValues[\"Directory\"] = 1] = \"Directory\";\n        __DataTypeValues[__DataTypeValues[\"File\"] = 2] = \"File\";\n        __DataTypeValues[__DataTypeValues[\"Metadata\"] = 3] = \"Metadata\";\n        __DataTypeValues[__DataTypeValues[\"Symlink\"] = 4] = \"Symlink\";\n        __DataTypeValues[__DataTypeValues[\"HAMTShard\"] = 5] = \"HAMTShard\";\n    })(__DataTypeValues || (__DataTypeValues = {}));\n    (function (DataType) {\n        DataType.codec = () => {\n            return enumeration(__DataTypeValues);\n        };\n    })(DataType = Data.DataType || (Data.DataType = {}));\n    let _codec;\n    Data.codec = () => {\n        if (_codec == null) {\n            _codec = message((obj, w, opts = {}) => {\n                if (opts.lengthDelimited !== false) {\n                    w.fork();\n                }\n                if (obj.Type != null) {\n                    w.uint32(8);\n                    Data.DataType.codec().encode(obj.Type, w);\n                }\n                if (obj.Data != null) {\n                    w.uint32(18);\n                    w.bytes(obj.Data);\n                }\n                if (obj.filesize != null) {\n                    w.uint32(24);\n                    w.uint64(obj.filesize);\n                }\n                if (obj.blocksizes != null) {\n                    for (const value of obj.blocksizes) {\n                        w.uint32(32);\n                        w.uint64(value);\n                    }\n                }\n                if (obj.hashType != null) {\n                    w.uint32(40);\n                    w.uint64(obj.hashType);\n                }\n                if (obj.fanout != null) {\n                    w.uint32(48);\n                    w.uint64(obj.fanout);\n                }\n                if (obj.mode != null) {\n                    w.uint32(56);\n                    w.uint32(obj.mode);\n                }\n                if (obj.mtime != null) {\n                    w.uint32(66);\n                    UnixTime.codec().encode(obj.mtime, w);\n                }\n                if (opts.lengthDelimited !== false) {\n                    w.ldelim();\n                }\n            }, (reader, length) => {\n                const obj = {\n                    blocksizes: []\n                };\n                const end = length == null ? reader.len : reader.pos + length;\n                while (reader.pos < end) {\n                    const tag = reader.uint32();\n                    switch (tag >>> 3) {\n                        case 1:\n                            obj.Type = Data.DataType.codec().decode(reader);\n                            break;\n                        case 2:\n                            obj.Data = reader.bytes();\n                            break;\n                        case 3:\n                            obj.filesize = reader.uint64();\n                            break;\n                        case 4:\n                            obj.blocksizes.push(reader.uint64());\n                            break;\n                        case 5:\n                            obj.hashType = reader.uint64();\n                            break;\n                        case 6:\n                            obj.fanout = reader.uint64();\n                            break;\n                        case 7:\n                            obj.mode = reader.uint32();\n                            break;\n                        case 8:\n                            obj.mtime = UnixTime.codec().decode(reader, reader.uint32());\n                            break;\n                        default:\n                            reader.skipType(tag & 7);\n                            break;\n                    }\n                }\n                return obj;\n            });\n        }\n        return _codec;\n    };\n    Data.encode = (obj) => {\n        return encodeMessage(obj, Data.codec());\n    };\n    Data.decode = (buf) => {\n        return decodeMessage(buf, Data.codec());\n    };\n})(Data || (Data = {}));\nexport var UnixTime;\n(function (UnixTime) {\n    let _codec;\n    UnixTime.codec = () => {\n        if (_codec == null) {\n            _codec = message((obj, w, opts = {}) => {\n                if (opts.lengthDelimited !== false) {\n                    w.fork();\n                }\n                if (obj.Seconds != null) {\n                    w.uint32(8);\n                    w.int64(obj.Seconds);\n                }\n                if (obj.FractionalNanoseconds != null) {\n                    w.uint32(21);\n                    w.fixed32(obj.FractionalNanoseconds);\n                }\n                if (opts.lengthDelimited !== false) {\n                    w.ldelim();\n                }\n            }, (reader, length) => {\n                const obj = {};\n                const end = length == null ? reader.len : reader.pos + length;\n                while (reader.pos < end) {\n                    const tag = reader.uint32();\n                    switch (tag >>> 3) {\n                        case 1:\n                            obj.Seconds = reader.int64();\n                            break;\n                        case 2:\n                            obj.FractionalNanoseconds = reader.fixed32();\n                            break;\n                        default:\n                            reader.skipType(tag & 7);\n                            break;\n                    }\n                }\n                return obj;\n            });\n        }\n        return _codec;\n    };\n    UnixTime.encode = (obj) => {\n        return encodeMessage(obj, UnixTime.codec());\n    };\n    UnixTime.decode = (buf) => {\n        return decodeMessage(buf, UnixTime.codec());\n    };\n})(UnixTime || (UnixTime = {}));\nexport var Metadata;\n(function (Metadata) {\n    let _codec;\n    Metadata.codec = () => {\n        if (_codec == null) {\n            _codec = message((obj, w, opts = {}) => {\n                if (opts.lengthDelimited !== false) {\n                    w.fork();\n                }\n                if (obj.MimeType != null) {\n                    w.uint32(10);\n                    w.string(obj.MimeType);\n                }\n                if (opts.lengthDelimited !== false) {\n                    w.ldelim();\n                }\n            }, (reader, length) => {\n                const obj = {};\n                const end = length == null ? reader.len : reader.pos + length;\n                while (reader.pos < end) {\n                    const tag = reader.uint32();\n                    switch (tag >>> 3) {\n                        case 1:\n                            obj.MimeType = reader.string();\n                            break;\n                        default:\n                            reader.skipType(tag & 7);\n                            break;\n                    }\n                }\n                return obj;\n            });\n        }\n        return _codec;\n    };\n    Metadata.encode = (obj) => {\n        return encodeMessage(obj, Metadata.codec());\n    };\n    Metadata.decode = (buf) => {\n        return decodeMessage(buf, Metadata.codec());\n    };\n})(Metadata || (Metadata = {}));\n//# sourceMappingURL=unixfs.js.map","/**\n * @packageDocumentation\n *\n * This module contains the protobuf definition of the UnixFS data structure found at the root of all UnixFS DAGs.\n *\n * The UnixFS spec can be found in the [ipfs/specs repository](http://github.com/ipfs/specs)\n *\n * @example Create a file composed of several blocks\n *\n * ```JavaScript\n * const data = new UnixFS({ type: 'file' })\n * data.addBlockSize(256) // add the size of each block\n * data.addBlockSize(256)\n * // ...\n * ```\n *\n * @example Create a directory that contains several files\n *\n * Creating a directory that contains several files is achieve by creating a unixfs element that identifies a MerkleDAG node as a directory. The links of that MerkleDAG node are the files that are contained in this directory.\n *\n * ```JavaScript\n * const data = new UnixFS({ type: 'directory' })\n * ```\n *\n * @example Create an unixfs Data element\n *\n * ```JavaScript\n * const data = new UnixFS([options])\n * ```\n *\n * `options` is an optional object argument that might include the following keys:\n *\n * - type (string, default `file`): The type of UnixFS entry.  Can be:\n *   - `raw`\n *   - `directory`\n *   - `file`\n *   - `metadata`\n *   - `symlink`\n *   - `hamt-sharded-directory`\n * - data (Uint8Array): The optional data field for this node\n * - blockSizes (Array, default: `[]`): If this is a `file` node that is made up of multiple blocks, `blockSizes` is a list numbers that represent the size of the file chunks stored in each child node. It is used to calculate the total file size.\n * - mode (Number, default `0644` for files, `0755` for directories/hamt-sharded-directories) file mode\n * - mtime (`Date`, `{ secs, nsecs }`, `{ Seconds, FractionalNanoseconds }`, `[ secs, nsecs ]`): The modification time of this node\n *\n * @example Add and remove a block size to the block size list\n *\n * ```JavaScript\n * data.addBlockSize(<size in bytes>)\n * ```\n *\n * ```JavaScript\n * data.removeBlockSize(<index>)\n * ```\n *\n * @example Get total fileSize\n *\n * ```JavaScript\n * data.fileSize() // => size in bytes\n * ```\n *\n * @example Marshal and unmarshal\n *\n * ```javascript\n * const marshaled = data.marshal()\n * const unmarshaled = Unixfs.unmarshal(marshaled)\n * ```\n *\n * @example Is this UnixFS entry a directory?\n *\n * ```JavaScript\n * const dir = new Data({ type: 'directory' })\n * dir.isDirectory() // true\n *\n * const file = new Data({ type: 'file' })\n * file.isDirectory() // false\n * ```\n *\n * @example Has an mtime been set?\n *\n * If no modification time has been set, no `mtime` property will be present on the `Data` instance:\n *\n * ```JavaScript\n * const file = new Data({ type: 'file' })\n * file.mtime // undefined\n *\n * Object.prototype.hasOwnProperty.call(file, 'mtime') // false\n *\n * const dir = new Data({ type: 'dir', mtime: new Date() })\n * dir.mtime // { secs: Number, nsecs: Number }\n * ```\n */\nimport { InvalidTypeError } from './errors.js';\nimport { Data as PBData } from './unixfs.js';\nconst types = {\n    Raw: 'raw',\n    Directory: 'directory',\n    File: 'file',\n    Metadata: 'metadata',\n    Symlink: 'symlink',\n    HAMTShard: 'hamt-sharded-directory'\n};\nconst dirTypes = [\n    'directory',\n    'hamt-sharded-directory'\n];\nconst DEFAULT_FILE_MODE = parseInt('0644', 8);\nconst DEFAULT_DIRECTORY_MODE = parseInt('0755', 8);\nclass UnixFS {\n    /**\n     * Decode from protobuf https://github.com/ipfs/specs/blob/master/UNIXFS.md\n     */\n    static unmarshal(marshaled) {\n        const message = PBData.decode(marshaled);\n        const data = new UnixFS({\n            type: types[message.Type != null ? message.Type.toString() : 'File'],\n            data: message.Data,\n            blockSizes: message.blocksizes,\n            mode: message.mode,\n            mtime: message.mtime != null\n                ? {\n                    secs: message.mtime.Seconds ?? 0n,\n                    nsecs: message.mtime.FractionalNanoseconds\n                }\n                : undefined,\n            fanout: message.fanout\n        });\n        // make sure we honour the original mode\n        data._originalMode = message.mode ?? 0;\n        return data;\n    }\n    type;\n    data;\n    blockSizes;\n    hashType;\n    fanout;\n    mtime;\n    _mode;\n    _originalMode;\n    constructor(options = {\n        type: 'file'\n    }) {\n        const { type, data, blockSizes, hashType, fanout, mtime, mode } = options;\n        if (type != null && !Object.values(types).includes(type)) {\n            throw new InvalidTypeError('Type: ' + type + ' is not valid');\n        }\n        this.type = type ?? 'file';\n        this.data = data;\n        this.hashType = hashType;\n        this.fanout = fanout;\n        this.blockSizes = blockSizes ?? [];\n        this._originalMode = 0;\n        this.mode = mode;\n        this.mtime = mtime;\n    }\n    set mode(mode) {\n        if (mode == null) {\n            this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE;\n        }\n        else {\n            this._mode = (mode & 0xFFF);\n        }\n    }\n    get mode() {\n        return this._mode;\n    }\n    isDirectory() {\n        return dirTypes.includes(this.type);\n    }\n    addBlockSize(size) {\n        this.blockSizes.push(size);\n    }\n    removeBlockSize(index) {\n        this.blockSizes.splice(index, 1);\n    }\n    /**\n     * Returns `0n` for directories or `data.length + sum(blockSizes)` for everything else\n     */\n    fileSize() {\n        if (this.isDirectory()) {\n            // dirs don't have file size\n            return 0n;\n        }\n        let sum = 0n;\n        this.blockSizes.forEach((size) => {\n            sum += size;\n        });\n        if (this.data != null) {\n            sum += BigInt(this.data.length);\n        }\n        return sum;\n    }\n    /**\n     * encode to protobuf Uint8Array\n     */\n    marshal() {\n        let type;\n        switch (this.type) {\n            case 'raw':\n                type = PBData.DataType.Raw;\n                break;\n            case 'directory':\n                type = PBData.DataType.Directory;\n                break;\n            case 'file':\n                type = PBData.DataType.File;\n                break;\n            case 'metadata':\n                type = PBData.DataType.Metadata;\n                break;\n            case 'symlink':\n                type = PBData.DataType.Symlink;\n                break;\n            case 'hamt-sharded-directory':\n                type = PBData.DataType.HAMTShard;\n                break;\n            default:\n                throw new InvalidTypeError(`Type: ${type} is not valid`);\n        }\n        let data = this.data;\n        if (this.data == null || this.data.length === 0) {\n            data = undefined;\n        }\n        let mode;\n        if (this.mode != null) {\n            mode = (this._originalMode & 0xFFFFF000) | (this.mode ?? 0);\n            if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {\n                mode = undefined;\n            }\n            if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {\n                mode = undefined;\n            }\n        }\n        let mtime;\n        if (this.mtime != null) {\n            mtime = {\n                Seconds: this.mtime.secs,\n                FractionalNanoseconds: this.mtime.nsecs\n            };\n        }\n        return PBData.encode({\n            Type: type,\n            Data: data,\n            filesize: this.isDirectory() ? undefined : this.fileSize(),\n            blocksizes: this.blockSizes,\n            hashType: this.hashType,\n            fanout: this.fanout,\n            mode,\n            mtime\n        });\n    }\n}\nexport { UnixFS };\nexport * from './errors.js';\n//# sourceMappingURL=index.js.map","import { bytes } from 'multiformats'\nimport { from } from 'multiformats/hashes/hasher'\n// @ts-expect-error no types\nimport mur from 'murmurhash3js-revisited'\n\n/**\n * @param {number} number\n * @returns {Uint8Array}\n */\nfunction fromNumberTo32BitBuf (number) {\n  const bytes = new Array(4)\n  for (let i = 0; i < 4; i++) {\n    bytes[i] = number & 0xff\n    number = number >> 8\n  }\n  return new Uint8Array(bytes)\n}\n\nexport const murmur332 = from({\n  name: 'murmur3-32',\n  code: 0x23,\n  encode: (input) => fromNumberTo32BitBuf(mur.x86.hash32(input))\n})\n\nexport const murmur3128 = from({\n  name: 'murmur3-128',\n  code: 0x22,\n  encode: (input) => bytes.fromHex(mur.x64.hash128(input))\n})\n\n// A special-use 0x22 that truncates 64 bits, specifically for use in the UnixFS HAMT\nexport const murmur364 = from({\n  name: 'murmur3-x64-64',\n  code: 0x22,\n  encode: (input) => bytes.fromHex(mur.x64.hash128(input)).subarray(0, 8)\n})\n","// @ts-expect-error no types\nimport SparseArray from 'sparse-array';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nexport class Bucket {\n    _options;\n    _popCount;\n    _parent;\n    _posAtParent;\n    _children;\n    key;\n    constructor(options, parent, posAtParent = 0) {\n        this._options = options;\n        this._popCount = 0;\n        this._parent = parent;\n        this._posAtParent = posAtParent;\n        this._children = new SparseArray();\n        this.key = null;\n    }\n    async put(key, value) {\n        const place = await this._findNewBucketAndPos(key);\n        place.bucket._putAt(place, key, value);\n    }\n    async get(key) {\n        const child = await this._findChild(key);\n        if (child != null) {\n            return child.value;\n        }\n    }\n    async del(key) {\n        const place = await this._findPlace(key);\n        const child = place.bucket._at(place.pos);\n        if (child != null && child.key === key) {\n            place.bucket._delAt(place.pos);\n        }\n    }\n    leafCount() {\n        const children = this._children.compactArray();\n        return children.reduce((acc, child) => {\n            if (child instanceof Bucket) {\n                return acc + child.leafCount();\n            }\n            return acc + 1;\n        }, 0);\n    }\n    childrenCount() {\n        return this._children.length;\n    }\n    onlyChild() {\n        return this._children.get(0);\n    }\n    *eachLeafSeries() {\n        const children = this._children.compactArray();\n        for (const child of children) {\n            if (child instanceof Bucket) {\n                yield* child.eachLeafSeries();\n            }\n            else {\n                yield child;\n            }\n        }\n    }\n    serialize(map, reduce) {\n        const acc = [];\n        // serialize to a custom non-sparse representation\n        return reduce(this._children.reduce((acc, child, index) => {\n            if (child != null) {\n                if (child instanceof Bucket) {\n                    acc.push(child.serialize(map, reduce));\n                }\n                else {\n                    acc.push(map(child, index));\n                }\n            }\n            return acc;\n        }, acc));\n    }\n    async asyncTransform(asyncMap, asyncReduce) {\n        return asyncTransformBucket(this, asyncMap, asyncReduce);\n    }\n    toJSON() {\n        return this.serialize(mapNode, reduceNodes);\n    }\n    prettyPrint() {\n        return JSON.stringify(this.toJSON(), null, '  ');\n    }\n    tableSize() {\n        return Math.pow(2, this._options.bits);\n    }\n    async _findChild(key) {\n        const result = await this._findPlace(key);\n        const child = result.bucket._at(result.pos);\n        if (child instanceof Bucket) {\n            // should not be possible, this._findPlace should always\n            // return a location for a child, not a bucket\n            return undefined;\n        }\n        if (child != null && child.key === key) {\n            return child;\n        }\n    }\n    async _findPlace(key) {\n        const hashValue = this._options.hash(typeof key === 'string' ? uint8ArrayFromString(key) : key);\n        const index = await hashValue.take(this._options.bits);\n        const child = this._children.get(index);\n        if (child instanceof Bucket) {\n            return child._findPlace(hashValue);\n        }\n        return {\n            bucket: this,\n            pos: index,\n            hash: hashValue,\n            existingChild: child\n        };\n    }\n    async _findNewBucketAndPos(key) {\n        const place = await this._findPlace(key);\n        if ((place.existingChild != null) && place.existingChild.key !== key) {\n            // conflict\n            const bucket = new Bucket(this._options, place.bucket, place.pos);\n            place.bucket._putObjectAt(place.pos, bucket);\n            // put the previous value\n            const newPlace = await bucket._findPlace(place.existingChild.hash);\n            newPlace.bucket._putAt(newPlace, place.existingChild.key, place.existingChild.value);\n            return bucket._findNewBucketAndPos(place.hash);\n        }\n        // no conflict, we found the place\n        return place;\n    }\n    _putAt(place, key, value) {\n        this._putObjectAt(place.pos, {\n            key,\n            value,\n            hash: place.hash\n        });\n    }\n    _putObjectAt(pos, object) {\n        if (this._children.get(pos) == null) {\n            this._popCount++;\n        }\n        this._children.set(pos, object);\n    }\n    _delAt(pos) {\n        if (pos === -1) {\n            throw new Error('Invalid position');\n        }\n        if (this._children.get(pos) != null) {\n            this._popCount--;\n        }\n        this._children.unset(pos);\n        this._level();\n    }\n    _level() {\n        if (this._parent != null && this._popCount <= 1) {\n            if (this._popCount === 1) {\n                // remove myself from parent, replacing me with my only child\n                const onlyChild = this._children.find(exists);\n                if ((onlyChild != null) && !(onlyChild instanceof Bucket)) {\n                    const hash = onlyChild.hash;\n                    hash.untake(this._options.bits);\n                    const place = {\n                        pos: this._posAtParent,\n                        hash,\n                        bucket: this._parent\n                    };\n                    this._parent._putAt(place, onlyChild.key, onlyChild.value);\n                }\n            }\n            else {\n                this._parent._delAt(this._posAtParent);\n            }\n        }\n    }\n    _at(index) {\n        return this._children.get(index);\n    }\n}\nfunction exists(o) {\n    return Boolean(o);\n}\nfunction mapNode(node, _) {\n    return node.key;\n}\nfunction reduceNodes(nodes) {\n    return nodes;\n}\nasync function asyncTransformBucket(bucket, asyncMap, asyncReduce) {\n    const output = [];\n    for (const child of bucket._children.compactArray()) {\n        if (child instanceof Bucket) {\n            await asyncTransformBucket(child, asyncMap, asyncReduce);\n        }\n        else {\n            const mappedChildren = await asyncMap(child);\n            output.push({\n                bitField: bucket._children.bitField(),\n                children: mappedChildren\n            });\n        }\n    }\n    return asyncReduce(output);\n}\n//# sourceMappingURL=bucket.js.map","const START_MASKS = [\n    0b11111111,\n    0b11111110,\n    0b11111100,\n    0b11111000,\n    0b11110000,\n    0b11100000,\n    0b11000000,\n    0b10000000\n];\nconst STOP_MASKS = [\n    0b00000001,\n    0b00000011,\n    0b00000111,\n    0b00001111,\n    0b00011111,\n    0b00111111,\n    0b01111111,\n    0b11111111\n];\nexport class ConsumableBuffer {\n    _value;\n    _currentBytePos;\n    _currentBitPos;\n    constructor(value) {\n        this._value = value;\n        this._currentBytePos = value.length - 1;\n        this._currentBitPos = 7;\n    }\n    availableBits() {\n        return this._currentBitPos + 1 + this._currentBytePos * 8;\n    }\n    totalBits() {\n        return this._value.length * 8;\n    }\n    take(bits) {\n        let pendingBits = bits;\n        let result = 0;\n        while (pendingBits > 0 && this._haveBits()) {\n            const byte = this._value[this._currentBytePos];\n            const availableBits = this._currentBitPos + 1;\n            const taking = Math.min(availableBits, pendingBits);\n            const value = byteBitsToInt(byte, availableBits - taking, taking);\n            result = (result << taking) + value;\n            pendingBits -= taking;\n            this._currentBitPos -= taking;\n            if (this._currentBitPos < 0) {\n                this._currentBitPos = 7;\n                this._currentBytePos--;\n            }\n        }\n        return result;\n    }\n    untake(bits) {\n        this._currentBitPos += bits;\n        while (this._currentBitPos > 7) {\n            this._currentBitPos -= 8;\n            this._currentBytePos += 1;\n        }\n    }\n    _haveBits() {\n        return this._currentBytePos >= 0;\n    }\n}\nfunction byteBitsToInt(byte, start, length) {\n    const mask = maskFor(start, length);\n    return (byte & mask) >>> start;\n}\nfunction maskFor(start, length) {\n    return START_MASKS[start] & STOP_MASKS[Math.min(length + start - 1, 7)];\n}\n//# sourceMappingURL=consumable-buffer.js.map","import { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nimport { ConsumableBuffer } from './consumable-buffer.js';\nexport function wrapHash(hashFn) {\n    function hashing(value) {\n        if (value instanceof InfiniteHash) {\n            // already a hash. return it\n            return value;\n        }\n        else {\n            return new InfiniteHash(value, hashFn);\n        }\n    }\n    return hashing;\n}\nexport class InfiniteHash {\n    _value;\n    _hashFn;\n    _depth;\n    _availableBits;\n    _currentBufferIndex;\n    _buffers;\n    constructor(value, hashFn) {\n        if (!(value instanceof Uint8Array)) {\n            throw new Error('can only hash Uint8Arrays');\n        }\n        this._value = value;\n        this._hashFn = hashFn;\n        this._depth = -1;\n        this._availableBits = 0;\n        this._currentBufferIndex = 0;\n        this._buffers = [];\n    }\n    async take(bits) {\n        let pendingBits = bits;\n        while (this._availableBits < pendingBits) {\n            await this._produceMoreBits();\n        }\n        let result = 0;\n        while (pendingBits > 0) {\n            const hash = this._buffers[this._currentBufferIndex];\n            const available = Math.min(hash.availableBits(), pendingBits);\n            const took = hash.take(available);\n            result = (result << available) + took;\n            pendingBits -= available;\n            this._availableBits -= available;\n            if (hash.availableBits() === 0) {\n                this._currentBufferIndex++;\n            }\n        }\n        return result;\n    }\n    untake(bits) {\n        let pendingBits = bits;\n        while (pendingBits > 0) {\n            const hash = this._buffers[this._currentBufferIndex];\n            const availableForUntake = Math.min(hash.totalBits() - hash.availableBits(), pendingBits);\n            hash.untake(availableForUntake);\n            pendingBits -= availableForUntake;\n            this._availableBits += availableForUntake;\n            if (this._currentBufferIndex > 0 && hash.totalBits() === hash.availableBits()) {\n                this._depth--;\n                this._currentBufferIndex--;\n            }\n        }\n    }\n    async _produceMoreBits() {\n        this._depth++;\n        const value = this._depth > 0 ? uint8ArrayConcat([this._value, Uint8Array.from([this._depth])]) : this._value;\n        const hashValue = await this._hashFn(value);\n        const buffer = new ConsumableBuffer(hashValue);\n        this._buffers.push(buffer);\n        this._availableBits += buffer.availableBits();\n    }\n}\n//# sourceMappingURL=consumable-hash.js.map","/**\n * @packageDocumentation\n *\n * A [Hash Mapped Trie](https://en.wikipedia.org/wiki/Hash_array_mapped_trie) implementation for JavaScript.\n *\n * This is used by [@helia/unixfs](https://www.npmjs.com/package/@helia/unixfs) for it's HAMT-sharded directory implementation.\n *\n * @example\n *\n * ```TypeScript\n * import { createHAMT } from 'hamt-sharding'\n * import crypto from 'crypto-promise'\n *\n * // decide how to hash buffers made from keys, can return a Promise\n * const hashFn = async (buf) => {\n *   return crypto\n *     .createHash('sha256')\n *     .update(buf)\n *     .digest()\n * }\n *\n * const bucket = createHAMT({\n *   hashFn: hashFn\n * })\n *\n * await bucket.put('key', 'value')\n *\n * const output = await bucket.get('key')\n * // output === 'value'\n * ```\n */\nimport { Bucket } from './bucket.js';\nimport { wrapHash } from './consumable-hash.js';\nexport function createHAMT(options) {\n    if (options == null || options.hashFn == null) {\n        throw new Error('please define an options.hashFn');\n    }\n    const bucketOptions = {\n        bits: options.bits ?? 8,\n        hash: wrapHash(options.hashFn)\n    };\n    return new Bucket(bucketOptions);\n}\nexport { Bucket };\n//# sourceMappingURL=index.js.map","import { decode } from '@ipld/dag-pb';\nimport { murmur3128 } from '@multiformats/murmur3';\nimport { Bucket, createHAMT } from 'hamt-sharding';\nimport { UnixFS } from 'ipfs-unixfs';\nimport { NotUnixFSError } from '../errors.js';\n// FIXME: this is copy/pasted from ipfs-unixfs-importer/src/options.js\nconst hashFn = async function (buf) {\n    return (await murmur3128.encode(buf))\n        // Murmur3 outputs 128 bit but, accidentally, IPFS Go's\n        // implementation only uses the first 64, so we must do the same\n        // for parity..\n        .slice(0, 8)\n        // Invert buffer because that's how Go impl does it\n        .reverse();\n};\nconst addLinksToHamtBucket = async (links, bucket, rootBucket) => {\n    const padLength = (bucket.tableSize() - 1).toString(16).length;\n    await Promise.all(links.map(async (link) => {\n        if (link.Name == null) {\n            // TODO(@rvagg): what do? this is technically possible\n            throw new Error('Unexpected Link without a Name');\n        }\n        if (link.Name.length === padLength) {\n            const pos = parseInt(link.Name, 16);\n            bucket._putObjectAt(pos, new Bucket({\n                hash: rootBucket._options.hash,\n                bits: rootBucket._options.bits\n            }, bucket, pos));\n            return;\n        }\n        await rootBucket.put(link.Name.substring(2), true);\n    }));\n};\nconst toPrefix = (position, padLength) => {\n    return position\n        .toString(16)\n        .toUpperCase()\n        .padStart(padLength, '0')\n        .substring(0, padLength);\n};\nconst toBucketPath = (position) => {\n    let bucket = position.bucket;\n    const path = [];\n    while (bucket._parent != null) {\n        path.push(bucket);\n        bucket = bucket._parent;\n    }\n    path.push(bucket);\n    return path.reverse();\n};\nconst findShardCid = async (node, name, blockstore, context, options) => {\n    if (context == null) {\n        if (node.Data == null) {\n            throw new NotUnixFSError('no data in PBNode');\n        }\n        let dir;\n        try {\n            dir = UnixFS.unmarshal(node.Data);\n        }\n        catch (err) {\n            throw new NotUnixFSError(err.message);\n        }\n        if (dir.type !== 'hamt-sharded-directory') {\n            throw new NotUnixFSError('not a HAMT');\n        }\n        if (dir.fanout == null) {\n            throw new NotUnixFSError('missing fanout');\n        }\n        const rootBucket = createHAMT({\n            hashFn,\n            bits: Math.log2(Number(dir.fanout))\n        });\n        context = {\n            rootBucket,\n            hamtDepth: 1,\n            lastBucket: rootBucket\n        };\n    }\n    const padLength = (context.lastBucket.tableSize() - 1).toString(16).length;\n    await addLinksToHamtBucket(node.Links, context.lastBucket, context.rootBucket);\n    const position = await context.rootBucket._findNewBucketAndPos(name);\n    let prefix = toPrefix(position.pos, padLength);\n    const bucketPath = toBucketPath(position);\n    if (bucketPath.length > context.hamtDepth) {\n        context.lastBucket = bucketPath[context.hamtDepth];\n        prefix = toPrefix(context.lastBucket._posAtParent, padLength);\n    }\n    const link = node.Links.find(link => {\n        if (link.Name == null) {\n            return false;\n        }\n        const entryPrefix = link.Name.substring(0, padLength);\n        const entryName = link.Name.substring(padLength);\n        if (entryPrefix !== prefix) {\n            // not the entry or subshard we're looking for\n            return false;\n        }\n        if (entryName !== '' && entryName !== name) {\n            // not the entry we're looking for\n            return false;\n        }\n        return true;\n    });\n    if (link == null) {\n        return;\n    }\n    if (link.Name != null && link.Name.substring(padLength) === name) {\n        return link.Hash;\n    }\n    context.hamtDepth++;\n    const block = await blockstore.get(link.Hash, options);\n    node = decode(block);\n    return findShardCid(node, name, blockstore, context, options);\n};\nexport default findShardCid;\n//# sourceMappingURL=find-cid-in-shard.js.map","/**\n * @packageDocumentation\n *\n * Takes an (async) iterable that emits promise-returning functions, invokes them in parallel up to the concurrency limit and emits the results as they become available, optionally in the same order as the input\n *\n * @example\n *\n * ```javascript\n * import parallel from 'it-parallel'\n * import all from 'it-all'\n * import delay from 'delay'\n *\n * // This can also be an iterator, async iterator, generator, etc\n * const input = [\n *   async () => {\n *     console.info('start 1')\n *     await delay(500)\n *\n *     console.info('end 1')\n *     return 1\n *   },\n *   async () => {\n *     console.info('start 2')\n *     await delay(200)\n *\n *     console.info('end 2')\n *     return 2\n *   },\n *   async () => {\n *     console.info('start 3')\n *     await delay(100)\n *\n *     console.info('end 3')\n *     return 3\n *   }\n * ]\n *\n * const result = await all(parallel(input, {\n *   concurrency: 2\n * }))\n *\n * // output:\n * // start 1\n * // start 2\n * // end 2\n * // start 3\n * // end 3\n * // end 1\n *\n * console.info(result) // [2, 3, 1]\n * ```\n *\n * If order is important, pass `ordered: true` as an option:\n *\n * ```javascript\n * const result = await all(parallel(input, {\n *   concurrency: 2,\n *   ordered: true\n * }))\n *\n * // output:\n * // start 1\n * // start 2\n * // end 2\n * // start 3\n * // end 3\n * // end 1\n *\n * console.info(result) // [1, 2, 3]\n * ```\n */\nimport defer from 'p-defer';\nconst CustomEvent = globalThis.CustomEvent ?? Event;\n/**\n * Takes an (async) iterator that emits promise-returning functions,\n * invokes them in parallel and emits the results as they become available but\n * in the same order as the input\n */\nexport default async function* parallel(source, options = {}) {\n    let concurrency = options.concurrency ?? Infinity;\n    if (concurrency < 1) {\n        concurrency = Infinity;\n    }\n    const ordered = options.ordered == null ? false : options.ordered;\n    const emitter = new EventTarget();\n    const ops = [];\n    let slotAvailable = defer();\n    let resultAvailable = defer();\n    let sourceFinished = false;\n    let sourceErr;\n    let opErred = false;\n    emitter.addEventListener('task-complete', () => {\n        resultAvailable.resolve();\n    });\n    void Promise.resolve().then(async () => {\n        try {\n            for await (const task of source) {\n                if (ops.length === concurrency) {\n                    slotAvailable = defer();\n                    await slotAvailable.promise;\n                }\n                if (opErred) {\n                    break;\n                }\n                const op = {\n                    done: false\n                };\n                ops.push(op);\n                task()\n                    .then(result => {\n                    op.done = true;\n                    op.ok = true;\n                    op.value = result;\n                    emitter.dispatchEvent(new CustomEvent('task-complete'));\n                }, err => {\n                    op.done = true;\n                    op.err = err;\n                    emitter.dispatchEvent(new CustomEvent('task-complete'));\n                });\n            }\n            sourceFinished = true;\n            emitter.dispatchEvent(new CustomEvent('task-complete'));\n        }\n        catch (err) {\n            sourceErr = err;\n            emitter.dispatchEvent(new CustomEvent('task-complete'));\n        }\n    });\n    function valuesAvailable() {\n        if (ordered) {\n            return ops[0]?.done;\n        }\n        return Boolean(ops.find(op => op.done));\n    }\n    function* yieldOrderedValues() {\n        while ((ops.length > 0) && ops[0].done) {\n            const op = ops[0];\n            ops.shift();\n            if (op.ok) {\n                yield op.value;\n            }\n            else {\n                // allow the source to exit\n                opErred = true;\n                slotAvailable.resolve();\n                throw op.err;\n            }\n            slotAvailable.resolve();\n        }\n    }\n    function* yieldUnOrderedValues() {\n        // more values can become available while we wait for `yield`\n        // to return control to this function\n        while (valuesAvailable()) {\n            for (let i = 0; i < ops.length; i++) {\n                if (ops[i].done) {\n                    const op = ops[i];\n                    ops.splice(i, 1);\n                    i--;\n                    if (op.ok) {\n                        yield op.value;\n                    }\n                    else {\n                        opErred = true;\n                        slotAvailable.resolve();\n                        throw op.err;\n                    }\n                    slotAvailable.resolve();\n                }\n            }\n        }\n    }\n    while (true) {\n        if (!valuesAvailable()) {\n            resultAvailable = defer();\n            await resultAvailable.promise;\n        }\n        if (sourceErr != null) {\n            // the source threw an error, propagate it\n            throw sourceErr;\n        }\n        if (ordered) {\n            yield* yieldOrderedValues();\n        }\n        else {\n            yield* yieldUnOrderedValues();\n        }\n        if (sourceFinished && ops.length === 0) {\n            // not waiting for any results and no more tasks so we are done\n            break;\n        }\n    }\n}\n//# sourceMappingURL=index.js.map","import filter from 'it-filter';\nimport map from 'it-map';\nimport parallel from 'it-parallel';\nimport { pipe } from 'it-pipe';\nimport { CustomProgressEvent } from 'progress-events';\nconst directoryContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n    async function* yieldDirectoryContent(options = {}) {\n        const offset = options.offset ?? 0;\n        const length = options.length ?? node.Links.length;\n        const links = node.Links.slice(offset, length);\n        options.onProgress?.(new CustomProgressEvent('unixfs:exporter:walk:directory', {\n            cid\n        }));\n        yield* pipe(links, source => map(source, link => {\n            return async () => {\n                const linkName = link.Name ?? '';\n                const linkPath = `${path}/${linkName}`;\n                const result = await resolve(link.Hash, linkName, linkPath, [], depth + 1, blockstore, options);\n                return result.entry;\n            };\n        }), source => parallel(source, {\n            ordered: true,\n            concurrency: options.blockReadConcurrency\n        }), source => filter(source, entry => entry != null));\n    }\n    return yieldDirectoryContent;\n};\nexport default directoryContent;\n//# sourceMappingURL=directory.js.map","import * as dagPb from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport map from 'it-map';\nimport parallel from 'it-parallel';\nimport { pipe } from 'it-pipe';\nimport { pushable } from 'it-pushable';\nimport * as raw from 'multiformats/codecs/raw';\nimport PQueue from 'p-queue';\nimport { CustomProgressEvent } from 'progress-events';\nimport { NotUnixFSError, OverReadError, UnderReadError } from '../../../errors.js';\nimport extractDataFromBlock from '../../../utils/extract-data-from-block.js';\nimport validateOffsetAndLength from '../../../utils/validate-offset-and-length.js';\nasync function walkDAG(blockstore, node, queue, streamPosition, start, end, options) {\n    // a `raw` node\n    if (node instanceof Uint8Array) {\n        const buf = extractDataFromBlock(node, streamPosition, start, end);\n        queue.push(buf);\n        return;\n    }\n    if (node.Data == null) {\n        throw new NotUnixFSError('no data in PBNode');\n    }\n    let file;\n    try {\n        file = UnixFS.unmarshal(node.Data);\n    }\n    catch (err) {\n        throw new NotUnixFSError(err.message);\n    }\n    // might be a unixfs `raw` node or have data on intermediate nodes\n    if (file.data != null) {\n        const data = file.data;\n        const buf = extractDataFromBlock(data, streamPosition, start, end);\n        queue.push(buf);\n        streamPosition += BigInt(buf.byteLength);\n    }\n    const childOps = [];\n    if (node.Links.length !== file.blockSizes.length) {\n        throw new NotUnixFSError('Inconsistent block sizes and dag links');\n    }\n    for (let i = 0; i < node.Links.length; i++) {\n        const childLink = node.Links[i];\n        const childStart = streamPosition; // inclusive\n        const childEnd = childStart + file.blockSizes[i]; // exclusive\n        if ((start >= childStart && start < childEnd) || // child has offset byte\n            (end >= childStart && end <= childEnd) || // child has end byte\n            (start < childStart && end > childEnd)) { // child is between offset and end bytes\n            childOps.push({\n                link: childLink,\n                blockStart: streamPosition\n            });\n        }\n        streamPosition = childEnd;\n        if (streamPosition > end) {\n            break;\n        }\n    }\n    await pipe(childOps, (source) => map(source, (op) => {\n        return async () => {\n            const block = await blockstore.get(op.link.Hash, options);\n            return {\n                ...op,\n                block\n            };\n        };\n    }), (source) => parallel(source, {\n        ordered: true,\n        concurrency: options.blockReadConcurrency\n    }), async (source) => {\n        for await (const { link, block, blockStart } of source) {\n            let child;\n            switch (link.Hash.code) {\n                case dagPb.code:\n                    child = dagPb.decode(block);\n                    break;\n                case raw.code:\n                    child = block;\n                    break;\n                default:\n                    queue.end(new NotUnixFSError(`Unsupported codec: ${link.Hash.code}`));\n                    return;\n            }\n            // create a queue for this child - we use a queue instead of recursion\n            // to avoid overflowing the stack\n            const childQueue = new PQueue({\n                concurrency: 1\n            });\n            // if any of the child jobs error, end the read queue with the error\n            childQueue.on('error', error => {\n                queue.end(error);\n            });\n            // if the job rejects the 'error' event will be emitted on the child queue\n            void childQueue.add(async () => {\n                options.onProgress?.(new CustomProgressEvent('unixfs:exporter:walk:file', {\n                    cid: link.Hash\n                }));\n                await walkDAG(blockstore, child, queue, blockStart, start, end, options);\n            });\n            // wait for this child to complete before moving on to the next\n            await childQueue.onIdle();\n        }\n    });\n    if (streamPosition >= end) {\n        queue.end();\n    }\n}\nconst fileContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n    async function* yieldFileContent(options = {}) {\n        const fileSize = unixfs.fileSize();\n        if (fileSize === undefined) {\n            throw new Error('File was a directory');\n        }\n        const { start, end } = validateOffsetAndLength(fileSize, options.offset, options.length);\n        if (end === 0n) {\n            return;\n        }\n        let read = 0n;\n        const wanted = end - start;\n        const queue = pushable();\n        options.onProgress?.(new CustomProgressEvent('unixfs:exporter:walk:file', {\n            cid\n        }));\n        void walkDAG(blockstore, node, queue, 0n, start, end, options)\n            .catch(err => {\n            queue.end(err);\n        });\n        for await (const buf of queue) {\n            if (buf == null) {\n                continue;\n            }\n            read += BigInt(buf.byteLength);\n            if (read > wanted) {\n                queue.end();\n                throw new OverReadError('Read too many bytes - the file size reported by the UnixFS data in the root node may be incorrect');\n            }\n            if (read === wanted) {\n                queue.end();\n            }\n            options.onProgress?.(new CustomProgressEvent('unixfs:exporter:progress:unixfs:file', {\n                bytesRead: read,\n                totalBytes: wanted,\n                fileSize\n            }));\n            yield buf;\n        }\n        if (read < wanted) {\n            throw new UnderReadError('Traversed entire DAG but did not read enough bytes');\n        }\n    }\n    return yieldFileContent;\n};\nexport default fileContent;\n//# sourceMappingURL=file.js.map","import { decode } from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport map from 'it-map';\nimport parallel from 'it-parallel';\nimport { pipe } from 'it-pipe';\nimport { CustomProgressEvent } from 'progress-events';\nimport { NotUnixFSError } from '../../../errors.js';\nconst hamtShardedDirectoryContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n    function yieldHamtDirectoryContent(options = {}) {\n        options.onProgress?.(new CustomProgressEvent('unixfs:exporter:walk:hamt-sharded-directory', {\n            cid\n        }));\n        return listDirectory(node, path, resolve, depth, blockstore, options);\n    }\n    return yieldHamtDirectoryContent;\n};\nasync function* listDirectory(node, path, resolve, depth, blockstore, options) {\n    const links = node.Links;\n    if (node.Data == null) {\n        throw new NotUnixFSError('no data in PBNode');\n    }\n    let dir;\n    try {\n        dir = UnixFS.unmarshal(node.Data);\n    }\n    catch (err) {\n        throw new NotUnixFSError(err.message);\n    }\n    if (dir.fanout == null) {\n        throw new NotUnixFSError('missing fanout');\n    }\n    const padLength = (dir.fanout - 1n).toString(16).length;\n    const results = pipe(links, source => map(source, link => {\n        return async () => {\n            const name = link.Name != null ? link.Name.substring(padLength) : null;\n            if (name != null && name !== '') {\n                const result = await resolve(link.Hash, name, `${path}/${name}`, [], depth + 1, blockstore, options);\n                return { entries: result.entry == null ? [] : [result.entry] };\n            }\n            else {\n                // descend into subshard\n                const block = await blockstore.get(link.Hash, options);\n                node = decode(block);\n                options.onProgress?.(new CustomProgressEvent('unixfs:exporter:walk:hamt-sharded-directory', {\n                    cid: link.Hash\n                }));\n                return { entries: listDirectory(node, path, resolve, depth, blockstore, options) };\n            }\n        };\n    }), source => parallel(source, {\n        ordered: true,\n        concurrency: options.blockReadConcurrency\n    }));\n    for await (const { entries } of results) {\n        yield* entries;\n    }\n}\nexport default hamtShardedDirectoryContent;\n//# sourceMappingURL=hamt-sharded-directory.js.map","import { decode } from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport { NotFoundError, NotUnixFSError } from '../../errors.js';\nimport findShardCid from '../../utils/find-cid-in-shard.js';\nimport contentDirectory from './content/directory.js';\nimport contentFile from './content/file.js';\nimport contentHamtShardedDirectory from './content/hamt-sharded-directory.js';\nconst findLinkCid = (node, name) => {\n    const link = node.Links.find(link => link.Name === name);\n    return link?.Hash;\n};\nconst contentExporters = {\n    raw: contentFile,\n    file: contentFile,\n    directory: contentDirectory,\n    'hamt-sharded-directory': contentHamtShardedDirectory,\n    metadata: (cid, node, unixfs, path, resolve, depth, blockstore) => {\n        return () => [];\n    },\n    symlink: (cid, node, unixfs, path, resolve, depth, blockstore) => {\n        return () => [];\n    }\n};\n// @ts-expect-error types are wrong\nconst unixFsResolver = async (cid, name, path, toResolve, resolve, depth, blockstore, options) => {\n    const block = await blockstore.get(cid, options);\n    const node = decode(block);\n    let unixfs;\n    let next;\n    if (name == null) {\n        name = cid.toString();\n    }\n    if (node.Data == null) {\n        throw new NotUnixFSError('no data in PBNode');\n    }\n    try {\n        unixfs = UnixFS.unmarshal(node.Data);\n    }\n    catch (err) {\n        // non-UnixFS dag-pb node? It could happen.\n        throw new NotUnixFSError(err.message);\n    }\n    if (path == null) {\n        path = name;\n    }\n    if (toResolve.length > 0) {\n        let linkCid;\n        if (unixfs?.type === 'hamt-sharded-directory') {\n            // special case - unixfs v1 hamt shards\n            linkCid = await findShardCid(node, toResolve[0], blockstore);\n        }\n        else {\n            linkCid = findLinkCid(node, toResolve[0]);\n        }\n        if (linkCid == null) {\n            throw new NotFoundError('file does not exist');\n        }\n        // remove the path component we have resolved\n        const nextName = toResolve.shift();\n        const nextPath = `${path}/${nextName}`;\n        next = {\n            cid: linkCid,\n            toResolve,\n            name: nextName ?? '',\n            path: nextPath\n        };\n    }\n    const content = contentExporters[unixfs.type](cid, node, unixfs, path, resolve, depth, blockstore);\n    if (content == null) {\n        throw new NotFoundError('could not find content exporter');\n    }\n    if (unixfs.isDirectory()) {\n        return {\n            entry: {\n                type: 'directory',\n                name,\n                path,\n                cid,\n                content,\n                unixfs,\n                depth,\n                node,\n                size: unixfs.fileSize()\n            },\n            next\n        };\n    }\n    return {\n        entry: {\n            type: 'file',\n            name,\n            path,\n            cid,\n            content,\n            unixfs,\n            depth,\n            node,\n            size: unixfs.fileSize()\n        },\n        next\n    };\n};\nexport default unixFsResolver;\n//# sourceMappingURL=index.js.map","import * as dagCbor from '@ipld/dag-cbor';\nimport * as dagJson from '@ipld/dag-json';\nimport * as dagPb from '@ipld/dag-pb';\nimport * as json from 'multiformats/codecs/json';\nimport * as raw from 'multiformats/codecs/raw';\nimport { identity } from 'multiformats/hashes/identity';\nimport { NoResolverError } from '../errors.js';\nimport dagCborResolver from './dag-cbor.js';\nimport dagJsonResolver from './dag-json.js';\nimport identifyResolver from './identity.js';\nimport jsonResolver from './json.js';\nimport rawResolver from './raw.js';\nimport dagPbResolver from './unixfs-v1/index.js';\nconst resolvers = {\n    [dagPb.code]: dagPbResolver,\n    [raw.code]: rawResolver,\n    [dagCbor.code]: dagCborResolver,\n    [dagJson.code]: dagJsonResolver,\n    [identity.code]: identifyResolver,\n    [json.code]: jsonResolver\n};\nconst resolve = async (cid, name, path, toResolve, depth, blockstore, options) => {\n    const resolver = resolvers[cid.code];\n    if (resolver == null) {\n        throw new NoResolverError(`No resolver for code ${cid.code}`);\n    }\n    return resolver(cid, name, path, toResolve, resolve, depth, blockstore, options);\n};\nexport default resolve;\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * The UnixFS Exporter provides a means to read DAGs from a blockstore given a CID.\n *\n * @example\n *\n * ```js\n * // import a file and export it again\n * import { importer } from 'ipfs-unixfs-importer'\n * import { exporter } from 'ipfs-unixfs-exporter'\n * import { MemoryBlockstore } from 'blockstore-core/memory'\n *\n * // Should contain the blocks we are trying to export\n * const blockstore = new MemoryBlockstore()\n * const files = []\n *\n * for await (const file of importer([{\n *   path: '/foo/bar.txt',\n *   content: new Uint8Array([0, 1, 2, 3])\n * }], blockstore)) {\n *   files.push(file)\n * }\n *\n * console.info(files[0].cid) // Qmbaz\n *\n * const entry = await exporter(files[0].cid, blockstore)\n *\n * console.info(entry.cid) // Qmqux\n * console.info(entry.path) // Qmbaz/foo/bar.txt\n * console.info(entry.name) // bar.txt\n * console.info(entry.unixfs.fileSize()) // 4\n *\n * // stream content from unixfs node\n * const size = entry.unixfs.fileSize()\n * const bytes = new Uint8Array(size)\n * let offset = 0\n *\n * for await (const buf of entry.content()) {\n *   bytes.set(buf, offset)\n *   offset += chunk.length\n * }\n *\n * console.info(bytes) // 0, 1, 2, 3\n * ```\n */\nimport last from 'it-last';\nimport { CID } from 'multiformats/cid';\nimport { BadPathError, NotFoundError } from './errors.js';\nimport resolve from './resolvers/index.js';\nexport * from './errors.js';\nconst toPathComponents = (path = '') => {\n    // split on / unless escaped with \\\n    return (path\n        .trim()\n        .match(/([^\\\\^/]|\\\\\\/)+/g) ?? [])\n        .filter(Boolean);\n};\nconst cidAndRest = (path) => {\n    if (path instanceof Uint8Array) {\n        return {\n            cid: CID.decode(path),\n            toResolve: []\n        };\n    }\n    const cid = CID.asCID(path);\n    if (cid != null) {\n        return {\n            cid,\n            toResolve: []\n        };\n    }\n    if (typeof path === 'string') {\n        if (path.indexOf('/ipfs/') === 0) {\n            path = path.substring(6);\n        }\n        const output = toPathComponents(path);\n        return {\n            cid: CID.parse(output[0]),\n            toResolve: output.slice(1)\n        };\n    }\n    throw new BadPathError(`Unknown path type ${path}`);\n};\n/**\n * Returns an async iterator that yields entries for all segments in a path\n *\n * @example\n *\n * ```javascript\n * import { walkPath } from 'ipfs-unixfs-exporter'\n *\n * const entries = []\n *\n * for await (const entry of walkPath('Qmfoo/foo/bar/baz.txt', blockstore)) {\n *   entries.push(entry)\n * }\n *\n * // entries contains 4x `entry` objects\n * ```\n */\nexport async function* walkPath(path, blockstore, options = {}) {\n    let { cid, toResolve } = cidAndRest(path);\n    let name = cid.toString();\n    let entryPath = name;\n    const startingDepth = toResolve.length;\n    while (true) {\n        const result = await resolve(cid, name, entryPath, toResolve, startingDepth, blockstore, options);\n        if (result.entry == null && result.next == null) {\n            throw new NotFoundError(`Could not resolve ${path}`);\n        }\n        if (result.entry != null) {\n            yield result.entry;\n        }\n        if (result.next == null) {\n            return;\n        }\n        // resolve further parts\n        toResolve = result.next.toResolve;\n        cid = result.next.cid;\n        name = result.next.name;\n        entryPath = result.next.path;\n    }\n}\n/**\n * Uses the given blockstore instance to fetch an IPFS node by a CID or path.\n *\n * Returns a {@link Promise} which resolves to a {@link UnixFSEntry}.\n *\n * @example\n *\n * ```typescript\n * import { exporter } from 'ipfs-unixfs-exporter'\n * import { CID } from 'multiformats/cid'\n *\n * const cid = CID.parse('QmFoo')\n *\n * const entry = await exporter(cid, blockstore, {\n *   signal: AbortSignal.timeout(50000)\n * })\n *\n * if (entry.type === 'file') {\n *   for await (const chunk of entry.content()) {\n *     // chunk is a Uint8Array\n *   }\n * }\n * ```\n */\nexport async function exporter(path, blockstore, options = {}) {\n    const result = await last(walkPath(path, blockstore, options));\n    if (result == null) {\n        throw new NotFoundError(`Could not resolve ${path}`);\n    }\n    return result;\n}\n/**\n * Returns an async iterator that yields all entries beneath a given CID or IPFS\n * path, as well as the containing directory.\n *\n * @example\n *\n * ```typescript\n * import { recursive } from 'ipfs-unixfs-exporter'\n *\n * const entries = []\n *\n * for await (const child of recursive('Qmfoo/foo/bar', blockstore)) {\n *   entries.push(entry)\n * }\n *\n * // entries contains all children of the `Qmfoo/foo/bar` directory and it's children\n * ```\n */\nexport async function* recursive(path, blockstore, options = {}) {\n    const node = await exporter(path, blockstore, options);\n    if (node == null) {\n        return;\n    }\n    yield node;\n    if (node.type === 'directory') {\n        for await (const child of recurse(node, options)) {\n            yield child;\n        }\n    }\n    async function* recurse(node, options) {\n        for await (const file of node.content(options)) {\n            yield file;\n            if (file instanceof Uint8Array) {\n                continue;\n            }\n            if (file.type === 'directory') {\n                yield* recurse(file, options);\n            }\n        }\n    }\n}\n//# sourceMappingURL=index.js.map","export function getIterator(obj) {\n    if (obj != null) {\n        if (typeof obj[Symbol.iterator] === 'function') {\n            return obj[Symbol.iterator]();\n        }\n        if (typeof obj[Symbol.asyncIterator] === 'function') {\n            return obj[Symbol.asyncIterator]();\n        }\n        if (typeof obj.next === 'function') {\n            return obj; // probably an iterator\n        }\n    }\n    throw new Error('argument is not an iterator or iterable');\n}\n//# sourceMappingURL=index.js.map","/**\n * @packageDocumentation\n *\n * Turns an (async)iterable into a W3C ReadbleStream.\n *\n * @example\n *\n * ```javascript\n * import toBrowserReadableStream from 'it-to-browser-readablestream'\n *\n * // This can also be an iterator, async iterator, generator, etc\n * const values = [Buffer.from([0, 1]), Buffer.from([2, 3])]\n *\n * const stream = await toBrowserReadableStream(values)\n *\n * for await (const buf of stream) {\n *   console.info(buf) // Buffer[0, 1]\n * }\n * ```\n */\nimport { getIterator } from 'get-iterator';\n/**\n * Converts an (async) iterator into a WHATWG ReadableStream\n */\nexport default function itToBrowserReadableStream(source, queuingStrategy = {}) {\n    const iter = getIterator(source);\n    const s = {\n        _cancelled: false,\n        async start() {\n            this._cancelled = false;\n        },\n        async pull(controller) {\n            try {\n                const { value, done } = await iter.next();\n                if (this._cancelled) {\n                    return;\n                }\n                if (done === true) {\n                    controller.close();\n                    return;\n                }\n                controller.enqueue(value);\n            }\n            catch (err) {\n                controller.error(err);\n            }\n        },\n        cancel() {\n            this._cancelled = true;\n        }\n    };\n    return new globalThis.ReadableStream(s, queuingStrategy);\n}\n//# sourceMappingURL=index.js.map","/**\n * @module LRUCache\n */\nconst perf = typeof performance === 'object' &&\n    performance &&\n    typeof performance.now === 'function'\n    ? performance\n    : Date;\nconst warned = new Set();\n/* c8 ignore start */\nconst PROCESS = (typeof process === 'object' && !!process ? process : {});\n/* c8 ignore start */\nconst emitWarning = (msg, type, code, fn) => {\n    typeof PROCESS.emitWarning === 'function'\n        ? PROCESS.emitWarning(msg, type, code, fn)\n        : console.error(`[${code}] ${type}: ${msg}`);\n};\nlet AC = globalThis.AbortController;\nlet AS = globalThis.AbortSignal;\n/* c8 ignore start */\nif (typeof AC === 'undefined') {\n    //@ts-ignore\n    AS = class AbortSignal {\n        onabort;\n        _onabort = [];\n        reason;\n        aborted = false;\n        addEventListener(_, fn) {\n            this._onabort.push(fn);\n        }\n    };\n    //@ts-ignore\n    AC = class AbortController {\n        constructor() {\n            warnACPolyfill();\n        }\n        signal = new AS();\n        abort(reason) {\n            if (this.signal.aborted)\n                return;\n            //@ts-ignore\n            this.signal.reason = reason;\n            //@ts-ignore\n            this.signal.aborted = true;\n            //@ts-ignore\n            for (const fn of this.signal._onabort) {\n                fn(reason);\n            }\n            this.signal.onabort?.(reason);\n        }\n    };\n    let printACPolyfillWarning = PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1';\n    const warnACPolyfill = () => {\n        if (!printACPolyfillWarning)\n            return;\n        printACPolyfillWarning = false;\n        emitWarning('AbortController is not defined. If using lru-cache in ' +\n            'node 14, load an AbortController polyfill from the ' +\n            '`node-abort-controller` package. A minimal polyfill is ' +\n            'provided for use by LRUCache.fetch(), but it should not be ' +\n            'relied upon in other contexts (eg, passing it to other APIs that ' +\n            'use AbortController/AbortSignal might have undesirable effects). ' +\n            'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.', 'NO_ABORT_CONTROLLER', 'ENOTSUP', warnACPolyfill);\n    };\n}\n/* c8 ignore stop */\nconst shouldWarn = (code) => !warned.has(code);\nconst TYPE = Symbol('type');\nconst isPosInt = (n) => n && n === Math.floor(n) && n > 0 && isFinite(n);\n/* c8 ignore start */\n// This is a little bit ridiculous, tbh.\n// The maximum array length is 2^32-1 or thereabouts on most JS impls.\n// And well before that point, you're caching the entire world, I mean,\n// that's ~32GB of just integers for the next/prev links, plus whatever\n// else to hold that many keys and values.  Just filling the memory with\n// zeroes at init time is brutal when you get that big.\n// But why not be complete?\n// Maybe in the future, these limits will have expanded.\nconst getUintArray = (max) => !isPosInt(max)\n    ? null\n    : max <= Math.pow(2, 8)\n        ? Uint8Array\n        : max <= Math.pow(2, 16)\n            ? Uint16Array\n            : max <= Math.pow(2, 32)\n                ? Uint32Array\n                : max <= Number.MAX_SAFE_INTEGER\n                    ? ZeroArray\n                    : null;\n/* c8 ignore stop */\nclass ZeroArray extends Array {\n    constructor(size) {\n        super(size);\n        this.fill(0);\n    }\n}\nclass Stack {\n    heap;\n    length;\n    // private constructor\n    static #constructing = false;\n    static create(max) {\n        const HeapCls = getUintArray(max);\n        if (!HeapCls)\n            return [];\n        Stack.#constructing = true;\n        const s = new Stack(max, HeapCls);\n        Stack.#constructing = false;\n        return s;\n    }\n    constructor(max, HeapCls) {\n        /* c8 ignore start */\n        if (!Stack.#constructing) {\n            throw new TypeError('instantiate Stack using Stack.create(n)');\n        }\n        /* c8 ignore stop */\n        this.heap = new HeapCls(max);\n        this.length = 0;\n    }\n    push(n) {\n        this.heap[this.length++] = n;\n    }\n    pop() {\n        return this.heap[--this.length];\n    }\n}\n/**\n * Default export, the thing you're using this module to get.\n *\n * The `K` and `V` types define the key and value types, respectively. The\n * optional `FC` type defines the type of the `context` object passed to\n * `cache.fetch()` and `cache.memo()`.\n *\n * Keys and values **must not** be `null` or `undefined`.\n *\n * All properties from the options object (with the exception of `max`,\n * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are\n * added as normal public members. (The listed options are read-only getters.)\n *\n * Changing any of these will alter the defaults for subsequent method calls.\n */\nexport class LRUCache {\n    // options that cannot be changed without disaster\n    #max;\n    #maxSize;\n    #dispose;\n    #disposeAfter;\n    #fetchMethod;\n    #memoMethod;\n    /**\n     * {@link LRUCache.OptionsBase.ttl}\n     */\n    ttl;\n    /**\n     * {@link LRUCache.OptionsBase.ttlResolution}\n     */\n    ttlResolution;\n    /**\n     * {@link LRUCache.OptionsBase.ttlAutopurge}\n     */\n    ttlAutopurge;\n    /**\n     * {@link LRUCache.OptionsBase.updateAgeOnGet}\n     */\n    updateAgeOnGet;\n    /**\n     * {@link LRUCache.OptionsBase.updateAgeOnHas}\n     */\n    updateAgeOnHas;\n    /**\n     * {@link LRUCache.OptionsBase.allowStale}\n     */\n    allowStale;\n    /**\n     * {@link LRUCache.OptionsBase.noDisposeOnSet}\n     */\n    noDisposeOnSet;\n    /**\n     * {@link LRUCache.OptionsBase.noUpdateTTL}\n     */\n    noUpdateTTL;\n    /**\n     * {@link LRUCache.OptionsBase.maxEntrySize}\n     */\n    maxEntrySize;\n    /**\n     * {@link LRUCache.OptionsBase.sizeCalculation}\n     */\n    sizeCalculation;\n    /**\n     * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}\n     */\n    noDeleteOnFetchRejection;\n    /**\n     * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}\n     */\n    noDeleteOnStaleGet;\n    /**\n     * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}\n     */\n    allowStaleOnFetchAbort;\n    /**\n     * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}\n     */\n    allowStaleOnFetchRejection;\n    /**\n     * {@link LRUCache.OptionsBase.ignoreFetchAbort}\n     */\n    ignoreFetchAbort;\n    // computed properties\n    #size;\n    #calculatedSize;\n    #keyMap;\n    #keyList;\n    #valList;\n    #next;\n    #prev;\n    #head;\n    #tail;\n    #free;\n    #disposed;\n    #sizes;\n    #starts;\n    #ttls;\n    #hasDispose;\n    #hasFetchMethod;\n    #hasDisposeAfter;\n    /**\n     * Do not call this method unless you need to inspect the\n     * inner workings of the cache.  If anything returned by this\n     * object is modified in any way, strange breakage may occur.\n     *\n     * These fields are private for a reason!\n     *\n     * @internal\n     */\n    static unsafeExposeInternals(c) {\n        return {\n            // properties\n            starts: c.#starts,\n            ttls: c.#ttls,\n            sizes: c.#sizes,\n            keyMap: c.#keyMap,\n            keyList: c.#keyList,\n            valList: c.#valList,\n            next: c.#next,\n            prev: c.#prev,\n            get head() {\n                return c.#head;\n            },\n            get tail() {\n                return c.#tail;\n            },\n            free: c.#free,\n            // methods\n            isBackgroundFetch: (p) => c.#isBackgroundFetch(p),\n            backgroundFetch: (k, index, options, context) => c.#backgroundFetch(k, index, options, context),\n            moveToTail: (index) => c.#moveToTail(index),\n            indexes: (options) => c.#indexes(options),\n            rindexes: (options) => c.#rindexes(options),\n            isStale: (index) => c.#isStale(index),\n        };\n    }\n    // Protected read-only members\n    /**\n     * {@link LRUCache.OptionsBase.max} (read-only)\n     */\n    get max() {\n        return this.#max;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.maxSize} (read-only)\n     */\n    get maxSize() {\n        return this.#maxSize;\n    }\n    /**\n     * The total computed size of items in the cache (read-only)\n     */\n    get calculatedSize() {\n        return this.#calculatedSize;\n    }\n    /**\n     * The number of items stored in the cache (read-only)\n     */\n    get size() {\n        return this.#size;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.fetchMethod} (read-only)\n     */\n    get fetchMethod() {\n        return this.#fetchMethod;\n    }\n    get memoMethod() {\n        return this.#memoMethod;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.dispose} (read-only)\n     */\n    get dispose() {\n        return this.#dispose;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.disposeAfter} (read-only)\n     */\n    get disposeAfter() {\n        return this.#disposeAfter;\n    }\n    constructor(options) {\n        const { max = 0, ttl, ttlResolution = 1, ttlAutopurge, updateAgeOnGet, updateAgeOnHas, allowStale, dispose, disposeAfter, noDisposeOnSet, noUpdateTTL, maxSize = 0, maxEntrySize = 0, sizeCalculation, fetchMethod, memoMethod, noDeleteOnFetchRejection, noDeleteOnStaleGet, allowStaleOnFetchRejection, allowStaleOnFetchAbort, ignoreFetchAbort, } = options;\n        if (max !== 0 && !isPosInt(max)) {\n            throw new TypeError('max option must be a nonnegative integer');\n        }\n        const UintArray = max ? getUintArray(max) : Array;\n        if (!UintArray) {\n            throw new Error('invalid max value: ' + max);\n        }\n        this.#max = max;\n        this.#maxSize = maxSize;\n        this.maxEntrySize = maxEntrySize || this.#maxSize;\n        this.sizeCalculation = sizeCalculation;\n        if (this.sizeCalculation) {\n            if (!this.#maxSize && !this.maxEntrySize) {\n                throw new TypeError('cannot set sizeCalculation without setting maxSize or maxEntrySize');\n            }\n            if (typeof this.sizeCalculation !== 'function') {\n                throw new TypeError('sizeCalculation set to non-function');\n            }\n        }\n        if (memoMethod !== undefined &&\n            typeof memoMethod !== 'function') {\n            throw new TypeError('memoMethod must be a function if defined');\n        }\n        this.#memoMethod = memoMethod;\n        if (fetchMethod !== undefined &&\n            typeof fetchMethod !== 'function') {\n            throw new TypeError('fetchMethod must be a function if specified');\n        }\n        this.#fetchMethod = fetchMethod;\n        this.#hasFetchMethod = !!fetchMethod;\n        this.#keyMap = new Map();\n        this.#keyList = new Array(max).fill(undefined);\n        this.#valList = new Array(max).fill(undefined);\n        this.#next = new UintArray(max);\n        this.#prev = new UintArray(max);\n        this.#head = 0;\n        this.#tail = 0;\n        this.#free = Stack.create(max);\n        this.#size = 0;\n        this.#calculatedSize = 0;\n        if (typeof dispose === 'function') {\n            this.#dispose = dispose;\n        }\n        if (typeof disposeAfter === 'function') {\n            this.#disposeAfter = disposeAfter;\n            this.#disposed = [];\n        }\n        else {\n            this.#disposeAfter = undefined;\n            this.#disposed = undefined;\n        }\n        this.#hasDispose = !!this.#dispose;\n        this.#hasDisposeAfter = !!this.#disposeAfter;\n        this.noDisposeOnSet = !!noDisposeOnSet;\n        this.noUpdateTTL = !!noUpdateTTL;\n        this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection;\n        this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection;\n        this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort;\n        this.ignoreFetchAbort = !!ignoreFetchAbort;\n        // NB: maxEntrySize is set to maxSize if it's set\n        if (this.maxEntrySize !== 0) {\n            if (this.#maxSize !== 0) {\n                if (!isPosInt(this.#maxSize)) {\n                    throw new TypeError('maxSize must be a positive integer if specified');\n                }\n            }\n            if (!isPosInt(this.maxEntrySize)) {\n                throw new TypeError('maxEntrySize must be a positive integer if specified');\n            }\n            this.#initializeSizeTracking();\n        }\n        this.allowStale = !!allowStale;\n        this.noDeleteOnStaleGet = !!noDeleteOnStaleGet;\n        this.updateAgeOnGet = !!updateAgeOnGet;\n        this.updateAgeOnHas = !!updateAgeOnHas;\n        this.ttlResolution =\n            isPosInt(ttlResolution) || ttlResolution === 0\n                ? ttlResolution\n                : 1;\n        this.ttlAutopurge = !!ttlAutopurge;\n        this.ttl = ttl || 0;\n        if (this.ttl) {\n            if (!isPosInt(this.ttl)) {\n                throw new TypeError('ttl must be a positive integer if specified');\n            }\n            this.#initializeTTLTracking();\n        }\n        // do not allow completely unbounded caches\n        if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {\n            throw new TypeError('At least one of max, maxSize, or ttl is required');\n        }\n        if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {\n            const code = 'LRU_CACHE_UNBOUNDED';\n            if (shouldWarn(code)) {\n                warned.add(code);\n                const msg = 'TTL caching without ttlAutopurge, max, or maxSize can ' +\n                    'result in unbounded memory consumption.';\n                emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache);\n            }\n        }\n    }\n    /**\n     * Return the number of ms left in the item's TTL. If item is not in cache,\n     * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.\n     */\n    getRemainingTTL(key) {\n        return this.#keyMap.has(key) ? Infinity : 0;\n    }\n    #initializeTTLTracking() {\n        const ttls = new ZeroArray(this.#max);\n        const starts = new ZeroArray(this.#max);\n        this.#ttls = ttls;\n        this.#starts = starts;\n        this.#setItemTTL = (index, ttl, start = perf.now()) => {\n            starts[index] = ttl !== 0 ? start : 0;\n            ttls[index] = ttl;\n            if (ttl !== 0 && this.ttlAutopurge) {\n                const t = setTimeout(() => {\n                    if (this.#isStale(index)) {\n                        this.#delete(this.#keyList[index], 'expire');\n                    }\n                }, ttl + 1);\n                // unref() not supported on all platforms\n                /* c8 ignore start */\n                if (t.unref) {\n                    t.unref();\n                }\n                /* c8 ignore stop */\n            }\n        };\n        this.#updateItemAge = index => {\n            starts[index] = ttls[index] !== 0 ? perf.now() : 0;\n        };\n        this.#statusTTL = (status, index) => {\n            if (ttls[index]) {\n                const ttl = ttls[index];\n                const start = starts[index];\n                /* c8 ignore next */\n                if (!ttl || !start)\n                    return;\n                status.ttl = ttl;\n                status.start = start;\n                status.now = cachedNow || getNow();\n                const age = status.now - start;\n                status.remainingTTL = ttl - age;\n            }\n        };\n        // debounce calls to perf.now() to 1s so we're not hitting\n        // that costly call repeatedly.\n        let cachedNow = 0;\n        const getNow = () => {\n            const n = perf.now();\n            if (this.ttlResolution > 0) {\n                cachedNow = n;\n                const t = setTimeout(() => (cachedNow = 0), this.ttlResolution);\n                // not available on all platforms\n                /* c8 ignore start */\n                if (t.unref) {\n                    t.unref();\n                }\n                /* c8 ignore stop */\n            }\n            return n;\n        };\n        this.getRemainingTTL = key => {\n            const index = this.#keyMap.get(key);\n            if (index === undefined) {\n                return 0;\n            }\n            const ttl = ttls[index];\n            const start = starts[index];\n            if (!ttl || !start) {\n                return Infinity;\n            }\n            const age = (cachedNow || getNow()) - start;\n            return ttl - age;\n        };\n        this.#isStale = index => {\n            const s = starts[index];\n            const t = ttls[index];\n            return !!t && !!s && (cachedNow || getNow()) - s > t;\n        };\n    }\n    // conditionally set private methods related to TTL\n    #updateItemAge = () => { };\n    #statusTTL = () => { };\n    #setItemTTL = () => { };\n    /* c8 ignore stop */\n    #isStale = () => false;\n    #initializeSizeTracking() {\n        const sizes = new ZeroArray(this.#max);\n        this.#calculatedSize = 0;\n        this.#sizes = sizes;\n        this.#removeItemSize = index => {\n            this.#calculatedSize -= sizes[index];\n            sizes[index] = 0;\n        };\n        this.#requireSize = (k, v, size, sizeCalculation) => {\n            // provisionally accept background fetches.\n            // actual value size will be checked when they return.\n            if (this.#isBackgroundFetch(v)) {\n                return 0;\n            }\n            if (!isPosInt(size)) {\n                if (sizeCalculation) {\n                    if (typeof sizeCalculation !== 'function') {\n                        throw new TypeError('sizeCalculation must be a function');\n                    }\n                    size = sizeCalculation(v, k);\n                    if (!isPosInt(size)) {\n                        throw new TypeError('sizeCalculation return invalid (expect positive integer)');\n                    }\n                }\n                else {\n                    throw new TypeError('invalid size value (must be positive integer). ' +\n                        'When maxSize or maxEntrySize is used, sizeCalculation ' +\n                        'or size must be set.');\n                }\n            }\n            return size;\n        };\n        this.#addItemSize = (index, size, status) => {\n            sizes[index] = size;\n            if (this.#maxSize) {\n                const maxSize = this.#maxSize - sizes[index];\n                while (this.#calculatedSize > maxSize) {\n                    this.#evict(true);\n                }\n            }\n            this.#calculatedSize += sizes[index];\n            if (status) {\n                status.entrySize = size;\n                status.totalCalculatedSize = this.#calculatedSize;\n            }\n        };\n    }\n    #removeItemSize = _i => { };\n    #addItemSize = (_i, _s, _st) => { };\n    #requireSize = (_k, _v, size, sizeCalculation) => {\n        if (size || sizeCalculation) {\n            throw new TypeError('cannot set size without setting maxSize or maxEntrySize on cache');\n        }\n        return 0;\n    };\n    *#indexes({ allowStale = this.allowStale } = {}) {\n        if (this.#size) {\n            for (let i = this.#tail; true;) {\n                if (!this.#isValidIndex(i)) {\n                    break;\n                }\n                if (allowStale || !this.#isStale(i)) {\n                    yield i;\n                }\n                if (i === this.#head) {\n                    break;\n                }\n                else {\n                    i = this.#prev[i];\n                }\n            }\n        }\n    }\n    *#rindexes({ allowStale = this.allowStale } = {}) {\n        if (this.#size) {\n            for (let i = this.#head; true;) {\n                if (!this.#isValidIndex(i)) {\n                    break;\n                }\n                if (allowStale || !this.#isStale(i)) {\n                    yield i;\n                }\n                if (i === this.#tail) {\n                    break;\n                }\n                else {\n                    i = this.#next[i];\n                }\n            }\n        }\n    }\n    #isValidIndex(index) {\n        return (index !== undefined &&\n            this.#keyMap.get(this.#keyList[index]) === index);\n    }\n    /**\n     * Return a generator yielding `[key, value]` pairs,\n     * in order from most recently used to least recently used.\n     */\n    *entries() {\n        for (const i of this.#indexes()) {\n            if (this.#valList[i] !== undefined &&\n                this.#keyList[i] !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield [this.#keyList[i], this.#valList[i]];\n            }\n        }\n    }\n    /**\n     * Inverse order version of {@link LRUCache.entries}\n     *\n     * Return a generator yielding `[key, value]` pairs,\n     * in order from least recently used to most recently used.\n     */\n    *rentries() {\n        for (const i of this.#rindexes()) {\n            if (this.#valList[i] !== undefined &&\n                this.#keyList[i] !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield [this.#keyList[i], this.#valList[i]];\n            }\n        }\n    }\n    /**\n     * Return a generator yielding the keys in the cache,\n     * in order from most recently used to least recently used.\n     */\n    *keys() {\n        for (const i of this.#indexes()) {\n            const k = this.#keyList[i];\n            if (k !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield k;\n            }\n        }\n    }\n    /**\n     * Inverse order version of {@link LRUCache.keys}\n     *\n     * Return a generator yielding the keys in the cache,\n     * in order from least recently used to most recently used.\n     */\n    *rkeys() {\n        for (const i of this.#rindexes()) {\n            const k = this.#keyList[i];\n            if (k !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield k;\n            }\n        }\n    }\n    /**\n     * Return a generator yielding the values in the cache,\n     * in order from most recently used to least recently used.\n     */\n    *values() {\n        for (const i of this.#indexes()) {\n            const v = this.#valList[i];\n            if (v !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield this.#valList[i];\n            }\n        }\n    }\n    /**\n     * Inverse order version of {@link LRUCache.values}\n     *\n     * Return a generator yielding the values in the cache,\n     * in order from least recently used to most recently used.\n     */\n    *rvalues() {\n        for (const i of this.#rindexes()) {\n            const v = this.#valList[i];\n            if (v !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield this.#valList[i];\n            }\n        }\n    }\n    /**\n     * Iterating over the cache itself yields the same results as\n     * {@link LRUCache.entries}\n     */\n    [Symbol.iterator]() {\n        return this.entries();\n    }\n    /**\n     * A String value that is used in the creation of the default string\n     * description of an object. Called by the built-in method\n     * `Object.prototype.toString`.\n     */\n    [Symbol.toStringTag] = 'LRUCache';\n    /**\n     * Find a value for which the supplied fn method returns a truthy value,\n     * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.\n     */\n    find(fn, getOptions = {}) {\n        for (const i of this.#indexes()) {\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined)\n                continue;\n            if (fn(value, this.#keyList[i], this)) {\n                return this.get(this.#keyList[i], getOptions);\n            }\n        }\n    }\n    /**\n     * Call the supplied function on each item in the cache, in order from most\n     * recently used to least recently used.\n     *\n     * `fn` is called as `fn(value, key, cache)`.\n     *\n     * If `thisp` is provided, function will be called in the `this`-context of\n     * the provided object, or the cache if no `thisp` object is provided.\n     *\n     * Does not update age or recenty of use, or iterate over stale values.\n     */\n    forEach(fn, thisp = this) {\n        for (const i of this.#indexes()) {\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined)\n                continue;\n            fn.call(thisp, value, this.#keyList[i], this);\n        }\n    }\n    /**\n     * The same as {@link LRUCache.forEach} but items are iterated over in\n     * reverse order.  (ie, less recently used items are iterated over first.)\n     */\n    rforEach(fn, thisp = this) {\n        for (const i of this.#rindexes()) {\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined)\n                continue;\n            fn.call(thisp, value, this.#keyList[i], this);\n        }\n    }\n    /**\n     * Delete any stale entries. Returns true if anything was removed,\n     * false otherwise.\n     */\n    purgeStale() {\n        let deleted = false;\n        for (const i of this.#rindexes({ allowStale: true })) {\n            if (this.#isStale(i)) {\n                this.#delete(this.#keyList[i], 'expire');\n                deleted = true;\n            }\n        }\n        return deleted;\n    }\n    /**\n     * Get the extended info about a given entry, to get its value, size, and\n     * TTL info simultaneously. Returns `undefined` if the key is not present.\n     *\n     * Unlike {@link LRUCache#dump}, which is designed to be portable and survive\n     * serialization, the `start` value is always the current timestamp, and the\n     * `ttl` is a calculated remaining time to live (negative if expired).\n     *\n     * Always returns stale values, if their info is found in the cache, so be\n     * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})\n     * if relevant.\n     */\n    info(key) {\n        const i = this.#keyMap.get(key);\n        if (i === undefined)\n            return undefined;\n        const v = this.#valList[i];\n        const value = this.#isBackgroundFetch(v)\n            ? v.__staleWhileFetching\n            : v;\n        if (value === undefined)\n            return undefined;\n        const entry = { value };\n        if (this.#ttls && this.#starts) {\n            const ttl = this.#ttls[i];\n            const start = this.#starts[i];\n            if (ttl && start) {\n                const remain = ttl - (perf.now() - start);\n                entry.ttl = remain;\n                entry.start = Date.now();\n            }\n        }\n        if (this.#sizes) {\n            entry.size = this.#sizes[i];\n        }\n        return entry;\n    }\n    /**\n     * Return an array of [key, {@link LRUCache.Entry}] tuples which can be\n     * passed to {@link LRLUCache#load}.\n     *\n     * The `start` fields are calculated relative to a portable `Date.now()`\n     * timestamp, even if `performance.now()` is available.\n     *\n     * Stale entries are always included in the `dump`, even if\n     * {@link LRUCache.OptionsBase.allowStale} is false.\n     *\n     * Note: this returns an actual array, not a generator, so it can be more\n     * easily passed around.\n     */\n    dump() {\n        const arr = [];\n        for (const i of this.#indexes({ allowStale: true })) {\n            const key = this.#keyList[i];\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined || key === undefined)\n                continue;\n            const entry = { value };\n            if (this.#ttls && this.#starts) {\n                entry.ttl = this.#ttls[i];\n                // always dump the start relative to a portable timestamp\n                // it's ok for this to be a bit slow, it's a rare operation.\n                const age = perf.now() - this.#starts[i];\n                entry.start = Math.floor(Date.now() - age);\n            }\n            if (this.#sizes) {\n                entry.size = this.#sizes[i];\n            }\n            arr.unshift([key, entry]);\n        }\n        return arr;\n    }\n    /**\n     * Reset the cache and load in the items in entries in the order listed.\n     *\n     * The shape of the resulting cache may be different if the same options are\n     * not used in both caches.\n     *\n     * The `start` fields are assumed to be calculated relative to a portable\n     * `Date.now()` timestamp, even if `performance.now()` is available.\n     */\n    load(arr) {\n        this.clear();\n        for (const [key, entry] of arr) {\n            if (entry.start) {\n                // entry.start is a portable timestamp, but we may be using\n                // node's performance.now(), so calculate the offset, so that\n                // we get the intended remaining TTL, no matter how long it's\n                // been on ice.\n                //\n                // it's ok for this to be a bit slow, it's a rare operation.\n                const age = Date.now() - entry.start;\n                entry.start = perf.now() - age;\n            }\n            this.set(key, entry.value, entry);\n        }\n    }\n    /**\n     * Add a value to the cache.\n     *\n     * Note: if `undefined` is specified as a value, this is an alias for\n     * {@link LRUCache#delete}\n     *\n     * Fields on the {@link LRUCache.SetOptions} options param will override\n     * their corresponding values in the constructor options for the scope\n     * of this single `set()` operation.\n     *\n     * If `start` is provided, then that will set the effective start\n     * time for the TTL calculation. Note that this must be a previous\n     * value of `performance.now()` if supported, or a previous value of\n     * `Date.now()` if not.\n     *\n     * Options object may also include `size`, which will prevent\n     * calling the `sizeCalculation` function and just use the specified\n     * number if it is a positive integer, and `noDisposeOnSet` which\n     * will prevent calling a `dispose` function in the case of\n     * overwrites.\n     *\n     * If the `size` (or return value of `sizeCalculation`) for a given\n     * entry is greater than `maxEntrySize`, then the item will not be\n     * added to the cache.\n     *\n     * Will update the recency of the entry.\n     *\n     * If the value is `undefined`, then this is an alias for\n     * `cache.delete(key)`. `undefined` is never stored in the cache.\n     */\n    set(k, v, setOptions = {}) {\n        if (v === undefined) {\n            this.delete(k);\n            return this;\n        }\n        const { ttl = this.ttl, start, noDisposeOnSet = this.noDisposeOnSet, sizeCalculation = this.sizeCalculation, status, } = setOptions;\n        let { noUpdateTTL = this.noUpdateTTL } = setOptions;\n        const size = this.#requireSize(k, v, setOptions.size || 0, sizeCalculation);\n        // if the item doesn't fit, don't do anything\n        // NB: maxEntrySize set to maxSize by default\n        if (this.maxEntrySize && size > this.maxEntrySize) {\n            if (status) {\n                status.set = 'miss';\n                status.maxEntrySizeExceeded = true;\n            }\n            // have to delete, in case something is there already.\n            this.#delete(k, 'set');\n            return this;\n        }\n        let index = this.#size === 0 ? undefined : this.#keyMap.get(k);\n        if (index === undefined) {\n            // addition\n            index = (this.#size === 0\n                ? this.#tail\n                : this.#free.length !== 0\n                    ? this.#free.pop()\n                    : this.#size === this.#max\n                        ? this.#evict(false)\n                        : this.#size);\n            this.#keyList[index] = k;\n            this.#valList[index] = v;\n            this.#keyMap.set(k, index);\n            this.#next[this.#tail] = index;\n            this.#prev[index] = this.#tail;\n            this.#tail = index;\n            this.#size++;\n            this.#addItemSize(index, size, status);\n            if (status)\n                status.set = 'add';\n            noUpdateTTL = false;\n        }\n        else {\n            // update\n            this.#moveToTail(index);\n            const oldVal = this.#valList[index];\n            if (v !== oldVal) {\n                if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {\n                    oldVal.__abortController.abort(new Error('replaced'));\n                    const { __staleWhileFetching: s } = oldVal;\n                    if (s !== undefined && !noDisposeOnSet) {\n                        if (this.#hasDispose) {\n                            this.#dispose?.(s, k, 'set');\n                        }\n                        if (this.#hasDisposeAfter) {\n                            this.#disposed?.push([s, k, 'set']);\n                        }\n                    }\n                }\n                else if (!noDisposeOnSet) {\n                    if (this.#hasDispose) {\n                        this.#dispose?.(oldVal, k, 'set');\n                    }\n                    if (this.#hasDisposeAfter) {\n                        this.#disposed?.push([oldVal, k, 'set']);\n                    }\n                }\n                this.#removeItemSize(index);\n                this.#addItemSize(index, size, status);\n                this.#valList[index] = v;\n                if (status) {\n                    status.set = 'replace';\n                    const oldValue = oldVal && this.#isBackgroundFetch(oldVal)\n                        ? oldVal.__staleWhileFetching\n                        : oldVal;\n                    if (oldValue !== undefined)\n                        status.oldValue = oldValue;\n                }\n            }\n            else if (status) {\n                status.set = 'update';\n            }\n        }\n        if (ttl !== 0 && !this.#ttls) {\n            this.#initializeTTLTracking();\n        }\n        if (this.#ttls) {\n            if (!noUpdateTTL) {\n                this.#setItemTTL(index, ttl, start);\n            }\n            if (status)\n                this.#statusTTL(status, index);\n        }\n        if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {\n            const dt = this.#disposed;\n            let task;\n            while ((task = dt?.shift())) {\n                this.#disposeAfter?.(...task);\n            }\n        }\n        return this;\n    }\n    /**\n     * Evict the least recently used item, returning its value or\n     * `undefined` if cache is empty.\n     */\n    pop() {\n        try {\n            while (this.#size) {\n                const val = this.#valList[this.#head];\n                this.#evict(true);\n                if (this.#isBackgroundFetch(val)) {\n                    if (val.__staleWhileFetching) {\n                        return val.__staleWhileFetching;\n                    }\n                }\n                else if (val !== undefined) {\n                    return val;\n                }\n            }\n        }\n        finally {\n            if (this.#hasDisposeAfter && this.#disposed) {\n                const dt = this.#disposed;\n                let task;\n                while ((task = dt?.shift())) {\n                    this.#disposeAfter?.(...task);\n                }\n            }\n        }\n    }\n    #evict(free) {\n        const head = this.#head;\n        const k = this.#keyList[head];\n        const v = this.#valList[head];\n        if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {\n            v.__abortController.abort(new Error('evicted'));\n        }\n        else if (this.#hasDispose || this.#hasDisposeAfter) {\n            if (this.#hasDispose) {\n                this.#dispose?.(v, k, 'evict');\n            }\n            if (this.#hasDisposeAfter) {\n                this.#disposed?.push([v, k, 'evict']);\n            }\n        }\n        this.#removeItemSize(head);\n        // if we aren't about to use the index, then null these out\n        if (free) {\n            this.#keyList[head] = undefined;\n            this.#valList[head] = undefined;\n            this.#free.push(head);\n        }\n        if (this.#size === 1) {\n            this.#head = this.#tail = 0;\n            this.#free.length = 0;\n        }\n        else {\n            this.#head = this.#next[head];\n        }\n        this.#keyMap.delete(k);\n        this.#size--;\n        return head;\n    }\n    /**\n     * Check if a key is in the cache, without updating the recency of use.\n     * Will return false if the item is stale, even though it is technically\n     * in the cache.\n     *\n     * Check if a key is in the cache, without updating the recency of\n     * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set\n     * to `true` in either the options or the constructor.\n     *\n     * Will return `false` if the item is stale, even though it is technically in\n     * the cache. The difference can be determined (if it matters) by using a\n     * `status` argument, and inspecting the `has` field.\n     *\n     * Will not update item age unless\n     * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.\n     */\n    has(k, hasOptions = {}) {\n        const { updateAgeOnHas = this.updateAgeOnHas, status } = hasOptions;\n        const index = this.#keyMap.get(k);\n        if (index !== undefined) {\n            const v = this.#valList[index];\n            if (this.#isBackgroundFetch(v) &&\n                v.__staleWhileFetching === undefined) {\n                return false;\n            }\n            if (!this.#isStale(index)) {\n                if (updateAgeOnHas) {\n                    this.#updateItemAge(index);\n                }\n                if (status) {\n                    status.has = 'hit';\n                    this.#statusTTL(status, index);\n                }\n                return true;\n            }\n            else if (status) {\n                status.has = 'stale';\n                this.#statusTTL(status, index);\n            }\n        }\n        else if (status) {\n            status.has = 'miss';\n        }\n        return false;\n    }\n    /**\n     * Like {@link LRUCache#get} but doesn't update recency or delete stale\n     * items.\n     *\n     * Returns `undefined` if the item is stale, unless\n     * {@link LRUCache.OptionsBase.allowStale} is set.\n     */\n    peek(k, peekOptions = {}) {\n        const { allowStale = this.allowStale } = peekOptions;\n        const index = this.#keyMap.get(k);\n        if (index === undefined ||\n            (!allowStale && this.#isStale(index))) {\n            return;\n        }\n        const v = this.#valList[index];\n        // either stale and allowed, or forcing a refresh of non-stale value\n        return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n    }\n    #backgroundFetch(k, index, options, context) {\n        const v = index === undefined ? undefined : this.#valList[index];\n        if (this.#isBackgroundFetch(v)) {\n            return v;\n        }\n        const ac = new AC();\n        const { signal } = options;\n        // when/if our AC signals, then stop listening to theirs.\n        signal?.addEventListener('abort', () => ac.abort(signal.reason), {\n            signal: ac.signal,\n        });\n        const fetchOpts = {\n            signal: ac.signal,\n            options,\n            context,\n        };\n        const cb = (v, updateCache = false) => {\n            const { aborted } = ac.signal;\n            const ignoreAbort = options.ignoreFetchAbort && v !== undefined;\n            if (options.status) {\n                if (aborted && !updateCache) {\n                    options.status.fetchAborted = true;\n                    options.status.fetchError = ac.signal.reason;\n                    if (ignoreAbort)\n                        options.status.fetchAbortIgnored = true;\n                }\n                else {\n                    options.status.fetchResolved = true;\n                }\n            }\n            if (aborted && !ignoreAbort && !updateCache) {\n                return fetchFail(ac.signal.reason);\n            }\n            // either we didn't abort, and are still here, or we did, and ignored\n            const bf = p;\n            if (this.#valList[index] === p) {\n                if (v === undefined) {\n                    if (bf.__staleWhileFetching) {\n                        this.#valList[index] = bf.__staleWhileFetching;\n                    }\n                    else {\n                        this.#delete(k, 'fetch');\n                    }\n                }\n                else {\n                    if (options.status)\n                        options.status.fetchUpdated = true;\n                    this.set(k, v, fetchOpts.options);\n                }\n            }\n            return v;\n        };\n        const eb = (er) => {\n            if (options.status) {\n                options.status.fetchRejected = true;\n                options.status.fetchError = er;\n            }\n            return fetchFail(er);\n        };\n        const fetchFail = (er) => {\n            const { aborted } = ac.signal;\n            const allowStaleAborted = aborted && options.allowStaleOnFetchAbort;\n            const allowStale = allowStaleAborted || options.allowStaleOnFetchRejection;\n            const noDelete = allowStale || options.noDeleteOnFetchRejection;\n            const bf = p;\n            if (this.#valList[index] === p) {\n                // if we allow stale on fetch rejections, then we need to ensure that\n                // the stale value is not removed from the cache when the fetch fails.\n                const del = !noDelete || bf.__staleWhileFetching === undefined;\n                if (del) {\n                    this.#delete(k, 'fetch');\n                }\n                else if (!allowStaleAborted) {\n                    // still replace the *promise* with the stale value,\n                    // since we are done with the promise at this point.\n                    // leave it untouched if we're still waiting for an\n                    // aborted background fetch that hasn't yet returned.\n                    this.#valList[index] = bf.__staleWhileFetching;\n                }\n            }\n            if (allowStale) {\n                if (options.status && bf.__staleWhileFetching !== undefined) {\n                    options.status.returnedStale = true;\n                }\n                return bf.__staleWhileFetching;\n            }\n            else if (bf.__returned === bf) {\n                throw er;\n            }\n        };\n        const pcall = (res, rej) => {\n            const fmp = this.#fetchMethod?.(k, v, fetchOpts);\n            if (fmp && fmp instanceof Promise) {\n                fmp.then(v => res(v === undefined ? undefined : v), rej);\n            }\n            // ignored, we go until we finish, regardless.\n            // defer check until we are actually aborting,\n            // so fetchMethod can override.\n            ac.signal.addEventListener('abort', () => {\n                if (!options.ignoreFetchAbort ||\n                    options.allowStaleOnFetchAbort) {\n                    res(undefined);\n                    // when it eventually resolves, update the cache.\n                    if (options.allowStaleOnFetchAbort) {\n                        res = v => cb(v, true);\n                    }\n                }\n            });\n        };\n        if (options.status)\n            options.status.fetchDispatched = true;\n        const p = new Promise(pcall).then(cb, eb);\n        const bf = Object.assign(p, {\n            __abortController: ac,\n            __staleWhileFetching: v,\n            __returned: undefined,\n        });\n        if (index === undefined) {\n            // internal, don't expose status.\n            this.set(k, bf, { ...fetchOpts.options, status: undefined });\n            index = this.#keyMap.get(k);\n        }\n        else {\n            this.#valList[index] = bf;\n        }\n        return bf;\n    }\n    #isBackgroundFetch(p) {\n        if (!this.#hasFetchMethod)\n            return false;\n        const b = p;\n        return (!!b &&\n            b instanceof Promise &&\n            b.hasOwnProperty('__staleWhileFetching') &&\n            b.__abortController instanceof AC);\n    }\n    async fetch(k, fetchOptions = {}) {\n        const { \n        // get options\n        allowStale = this.allowStale, updateAgeOnGet = this.updateAgeOnGet, noDeleteOnStaleGet = this.noDeleteOnStaleGet, \n        // set options\n        ttl = this.ttl, noDisposeOnSet = this.noDisposeOnSet, size = 0, sizeCalculation = this.sizeCalculation, noUpdateTTL = this.noUpdateTTL, \n        // fetch exclusive options\n        noDeleteOnFetchRejection = this.noDeleteOnFetchRejection, allowStaleOnFetchRejection = this.allowStaleOnFetchRejection, ignoreFetchAbort = this.ignoreFetchAbort, allowStaleOnFetchAbort = this.allowStaleOnFetchAbort, context, forceRefresh = false, status, signal, } = fetchOptions;\n        if (!this.#hasFetchMethod) {\n            if (status)\n                status.fetch = 'get';\n            return this.get(k, {\n                allowStale,\n                updateAgeOnGet,\n                noDeleteOnStaleGet,\n                status,\n            });\n        }\n        const options = {\n            allowStale,\n            updateAgeOnGet,\n            noDeleteOnStaleGet,\n            ttl,\n            noDisposeOnSet,\n            size,\n            sizeCalculation,\n            noUpdateTTL,\n            noDeleteOnFetchRejection,\n            allowStaleOnFetchRejection,\n            allowStaleOnFetchAbort,\n            ignoreFetchAbort,\n            status,\n            signal,\n        };\n        let index = this.#keyMap.get(k);\n        if (index === undefined) {\n            if (status)\n                status.fetch = 'miss';\n            const p = this.#backgroundFetch(k, index, options, context);\n            return (p.__returned = p);\n        }\n        else {\n            // in cache, maybe already fetching\n            const v = this.#valList[index];\n            if (this.#isBackgroundFetch(v)) {\n                const stale = allowStale && v.__staleWhileFetching !== undefined;\n                if (status) {\n                    status.fetch = 'inflight';\n                    if (stale)\n                        status.returnedStale = true;\n                }\n                return stale ? v.__staleWhileFetching : (v.__returned = v);\n            }\n            // if we force a refresh, that means do NOT serve the cached value,\n            // unless we are already in the process of refreshing the cache.\n            const isStale = this.#isStale(index);\n            if (!forceRefresh && !isStale) {\n                if (status)\n                    status.fetch = 'hit';\n                this.#moveToTail(index);\n                if (updateAgeOnGet) {\n                    this.#updateItemAge(index);\n                }\n                if (status)\n                    this.#statusTTL(status, index);\n                return v;\n            }\n            // ok, it is stale or a forced refresh, and not already fetching.\n            // refresh the cache.\n            const p = this.#backgroundFetch(k, index, options, context);\n            const hasStale = p.__staleWhileFetching !== undefined;\n            const staleVal = hasStale && allowStale;\n            if (status) {\n                status.fetch = isStale ? 'stale' : 'refresh';\n                if (staleVal && isStale)\n                    status.returnedStale = true;\n            }\n            return staleVal ? p.__staleWhileFetching : (p.__returned = p);\n        }\n    }\n    async forceFetch(k, fetchOptions = {}) {\n        const v = await this.fetch(k, fetchOptions);\n        if (v === undefined)\n            throw new Error('fetch() returned undefined');\n        return v;\n    }\n    memo(k, memoOptions = {}) {\n        const memoMethod = this.#memoMethod;\n        if (!memoMethod) {\n            throw new Error('no memoMethod provided to constructor');\n        }\n        const { context, forceRefresh, ...options } = memoOptions;\n        const v = this.get(k, options);\n        if (!forceRefresh && v !== undefined)\n            return v;\n        const vv = memoMethod(k, v, {\n            options,\n            context,\n        });\n        this.set(k, vv, options);\n        return vv;\n    }\n    /**\n     * Return a value from the cache. Will update the recency of the cache\n     * entry found.\n     *\n     * If the key is not found, get() will return `undefined`.\n     */\n    get(k, getOptions = {}) {\n        const { allowStale = this.allowStale, updateAgeOnGet = this.updateAgeOnGet, noDeleteOnStaleGet = this.noDeleteOnStaleGet, status, } = getOptions;\n        const index = this.#keyMap.get(k);\n        if (index !== undefined) {\n            const value = this.#valList[index];\n            const fetching = this.#isBackgroundFetch(value);\n            if (status)\n                this.#statusTTL(status, index);\n            if (this.#isStale(index)) {\n                if (status)\n                    status.get = 'stale';\n                // delete only if not an in-flight background fetch\n                if (!fetching) {\n                    if (!noDeleteOnStaleGet) {\n                        this.#delete(k, 'expire');\n                    }\n                    if (status && allowStale)\n                        status.returnedStale = true;\n                    return allowStale ? value : undefined;\n                }\n                else {\n                    if (status &&\n                        allowStale &&\n                        value.__staleWhileFetching !== undefined) {\n                        status.returnedStale = true;\n                    }\n                    return allowStale ? value.__staleWhileFetching : undefined;\n                }\n            }\n            else {\n                if (status)\n                    status.get = 'hit';\n                // if we're currently fetching it, we don't actually have it yet\n                // it's not stale, which means this isn't a staleWhileRefetching.\n                // If it's not stale, and fetching, AND has a __staleWhileFetching\n                // value, then that means the user fetched with {forceRefresh:true},\n                // so it's safe to return that value.\n                if (fetching) {\n                    return value.__staleWhileFetching;\n                }\n                this.#moveToTail(index);\n                if (updateAgeOnGet) {\n                    this.#updateItemAge(index);\n                }\n                return value;\n            }\n        }\n        else if (status) {\n            status.get = 'miss';\n        }\n    }\n    #connect(p, n) {\n        this.#prev[n] = p;\n        this.#next[p] = n;\n    }\n    #moveToTail(index) {\n        // if tail already, nothing to do\n        // if head, move head to next[index]\n        // else\n        //   move next[prev[index]] to next[index] (head has no prev)\n        //   move prev[next[index]] to prev[index]\n        // prev[index] = tail\n        // next[tail] = index\n        // tail = index\n        if (index !== this.#tail) {\n            if (index === this.#head) {\n                this.#head = this.#next[index];\n            }\n            else {\n                this.#connect(this.#prev[index], this.#next[index]);\n            }\n            this.#connect(this.#tail, index);\n            this.#tail = index;\n        }\n    }\n    /**\n     * Deletes a key out of the cache.\n     *\n     * Returns true if the key was deleted, false otherwise.\n     */\n    delete(k) {\n        return this.#delete(k, 'delete');\n    }\n    #delete(k, reason) {\n        let deleted = false;\n        if (this.#size !== 0) {\n            const index = this.#keyMap.get(k);\n            if (index !== undefined) {\n                deleted = true;\n                if (this.#size === 1) {\n                    this.#clear(reason);\n                }\n                else {\n                    this.#removeItemSize(index);\n                    const v = this.#valList[index];\n                    if (this.#isBackgroundFetch(v)) {\n                        v.__abortController.abort(new Error('deleted'));\n                    }\n                    else if (this.#hasDispose || this.#hasDisposeAfter) {\n                        if (this.#hasDispose) {\n                            this.#dispose?.(v, k, reason);\n                        }\n                        if (this.#hasDisposeAfter) {\n                            this.#disposed?.push([v, k, reason]);\n                        }\n                    }\n                    this.#keyMap.delete(k);\n                    this.#keyList[index] = undefined;\n                    this.#valList[index] = undefined;\n                    if (index === this.#tail) {\n                        this.#tail = this.#prev[index];\n                    }\n                    else if (index === this.#head) {\n                        this.#head = this.#next[index];\n                    }\n                    else {\n                        const pi = this.#prev[index];\n                        this.#next[pi] = this.#next[index];\n                        const ni = this.#next[index];\n                        this.#prev[ni] = this.#prev[index];\n                    }\n                    this.#size--;\n                    this.#free.push(index);\n                }\n            }\n        }\n        if (this.#hasDisposeAfter && this.#disposed?.length) {\n            const dt = this.#disposed;\n            let task;\n            while ((task = dt?.shift())) {\n                this.#disposeAfter?.(...task);\n            }\n        }\n        return deleted;\n    }\n    /**\n     * Clear the cache entirely, throwing away all values.\n     */\n    clear() {\n        return this.#clear('delete');\n    }\n    #clear(reason) {\n        for (const index of this.#rindexes({ allowStale: true })) {\n            const v = this.#valList[index];\n            if (this.#isBackgroundFetch(v)) {\n                v.__abortController.abort(new Error('deleted'));\n            }\n            else {\n                const k = this.#keyList[index];\n                if (this.#hasDispose) {\n                    this.#dispose?.(v, k, reason);\n                }\n                if (this.#hasDisposeAfter) {\n                    this.#disposed?.push([v, k, reason]);\n                }\n            }\n        }\n        this.#keyMap.clear();\n        this.#valList.fill(undefined);\n        this.#keyList.fill(undefined);\n        if (this.#ttls && this.#starts) {\n            this.#ttls.fill(0);\n            this.#starts.fill(0);\n        }\n        if (this.#sizes) {\n            this.#sizes.fill(0);\n        }\n        this.#head = 0;\n        this.#tail = 0;\n        this.#free.length = 0;\n        this.#calculatedSize = 0;\n        this.#size = 0;\n        if (this.#hasDisposeAfter && this.#disposed) {\n            const dt = this.#disposed;\n            let task;\n            while ((task = dt?.shift())) {\n                this.#disposeAfter?.(...task);\n            }\n        }\n    }\n}\n//# sourceMappingURL=index.js.map","export class InvalidRangeError extends Error {\n    static name = 'InvalidRangeError';\n    constructor(message = 'Invalid range request') {\n        super(message);\n        this.name = 'InvalidRangeError';\n    }\n}\nexport class NoContentError extends Error {\n    static name = 'NoContentError';\n    constructor(message = 'No content found') {\n        super(message);\n        this.name = 'NoContentError';\n    }\n}\nexport class SubdomainNotSupportedError extends Error {\n    static name = 'SubdomainNotSupportedError';\n    constructor(message = 'Subdomain not supported') {\n        super(message);\n        this.name = 'SubdomainNotSupportedError';\n    }\n}\n//# sourceMappingURL=errors.js.map","import { InvalidRangeError } from '../errors.js';\nexport function getHeader(headers, header) {\n    if (headers == null) {\n        return undefined;\n    }\n    if (headers instanceof Headers) {\n        return headers.get(header) ?? undefined;\n    }\n    if (Array.isArray(headers)) {\n        const entry = headers.find(([key]) => key.toLowerCase() === header.toLowerCase());\n        return entry?.[1];\n    }\n    const key = Object.keys(headers).find(k => k.toLowerCase() === header.toLowerCase());\n    if (key == null) {\n        return undefined;\n    }\n    return headers[key];\n}\n/**\n * Given two ints from a Range header, and potential fileSize, returns:\n * 1. number of bytes the response should contain.\n * 2. the start index of the range. // inclusive\n * 3. the end index of the range. // inclusive\n */\n// eslint-disable-next-line complexity\nexport function calculateByteRangeIndexes(start, end, fileSize) {\n    if ((start ?? 0) > (end ?? Infinity)) {\n        throw new InvalidRangeError('Invalid range: Range-start index is greater than range-end index.');\n    }\n    if (start != null && (end ?? 0) >= (fileSize ?? Infinity)) {\n        throw new InvalidRangeError('Invalid range: Range-end index is greater than or equal to the size of the file.');\n    }\n    if (start == null && (end ?? 0) > (fileSize ?? Infinity)) {\n        throw new InvalidRangeError('Invalid range: Range-end index is greater than the size of the file.');\n    }\n    if (start != null && start < 0) {\n        throw new InvalidRangeError('Invalid range: Range-start index cannot be negative.');\n    }\n    if (start != null && end != null) {\n        return { byteSize: end - start + 1, start, end };\n    }\n    else if (start == null && end != null) {\n        // suffix byte range requested\n        if (fileSize == null) {\n            return { end };\n        }\n        if (end === fileSize) {\n            return { byteSize: fileSize, start: 0, end: fileSize - 1 };\n        }\n        return { byteSize: end, start: fileSize - end, end: fileSize - 1 };\n    }\n    else if (start != null && end == null) {\n        if (fileSize == null) {\n            // we only have the start index, and no fileSize, so we can't return a valid range.\n            return { start };\n        }\n        const end = fileSize - 1;\n        const byteSize = fileSize - start;\n        return { byteSize, start, end };\n    }\n    return { byteSize: fileSize, start: 0, end: fileSize != null ? fileSize - 1 : 0 };\n}\n//# sourceMappingURL=request-headers.js.map","import { InvalidRangeError } from '../errors.js';\n/**\n * Implementations may place an upper bound on any TTL received, as noted in Section 8 of [rfc2181].\n * If TTL value is unknown, implementations should not send a Cache-Control\n * No matter if TTL value is known or not, implementations should always send a Last-Modified header with the timestamp of the record resolution.\n *\n * @see https://specs.ipfs.tech/http-gateways/path-gateway/#cache-control-response-header\n */\nexport function setCacheControlHeader({ ttl, protocol, response }) {\n    let headerValue;\n    if (protocol === 'ipfs') {\n        headerValue = 'public, max-age=29030400, immutable';\n    }\n    else if (ttl == null) {\n        /**\n         * default limit for unknown TTL: \"use 5 minute as default fallback when it is not available.\"\n         *\n         * @see https://github.com/ipfs/boxo/issues/329#issuecomment-1995236409\n         */\n        headerValue = 'public, max-age=300';\n    }\n    else {\n        headerValue = `public, max-age=${ttl}`;\n    }\n    response.headers.set('cache-control', headerValue);\n}\n/**\n * This function returns the value of the `Content-Range` header for a given range.\n * If you know the total size of the body, pass it as `byteSize`\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Range\n */\nexport function getContentRangeHeader({ byteStart, byteEnd, byteSize }) {\n    const total = byteSize ?? '*'; // if we don't know the total size, we should use *\n    if ((byteEnd ?? 0) >= (byteSize ?? Infinity)) {\n        throw new InvalidRangeError('Invalid range: Range-end index is greater than or equal to the size of the file.');\n    }\n    if ((byteStart ?? 0) >= (byteSize ?? Infinity)) {\n        throw new InvalidRangeError('Invalid range: Range-start index is greater than or equal to the size of the file.');\n    }\n    if (byteStart != null && byteEnd == null) {\n        // only byteStart in range\n        if (byteSize == null) {\n            return `bytes */${total}`;\n        }\n        return `bytes ${byteStart}-${byteSize - 1}/${byteSize}`;\n    }\n    if (byteStart == null && byteEnd != null) {\n        // only byteEnd in range\n        if (byteSize == null) {\n            return `bytes */${total}`;\n        }\n        const end = byteSize - 1;\n        const start = end - byteEnd + 1;\n        return `bytes ${start}-${end}/${byteSize}`;\n    }\n    if (byteStart == null && byteEnd == null) {\n        // neither are provided, we can't return a valid range.\n        return `bytes */${total}`;\n    }\n    return `bytes ${byteStart}-${byteEnd}/${total}`;\n}\n/**\n * Sets the `X-Ipfs-Roots` header on the response if it exists.\n *\n * @see https://specs.ipfs.tech/http-gateways/path-gateway/#x-ipfs-roots-response-header\n */\nexport function setIpfsRoots(response, ipfsRoots) {\n    if (ipfsRoots != null) {\n        response.headers.set('X-Ipfs-Roots', ipfsRoots.map(cid => cid.toV1().toString()).join(','));\n    }\n}\n//# sourceMappingURL=response-headers.js.map","import { InvalidRangeError } from '../errors.js';\nimport { calculateByteRangeIndexes, getHeader } from './request-headers.js';\nimport { getContentRangeHeader } from './response-headers.js';\n/**\n * Gets the body size of a given body if it's possible to calculate it synchronously.\n */\nfunction getBodySizeSync(body) {\n    if (typeof body === 'string') {\n        return body.length;\n    }\n    if (body instanceof ArrayBuffer || body instanceof Uint8Array) {\n        return body.byteLength;\n    }\n    if (body instanceof Blob) {\n        return body.size;\n    }\n    if (body instanceof ReadableStream) {\n        return null;\n    }\n    return null;\n}\nfunction getByteRangeFromHeader(rangeHeader) {\n    /**\n     * Range: bytes=<start>-<end> | bytes=<start2>- | bytes=-<end2>\n     */\n    const match = rangeHeader.match(/^bytes=(?<start>\\d+)?-(?<end>\\d+)?$/);\n    if (match?.groups == null) {\n        throw new InvalidRangeError('Invalid range request');\n    }\n    const { start, end } = match.groups;\n    return { start, end };\n}\nexport class ByteRangeContext {\n    headers;\n    isRangeRequest;\n    /**\n     * This property is purposefully only set in `set fileSize` and should not be set directly.\n     */\n    _fileSize;\n    _body = null;\n    rangeRequestHeader;\n    log;\n    requestRangeStart;\n    requestRangeEnd;\n    byteStart;\n    byteEnd;\n    byteSize;\n    constructor(logger, headers) {\n        this.headers = headers;\n        this.log = logger.forComponent('helia:verified-fetch:byte-range-context');\n        this.rangeRequestHeader = getHeader(this.headers, 'Range');\n        if (this.rangeRequestHeader != null) {\n            this.isRangeRequest = true;\n            this.log.trace('range request detected');\n            try {\n                const { start, end } = getByteRangeFromHeader(this.rangeRequestHeader);\n                this.requestRangeStart = start != null ? parseInt(start) : null;\n                this.requestRangeEnd = end != null ? parseInt(end) : null;\n            }\n            catch (e) {\n                this.log.error('error parsing range request header: %o', e);\n                this.requestRangeStart = null;\n                this.requestRangeEnd = null;\n            }\n            this.setOffsetDetails();\n        }\n        else {\n            this.log.trace('no range request detected');\n            this.isRangeRequest = false;\n            this.requestRangeStart = null;\n            this.requestRangeEnd = null;\n        }\n    }\n    setBody(body) {\n        this._body = body;\n        // if fileSize was already set, don't recalculate it\n        this.setFileSize(this._fileSize ?? getBodySizeSync(body));\n        this.log.trace('set request body with fileSize %o', this._fileSize);\n    }\n    getBody() {\n        const body = this._body;\n        if (body == null) {\n            this.log.trace('body is null');\n            return body;\n        }\n        if (!this.isRangeRequest || !this.isValidRangeRequest) {\n            this.log.trace('returning body unmodified for non-range, or invalid range, request');\n            return body;\n        }\n        const byteStart = this.byteStart;\n        const byteEnd = this.byteEnd;\n        const byteSize = this.byteSize;\n        if (byteStart != null || byteEnd != null) {\n            this.log.trace('returning body with byteStart=%o, byteEnd=%o, byteSize=%o', byteStart, byteEnd, byteSize);\n            if (body instanceof ReadableStream) {\n                // stream should already be spliced by `unixfs.cat`\n                return body;\n            }\n            return this.getSlicedBody(body);\n        }\n        // we should not reach this point, but return body untouched.\n        this.log.error('returning unmodified body for valid range request');\n        return body;\n    }\n    // TODO: we should be able to use this.offset and this.length to slice the body\n    getSlicedBody(body) {\n        const offset = this.byteStart ?? 0;\n        const length = this.byteEnd == null ? undefined : this.byteEnd + 1;\n        this.log.trace('returning body with offset %o and length %o', offset, length);\n        return body.slice(offset, length);\n    }\n    /**\n     * Sometimes, we need to set the fileSize explicitly because we can't calculate\n     * the size of the body (e.g. for unixfs content where we call .stat).\n     *\n     * This fileSize should otherwise only be called from `setBody`.\n     */\n    setFileSize(size) {\n        this._fileSize = size != null ? Number(size) : null;\n        this.log.trace('set _fileSize to %o', this._fileSize);\n        // when fileSize changes, we need to recalculate the offset details\n        this.setOffsetDetails();\n    }\n    getFileSize() {\n        return this._fileSize;\n    }\n    isValidByteStart() {\n        if (this.byteStart != null) {\n            if (this.byteStart < 0) {\n                return false;\n            }\n            if (this._fileSize != null && this.byteStart >= this._fileSize) {\n                return false;\n            }\n            if (this.byteEnd != null && this.byteStart > this.byteEnd) {\n                return false;\n            }\n        }\n        return true;\n    }\n    isValidByteEnd() {\n        if (this.byteEnd != null) {\n            if (this.byteEnd < 0) {\n                return false;\n            }\n            if (this._fileSize != null && this.byteEnd >= this._fileSize) {\n                return false;\n            }\n            if (this.byteStart != null && this.byteEnd < this.byteStart) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * We may get the values required to determine if this is a valid range request at different times\n     * so we need to calculate it when asked.\n     */\n    get isValidRangeRequest() {\n        if (!this.isRangeRequest) {\n            return false;\n        }\n        if (this.requestRangeStart == null && this.requestRangeEnd == null) {\n            this.log.trace('invalid range request, range request values not provided');\n            return false;\n        }\n        if (!this.isValidByteStart()) {\n            this.log.trace('invalid range request, byteStart is less than 0 or greater than fileSize');\n            return false;\n        }\n        if (!this.isValidByteEnd()) {\n            this.log.trace('invalid range request, byteEnd is less than 0 or greater than fileSize');\n            return false;\n        }\n        if (this.requestRangeEnd != null && this.requestRangeStart != null) {\n            // we may not have enough info.. base check on requested bytes\n            if (this.requestRangeStart > this.requestRangeEnd) {\n                this.log.trace('invalid range request, start is greater than end');\n                return false;\n            }\n            else if (this.requestRangeStart < 0) {\n                this.log.trace('invalid range request, start is less than 0');\n                return false;\n            }\n            else if (this.requestRangeEnd < 0) {\n                this.log.trace('invalid range request, end is less than 0');\n                return false;\n            }\n        }\n        if (this.byteEnd == null && this.byteStart == null && this.byteSize == null) {\n            this.log.trace('invalid range request, could not calculate byteStart, byteEnd, or byteSize');\n            return false;\n        }\n        return true;\n    }\n    /**\n     * Given all the information we have, this function returns the offset that will be used when:\n     * 1. calling unixfs.cat\n     * 2. slicing the body\n     */\n    get offset() {\n        return this.byteStart ?? 0;\n    }\n    /**\n     * Given all the information we have, this function returns the length that will be used when:\n     * 1. calling unixfs.cat\n     * 2. slicing the body\n     */\n    get length() {\n        if (this.byteEnd != null && this.byteStart != null && this.byteStart === this.byteEnd) {\n            return 1;\n        }\n        if (this.byteEnd != null) {\n            return this.byteEnd + 1;\n        }\n        return this.byteSize != null ? this.byteSize - 1 : undefined;\n    }\n    /**\n     * Converts a range request header into helia/unixfs supported range options\n     * Note that the gateway specification says we \"MAY\" support multiple ranges (https://specs.ipfs.tech/http-gateways/path-gateway/#range-request-header) but we don't\n     *\n     * Also note that @helia/unixfs and ipfs-unixfs-exporter expect length and offset to be numbers, the range header is a string, and the size of the resource is likely a bigint.\n     *\n     * SUPPORTED:\n     * Range: bytes=<range-start>-<range-end>\n     * Range: bytes=<range-start>-\n     * Range: bytes=-<suffix-length> // must pass size so we can calculate the offset. suffix-length is the number of bytes from the end of the file.\n     *\n     * NOT SUPPORTED:\n     * Range: bytes=<range-start>-<range-end>, <range-start>-<range-end>\n     * Range: bytes=<range-start>-<range-end>, <range-start>-<range-end>, <range-start>-<range-end>\n     *\n     * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range#directives\n     */\n    setOffsetDetails() {\n        if (this.requestRangeStart == null && this.requestRangeEnd == null) {\n            this.log.trace('requestRangeStart and requestRangeEnd are null');\n            return;\n        }\n        try {\n            const { start, end, byteSize } = calculateByteRangeIndexes(this.requestRangeStart ?? undefined, this.requestRangeEnd ?? undefined, this._fileSize ?? undefined);\n            this.log.trace('set byteStart to %o, byteEnd to %o, byteSize to %o', start, end, byteSize);\n            this.byteStart = start;\n            this.byteEnd = end;\n            this.byteSize = byteSize;\n        }\n        catch (e) {\n            this.log.error('error setting offset details: %o', e);\n            this.byteStart = undefined;\n            this.byteEnd = undefined;\n            this.byteSize = undefined;\n        }\n    }\n    /**\n     * This function returns the value of the \"content-range\" header.\n     *\n     * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Range\n     *\n     * Returns a string representing the following content ranges:\n     *\n     * @example\n     * - Content-Range: <unit> <byteStart>-<byteEnd>/<byteSize>\n     * - Content-Range: <unit> <byteStart>-<byteEnd>/*\n     */\n    // - Content-Range: <unit> */<byteSize> // this is purposefully not in jsdoc block\n    get contentRangeHeaderValue() {\n        if (!this.isValidRangeRequest) {\n            this.log.error('cannot get contentRangeHeaderValue for invalid range request');\n            throw new InvalidRangeError('Invalid range request');\n        }\n        return getContentRangeHeader({\n            byteStart: this.byteStart,\n            byteEnd: this.byteEnd,\n            byteSize: this._fileSize ?? undefined\n        });\n    }\n}\n//# sourceMappingURL=byte-range-context.js.map","import { decode } from 'cborg';\nimport { encode } from 'cborg/json';\n/**\n * Take a `DAG-CBOR` encoded `Uint8Array`, deserialize it as an object and\n * re-serialize it in a form that can be passed to `JSON.serialize` and then\n * `JSON.parse` without losing any data.\n */\nexport function dagCborToSafeJSON(buf) {\n    const obj = decode(buf, {\n        allowIndefinite: false,\n        coerceUndefinedToNull: false,\n        allowNaN: false,\n        allowInfinity: false,\n        strict: true,\n        useMaps: false,\n        rejectDuplicateMapKeys: true,\n        // this is different to `DAG-CBOR` - the reason we disallow BigInts is\n        // because we are about to re-encode to `JSON` which does not support\n        // BigInts. Blocks containing large numbers should be deserialized using a\n        // cbor decoder instead\n        allowBigInt: false\n    });\n    return new TextDecoder().decode(encode(obj));\n}\n//# sourceMappingURL=dag-cbor-to-safe-json.js.map","/**\n * Takes a filename URL param and returns a string for use in a\n * `Content-Disposition` header\n */\nexport function getContentDispositionFilename(filename) {\n    const asciiOnly = replaceNonAsciiCharacters(filename);\n    if (asciiOnly === filename) {\n        return `filename=\"${filename}\"`;\n    }\n    return `filename=\"${asciiOnly}\"; filename*=UTF-8''${encodeURIComponent(filename)}`;\n}\nfunction replaceNonAsciiCharacters(filename) {\n    // eslint-disable-next-line no-control-regex\n    return filename.replace(/[^\\x00-\\x7F]/g, '_');\n}\n//# sourceMappingURL=get-content-disposition-filename.js.map","/**\n * etag\n * you need to wrap cid  with \"\"\n * we use strong Etags for immutable responses and weak one (prefixed with W/ ) for mutable/generated ones (ipns and generated HTML).\n * block and car responses should have different etag than deserialized one, so you can add some prefix like we do in existing gateway\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag\n * @see https://specs.ipfs.tech/http-gateways/path-gateway/#etag-response-header\n */\nexport function getETag({ cid, reqFormat, weak, rangeStart, rangeEnd }) {\n    const prefix = weak === true ? 'W/' : '';\n    let suffix = reqFormat == null ? '' : `.${reqFormat}`;\n    if (rangeStart != null || rangeEnd != null) {\n        suffix += `.${rangeStart ?? '0'}-${rangeEnd ?? 'N'}`;\n    }\n    return `${prefix}\"${cid.toString()}${suffix}\"`;\n}\n//# sourceMappingURL=get-e-tag.js.map","import { code as dagCborCode } from '@ipld/dag-cbor';\nimport { code as dagJsonCode } from '@ipld/dag-json';\nimport { code as dagPbCode } from '@ipld/dag-pb';\nimport { code as jsonCode } from 'multiformats/codecs/json';\nimport { code as rawCode } from 'multiformats/codecs/raw';\n/**\n * This maps supported response types for each codec supported by verified-fetch\n */\nconst CID_TYPE_MAP = {\n    [dagCborCode]: [\n        'application/json',\n        'application/vnd.ipld.dag-cbor',\n        'application/cbor',\n        'application/vnd.ipld.dag-json',\n        'application/octet-stream',\n        'application/vnd.ipld.raw',\n        'application/vnd.ipfs.ipns-record',\n        'application/vnd.ipld.car'\n    ],\n    [dagJsonCode]: [\n        'application/json',\n        'application/vnd.ipld.dag-cbor',\n        'application/cbor',\n        'application/vnd.ipld.dag-json',\n        'application/octet-stream',\n        'application/vnd.ipld.raw',\n        'application/vnd.ipfs.ipns-record',\n        'application/vnd.ipld.car'\n    ],\n    [jsonCode]: [\n        'application/json',\n        'application/vnd.ipld.dag-cbor',\n        'application/cbor',\n        'application/vnd.ipld.dag-json',\n        'application/octet-stream',\n        'application/vnd.ipld.raw',\n        'application/vnd.ipfs.ipns-record',\n        'application/vnd.ipld.car'\n    ],\n    [dagPbCode]: [\n        'application/octet-stream',\n        'application/json',\n        'application/vnd.ipld.dag-cbor',\n        'application/cbor',\n        'application/vnd.ipld.dag-json',\n        'application/vnd.ipld.raw',\n        'application/vnd.ipfs.ipns-record',\n        'application/vnd.ipld.car',\n        'application/x-tar'\n    ],\n    [rawCode]: [\n        'application/octet-stream',\n        'application/vnd.ipld.raw',\n        'application/vnd.ipfs.ipns-record',\n        'application/vnd.ipld.dag-json',\n        'application/vnd.ipld.car',\n        'application/x-tar'\n    ]\n};\n/**\n * Selects an output mime-type based on the CID and a passed `Accept` header\n */\nexport function selectOutputType(cid, accept) {\n    const cidMimeTypes = CID_TYPE_MAP[cid.code];\n    if (accept != null) {\n        return chooseMimeType(accept, cidMimeTypes);\n    }\n}\nfunction chooseMimeType(accept, validMimeTypes) {\n    const requestedMimeTypes = accept\n        .split(',')\n        .map(s => {\n        const parts = s.trim().split(';');\n        return {\n            mimeType: `${parts[0]}`.trim(),\n            weight: parseQFactor(parts[1])\n        };\n    })\n        .sort((a, b) => {\n        if (a.weight === b.weight) {\n            return 0;\n        }\n        if (a.weight > b.weight) {\n            return -1;\n        }\n        return 1;\n    })\n        .map(s => s.mimeType);\n    for (const headerFormat of requestedMimeTypes) {\n        for (const mimeType of validMimeTypes) {\n            if (headerFormat.includes(mimeType)) {\n                return mimeType;\n            }\n            if (headerFormat === '*/*') {\n                return mimeType;\n            }\n            if (headerFormat.startsWith('*/') && mimeType.split('/')[1] === headerFormat.split('/')[1]) {\n                return mimeType;\n            }\n            if (headerFormat.endsWith('/*') && mimeType.split('/')[0] === headerFormat.split('/')[0]) {\n                return mimeType;\n            }\n        }\n    }\n}\n/**\n * Parses q-factor weighting from the accept header to allow letting some mime\n * types take precedence over others.\n *\n * If the q-factor for an acceptable mime representation is omitted it defaults\n * to `1`.\n *\n * All specified values should be in the range 0-1.\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Accept#q\n */\nfunction parseQFactor(str) {\n    if (str != null) {\n        str = str.trim();\n    }\n    if (str?.startsWith('q=') !== true) {\n        return 1;\n    }\n    const factor = parseFloat(str.replace('q=', ''));\n    if (isNaN(factor)) {\n        return 0;\n    }\n    return factor;\n}\nexport const FORMAT_TO_MIME_TYPE = {\n    raw: 'application/vnd.ipld.raw',\n    car: 'application/vnd.ipld.car',\n    'dag-json': 'application/vnd.ipld.dag-json',\n    'dag-cbor': 'application/vnd.ipld.dag-cbor',\n    json: 'application/json',\n    cbor: 'application/cbor',\n    'ipns-record': 'application/vnd.ipfs.ipns-record',\n    tar: 'application/x-tar'\n};\n/**\n * Converts a `format=...` query param to a mime type as would be found in the\n * `Accept` header, if a valid mapping is available\n */\nexport function queryFormatToAcceptHeader(format) {\n    if (format != null) {\n        return FORMAT_TO_MIME_TYPE[format];\n    }\n}\n//# sourceMappingURL=select-output-type.js.map","import { FORMAT_TO_MIME_TYPE } from './select-output-type.js';\nexport function isExplicitAcceptHeader(headers) {\n    const incomingAcceptHeader = headers.get('accept');\n    if (incomingAcceptHeader != null && Object.values(FORMAT_TO_MIME_TYPE).includes(incomingAcceptHeader)) {\n        return true;\n    }\n    return false;\n}\nexport function isExplicitFormatQuery(query) {\n    const formatQuery = query?.format;\n    if (formatQuery != null && Object.keys(FORMAT_TO_MIME_TYPE).includes(formatQuery)) {\n        return true;\n    }\n    return false;\n}\n/**\n * The user can provide an explicit `accept` header in the request headers or a `format` query parameter in the URL.\n * If either of these are provided, this function returns true.\n */\nexport function isExplicitIpldAcceptRequest({ query, headers }) {\n    return isExplicitAcceptHeader(headers) || isExplicitFormatQuery(query);\n}\n//# sourceMappingURL=is-accept-explicit.js.map","import { isExplicitAcceptHeader, isExplicitFormatQuery, isExplicitIpldAcceptRequest } from './is-accept-explicit.js';\nimport { queryFormatToAcceptHeader } from './select-output-type.js';\nexport function getResolvedAcceptHeader({ query, headers, logger }) {\n    const log = logger.forComponent('helia:verified-fetch:get-resolved-accept-header');\n    const requestHeaders = new Headers(headers);\n    const incomingAcceptHeader = requestHeaders.get('accept') ?? undefined;\n    if (incomingAcceptHeader != null) {\n        log('incoming accept header \"%s\"', incomingAcceptHeader);\n    }\n    if (!isExplicitIpldAcceptRequest({ query, headers: requestHeaders })) {\n        log('no explicit IPLD content-type requested, returning incoming accept header %s', incomingAcceptHeader);\n        return incomingAcceptHeader;\n    }\n    const queryFormatMapping = queryFormatToAcceptHeader(query?.format);\n    if (query?.format != null) {\n        log('incoming query format \"%s\", mapped to %s', query.format, queryFormatMapping);\n    }\n    let acceptHeader = incomingAcceptHeader;\n    // if the incomingAcceptHeader is autogenerated by the requesting client (browser/curl/fetch/etc) then we may need to override it if query.format is specified\n    if (!isExplicitAcceptHeader(requestHeaders) && isExplicitFormatQuery(query)) {\n        log('accept header not recognized, but query format provided, setting accept header to %s', queryFormatMapping);\n        acceptHeader = queryFormatMapping;\n    }\n    log('resolved accept header to \"%s\"', acceptHeader);\n    return acceptHeader;\n}\n//# sourceMappingURL=get-resolved-accept-header.js.map","import { AbortError } from '@libp2p/interface';\nimport { CustomProgressEvent } from 'progress-events';\nimport { NoContentError } from '../errors.js';\n/**\n * Converts an async iterator of Uint8Array bytes to a stream and returns the first chunk of bytes\n */\nexport async function getStreamFromAsyncIterable(iterator, path, logger, options) {\n    const log = logger.forComponent('helia:verified-fetch:get-stream-from-async-iterable');\n    const reader = iterator[Symbol.asyncIterator]();\n    const { value: firstChunk, done } = await reader.next();\n    if (done === true) {\n        log.error('no content found for path', path);\n        throw new NoContentError();\n    }\n    const stream = new ReadableStream({\n        async start(controller) {\n            // the initial value is already available\n            options?.onProgress?.(new CustomProgressEvent('verified-fetch:request:progress:chunk'));\n            controller.enqueue(firstChunk);\n        },\n        async pull(controller) {\n            const { value, done } = await reader.next();\n            if (options?.signal?.aborted === true) {\n                controller.error(new AbortError(options.signal.reason ?? 'signal aborted by user'));\n                controller.close();\n                return;\n            }\n            if (done === true) {\n                if (value != null) {\n                    options?.onProgress?.(new CustomProgressEvent('verified-fetch:request:progress:chunk'));\n                    controller.enqueue(value);\n                }\n                controller.close();\n                return;\n            }\n            options?.onProgress?.(new CustomProgressEvent('verified-fetch:request:progress:chunk'));\n            controller.enqueue(value);\n        }\n    });\n    return {\n        stream,\n        firstChunk\n    };\n}\n//# sourceMappingURL=get-stream-from-async-iterable.js.map","export class UnixFSError extends Error {\n    name;\n    code;\n    constructor(message, name, code) {\n        super(message);\n        this.name = name;\n        this.code = code;\n    }\n}\nexport class NotUnixFSError extends UnixFSError {\n    constructor(message = 'not a Unixfs node') {\n        super(message, 'NotUnixFSError', 'ERR_NOT_UNIXFS');\n    }\n}\nexport class InvalidPBNodeError extends UnixFSError {\n    constructor(message = 'invalid PBNode') {\n        super(message, 'InvalidPBNodeError', 'ERR_INVALID_PBNODE');\n    }\n}\nexport class UnknownError extends UnixFSError {\n    constructor(message = 'unknown error') {\n        super(message, 'InvalidPBNodeError', 'ERR_UNKNOWN_ERROR');\n    }\n}\nexport class AlreadyExistsError extends UnixFSError {\n    constructor(message = 'path already exists') {\n        super(message, 'AlreadyExistsError', 'ERR_ALREADY_EXISTS');\n    }\n}\nexport class DoesNotExistError extends UnixFSError {\n    constructor(message = 'path does not exist') {\n        super(message, 'DoesNotExistError', 'ERR_DOES_NOT_EXIST');\n    }\n}\nexport class NoContentError extends UnixFSError {\n    constructor(message = 'no content') {\n        super(message, 'NoContentError', 'ERR_NO_CONTENT');\n    }\n}\nexport class NotAFileError extends UnixFSError {\n    constructor(message = 'not a file') {\n        super(message, 'NotAFileError', 'ERR_NOT_A_FILE');\n    }\n}\nexport class NotADirectoryError extends UnixFSError {\n    constructor(message = 'not a directory') {\n        super(message, 'NotADirectoryError', 'ERR_NOT_A_DIRECTORY');\n    }\n}\nexport class InvalidParametersError extends UnixFSError {\n    constructor(message = 'invalid parameters') {\n        super(message, 'InvalidParametersError', 'ERR_INVALID_PARAMETERS');\n    }\n}\n//# sourceMappingURL=errors.js.map","/**\n * @packageDocumentation\n *\n * A class that lets you do operations over a list of Uint8Arrays without\n * copying them.\n *\n * ```js\n * import { Uint8ArrayList } from 'uint8arraylist'\n *\n * const list = new Uint8ArrayList()\n * list.append(Uint8Array.from([0, 1, 2]))\n * list.append(Uint8Array.from([3, 4, 5]))\n *\n * list.subarray()\n * // -> Uint8Array([0, 1, 2, 3, 4, 5])\n *\n * list.consume(3)\n * list.subarray()\n * // -> Uint8Array([3, 4, 5])\n *\n * // you can also iterate over the list\n * for (const buf of list) {\n *   // ..do something with `buf`\n * }\n *\n * list.subarray(0, 1)\n * // -> Uint8Array([0])\n * ```\n *\n * ## Converting Uint8ArrayLists to Uint8Arrays\n *\n * There are two ways to turn a `Uint8ArrayList` into a `Uint8Array` - `.slice` and `.subarray` and one way to turn a `Uint8ArrayList` into a `Uint8ArrayList` with different contents - `.sublist`.\n *\n * ### slice\n *\n * Slice follows the same semantics as [Uint8Array.slice](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/slice) in that it creates a new `Uint8Array` and copies bytes into it using an optional offset & length.\n *\n * ```js\n * const list = new Uint8ArrayList()\n * list.append(Uint8Array.from([0, 1, 2]))\n * list.append(Uint8Array.from([3, 4, 5]))\n *\n * list.slice(0, 1)\n * // -> Uint8Array([0])\n * ```\n *\n * ### subarray\n *\n * Subarray attempts to follow the same semantics as [Uint8Array.subarray](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/subarray) with one important different - this is a no-copy operation, unless the requested bytes span two internal buffers in which case it is a copy operation.\n *\n * ```js\n * const list = new Uint8ArrayList()\n * list.append(Uint8Array.from([0, 1, 2]))\n * list.append(Uint8Array.from([3, 4, 5]))\n *\n * list.subarray(0, 1)\n * // -> Uint8Array([0]) - no-copy\n *\n * list.subarray(2, 5)\n * // -> Uint8Array([2, 3, 4]) - copy\n * ```\n *\n * ### sublist\n *\n * Sublist creates and returns a new `Uint8ArrayList` that shares the underlying buffers with the original so is always a no-copy operation.\n *\n * ```js\n * const list = new Uint8ArrayList()\n * list.append(Uint8Array.from([0, 1, 2]))\n * list.append(Uint8Array.from([3, 4, 5]))\n *\n * list.sublist(0, 1)\n * // -> Uint8ArrayList([0]) - no-copy\n *\n * list.sublist(2, 5)\n * // -> Uint8ArrayList([2], [3, 4]) - no-copy\n * ```\n *\n * ## Inspiration\n *\n * Borrows liberally from [bl](https://www.npmjs.com/package/bl) but only uses native JS types.\n */\nimport { allocUnsafe, alloc } from 'uint8arrays/alloc';\nimport { concat } from 'uint8arrays/concat';\nimport { equals } from 'uint8arrays/equals';\nconst symbol = Symbol.for('@achingbrain/uint8arraylist');\nfunction findBufAndOffset(bufs, index) {\n    if (index == null || index < 0) {\n        throw new RangeError('index is out of bounds');\n    }\n    let offset = 0;\n    for (const buf of bufs) {\n        const bufEnd = offset + buf.byteLength;\n        if (index < bufEnd) {\n            return {\n                buf,\n                index: index - offset\n            };\n        }\n        offset = bufEnd;\n    }\n    throw new RangeError('index is out of bounds');\n}\n/**\n * Check if object is a CID instance\n *\n * @example\n *\n * ```js\n * import { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist'\n *\n * isUint8ArrayList(true) // false\n * isUint8ArrayList([]) // false\n * isUint8ArrayList(new Uint8ArrayList()) // true\n * ```\n */\nexport function isUint8ArrayList(value) {\n    return Boolean(value?.[symbol]);\n}\nexport class Uint8ArrayList {\n    bufs;\n    length;\n    [symbol] = true;\n    constructor(...data) {\n        this.bufs = [];\n        this.length = 0;\n        if (data.length > 0) {\n            this.appendAll(data);\n        }\n    }\n    *[Symbol.iterator]() {\n        yield* this.bufs;\n    }\n    get byteLength() {\n        return this.length;\n    }\n    /**\n     * Add one or more `bufs` to the end of this Uint8ArrayList\n     */\n    append(...bufs) {\n        this.appendAll(bufs);\n    }\n    /**\n     * Add all `bufs` to the end of this Uint8ArrayList\n     */\n    appendAll(bufs) {\n        let length = 0;\n        for (const buf of bufs) {\n            if (buf instanceof Uint8Array) {\n                length += buf.byteLength;\n                this.bufs.push(buf);\n            }\n            else if (isUint8ArrayList(buf)) {\n                length += buf.byteLength;\n                this.bufs.push(...buf.bufs);\n            }\n            else {\n                throw new Error('Could not append value, must be an Uint8Array or a Uint8ArrayList');\n            }\n        }\n        this.length += length;\n    }\n    /**\n     * Add one or more `bufs` to the start of this Uint8ArrayList\n     */\n    prepend(...bufs) {\n        this.prependAll(bufs);\n    }\n    /**\n     * Add all `bufs` to the start of this Uint8ArrayList\n     */\n    prependAll(bufs) {\n        let length = 0;\n        for (const buf of bufs.reverse()) {\n            if (buf instanceof Uint8Array) {\n                length += buf.byteLength;\n                this.bufs.unshift(buf);\n            }\n            else if (isUint8ArrayList(buf)) {\n                length += buf.byteLength;\n                this.bufs.unshift(...buf.bufs);\n            }\n            else {\n                throw new Error('Could not prepend value, must be an Uint8Array or a Uint8ArrayList');\n            }\n        }\n        this.length += length;\n    }\n    /**\n     * Read the value at `index`\n     */\n    get(index) {\n        const res = findBufAndOffset(this.bufs, index);\n        return res.buf[res.index];\n    }\n    /**\n     * Set the value at `index` to `value`\n     */\n    set(index, value) {\n        const res = findBufAndOffset(this.bufs, index);\n        res.buf[res.index] = value;\n    }\n    /**\n     * Copy bytes from `buf` to the index specified by `offset`\n     */\n    write(buf, offset = 0) {\n        if (buf instanceof Uint8Array) {\n            for (let i = 0; i < buf.length; i++) {\n                this.set(offset + i, buf[i]);\n            }\n        }\n        else if (isUint8ArrayList(buf)) {\n            for (let i = 0; i < buf.length; i++) {\n                this.set(offset + i, buf.get(i));\n            }\n        }\n        else {\n            throw new Error('Could not write value, must be an Uint8Array or a Uint8ArrayList');\n        }\n    }\n    /**\n     * Remove bytes from the front of the pool\n     */\n    consume(bytes) {\n        // first, normalize the argument, in accordance with how Buffer does it\n        bytes = Math.trunc(bytes);\n        // do nothing if not a positive number\n        if (Number.isNaN(bytes) || bytes <= 0) {\n            return;\n        }\n        // if consuming all bytes, skip iterating\n        if (bytes === this.byteLength) {\n            this.bufs = [];\n            this.length = 0;\n            return;\n        }\n        while (this.bufs.length > 0) {\n            if (bytes >= this.bufs[0].byteLength) {\n                bytes -= this.bufs[0].byteLength;\n                this.length -= this.bufs[0].byteLength;\n                this.bufs.shift();\n            }\n            else {\n                this.bufs[0] = this.bufs[0].subarray(bytes);\n                this.length -= bytes;\n                break;\n            }\n        }\n    }\n    /**\n     * Extracts a section of an array and returns a new array.\n     *\n     * This is a copy operation as it is with Uint8Arrays and Arrays\n     * - note this is different to the behaviour of Node Buffers.\n     */\n    slice(beginInclusive, endExclusive) {\n        const { bufs, length } = this._subList(beginInclusive, endExclusive);\n        return concat(bufs, length);\n    }\n    /**\n     * Returns a alloc from the given start and end element index.\n     *\n     * In the best case where the data extracted comes from a single Uint8Array\n     * internally this is a no-copy operation otherwise it is a copy operation.\n     */\n    subarray(beginInclusive, endExclusive) {\n        const { bufs, length } = this._subList(beginInclusive, endExclusive);\n        if (bufs.length === 1) {\n            return bufs[0];\n        }\n        return concat(bufs, length);\n    }\n    /**\n     * Returns a allocList from the given start and end element index.\n     *\n     * This is a no-copy operation.\n     */\n    sublist(beginInclusive, endExclusive) {\n        const { bufs, length } = this._subList(beginInclusive, endExclusive);\n        const list = new Uint8ArrayList();\n        list.length = length;\n        // don't loop, just set the bufs\n        list.bufs = [...bufs];\n        return list;\n    }\n    _subList(beginInclusive, endExclusive) {\n        beginInclusive = beginInclusive ?? 0;\n        endExclusive = endExclusive ?? this.length;\n        if (beginInclusive < 0) {\n            beginInclusive = this.length + beginInclusive;\n        }\n        if (endExclusive < 0) {\n            endExclusive = this.length + endExclusive;\n        }\n        if (beginInclusive < 0 || endExclusive > this.length) {\n            throw new RangeError('index is out of bounds');\n        }\n        if (beginInclusive === endExclusive) {\n            return { bufs: [], length: 0 };\n        }\n        if (beginInclusive === 0 && endExclusive === this.length) {\n            return { bufs: this.bufs, length: this.length };\n        }\n        const bufs = [];\n        let offset = 0;\n        for (let i = 0; i < this.bufs.length; i++) {\n            const buf = this.bufs[i];\n            const bufStart = offset;\n            const bufEnd = bufStart + buf.byteLength;\n            // for next loop\n            offset = bufEnd;\n            if (beginInclusive >= bufEnd) {\n                // start after this buf\n                continue;\n            }\n            const sliceStartInBuf = beginInclusive >= bufStart && beginInclusive < bufEnd;\n            const sliceEndsInBuf = endExclusive > bufStart && endExclusive <= bufEnd;\n            if (sliceStartInBuf && sliceEndsInBuf) {\n                // slice is wholly contained within this buffer\n                if (beginInclusive === bufStart && endExclusive === bufEnd) {\n                    // requested whole buffer\n                    bufs.push(buf);\n                    break;\n                }\n                // requested part of buffer\n                const start = beginInclusive - bufStart;\n                bufs.push(buf.subarray(start, start + (endExclusive - beginInclusive)));\n                break;\n            }\n            if (sliceStartInBuf) {\n                // slice starts in this buffer\n                if (beginInclusive === 0) {\n                    // requested whole buffer\n                    bufs.push(buf);\n                    continue;\n                }\n                // requested part of buffer\n                bufs.push(buf.subarray(beginInclusive - bufStart));\n                continue;\n            }\n            if (sliceEndsInBuf) {\n                if (endExclusive === bufEnd) {\n                    // requested whole buffer\n                    bufs.push(buf);\n                    break;\n                }\n                // requested part of buffer\n                bufs.push(buf.subarray(0, endExclusive - bufStart));\n                break;\n            }\n            // slice started before this buffer and ends after it\n            bufs.push(buf);\n        }\n        return { bufs, length: endExclusive - beginInclusive };\n    }\n    indexOf(search, offset = 0) {\n        if (!isUint8ArrayList(search) && !(search instanceof Uint8Array)) {\n            throw new TypeError('The \"value\" argument must be a Uint8ArrayList or Uint8Array');\n        }\n        const needle = search instanceof Uint8Array ? search : search.subarray();\n        offset = Number(offset ?? 0);\n        if (isNaN(offset)) {\n            offset = 0;\n        }\n        if (offset < 0) {\n            offset = this.length + offset;\n        }\n        if (offset < 0) {\n            offset = 0;\n        }\n        if (search.length === 0) {\n            return offset > this.length ? this.length : offset;\n        }\n        // https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string-search_algorithm\n        const M = needle.byteLength;\n        if (M === 0) {\n            throw new TypeError('search must be at least 1 byte long');\n        }\n        // radix\n        const radix = 256;\n        const rightmostPositions = new Int32Array(radix);\n        // position of the rightmost occurrence of the byte c in the pattern\n        for (let c = 0; c < radix; c++) {\n            // -1 for bytes not in pattern\n            rightmostPositions[c] = -1;\n        }\n        for (let j = 0; j < M; j++) {\n            // rightmost position for bytes in pattern\n            rightmostPositions[needle[j]] = j;\n        }\n        // Return offset of first match, -1 if no match\n        const right = rightmostPositions;\n        const lastIndex = this.byteLength - needle.byteLength;\n        const lastPatIndex = needle.byteLength - 1;\n        let skip;\n        for (let i = offset; i <= lastIndex; i += skip) {\n            skip = 0;\n            for (let j = lastPatIndex; j >= 0; j--) {\n                const char = this.get(i + j);\n                if (needle[j] !== char) {\n                    skip = Math.max(1, j - right[char]);\n                    break;\n                }\n            }\n            if (skip === 0) {\n                return i;\n            }\n        }\n        return -1;\n    }\n    getInt8(byteOffset) {\n        const buf = this.subarray(byteOffset, byteOffset + 1);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getInt8(0);\n    }\n    setInt8(byteOffset, value) {\n        const buf = allocUnsafe(1);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setInt8(0, value);\n        this.write(buf, byteOffset);\n    }\n    getInt16(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 2);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getInt16(0, littleEndian);\n    }\n    setInt16(byteOffset, value, littleEndian) {\n        const buf = alloc(2);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setInt16(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    getInt32(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 4);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getInt32(0, littleEndian);\n    }\n    setInt32(byteOffset, value, littleEndian) {\n        const buf = alloc(4);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setInt32(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    getBigInt64(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 8);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getBigInt64(0, littleEndian);\n    }\n    setBigInt64(byteOffset, value, littleEndian) {\n        const buf = alloc(8);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setBigInt64(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    getUint8(byteOffset) {\n        const buf = this.subarray(byteOffset, byteOffset + 1);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getUint8(0);\n    }\n    setUint8(byteOffset, value) {\n        const buf = allocUnsafe(1);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setUint8(0, value);\n        this.write(buf, byteOffset);\n    }\n    getUint16(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 2);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getUint16(0, littleEndian);\n    }\n    setUint16(byteOffset, value, littleEndian) {\n        const buf = alloc(2);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setUint16(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    getUint32(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 4);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getUint32(0, littleEndian);\n    }\n    setUint32(byteOffset, value, littleEndian) {\n        const buf = alloc(4);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setUint32(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    getBigUint64(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 8);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getBigUint64(0, littleEndian);\n    }\n    setBigUint64(byteOffset, value, littleEndian) {\n        const buf = alloc(8);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setBigUint64(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    getFloat32(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 4);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getFloat32(0, littleEndian);\n    }\n    setFloat32(byteOffset, value, littleEndian) {\n        const buf = alloc(4);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setFloat32(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    getFloat64(byteOffset, littleEndian) {\n        const buf = this.subarray(byteOffset, byteOffset + 8);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        return view.getFloat64(0, littleEndian);\n    }\n    setFloat64(byteOffset, value, littleEndian) {\n        const buf = alloc(8);\n        const view = new DataView(buf.buffer, buf.byteOffset, buf.byteLength);\n        view.setFloat64(0, value, littleEndian);\n        this.write(buf, byteOffset);\n    }\n    equals(other) {\n        if (other == null) {\n            return false;\n        }\n        if (!(other instanceof Uint8ArrayList)) {\n            return false;\n        }\n        if (other.bufs.length !== this.bufs.length) {\n            return false;\n        }\n        for (let i = 0; i < this.bufs.length; i++) {\n            if (!equals(this.bufs[i], other.bufs[i])) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Create a Uint8ArrayList from a pre-existing list of Uint8Arrays.  Use this\n     * method if you know the total size of all the Uint8Arrays ahead of time.\n     */\n    static fromUint8Arrays(bufs, length) {\n        const list = new Uint8ArrayList();\n        list.bufs = bufs;\n        if (length == null) {\n            length = bufs.reduce((acc, curr) => acc + curr.byteLength, 0);\n        }\n        list.length = length;\n        return list;\n    }\n}\n/*\nfunction indexOf (needle: Uint8Array, haystack: Uint8Array, offset = 0) {\n  for (let i = offset; i < haystack.byteLength; i++) {\n    for (let j = 0; j < needle.length; j++) {\n      if (haystack[i + j] !== needle[j]) {\n        break\n      }\n\n      if (j === needle.byteLength -1) {\n        return i\n      }\n    }\n\n    if (haystack.byteLength - i < needle.byteLength) {\n      break\n    }\n  }\n\n  return -1\n}\n*/\n//# sourceMappingURL=index.js.map","import { Uint8ArrayList, isUint8ArrayList } from 'uint8arraylist';\nimport { compare as uint8ArrayCompare } from 'uint8arrays/compare';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nconst ZERO_OFFSET = '0'.charCodeAt(0);\nconst USTAR_MAGIC = uint8ArrayFromString('ustar\\x00', 'binary');\nconst GNU_MAGIC = uint8ArrayFromString('ustar\\x20', 'binary');\nconst GNU_VER = uint8ArrayFromString('\\x20\\x00', 'binary');\nconst MAGIC_OFFSET = 257;\nconst VERSION_OFFSET = 263;\nconst clamp = function (index, len, defaultValue) {\n    if (typeof index !== 'number')\n        return defaultValue;\n    index = ~~index; // Coerce to integer.\n    if (index >= len)\n        return len;\n    if (index >= 0)\n        return index;\n    index += len;\n    if (index >= 0)\n        return index;\n    return 0;\n};\nconst toType = function (flag) {\n    switch (flag) {\n        case 0:\n            return 'file';\n        case 1:\n            return 'link';\n        case 2:\n            return 'symlink';\n        case 3:\n            return 'character-device';\n        case 4:\n            return 'block-device';\n        case 5:\n            return 'directory';\n        case 6:\n            return 'fifo';\n        case 7:\n            return 'contiguous-file';\n        case 72:\n            return 'pax-header';\n        case 55:\n            return 'pax-global-header';\n        case 27:\n            return 'gnu-long-link-path';\n        case 28:\n        case 30:\n            return 'gnu-long-path';\n        default:\n            return undefined;\n    }\n};\nconst indexOf = function (block, num, offset, end) {\n    for (; offset < end; offset++) {\n        if (block.get(offset) === num)\n            return offset;\n    }\n    return end;\n};\nconst cksum = function (block) {\n    let sum = 8 * 32;\n    for (let i = 0; i < 148; i++)\n        sum += block.get(i);\n    for (let j = 156; j < 512; j++)\n        sum += block.get(j);\n    return sum;\n};\n/* Copied from the node-tar repo and modified to meet\n * tar-stream coding standard.\n *\n * Source: https://github.com/npm/node-tar/blob/51b6627a1f357d2eb433e7378e5f05e83b7aa6cd/lib/header.js#L349\n */\nfunction parse256(buf) {\n    // first byte MUST be either 80 or FF\n    // 80 for positive, FF for 2's comp\n    let positive;\n    if (buf.get(0) === 0x80) {\n        positive = true;\n    }\n    else if (buf.get(0) === 0xFF) {\n        positive = false;\n    }\n    else {\n        return 0;\n    }\n    // build up a base-256 tuple from the least sig to the highest\n    let zero = false;\n    const tuple = [];\n    for (let i = buf.length - 1; i > 0; i--) {\n        const byte = buf.get(i);\n        if (positive)\n            tuple.push(byte);\n        else if (zero && byte === 0)\n            tuple.push(0);\n        else if (zero) {\n            zero = false;\n            tuple.push(0x100 - byte);\n        }\n        else\n            tuple.push(0xFF - byte);\n    }\n    let sum = 0;\n    const l = tuple.length;\n    for (let i = 0; i < l; i++) {\n        sum += tuple[i] * Math.pow(256, i);\n    }\n    return positive ? sum : -1 * sum;\n}\nconst decodeOct = function (val, offset, length) {\n    val = val.sublist(offset, offset + length);\n    offset = 0;\n    // If prefixed with 0x80 then parse as a base-256 integer\n    if ((val.get(offset) & 0x80) !== 0) {\n        return parse256(val);\n    }\n    else {\n        // Older versions of tar can prefix with spaces\n        while (offset < val.length && val.get(offset) === 32) {\n            offset++;\n        }\n        const end = clamp(indexOf(val, 32, offset, val.length), val.length, val.length);\n        while (offset < end && val.get(offset) === 0) {\n            offset++;\n        }\n        if (end === offset) {\n            return 0;\n        }\n        return parseInt(uint8ArrayToString(val.subarray(offset, end)), 8);\n    }\n};\nconst decodeStr = function (val, offset, length, encoding) {\n    return uint8ArrayToString(val.subarray(offset, indexOf(val, 0, offset, offset + length)), encoding);\n};\nexport function decodeLongPath(buf, encoding) {\n    const list = isUint8ArrayList(buf) ? buf : new Uint8ArrayList(buf);\n    return decodeStr(list, 0, buf.length, encoding);\n}\nexport function decodePax(buf, encoding) {\n    let list = isUint8ArrayList(buf) ? buf : new Uint8ArrayList(buf);\n    const result = {};\n    while (list.length > 0) {\n        let i = 0;\n        while (i < buf.length && list.get(i) !== 32) {\n            i++;\n        }\n        const len = parseInt(uint8ArrayToString(list.subarray(0, i)), 10);\n        if (len === 0) {\n            return result;\n        }\n        const b = uint8ArrayToString(list.subarray(i + 1, len - 1), encoding);\n        const keyIndex = b.indexOf('=');\n        if (keyIndex === -1) {\n            return result;\n        }\n        result[b.slice(0, keyIndex)] = b.slice(keyIndex + 1);\n        list = list.sublist(len);\n    }\n    return result;\n}\nexport function decode(buf, filenameEncoding) {\n    const list = isUint8ArrayList(buf) ? buf : new Uint8ArrayList(buf);\n    let typeflag = list.get(156) === 0 ? 0 : list.get(156) - ZERO_OFFSET;\n    let name = decodeStr(list, 0, 100, filenameEncoding);\n    const mode = decodeOct(list, 100, 8);\n    const uid = decodeOct(list, 108, 8);\n    const gid = decodeOct(list, 116, 8);\n    const size = decodeOct(list, 124, 12);\n    const mtime = decodeOct(list, 136, 12);\n    const type = toType(typeflag);\n    const linkname = list.get(157) === 0 ? undefined : decodeStr(list, 157, 100, filenameEncoding);\n    const uname = decodeStr(list, 265, 32);\n    const gname = decodeStr(list, 297, 32);\n    const devmajor = decodeOct(list, 329, 8);\n    const devminor = decodeOct(list, 337, 8);\n    const c = cksum(list);\n    // checksum is still initial value if header was null.\n    if (c === 8 * 32) {\n        return null;\n    }\n    // valid checksum\n    if (c !== decodeOct(list, 148, 8)) {\n        throw new Error('Invalid tar header. Maybe the tar is corrupted or it needs to be gunzipped?');\n    }\n    if (uint8ArrayCompare(USTAR_MAGIC, list.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6)) === 0) {\n        // ustar (posix) format.\n        // prepend prefix, if present.\n        if (list.get(345) !== 0) {\n            name = decodeStr(list, 345, 155, filenameEncoding) + '/' + name;\n        }\n    }\n    else if (uint8ArrayCompare(GNU_MAGIC, list.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6)) === 0 &&\n        uint8ArrayCompare(GNU_VER, list.subarray(VERSION_OFFSET, VERSION_OFFSET + 2)) === 0) {\n        // 'gnu'/'oldgnu' format. Similar to ustar, but has support for incremental and\n        // multi-volume tarballs.\n    }\n    else {\n        throw new Error('Invalid tar header: unknown format.');\n    }\n    // to support old tar versions that use trailing / to indicate dirs\n    if (typeflag === 0 && name != null && name[name.length - 1] === '/') {\n        typeflag = 5;\n    }\n    return {\n        name,\n        mode,\n        uid,\n        gid,\n        size,\n        mtime: new Date(1000 * (mtime ?? 0)),\n        type,\n        linkname,\n        uname,\n        gname,\n        devmajor,\n        devminor\n    };\n}\n//# sourceMappingURL=extract-headers.js.map","import { Uint8ArrayList } from 'uint8arraylist';\n/**\n * Returns an `AsyncGenerator` that allows reading a set number of bytes from the passed source.\n *\n * @example\n *\n * ```javascript\n * import { reader } from 'it-reader'\n *\n * const stream = reader(source)\n *\n * // read 10 bytes from the stream\n * const { done, value } = await stream.next(10)\n *\n * if (done === true) {\n *   // stream finished\n * }\n *\n * if (value != null) {\n *   // do something with value\n * }\n * ```\n */\nexport function reader(source) {\n    const reader = (async function* () {\n        // @ts-expect-error first yield in stream is ignored\n        let bytes = yield; // Allows us to receive 8 when reader.next(8) is called\n        let bl = new Uint8ArrayList();\n        for await (const chunk of source) {\n            if (bytes == null) {\n                bl.append(chunk);\n                bytes = yield bl;\n                bl = new Uint8ArrayList();\n                continue;\n            }\n            bl.append(chunk);\n            while (bl.length >= bytes) {\n                const data = bl.sublist(0, bytes);\n                bl.consume(bytes);\n                bytes = yield data;\n                // If we no longer want a specific byte length, we yield the rest now\n                if (bytes == null) {\n                    if (bl.length > 0) {\n                        bytes = yield bl;\n                        bl = new Uint8ArrayList();\n                    }\n                    break; // bytes is null and/or no more buffer to yield\n                }\n            }\n        }\n        // Consumer wants more bytes but the source has ended and our buffer\n        // is not big enough to satisfy.\n        if (bytes != null) {\n            throw Object.assign(new Error(`stream ended before ${bytes} bytes became available`), { code: 'ERR_UNDER_READ', buffer: bl });\n        }\n    })();\n    void reader.next();\n    return reader;\n}\n//# sourceMappingURL=index.js.map","import { reader } from 'it-reader';\nimport { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist';\nexport function lteReader(source) {\n    const input = reader(source);\n    let overflow;\n    const lteReader = {\n        [Symbol.asyncIterator]: () => lteReader,\n        async next(bytes) {\n            if (overflow != null) {\n                let value;\n                if (bytes == null || overflow.length === bytes) {\n                    value = overflow;\n                    overflow = null;\n                }\n                else if (overflow.length > bytes) {\n                    value = overflow.sublist(0, bytes);\n                    overflow = overflow.sublist(bytes);\n                }\n                else if (overflow.length < bytes) {\n                    const { value: nextValue, done } = await input.next(bytes - overflow.length);\n                    if (done === true) {\n                        throw Object.assign(new Error(`stream ended before ${bytes - overflow.length} bytes became available`), { code: 'ERR_UNDER_READ' });\n                    }\n                    value = new Uint8ArrayList(overflow, nextValue);\n                    overflow = null;\n                }\n                if (value == null) {\n                    const result = { done: true, value: undefined };\n                    return result;\n                }\n                const result = { done: false, value };\n                return result;\n            }\n            return input.next(bytes);\n        },\n        async nextLte(bytes) {\n            const { done, value } = await lteReader.next();\n            if (done === true) {\n                return {\n                    done: true,\n                    value: undefined\n                };\n            }\n            if (value.length <= bytes) {\n                return { done: false, value };\n            }\n            const list = isUint8ArrayList(value) ? value : new Uint8ArrayList(value);\n            if (overflow != null) {\n                overflow.append(list.sublist(bytes));\n            }\n            else {\n                overflow = list.sublist(bytes);\n            }\n            return { done: false, value: list.sublist(0, bytes) };\n        },\n        async return() {\n            return input.return();\n        }\n    };\n    return lteReader;\n}\n//# sourceMappingURL=lte-reader.js.map","import defer from 'p-defer';\nimport * as Headers from './extract-headers.js';\nimport { lteReader } from './lte-reader.js';\nfunction getPadding(size) {\n    size &= 511;\n    if (size !== 0) {\n        return 512 - size;\n    }\n    return 0;\n}\nasync function discardPadding(reader, size) {\n    const overflow = getPadding(size);\n    if (overflow > 0) {\n        await reader.next(overflow);\n    }\n}\nexport function extract(options = {}) {\n    options.highWaterMark = options.highWaterMark ?? 1024 * 16;\n    return async function* (source) {\n        const reader = lteReader(source);\n        let gnuLongPath, gnuLongLinkPath, paxGlobal, pax;\n        try {\n            while (true) {\n                let headerBytes;\n                try {\n                    const result = await reader.next(512);\n                    if (result.done === true) {\n                        return;\n                    }\n                    headerBytes = result.value;\n                }\n                catch (err) {\n                    // Is ok, this is the end of the stream!\n                    if (err.code === 'ERR_UNDER_READ') {\n                        return;\n                    }\n                    throw err;\n                }\n                const header = Headers.decode(headerBytes, options.filenameEncoding);\n                if (header == null) {\n                    continue;\n                }\n                if (header.type === 'gnu-long-path') {\n                    const { done, value: gnuLongPathBytes } = await reader.next(header.size);\n                    if (done === true || gnuLongPathBytes == null) {\n                        return;\n                    }\n                    gnuLongPath = Headers.decodeLongPath(gnuLongPathBytes, options.filenameEncoding);\n                    await discardPadding(reader, header.size);\n                    continue;\n                }\n                if (header.type === 'gnu-long-link-path') {\n                    const { done, value: gnuLongLinkPathBytes } = await reader.next(header.size);\n                    if (done === true || gnuLongLinkPathBytes == null) {\n                        return;\n                    }\n                    gnuLongLinkPath = Headers.decodeLongPath(gnuLongLinkPathBytes, options.filenameEncoding);\n                    await discardPadding(reader, header.size);\n                    continue;\n                }\n                if (header.type === 'pax-global-header') {\n                    const { done, value: paxGlobalBytes } = await reader.next(header.size);\n                    if (done === true || paxGlobalBytes == null) {\n                        return;\n                    }\n                    paxGlobal = Headers.decodePax(paxGlobalBytes, options.filenameEncoding);\n                    await discardPadding(reader, header.size);\n                    continue;\n                }\n                if (header.type === 'pax-header') {\n                    const { done, value: paxBytes } = await reader.next(header.size);\n                    if (done === true || paxBytes == null) {\n                        return;\n                    }\n                    pax = Headers.decodePax(paxBytes, options.filenameEncoding);\n                    if (paxGlobal != null) {\n                        pax = { ...paxGlobal, ...pax };\n                    }\n                    await discardPadding(reader, header.size);\n                    continue;\n                }\n                if (gnuLongPath != null) {\n                    header.name = gnuLongPath;\n                    gnuLongPath = null;\n                }\n                if (gnuLongLinkPath != null) {\n                    header.linkname = gnuLongLinkPath;\n                    gnuLongLinkPath = null;\n                }\n                if (pax != null) {\n                    if (pax.path != null) {\n                        header.name = pax.path;\n                    }\n                    if (pax.linkpath != null) {\n                        header.linkname = pax.linkpath;\n                    }\n                    if (pax.size != null) {\n                        header.size = parseInt(pax.size, 10);\n                    }\n                    header.pax = pax;\n                    pax = null;\n                }\n                if (header.size == null || header.size === 0 || header.type === 'directory') {\n                    yield { header, body: (async function* () { })() };\n                    continue;\n                }\n                let bytesRemaining = header.size;\n                const bodyConsumed = defer();\n                // Prefetch the first chunk.\n                // This allows us to stream entries for small files from the tar without\n                // explicitly streaming the body of each.\n                const firstChunk = await reader.nextLte(Math.min(bytesRemaining, options.highWaterMark ?? Infinity));\n                bytesRemaining -= firstChunk.value.length;\n                if (bytesRemaining === 0) {\n                    bodyConsumed.resolve();\n                }\n                const body = (async function* () {\n                    try {\n                        yield firstChunk.value.subarray();\n                        while (bytesRemaining > 0) {\n                            const { done, value } = await reader.nextLte(bytesRemaining);\n                            if (done === true) {\n                                bytesRemaining = 0;\n                                return;\n                            }\n                            bytesRemaining -= value.length;\n                            yield value.subarray();\n                        }\n                    }\n                    finally {\n                        bodyConsumed.resolve();\n                    }\n                })();\n                yield { header, body };\n                // Wait for the body to be consumed\n                await bodyConsumed.promise;\n                // In case the body was not consumed entirely...\n                if (bytesRemaining > 0) {\n                    for await (const _ of body) { } // eslint-disable-line no-unused-vars,no-empty,@typescript-eslint/no-unused-vars\n                }\n                await discardPadding(reader, header.size);\n            }\n        }\n        finally {\n            await reader.return();\n        }\n    };\n}\n//# sourceMappingURL=extract.js.map","/**\n * @packageDocumentation\n *\n * Collects all `Uint8Array` values from an (async)iterable and returns them as a single `Uint8Array`.\n *\n * @example\n *\n * ```javascript\n * import toBuffer from 'it-to-buffer'\n *\n * // This can also be an iterator, generator, etc\n * const values = [Buffer.from([0, 1]), Buffer.from([2, 3])]\n *\n * const result = toBuffer(values)\n *\n * console.info(result) // Buffer[0, 1, 2, 3]\n * ```\n *\n * Async sources must be awaited:\n *\n * ```javascript\n * import toBuffer from 'it-to-buffer'\n *\n * const values = async function * () {\n *   yield Buffer.from([0, 1])\n *   yield Buffer.from([2, 3])\n * }\n *\n * const result = await toBuffer(values())\n *\n * console.info(result) // Buffer[0, 1, 2, 3]\n * ```\n */\nimport { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nfunction isAsyncIterable(thing) {\n    return thing[Symbol.asyncIterator] != null;\n}\nfunction toBuffer(source) {\n    if (isAsyncIterable(source)) {\n        return (async () => {\n            let buffer = new Uint8Array(0);\n            for await (const buf of source) {\n                buffer = uint8ArrayConcat([buffer, buf], buffer.length + buf.length);\n            }\n            return buffer;\n        })();\n    }\n    const bufs = [];\n    let length = 0;\n    for (const buf of source) {\n        bufs.push(buf);\n        length += buf.byteLength;\n    }\n    return uint8ArrayConcat(bufs, length);\n}\nexport default toBuffer;\n//# sourceMappingURL=index.js.map","import { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nconst ZEROS = '0000000000000000000';\nconst SEVENS = '7777777777777777777';\nconst ZERO_OFFSET = '0'.charCodeAt(0);\nconst USTAR_MAGIC = uint8ArrayFromString('ustar\\x00', 'binary');\nconst USTAR_VER = uint8ArrayFromString('00', 'binary');\nconst MASK = parseInt('7777', 8);\nconst MAGIC_OFFSET = 257;\nconst VERSION_OFFSET = 263;\nconst toTypeflag = function (flag) {\n    switch (flag) {\n        case 'file':\n            return 0;\n        case 'link':\n            return 1;\n        case 'symlink':\n            return 2;\n        case 'character-device':\n            return 3;\n        case 'block-device':\n            return 4;\n        case 'directory':\n            return 5;\n        case 'fifo':\n            return 6;\n        case 'contiguous-file':\n            return 7;\n        case 'pax-header':\n            return 72;\n        default:\n            return 0;\n    }\n};\nconst cksum = function (block) {\n    let sum = 8 * 32;\n    for (let i = 0; i < 148; i++)\n        sum += block[i];\n    for (let j = 156; j < 512; j++)\n        sum += block[j];\n    return sum;\n};\nconst encodeOct = function (val, n) {\n    const str = val.toString(8);\n    if (str.length > n) {\n        return uint8ArrayFromString(SEVENS.slice(0, n) + ' ');\n    }\n    return uint8ArrayFromString(ZEROS.slice(0, n - str.length) + str + ' ');\n};\nconst addLength = function (str) {\n    const len = uint8ArrayFromString(str).byteLength;\n    let digits = Math.floor(Math.log(len) / Math.log(10)) + 1;\n    if (len + digits >= Math.pow(10, digits)) {\n        digits++;\n    }\n    return `${len + digits}${str}`;\n};\nexport function encodePax(opts) {\n    let result = '';\n    if (opts.name != null) {\n        result += addLength(' path=' + opts.name + '\\n');\n    }\n    if (opts.linkname != null) {\n        result += addLength(' linkpath=' + opts.linkname + '\\n');\n    }\n    const pax = opts.pax;\n    if (pax != null) {\n        for (const key in pax) {\n            if (Object.prototype.hasOwnProperty.call(pax, key)) {\n                result += addLength(' ' + key + '=' + pax[key] + '\\n');\n            }\n        }\n    }\n    return uint8ArrayFromString(result);\n}\nexport function encode(opts) {\n    const buf = new Uint8Array(512);\n    let name = opts.name;\n    let prefix = '';\n    if (opts.typeflag === 5 && name[name.length - 1] !== '/') {\n        name += '/';\n    }\n    if (uint8ArrayFromString(name).byteLength !== name.length) {\n        return null; // utf-8\n    }\n    while (uint8ArrayFromString(name).byteLength > 100) {\n        const i = name.indexOf('/');\n        if (i === -1) {\n            return null;\n        }\n        prefix += prefix !== '' ? '/' + name.slice(0, i) : name.slice(0, i);\n        name = name.slice(i + 1);\n    }\n    if (uint8ArrayFromString(name).byteLength > 100 || uint8ArrayFromString(prefix).byteLength > 155) {\n        return null;\n    }\n    if (opts.linkname != null && uint8ArrayFromString(opts.linkname).byteLength > 100) {\n        return null;\n    }\n    buf.set(uint8ArrayFromString(name), 0);\n    buf.set(encodeOct(opts.mode & MASK, 6), 100);\n    buf.set(encodeOct(opts.uid, 6), 108);\n    buf.set(encodeOct(opts.gid, 6), 116);\n    buf.set(encodeOct(opts.size, 11), 124);\n    buf.set(encodeOct((opts.mtime.getTime() / 1000) | 0, 11), 136);\n    buf[156] = ZERO_OFFSET + toTypeflag(opts.type);\n    if (opts.linkname != null) {\n        buf.set(uint8ArrayFromString(opts.linkname), 157);\n    }\n    buf.set(USTAR_MAGIC, MAGIC_OFFSET);\n    buf.set(USTAR_VER, VERSION_OFFSET);\n    if (opts.uname != null) {\n        buf.set(uint8ArrayFromString(opts.uname), 265);\n    }\n    if (opts.gname != null) {\n        buf.set(uint8ArrayFromString(opts.gname), 297);\n    }\n    buf.set(encodeOct(opts.devmajor ?? 0, 6), 329);\n    buf.set(encodeOct(opts.devminor ?? 0, 6), 337);\n    if (prefix != null) {\n        buf.set(uint8ArrayFromString(prefix), 345);\n    }\n    buf.set(encodeOct(cksum(buf), 6), 148);\n    return buf;\n}\n//# sourceMappingURL=pack-headers.js.map","// @ts-expect-error no types\nimport isoConstants from 'iso-constants';\nimport toBuffer from 'it-to-buffer';\nimport { isUint8ArrayList, Uint8ArrayList } from 'uint8arraylist';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport * as Headers from './pack-headers.js';\nconst { S_IFMT, S_IFBLK, S_IFCHR, S_IFDIR, S_IFIFO, S_IFLNK } = isoConstants;\nconst DMODE = parseInt('755', 8);\nconst FMODE = parseInt('644', 8);\nconst END_OF_TAR = new Uint8Array(1024);\nfunction modeToType(mode = 0) {\n    switch (mode & S_IFMT) {\n        case S_IFBLK: return 'block-device';\n        case S_IFCHR: return 'character-device';\n        case S_IFDIR: return 'directory';\n        case S_IFIFO: return 'fifo';\n        case S_IFLNK: return 'symlink';\n        default: return 'file';\n    }\n}\nfunction getPadding(size) {\n    size &= 511;\n    if (size !== 0) {\n        return END_OF_TAR.subarray(0, 512 - size);\n    }\n    return new Uint8Array(0);\n}\nfunction encode(header) {\n    if (header.pax == null) {\n        const encoded = Headers.encode(header);\n        if (encoded != null) {\n            return encoded;\n        }\n    }\n    return encodePax(header);\n}\nfunction encodePax(header) {\n    const paxHeader = Headers.encodePax(header);\n    const newHeader = {\n        name: 'PaxHeader',\n        mode: header.mode,\n        uid: header.uid,\n        gid: header.gid,\n        size: paxHeader.length,\n        mtime: header.mtime,\n        type: 'pax-header',\n        linkname: header.linkname,\n        uname: header.uname,\n        gname: header.gname,\n        devmajor: header.devmajor,\n        devminor: header.devminor\n    };\n    return new Uint8ArrayList(Headers.encode(newHeader) ?? new Uint8Array(0), paxHeader, getPadding(paxHeader.length), Headers.encode({ ...newHeader, size: header.size, type: header.type }) ?? new Uint8Array(0)).subarray();\n}\nexport function pack() {\n    return async function* (source) {\n        for await (let { header: partialHeader, body } of source) {\n            const header = {\n                ...partialHeader,\n                size: partialHeader.type === 'symlink' ? 0 : partialHeader.size ?? 0,\n                type: partialHeader.type ?? modeToType(partialHeader.mode),\n                mode: partialHeader.mode ?? (partialHeader.type === 'directory' ? DMODE : FMODE),\n                uid: partialHeader.uid ?? 0,\n                gid: partialHeader.gid ?? 0,\n                mtime: partialHeader.mtime ?? new Date()\n            };\n            if (typeof body === 'string') {\n                body = uint8ArrayFromString(body);\n            }\n            if (body instanceof Uint8Array || isUint8ArrayList(body)) {\n                header.size = body.length;\n                yield encode(header);\n                yield isUint8ArrayList(body) ? body.subarray() : body;\n                yield getPadding(header.size);\n                continue;\n            }\n            if (header.type === 'symlink' && header.linkname == null) {\n                if (body == null) {\n                    throw new Error('type was symlink but no linkname or body specified');\n                }\n                header.linkname = uint8ArrayToString(await toBuffer(body));\n                yield encode(header);\n                continue;\n            }\n            yield encode(header);\n            if (header.type !== 'file' && header.type !== 'contiguous-file') {\n                continue;\n            }\n            let written = 0;\n            for await (const chunk of (body ?? [])) {\n                written += chunk.length; // eslint-disable-line @typescript-eslint/restrict-plus-operands\n                yield isUint8ArrayList(chunk) ? chunk.subarray() : chunk;\n            }\n            if (written !== header.size) { // corrupting tar\n                throw new Error(`size mismatch, wrote ${written} of ${header.size} bytes`);\n            }\n            yield getPadding(header.size);\n        }\n        yield END_OF_TAR;\n    };\n}\n//# sourceMappingURL=pack.js.map","/**\n * @packageDocumentation\n *\n * `it-tar` [packs](#packing) and [extracts](#extracts) tarballs.\n *\n * It implements USTAR with additional support for pax extended headers. It should be compatible with all popular tar distributions out there (gnutar, bsdtar etc)\n *\n * @example Packing\n *\n * To create a pack stream use `tar.pack()` and pipe entries to it.\n *\n * ```TypeScript\n * import fs from 'node:fs'\n * import Tar from 'it-tar'\n * import { pipe } from 'it-pipe'\n * // @ts-expect-error no types\n * import { sink } from 'stream-to-it'\n *\n * await pipe(\n *   [\n *     // add a file called my-test.txt with the content \"Hello World!\"\n *     {\n *       header: { name: 'my-test.txt' },\n *       body: 'Hello World!'\n *     },\n *     // add a file called my-stream-test.txt from a stream\n *     {\n *       header: { name: 'my-stream-test.txt', size: 11 },\n *       body: fs.createReadStream('./my-stream-test.txt')\n *     }\n *   ],\n *   Tar.pack(),\n *   // pipe the pack stream somewhere\n *   sink(process.stdout)\n * )\n * ```\n *\n * @example Extracting\n *\n * To extract a stream use `tar.extract()` and pipe a [source iterable](https://gist.github.com/alanshaw/591dc7dd54e4f99338a347ef568d6ee9#source-it) to it.\n *\n * ```TypeScript\n * import Tar from 'it-tar'\n * import { pipe } from 'it-pipe'\n *\n * await pipe(\n *   [Uint8Array.from([0, 1, 2, 3, 4])], // An async iterable (for example a Node.js readable stream)\n *   Tar.extract(),\n *   async source => {\n *     for await (const entry of source) {\n *       // entry.header is the tar header (see below)\n *       // entry.body is the content body (might be an empty async iterable)\n *       for await (const data of entry.body) {\n *         // do something with the data\n *       }\n *     }\n *     // all entries read\n *   }\n * )\n * ```\n *\n * The tar archive is streamed sequentially, meaning you **must** drain each entry's body as you get them or else the main extract stream will receive backpressure and stop reading.\n *\n * Note that the body stream yields [`Uint8ArrayList`](https://npm.im/uint8arraylist) objects **not** `Uint8Arrays`s.\n *\n * @example Modifying existing tarballs\n *\n * Using tar-stream it is easy to rewrite paths / change modes etc in an existing tarball.\n *\n * ```TypeScript\n * import Tar from 'it-tar'\n * import { pipe } from 'it-pipe'\n * // @ts-expect-error no types\n * import { sink } from 'stream-to-it'\n * import fs from 'node:fs'\n * import path from 'node:path'\n *\n * await pipe(\n *   fs.createReadStream('./old-tarball.tar'),\n *   Tar.extract(),\n *   async function * (source) {\n *     for await (const entry of source) {\n *       // let's prefix all names with 'tmp'\n *       entry.header.name = path.join('tmp', entry.header.name)\n *       // write the new entry to the pack stream\n *       yield entry\n *     }\n *   },\n *   Tar.pack(),\n *   sink(fs.createWriteStream('./new-tarball.tar'))\n * )\n * ```\n *\n * #### Headers\n *\n * The header object using in `entry` should contain the following properties.\n * Most of these values can be found by stat'ing a file.\n *\n * ```js\n * {\n *   name: 'path/to/this/entry.txt',\n *   size: 1314,        // entry size. defaults to 0\n *   mode: 0644,        // entry mode. defaults to to 0755 for dirs and 0644 otherwise\n *   mtime: new Date(), // last modified date for entry. defaults to now.\n *   type: 'file',      // type of entry. defaults to file. can be:\n *                      // file | link | symlink | directory | block-device\n *                      // character-device | fifo | contiguous-file\n *   linkname: 'path',  // linked file name\n *   uid: 0,            // uid of entry owner. defaults to 0\n *   gid: 0,            // gid of entry owner. defaults to 0\n *   uname: 'maf',      // uname of entry owner. defaults to null\n *   gname: 'staff',    // gname of entry owner. defaults to null\n *   devmajor: 0,       // device major version. defaults to 0\n *   devminor: 0        // device minor version. defaults to 0\n * }\n * ```\n *\n * ## Related\n *\n * - [`it-pipe`](https://www.npmjs.com/package/it-pipe) Utility to \"pipe\" async iterables together\n * - [`it-reader`](https://www.npmjs.com/package/it-reader) Read an exact number of bytes from a binary (async) iterable\n * - [`stream-to-it`](https://www.npmjs.com/package/stream-to-it) Convert Node.js streams to streaming iterables\n */\nexport { extract } from './extract.js';\nexport { pack } from './pack.js';\n//# sourceMappingURL=index.js.map","import { NotUnixFSError } from '@helia/unixfs/errors';\nimport { exporter, recursive } from 'ipfs-unixfs-exporter';\nimport map from 'it-map';\nimport { pipe } from 'it-pipe';\nimport { pack } from 'it-tar';\nconst EXPORTABLE = ['file', 'raw', 'directory'];\nfunction toHeader(file) {\n    let mode;\n    let mtime;\n    if (file.type === 'file' || file.type === 'directory') {\n        mode = file.unixfs.mode;\n        mtime = file.unixfs.mtime != null ? new Date(Number(file.unixfs.mtime.secs * 1000n)) : undefined;\n    }\n    return {\n        name: file.path,\n        mode,\n        mtime,\n        size: Number(file.size),\n        type: file.type === 'directory' ? 'directory' : 'file'\n    };\n}\nfunction toTarImportCandidate(entry) {\n    if (!EXPORTABLE.includes(entry.type)) {\n        throw new NotUnixFSError(`${entry.type} is not a UnixFS node`);\n    }\n    const candidate = {\n        header: toHeader(entry)\n    };\n    if (entry.type === 'file' || entry.type === 'raw') {\n        candidate.body = entry.content();\n    }\n    return candidate;\n}\nexport async function* tarStream(ipfsPath, blockstore, options) {\n    const file = await exporter(ipfsPath, blockstore, options);\n    if (file.type === 'file' || file.type === 'raw') {\n        yield* pipe([toTarImportCandidate(file)], pack());\n        return;\n    }\n    if (file.type === 'directory') {\n        yield* pipe(recursive(ipfsPath, blockstore, options), (source) => map(source, (entry) => toTarImportCandidate(entry)), pack());\n        return;\n    }\n    throw new NotUnixFSError('Not a UnixFS node');\n}\n//# sourceMappingURL=get-tar-stream.js.map","import hashlru from 'hashlru';\n/**\n * Time Aware Least Recent Used Cache\n *\n * @see https://arxiv.org/pdf/1801.00390\n */\nexport class TLRU {\n    lru;\n    constructor(maxSize) {\n        this.lru = hashlru(maxSize);\n    }\n    get(key) {\n        const value = this.lru.get(key);\n        if (value != null) {\n            if (value.expire != null && value.expire < Date.now()) {\n                this.lru.remove(key);\n                return undefined;\n            }\n            return value.value;\n        }\n        return undefined;\n    }\n    set(key, value, ttlMs) {\n        this.lru.set(key, { value, expire: Date.now() + ttlMs });\n    }\n    has(key) {\n        const value = this.get(key);\n        if (value != null) {\n            return true;\n        }\n        return false;\n    }\n    remove(key) {\n        this.lru.remove(key);\n    }\n    clear() {\n        this.lru.clear();\n    }\n}\n//# sourceMappingURL=tlru.js.map","import { peerIdFromCID, peerIdFromString } from '@libp2p/peer-id';\nimport { CID } from 'multiformats/cid';\nimport { TLRU } from './tlru.js';\nconst ipnsCache = new TLRU(1000);\nconst URL_REGEX = /^(?<protocol>ip[fn]s):\\/\\/(?<cidOrPeerIdOrDnsLink>[^/?]+)\\/?(?<path>[^?]*)\\??(?<queryString>.*)$/;\nconst PATH_REGEX = /^\\/(?<protocol>ip[fn]s)\\/(?<cidOrPeerIdOrDnsLink>[^/?]+)\\/?(?<path>[^?]*)\\??(?<queryString>.*)$/;\nconst PATH_GATEWAY_REGEX = /^https?:\\/\\/(.*[^/])\\/(?<protocol>ip[fn]s)\\/(?<cidOrPeerIdOrDnsLink>[^/?]+)\\/?(?<path>[^?]*)\\??(?<queryString>.*)$/;\nconst SUBDOMAIN_GATEWAY_REGEX = /^https?:\\/\\/(?<cidOrPeerIdOrDnsLink>[^/?]+)\\.(?<protocol>ip[fn]s)\\.([^/?]+)\\/?(?<path>[^?]*)\\??(?<queryString>.*)$/;\nfunction matchUrlGroupsGuard(groups) {\n    const protocol = groups?.protocol;\n    if (protocol == null)\n        return false;\n    const cidOrPeerIdOrDnsLink = groups?.cidOrPeerIdOrDnsLink;\n    if (cidOrPeerIdOrDnsLink == null)\n        return false;\n    const path = groups?.path;\n    const queryString = groups?.queryString;\n    return ['ipns', 'ipfs'].includes(protocol) &&\n        typeof cidOrPeerIdOrDnsLink === 'string' &&\n        (path == null || typeof path === 'string') &&\n        (queryString == null || typeof queryString === 'string');\n}\nexport function matchURLString(urlString) {\n    for (const pattern of [SUBDOMAIN_GATEWAY_REGEX, URL_REGEX, PATH_GATEWAY_REGEX, PATH_REGEX]) {\n        const match = urlString.match(pattern);\n        if (matchUrlGroupsGuard(match?.groups)) {\n            return match.groups;\n        }\n    }\n    throw new TypeError(`Invalid URL: ${urlString}, please use ipfs://, ipns://, or gateway URLs only`);\n}\n/**\n * determines the TTL for the resolved resource that will be used for the `Cache-Control` header's `max-age` directive.\n * max-age is in seconds\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cache-Control#response_directives\n *\n * If we have ipnsTtlNs, it will be a BigInt representing \"nanoseconds\". We need to convert it back to seconds.\n *\n * For more TTL nuances:\n *\n * @see https://github.com/ipfs/js-ipns/blob/16e0e10682fa9a663e0bb493a44d3e99a5200944/src/index.ts#L200\n * @see https://github.com/ipfs/js-ipns/pull/308\n * @returns the ttl in seconds\n */\nfunction calculateTtl(resolveResult) {\n    if (resolveResult == null) {\n        return undefined;\n    }\n    const dnsLinkTtl = resolveResult.answer?.TTL;\n    const ipnsTtlNs = resolveResult.record?.ttl;\n    const ipnsTtl = ipnsTtlNs != null ? Number(ipnsTtlNs / BigInt(1e9)) : undefined;\n    return dnsLinkTtl ?? ipnsTtl;\n}\n/**\n * For dnslinks see https://specs.ipfs.tech/http-gateways/subdomain-gateway/#host-request-header\n * DNSLink names include . which means they must be inlined into a single DNS label to provide unique origin and work with wildcard TLS certificates.\n */\n// DNS label can have up to 63 characters, consisting of alphanumeric\n// characters or hyphens -, but it must not start or end with a hyphen.\nconst dnsLabelRegex = /^[a-zA-Z0-9]([a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?$/;\n/**\n * Checks if label looks like inlined DNSLink.\n * (https://specs.ipfs.tech/http-gateways/subdomain-gateway/#host-request-header)\n */\nfunction isInlinedDnsLink(label) {\n    return dnsLabelRegex.test(label) && label.includes('-') && !label.includes('.');\n}\n/**\n * DNSLink label decoding\n * * Every standalone - is replaced with .\n * * Every remaining -- is replaced with -\n *\n * @example en-wikipedia--on--ipfs-org.ipns.example.net -> example.net/ipns/en.wikipedia-on-ipfs.org\n */\nfunction dnsLinkLabelDecoder(linkLabel) {\n    return linkLabel.replace(/--/g, '%').replace(/-/g, '.').replace(/%/g, '-');\n}\n/**\n * A function that parses ipfs:// and ipns:// URLs, returning an object with easily recognizable properties.\n *\n * After determining the protocol successfully, we process the cidOrPeerIdOrDnsLink:\n * * If it's ipfs, it parses the CID or throws an Aggregate error\n * * If it's ipns, it attempts to resolve the PeerId and then the DNSLink. If both fail, an Aggregate error is thrown.\n *\n * @todo we need to break out each step of this function (cid parsing, ipns resolving, dnslink resolving) into separate functions and then remove the eslint-disable comment\n */\n// eslint-disable-next-line complexity\nexport async function parseUrlString({ urlString, ipns, logger }, options) {\n    const log = logger.forComponent('helia:verified-fetch:parse-url-string');\n    const { protocol, cidOrPeerIdOrDnsLink, path: urlPath, queryString } = matchURLString(urlString);\n    let cid;\n    let resolvedPath;\n    const errors = [];\n    let resolveResult;\n    if (protocol === 'ipfs') {\n        try {\n            cid = CID.parse(cidOrPeerIdOrDnsLink);\n            /**\n             * no ttl set. @link {setCacheControlHeader}\n             */\n        }\n        catch (err) {\n            log.error(err);\n            errors.push(new TypeError('Invalid CID for ipfs://<cid> URL'));\n        }\n    }\n    else {\n        // protocol is ipns\n        resolveResult = ipnsCache.get(cidOrPeerIdOrDnsLink);\n        if (resolveResult != null) {\n            cid = resolveResult.cid;\n            resolvedPath = resolveResult.path;\n            log.trace('resolved %s to %c from cache', cidOrPeerIdOrDnsLink, cid);\n        }\n        else {\n            log.trace('Attempting to resolve PeerId for %s', cidOrPeerIdOrDnsLink);\n            let peerId;\n            try {\n                // try resolving as an IPNS name\n                if (cidOrPeerIdOrDnsLink.charAt(0) === '1' || cidOrPeerIdOrDnsLink.charAt(0) === 'Q') {\n                    peerId = peerIdFromString(cidOrPeerIdOrDnsLink);\n                }\n                else {\n                    // try resolving as a base36 CID\n                    peerId = peerIdFromCID(CID.parse(cidOrPeerIdOrDnsLink));\n                }\n                if (peerId.publicKey == null) {\n                    throw new TypeError('cidOrPeerIdOrDnsLink contains no public key');\n                }\n                resolveResult = await ipns.resolve(peerId.publicKey, options);\n                cid = resolveResult?.cid;\n                resolvedPath = resolveResult?.path;\n                log.trace('resolved %s to %c', cidOrPeerIdOrDnsLink, cid);\n            }\n            catch (err) {\n                options?.signal?.throwIfAborted();\n                if (peerId == null) {\n                    log.error('could not parse PeerId string \"%s\"', cidOrPeerIdOrDnsLink, err);\n                    errors.push(new TypeError(`Could not parse PeerId in ipns url \"${cidOrPeerIdOrDnsLink}\", ${err.message}`));\n                }\n                else {\n                    log.error('could not resolve PeerId %c', peerId, err);\n                    errors.push(new TypeError(`Could not resolve PeerId \"${cidOrPeerIdOrDnsLink}\", ${err.message}`));\n                }\n            }\n            if (cid == null) {\n                // cid is still null, try resolving as a DNSLink\n                let decodedDnsLinkLabel = cidOrPeerIdOrDnsLink;\n                if (isInlinedDnsLink(cidOrPeerIdOrDnsLink)) {\n                    decodedDnsLinkLabel = dnsLinkLabelDecoder(cidOrPeerIdOrDnsLink);\n                    log.trace('decoded dnslink from \"%s\" to \"%s\"', cidOrPeerIdOrDnsLink, decodedDnsLinkLabel);\n                }\n                log.trace('Attempting to resolve DNSLink for %s', decodedDnsLinkLabel);\n                try {\n                    resolveResult = await ipns.resolveDNSLink(decodedDnsLinkLabel, options);\n                    cid = resolveResult?.cid;\n                    resolvedPath = resolveResult?.path;\n                    log.trace('resolved %s to %c', decodedDnsLinkLabel, cid);\n                }\n                catch (err) {\n                    options?.signal?.throwIfAborted();\n                    log.error('could not resolve DnsLink for \"%s\"', cidOrPeerIdOrDnsLink, err);\n                    errors.push(err);\n                }\n            }\n        }\n    }\n    if (cid == null) {\n        if (errors.length === 1) {\n            throw errors[0];\n        }\n        throw new AggregateError(errors, `Invalid resource. Cannot determine CID from URL \"${urlString}\"`);\n    }\n    let ttl = calculateTtl(resolveResult);\n    if (resolveResult != null) {\n        // use the ttl for the resolved resouce for the cache, but fallback to 2 minutes if not available\n        ttl = ttl ?? 60 * 2;\n        log.trace('caching %s resolved to %s with TTL: %s', cidOrPeerIdOrDnsLink, cid, ttl);\n        // convert ttl from seconds to ms for the cache\n        ipnsCache.set(cidOrPeerIdOrDnsLink, resolveResult, ttl * 1000);\n    }\n    // parse query string\n    const query = {};\n    if (queryString != null && queryString.length > 0) {\n        const queryParts = queryString.split('&');\n        for (const part of queryParts) {\n            const [key, value] = part.split('=');\n            query[key] = decodeURIComponent(value);\n        }\n        if (query.download != null) {\n            query.download = query.download === 'true';\n        }\n        if (query.filename != null) {\n            query.filename = query.filename.toString();\n        }\n    }\n    return {\n        protocol,\n        cid,\n        path: joinPaths(resolvedPath, urlPath ?? ''),\n        query,\n        ttl,\n        ipfsPath: `/${protocol}/${cidOrPeerIdOrDnsLink}${urlPath != null && urlPath !== '' ? `/${urlPath}` : ''}`\n    };\n}\n/**\n * join the path from resolve result & given path.\n * e.g. /ipns/<peerId>/ that is resolved to /ipfs/<cid>/<path1>, when requested as /ipns/<peerId>/<path2>, should be\n * resolved to /ipfs/<cid>/<path1>/<path2>\n */\nfunction joinPaths(resolvedPath, urlPath) {\n    let path = '';\n    if (resolvedPath != null) {\n        path += resolvedPath;\n    }\n    if (urlPath.length > 0) {\n        path = `${path.length > 0 ? `${path}/` : path}${urlPath}`;\n    }\n    // replace duplicate forward slashes\n    path = path.replace(/\\/(\\/)+/g, '/');\n    // strip trailing forward slash if present\n    if (path.startsWith('/')) {\n        path = path.substring(1);\n    }\n    return path.split('/').map(decodeURIComponent).join('/');\n}\n//# sourceMappingURL=parse-url-string.js.map","function setField(response, name, value) {\n    Object.defineProperty(response, name, {\n        enumerable: true,\n        configurable: false,\n        set: () => { },\n        get: () => value\n    });\n}\nfunction setType(response, value) {\n    setField(response, 'type', value);\n}\nfunction setUrl(response, value) {\n    setField(response, 'url', value);\n}\nfunction setRedirected(response) {\n    setField(response, 'redirected', true);\n}\nexport function okResponse(url, body, init) {\n    const response = new Response(body, {\n        ...(init ?? {}),\n        status: 200,\n        statusText: 'OK'\n    });\n    if (init?.redirected === true) {\n        setRedirected(response);\n    }\n    setType(response, 'basic');\n    setUrl(response, url);\n    response.headers.set('Accept-Ranges', 'bytes');\n    return response;\n}\nexport function badGatewayResponse(url, body, init) {\n    const response = new Response(body, {\n        ...(init ?? {}),\n        status: 502,\n        statusText: 'Bad Gateway'\n    });\n    setType(response, 'basic');\n    setUrl(response, url);\n    return response;\n}\nexport function notSupportedResponse(url, body, init) {\n    const response = new Response(body, {\n        ...(init ?? {}),\n        status: 501,\n        statusText: 'Not Implemented'\n    });\n    response.headers.set('X-Content-Type-Options', 'nosniff'); // see https://specs.ipfs.tech/http-gateways/path-gateway/#x-content-type-options-response-header\n    setType(response, 'basic');\n    setUrl(response, url);\n    return response;\n}\nexport function notAcceptableResponse(url, body, init) {\n    const response = new Response(body, {\n        ...(init ?? {}),\n        status: 406,\n        statusText: 'Not Acceptable'\n    });\n    setType(response, 'basic');\n    setUrl(response, url);\n    return response;\n}\nexport function notFoundResponse(url, body, init) {\n    const response = new Response(body, {\n        ...(init ?? {}),\n        status: 404,\n        statusText: 'Not Found'\n    });\n    setType(response, 'basic');\n    setUrl(response, url);\n    return response;\n}\n/**\n * if body is an Error, it will be converted to a string containing the error message.\n */\nexport function badRequestResponse(url, body, init) {\n    if (body instanceof Error) {\n        body = body.message;\n    }\n    const response = new Response(body, {\n        ...(init ?? {}),\n        status: 400,\n        statusText: 'Bad Request'\n    });\n    setType(response, 'basic');\n    setUrl(response, url);\n    return response;\n}\nexport function movedPermanentlyResponse(url, location, init) {\n    const response = new Response(null, {\n        ...(init ?? {}),\n        status: 301,\n        statusText: 'Moved Permanently',\n        headers: {\n            ...(init?.headers ?? {}),\n            location\n        }\n    });\n    setType(response, 'basic');\n    setUrl(response, url);\n    return response;\n}\nexport function okRangeResponse(url, body, { byteRangeContext, log }, init) {\n    if (!byteRangeContext.isRangeRequest) {\n        return okResponse(url, body, init);\n    }\n    if (!byteRangeContext.isValidRangeRequest) {\n        return badRangeResponse(url, body, init);\n    }\n    let response;\n    try {\n        response = new Response(body, {\n            ...(init ?? {}),\n            status: 206,\n            statusText: 'Partial Content',\n            headers: {\n                ...(init?.headers ?? {}),\n                'content-range': byteRangeContext.contentRangeHeaderValue\n            }\n        });\n    }\n    catch (e) {\n        log?.error('failed to create range response', e);\n        return badRangeResponse(url, body, init);\n    }\n    if (init?.redirected === true) {\n        setRedirected(response);\n    }\n    setType(response, 'basic');\n    setUrl(response, url);\n    response.headers.set('Accept-Ranges', 'bytes');\n    return response;\n}\n/**\n * We likely need to catch errors handled by upstream helia libraries if range-request throws an error. Some examples:\n * * The range is out of bounds\n * * The range is invalid\n * * The range is not supported for the given type\n */\nexport function badRangeResponse(url, body, init) {\n    const response = new Response(body, {\n        ...(init ?? {}),\n        status: 416,\n        statusText: 'Requested Range Not Satisfiable'\n    });\n    setType(response, 'basic');\n    setUrl(response, url);\n    return response;\n}\n//# sourceMappingURL=responses.js.map","import {} from '@libp2p/interface';\nimport { SubdomainNotSupportedError } from '../errors.js';\nimport {} from '../index.js';\nimport { matchURLString } from './parse-url-string.js';\nimport { movedPermanentlyResponse } from './responses.js';\nfunction maybeAddTraillingSlash(path) {\n    // if it has an extension-like ending, don't add a trailing slash\n    if (path.match(/\\.[a-zA-Z0-9]{1,4}$/) != null) {\n        return path;\n    }\n    return path.endsWith('/') ? path : `${path}/`;\n}\n// See https://specs.ipfs.tech/http-gateways/path-gateway/#location-response-header\nexport async function getRedirectResponse({ resource, options, logger, cid, fetch = globalThis.fetch }) {\n    const log = logger.forComponent('helia:verified-fetch:get-redirect-response');\n    if (typeof resource !== 'string' || options == null || ['ipfs://', 'ipns://'].some((prefix) => resource.startsWith(prefix))) {\n        return null;\n    }\n    const headers = new Headers(options?.headers);\n    const forwardedHost = headers.get('x-forwarded-host');\n    const headerHost = headers.get('host');\n    const forwardedFor = headers.get('x-forwarded-for');\n    if (forwardedFor == null && forwardedHost == null && headerHost == null) {\n        log.trace('no redirect info found in headers');\n        return null;\n    }\n    log.trace('checking for redirect info');\n    // if x-forwarded-host is passed, we need to set the location header to the subdomain\n    // so that the browser can redirect to the correct subdomain\n    try {\n        const urlParts = matchURLString(resource);\n        const reqUrl = new URL(resource);\n        const actualHost = forwardedHost ?? reqUrl.host;\n        const subdomainUrl = new URL(reqUrl);\n        if (urlParts.protocol === 'ipfs' && cid.version === 0) {\n            subdomainUrl.host = `${cid.toV1()}.ipfs.${actualHost}`;\n        }\n        else {\n            subdomainUrl.host = `${urlParts.cidOrPeerIdOrDnsLink}.${urlParts.protocol}.${actualHost}`;\n        }\n        if (headerHost?.includes(urlParts.protocol) === true && subdomainUrl.host.includes(headerHost)) {\n            log.trace('request was for a subdomain already, not setting location header');\n            return null;\n        }\n        if (headerHost != null && !subdomainUrl.host.includes(headerHost)) {\n            log.trace('host header is not the same as the subdomain url host, not setting location header');\n            return null;\n        }\n        if (reqUrl.host === subdomainUrl.host) {\n            log.trace('req url is the same as the subdomain url, not setting location header');\n            return null;\n        }\n        subdomainUrl.pathname = maybeAddTraillingSlash(reqUrl.pathname.replace(`/${urlParts.cidOrPeerIdOrDnsLink}`, '').replace(`/${urlParts.protocol}`, ''));\n        log.trace('subdomain url %s', subdomainUrl.href);\n        const pathUrl = new URL(reqUrl, `${reqUrl.protocol}//${actualHost}`);\n        pathUrl.pathname = maybeAddTraillingSlash(reqUrl.pathname);\n        log.trace('path url %s', pathUrl.href);\n        // try to query subdomain with HEAD request to see if it's supported\n        try {\n            const subdomainTest = await fetch(subdomainUrl, { method: 'HEAD' });\n            if (subdomainTest.ok) {\n                log('subdomain supported, redirecting to subdomain');\n                return movedPermanentlyResponse(resource.toString(), subdomainUrl.href);\n            }\n            else {\n                log('subdomain not supported, subdomain failed with status %s %s', subdomainTest.status, subdomainTest.statusText);\n                throw new SubdomainNotSupportedError('subdomain not supported');\n            }\n        }\n        catch (err) {\n            log('subdomain not supported', err);\n            if (pathUrl.href === reqUrl.href) {\n                log('path url is the same as the request url, not setting location header');\n                return null;\n            }\n            // pathUrl is different from request URL (maybe even with just a trailing slash)\n            return movedPermanentlyResponse(resource.toString(), pathUrl.href);\n        }\n    }\n    catch (e) {\n        // if it's not a full URL, we have nothing left to do.\n        log.error('error setting location header for x-forwarded-host', e);\n    }\n    return null;\n}\n//# sourceMappingURL=handle-redirects.js.map","import { CID } from 'multiformats/cid';\nimport { parseUrlString } from './parse-url-string.js';\n/**\n * Handles the different use cases for the `resource` argument.\n * The resource can represent an IPFS path, IPNS path, or CID.\n * If the resource represents an IPNS path, we need to resolve it to a CID.\n */\nexport async function parseResource(resource, { ipns, logger }, options) {\n    if (typeof resource === 'string') {\n        return parseUrlString({ urlString: resource, ipns, logger }, options);\n    }\n    const cid = CID.asCID(resource);\n    if (cid != null) {\n        // an actual CID\n        return {\n            cid,\n            protocol: 'ipfs',\n            path: '',\n            query: {},\n            ipfsPath: `/ipfs/${cid.toString()}`,\n            ttl: 29030400 // 1 year for ipfs content\n        };\n    }\n    throw new TypeError(`Invalid resource. Cannot determine CID from resource: ${resource}`);\n}\n//# sourceMappingURL=parse-resource.js.map","import { CID } from 'multiformats/cid';\nimport { matchURLString } from './parse-url-string.js';\n/**\n * Takes a resource and returns a session cache key as an IPFS or IPNS path with\n * any trailing segments removed.\n *\n * E.g.\n *\n * - Qmfoo -> /ipfs/Qmfoo\n * - https://Qmfoo.ipfs.gateway.org -> /ipfs/Qmfoo\n * - https://gateway.org/ipfs/Qmfoo -> /ipfs/Qmfoo\n * - https://gateway.org/ipfs/Qmfoo/bar.txt -> /ipfs/Qmfoo\n * - etc\n */\nexport function resourceToSessionCacheKey(url) {\n    const cid = CID.asCID(url);\n    if (cid != null) {\n        return `ipfs://${cid}`;\n    }\n    try {\n        return `ipfs://${CID.parse(url.toString())}`;\n    }\n    catch { }\n    const { protocol, cidOrPeerIdOrDnsLink } = matchURLString(url.toString());\n    return `${protocol}://${cidOrPeerIdOrDnsLink}`;\n}\n//# sourceMappingURL=resource-to-cache-key.js.map","import { DoesNotExistError } from '@helia/unixfs/errors';\nimport {} from '@libp2p/interface';\nimport {} from 'interface-blockstore';\nimport { walkPath as exporterWalk } from 'ipfs-unixfs-exporter';\nimport {} from '../types.js';\nimport { badGatewayResponse, notFoundResponse } from './responses.js';\nexport async function walkPath(blockstore, path, options) {\n    const ipfsRoots = [];\n    let terminalElement;\n    for await (const entry of exporterWalk(path, blockstore, options)) {\n        ipfsRoots.push(entry.cid);\n        terminalElement = entry;\n    }\n    if (terminalElement == null) {\n        throw new DoesNotExistError('No terminal element found');\n    }\n    return {\n        ipfsRoots,\n        terminalElement\n    };\n}\nexport function isObjectNode(node) {\n    return node.type === 'object';\n}\n/**\n * Attempts to walk the path in the blockstore, returning ipfsRoots needed to resolve the path, and the terminal element.\n * If the signal is aborted, the function will throw an AbortError\n * If a terminal element is not found, a notFoundResponse is returned\n * If another unknown error occurs, a badGatewayResponse is returned\n */\nexport async function handlePathWalking({ cid, path, resource, options, blockstore, log }) {\n    try {\n        return await walkPath(blockstore, `${cid.toString()}/${path}`, options);\n    }\n    catch (err) {\n        options?.signal?.throwIfAborted();\n        if (['ERR_NO_PROP', 'ERR_NO_TERMINAL_ELEMENT', 'ERR_NOT_FOUND'].includes(err.code)) {\n            return notFoundResponse(resource);\n        }\n        log.error('error walking path %s', path, err);\n        return badGatewayResponse(resource, 'Error walking path');\n    }\n}\n//# sourceMappingURL=walk-path.js.map","import { car } from '@helia/car';\nimport { ipns as heliaIpns } from '@helia/ipns';\nimport * as ipldDagCbor from '@ipld/dag-cbor';\nimport * as ipldDagJson from '@ipld/dag-json';\nimport { code as dagPbCode } from '@ipld/dag-pb';\nimport {} from '@libp2p/interface';\nimport { Record as DHTRecord } from '@libp2p/kad-dht';\nimport { peerIdFromString } from '@libp2p/peer-id';\nimport { Key } from 'interface-datastore';\nimport { exporter } from 'ipfs-unixfs-exporter';\nimport toBrowserReadableStream from 'it-to-browser-readablestream';\nimport { LRUCache } from 'lru-cache';\nimport { code as jsonCode } from 'multiformats/codecs/json';\nimport { code as rawCode } from 'multiformats/codecs/raw';\nimport { identity } from 'multiformats/hashes/identity';\nimport { CustomProgressEvent } from 'progress-events';\nimport { concat as uint8ArrayConcat } from 'uint8arrays/concat';\nimport { fromString as uint8ArrayFromString } from 'uint8arrays/from-string';\nimport { toString as uint8ArrayToString } from 'uint8arrays/to-string';\nimport { ByteRangeContext } from './utils/byte-range-context.js';\nimport { dagCborToSafeJSON } from './utils/dag-cbor-to-safe-json.js';\nimport { getContentDispositionFilename } from './utils/get-content-disposition-filename.js';\nimport { getETag } from './utils/get-e-tag.js';\nimport { getResolvedAcceptHeader } from './utils/get-resolved-accept-header.js';\nimport { getStreamFromAsyncIterable } from './utils/get-stream-from-async-iterable.js';\nimport { tarStream } from './utils/get-tar-stream.js';\nimport { getRedirectResponse } from './utils/handle-redirects.js';\nimport { parseResource } from './utils/parse-resource.js';\nimport {} from './utils/parse-url-string.js';\nimport { resourceToSessionCacheKey } from './utils/resource-to-cache-key.js';\nimport { setCacheControlHeader, setIpfsRoots } from './utils/response-headers.js';\nimport { badRequestResponse, movedPermanentlyResponse, notAcceptableResponse, notSupportedResponse, okResponse, badRangeResponse, okRangeResponse, badGatewayResponse, notFoundResponse } from './utils/responses.js';\nimport { selectOutputType } from './utils/select-output-type.js';\nimport { handlePathWalking, isObjectNode } from './utils/walk-path.js';\nconst SESSION_CACHE_MAX_SIZE = 100;\nconst SESSION_CACHE_TTL_MS = 60 * 1000;\nfunction convertOptions(options) {\n    if (options == null) {\n        return undefined;\n    }\n    let signal;\n    if (options?.signal === null) {\n        signal = undefined;\n    }\n    else {\n        signal = options?.signal;\n    }\n    return {\n        ...options,\n        signal\n    };\n}\n/**\n * These are Accept header values that will cause content type sniffing to be\n * skipped and set to these values.\n */\nconst RAW_HEADERS = [\n    'application/vnd.ipld.dag-json',\n    'application/vnd.ipld.raw',\n    'application/octet-stream'\n];\n/**\n * if the user has specified an `Accept` header, and it's in our list of\n * allowable \"raw\" format headers, use that instead of detecting the content\n * type. This avoids the user from receiving something different when they\n * signal that they want to `Accept` a specific mime type.\n */\nfunction getOverridenRawContentType({ headers, accept }) {\n    // accept has already been resolved by getResolvedAcceptHeader, if we have it, use it.\n    const acceptHeader = accept ?? new Headers(headers).get('accept') ?? '';\n    // e.g. \"Accept: text/html, application/xhtml+xml, application/xml;q=0.9, image/webp, */*;q=0.8\"\n    const acceptHeaders = acceptHeader.split(',')\n        .map(s => s.split(';')[0])\n        .map(s => s.trim());\n    for (const mimeType of acceptHeaders) {\n        if (mimeType === '*/*') {\n            return;\n        }\n        if (RAW_HEADERS.includes(mimeType ?? '')) {\n            return mimeType;\n        }\n    }\n}\nexport class VerifiedFetch {\n    helia;\n    ipns;\n    log;\n    contentTypeParser;\n    blockstoreSessions;\n    constructor({ helia, ipns }, init) {\n        this.helia = helia;\n        this.log = helia.logger.forComponent('helia:verified-fetch');\n        this.ipns = ipns ?? heliaIpns(helia);\n        this.contentTypeParser = init?.contentTypeParser;\n        this.blockstoreSessions = new LRUCache({\n            max: init?.sessionCacheSize ?? SESSION_CACHE_MAX_SIZE,\n            ttl: init?.sessionTTLms ?? SESSION_CACHE_TTL_MS,\n            dispose: (store) => {\n                store.close();\n            }\n        });\n        this.log.trace('created VerifiedFetch instance');\n    }\n    getBlockstore(root, resource, useSession, options) {\n        const key = resourceToSessionCacheKey(resource);\n        if (!useSession) {\n            return this.helia.blockstore;\n        }\n        let session = this.blockstoreSessions.get(key);\n        if (session == null) {\n            session = this.helia.blockstore.createSession(root, options);\n            this.blockstoreSessions.set(key, session);\n        }\n        return session;\n    }\n    /**\n     * Accepts an `ipns://...` URL as a string and returns a `Response` containing\n     * a raw IPNS record.\n     */\n    async handleIPNSRecord({ resource, cid, path, options }) {\n        if (path !== '' || !resource.startsWith('ipns://')) {\n            return badRequestResponse(resource, 'Invalid IPNS name');\n        }\n        let peerId;\n        try {\n            peerId = peerIdFromString(resource.replace('ipns://', ''));\n        }\n        catch (err) {\n            this.log.error('could not parse peer id from IPNS url %s', resource);\n            return badRequestResponse(resource, err);\n        }\n        // since this call happens after parseResource, we've already resolved the\n        // IPNS name so a local copy should be in the helia datastore, so we can\n        // just read it out..\n        const routingKey = uint8ArrayConcat([\n            uint8ArrayFromString('/ipns/'),\n            peerId.toMultihash().bytes\n        ]);\n        const datastoreKey = new Key('/dht/record/' + uint8ArrayToString(routingKey, 'base32'), false);\n        const buf = await this.helia.datastore.get(datastoreKey, options);\n        const record = DHTRecord.deserialize(buf);\n        const response = okResponse(resource, record.value);\n        response.headers.set('content-type', 'application/vnd.ipfs.ipns-record');\n        return response;\n    }\n    /**\n     * Accepts a `CID` and returns a `Response` with a body stream that is a CAR\n     * of the `DAG` referenced by the `CID`.\n     */\n    async handleCar({ resource, cid, session, options }) {\n        const blockstore = this.getBlockstore(cid, resource, session, options);\n        const c = car({ blockstore, getCodec: this.helia.getCodec });\n        const stream = toBrowserReadableStream(c.stream(cid, options));\n        const response = okResponse(resource, stream);\n        response.headers.set('content-type', 'application/vnd.ipld.car; version=1');\n        return response;\n    }\n    /**\n     * Accepts a UnixFS `CID` and returns a `.tar` file containing the file or\n     * directory structure referenced by the `CID`.\n     */\n    async handleTar({ resource, cid, path, session, options }) {\n        if (cid.code !== dagPbCode && cid.code !== rawCode) {\n            return notAcceptableResponse('only UnixFS data can be returned in a TAR file');\n        }\n        const blockstore = this.getBlockstore(cid, resource, session, options);\n        const stream = toBrowserReadableStream(tarStream(`/ipfs/${cid}/${path}`, blockstore, options));\n        const response = okResponse(resource, stream);\n        response.headers.set('content-type', 'application/x-tar');\n        return response;\n    }\n    async handleJson({ resource, cid, path, accept, session, options }) {\n        this.log.trace('fetching %c/%s', cid, path);\n        const blockstore = this.getBlockstore(cid, resource, session, options);\n        const block = await blockstore.get(cid, options);\n        let body;\n        if (accept === 'application/vnd.ipld.dag-cbor' || accept === 'application/cbor') {\n            try {\n                // if vnd.ipld.dag-cbor has been specified, convert to the format - note\n                // that this supports more data types than regular JSON, the content-type\n                // response header is set so the user knows to process it differently\n                const obj = ipldDagJson.decode(block);\n                body = ipldDagCbor.encode(obj);\n            }\n            catch (err) {\n                this.log.error('could not transform %c to application/vnd.ipld.dag-cbor', err);\n                return notAcceptableResponse(resource);\n            }\n        }\n        else {\n            // skip decoding\n            body = block;\n        }\n        const response = okResponse(resource, body);\n        response.headers.set('content-type', accept ?? 'application/json');\n        return response;\n    }\n    async handleDagCbor({ resource, cid, path, accept, session, options }) {\n        this.log.trace('fetching %c/%s', cid, path);\n        let terminalElement;\n        const blockstore = this.getBlockstore(cid, resource, session, options);\n        // need to walk path, if it exists, to get the terminal element\n        const pathDetails = await handlePathWalking({ cid, path, resource, options, blockstore, log: this.log });\n        if (pathDetails instanceof Response) {\n            return pathDetails;\n        }\n        const ipfsRoots = pathDetails.ipfsRoots;\n        if (isObjectNode(pathDetails.terminalElement)) {\n            terminalElement = pathDetails.terminalElement;\n        }\n        else {\n            // this should never happen, but if it does, we should log it and return notSupportedResponse\n            this.log.error('terminal element is not a dag-cbor node');\n            return notSupportedResponse(resource, 'Terminal element is not a dag-cbor node');\n        }\n        const block = terminalElement.node;\n        let body;\n        if (accept === 'application/octet-stream' || accept === 'application/vnd.ipld.dag-cbor' || accept === 'application/cbor') {\n            // skip decoding\n            body = block;\n        }\n        else if (accept === 'application/vnd.ipld.dag-json') {\n            try {\n                // if vnd.ipld.dag-json has been specified, convert to the format - note\n                // that this supports more data types than regular JSON, the content-type\n                // response header is set so the user knows to process it differently\n                const obj = ipldDagCbor.decode(block);\n                body = ipldDagJson.encode(obj);\n            }\n            catch (err) {\n                this.log.error('could not transform %c to application/vnd.ipld.dag-json', err);\n                return notAcceptableResponse(resource);\n            }\n        }\n        else {\n            try {\n                body = dagCborToSafeJSON(block);\n            }\n            catch (err) {\n                if (accept === 'application/json') {\n                    this.log('could not decode DAG-CBOR as JSON-safe, but the client sent \"Accept: application/json\"', err);\n                    return notAcceptableResponse(resource);\n                }\n                this.log('could not decode DAG-CBOR as JSON-safe, falling back to `application/octet-stream`', err);\n                body = block;\n            }\n        }\n        const response = okResponse(resource, body);\n        if (accept == null) {\n            accept = body instanceof Uint8Array ? 'application/octet-stream' : 'application/json';\n        }\n        response.headers.set('content-type', accept);\n        setIpfsRoots(response, ipfsRoots);\n        return response;\n    }\n    async handleDagPb({ cid, path, resource, session, options }) {\n        let redirected = false;\n        const byteRangeContext = new ByteRangeContext(this.helia.logger, options?.headers);\n        const blockstore = this.getBlockstore(cid, resource, session, options);\n        const pathDetails = await handlePathWalking({ cid, path, resource, options, blockstore, log: this.log });\n        if (pathDetails instanceof Response) {\n            return pathDetails;\n        }\n        const ipfsRoots = pathDetails.ipfsRoots;\n        const terminalElement = pathDetails.terminalElement;\n        let resolvedCID = terminalElement.cid;\n        if (terminalElement?.type === 'directory') {\n            const dirCid = terminalElement.cid;\n            const redirectCheckNeeded = path === '' ? !resource.toString().endsWith('/') : !path.endsWith('/');\n            // https://specs.ipfs.tech/http-gateways/path-gateway/#use-in-directory-url-normalization\n            if (redirectCheckNeeded) {\n                if (options?.redirect === 'error') {\n                    this.log('could not redirect to %s/ as redirect option was set to \"error\"', resource);\n                    throw new TypeError('Failed to fetch');\n                }\n                else if (options?.redirect === 'manual') {\n                    this.log('returning 301 permanent redirect to %s/', resource);\n                    return movedPermanentlyResponse(resource, `${resource}/`);\n                }\n                // fall-through simulates following the redirect?\n                resource = `${resource}/`;\n                redirected = true;\n            }\n            const rootFilePath = 'index.html';\n            try {\n                this.log.trace('found directory at %c/%s, looking for index.html', cid, path);\n                const entry = await exporter(`/ipfs/${dirCid}/${rootFilePath}`, this.helia.blockstore, {\n                    signal: options?.signal,\n                    onProgress: options?.onProgress\n                });\n                this.log.trace('found root file at %c/%s with cid %c', dirCid, rootFilePath, entry.cid);\n                path = rootFilePath;\n                resolvedCID = entry.cid;\n            }\n            catch (err) {\n                options?.signal?.throwIfAborted();\n                this.log('error loading path %c/%s', dirCid, rootFilePath, err);\n                return notSupportedResponse('Unable to find index.html for directory at given path. Support for directories with implicit root is not implemented');\n            }\n            finally {\n                options?.onProgress?.(new CustomProgressEvent('verified-fetch:request:end', { cid: dirCid, path: rootFilePath }));\n            }\n        }\n        // we have a validRangeRequest & terminalElement is a file, we know the size and should set it\n        if (byteRangeContext.isRangeRequest && byteRangeContext.isValidRangeRequest && terminalElement.type === 'file') {\n            byteRangeContext.setFileSize(terminalElement.unixfs.fileSize());\n            this.log.trace('fileSize for rangeRequest %d', byteRangeContext.getFileSize());\n        }\n        const offset = byteRangeContext.offset;\n        const length = byteRangeContext.length;\n        this.log.trace('calling exporter for %c/%s with offset=%o & length=%o', resolvedCID, path, offset, length);\n        try {\n            const entry = await exporter(resolvedCID, this.helia.blockstore, {\n                signal: options?.signal,\n                onProgress: options?.onProgress\n            });\n            const asyncIter = entry.content({\n                signal: options?.signal,\n                onProgress: options?.onProgress,\n                offset,\n                length\n            });\n            this.log('got async iterator for %c/%s', cid, path);\n            const { stream, firstChunk } = await getStreamFromAsyncIterable(asyncIter, path ?? '', this.helia.logger, {\n                onProgress: options?.onProgress,\n                signal: options?.signal\n            });\n            byteRangeContext.setBody(stream);\n            // if not a valid range request, okRangeRequest will call okResponse\n            const response = okRangeResponse(resource, byteRangeContext.getBody(), { byteRangeContext, log: this.log }, {\n                redirected\n            });\n            await this.setContentType(firstChunk, path, response);\n            setIpfsRoots(response, ipfsRoots);\n            return response;\n        }\n        catch (err) {\n            options?.signal?.throwIfAborted();\n            this.log.error('error streaming %c/%s', cid, path, err);\n            if (byteRangeContext.isRangeRequest && err.code === 'ERR_INVALID_PARAMS') {\n                return badRangeResponse(resource);\n            }\n            return badGatewayResponse(resource.toString(), 'Unable to stream content');\n        }\n    }\n    async handleRaw({ resource, cid, path, session, options, accept }) {\n        /**\n         * if we have a path, we can't walk it, so we need to return a 404.\n         *\n         * @see https://github.com/ipfs/gateway-conformance/blob/26994cfb056b717a23bf694ce4e94386728748dd/tests/subdomain_gateway_ipfs_test.go#L198-L204\n         */\n        if (path !== '') {\n            this.log.trace('404-ing raw codec request for %c/%s', cid, path);\n            return notFoundResponse(resource, 'Raw codec does not support paths');\n        }\n        const byteRangeContext = new ByteRangeContext(this.helia.logger, options?.headers);\n        const blockstore = this.getBlockstore(cid, resource, session, options);\n        const result = await blockstore.get(cid, options);\n        byteRangeContext.setBody(result);\n        const response = okRangeResponse(resource, byteRangeContext.getBody(), { byteRangeContext, log: this.log }, {\n            redirected: false\n        });\n        // if the user has specified an `Accept` header that corresponds to a raw\n        // type, honour that header, so for example they don't request\n        // `application/vnd.ipld.raw` but get `application/octet-stream`\n        await this.setContentType(result, path, response, getOverridenRawContentType({ headers: options?.headers, accept }));\n        return response;\n    }\n    async setContentType(bytes, path, response, defaultContentType = 'application/octet-stream') {\n        let contentType;\n        if (this.contentTypeParser != null) {\n            try {\n                let fileName = path.split('/').pop()?.trim();\n                fileName = fileName === '' ? undefined : fileName;\n                const parsed = this.contentTypeParser(bytes, fileName);\n                if (isPromise(parsed)) {\n                    const result = await parsed;\n                    if (result != null) {\n                        contentType = result;\n                    }\n                }\n                else if (parsed != null) {\n                    contentType = parsed;\n                }\n            }\n            catch (err) {\n                this.log.error('error parsing content type', err);\n            }\n        }\n        this.log.trace('setting content type to \"%s\"', contentType ?? defaultContentType);\n        response.headers.set('content-type', contentType ?? defaultContentType);\n    }\n    /**\n     * If the user has not specified an Accept header or format query string arg,\n     * use the CID codec to choose an appropriate handler for the block data.\n     */\n    codecHandlers = {\n        [dagPbCode]: this.handleDagPb,\n        [ipldDagJson.code]: this.handleJson,\n        [jsonCode]: this.handleJson,\n        [ipldDagCbor.code]: this.handleDagCbor,\n        [rawCode]: this.handleRaw,\n        [identity.code]: this.handleRaw\n    };\n    /**\n     * We're starting to get to the point where we need a queue or pipeline of\n     * operations to perform and a single place to handle errors.\n     *\n     * TODO: move operations called by fetch to a queue of operations where we can\n     * always exit early (and cleanly) if a given signal is aborted\n     */\n    async fetch(resource, opts) {\n        this.log('fetch %s', resource);\n        const options = convertOptions(opts);\n        options?.onProgress?.(new CustomProgressEvent('verified-fetch:request:start', { resource }));\n        // resolve the CID/path from the requested resource\n        let cid;\n        let path;\n        let query;\n        let ttl;\n        let protocol;\n        let ipfsPath;\n        try {\n            const result = await parseResource(resource, { ipns: this.ipns, logger: this.helia.logger }, options);\n            cid = result.cid;\n            path = result.path;\n            query = result.query;\n            ttl = result.ttl;\n            protocol = result.protocol;\n            ipfsPath = result.ipfsPath;\n        }\n        catch (err) {\n            options?.signal?.throwIfAborted();\n            this.log.error('error parsing resource %s', resource, err);\n            return badRequestResponse(resource.toString(), err);\n        }\n        options?.onProgress?.(new CustomProgressEvent('verified-fetch:request:resolve', { cid, path }));\n        const acceptHeader = getResolvedAcceptHeader({ query, headers: options?.headers, logger: this.helia.logger });\n        const accept = selectOutputType(cid, acceptHeader);\n        this.log('output type %s', accept);\n        if (acceptHeader != null && accept == null) {\n            return notAcceptableResponse(resource.toString());\n        }\n        let response;\n        let reqFormat;\n        const redirectResponse = await getRedirectResponse({ resource, options, logger: this.helia.logger, cid });\n        if (redirectResponse != null) {\n            return redirectResponse;\n        }\n        const handlerArgs = { resource: resource.toString(), cid, path, accept, session: options?.session ?? true, options };\n        if (accept === 'application/vnd.ipfs.ipns-record') {\n            // the user requested a raw IPNS record\n            reqFormat = 'ipns-record';\n            response = await this.handleIPNSRecord(handlerArgs);\n        }\n        else if (accept === 'application/vnd.ipld.car') {\n            // the user requested a CAR file\n            reqFormat = 'car';\n            query.download = true;\n            query.filename = query.filename ?? `${cid.toString()}.car`;\n            response = await this.handleCar(handlerArgs);\n        }\n        else if (accept === 'application/vnd.ipld.raw') {\n            // the user requested a raw block\n            reqFormat = 'raw';\n            query.download = true;\n            query.filename = query.filename ?? `${cid.toString()}.bin`;\n            response = await this.handleRaw(handlerArgs);\n        }\n        else if (accept === 'application/x-tar') {\n            // the user requested a TAR file\n            reqFormat = 'tar';\n            query.download = true;\n            query.filename = query.filename ?? `${cid.toString()}.tar`;\n            response = await this.handleTar(handlerArgs);\n        }\n        else {\n            this.log.trace('finding handler for cid code \"%s\" and output type \"%s\"', cid.code, accept);\n            // derive the handler from the CID type\n            const codecHandler = this.codecHandlers[cid.code];\n            if (codecHandler == null) {\n                return notSupportedResponse(`Support for codec with code ${cid.code} is not yet implemented. Please open an issue at https://github.com/ipfs/helia-verified-fetch/issues/new`);\n            }\n            this.log.trace('calling handler \"%s\"', codecHandler.name);\n            response = await codecHandler.call(this, handlerArgs);\n        }\n        response.headers.set('etag', getETag({ cid, reqFormat, weak: false }));\n        setCacheControlHeader({ response, ttl, protocol });\n        response.headers.set('X-Ipfs-Path', ipfsPath);\n        // set Content-Disposition header\n        let contentDisposition;\n        // force download if requested\n        if (query.download === true) {\n            contentDisposition = 'attachment';\n        }\n        // override filename if requested\n        if (query.filename != null) {\n            if (contentDisposition == null) {\n                contentDisposition = 'inline';\n            }\n            contentDisposition = `${contentDisposition}; ${getContentDispositionFilename(query.filename)}`;\n        }\n        if (contentDisposition != null) {\n            response.headers.set('Content-Disposition', contentDisposition);\n        }\n        options?.onProgress?.(new CustomProgressEvent('verified-fetch:request:end', { cid, path }));\n        return response;\n    }\n    /**\n     * Start the Helia instance\n     */\n    async start() {\n        await this.helia.start();\n    }\n    /**\n     * Shut down the Helia instance\n     */\n    async stop() {\n        await this.helia.stop();\n    }\n}\nfunction isPromise(p) {\n    return p?.then != null;\n}\n//# sourceMappingURL=verified-fetch.js.map","/**\n * @packageDocumentation\n *\n * `@helia/verified-fetch` provides a [fetch](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)-like API for retrieving content from the [IPFS](https://ipfs.tech/) network.\n *\n * All content is retrieved in a [trustless manner](https://www.techopedia.com/definition/trustless), and the integrity of all bytes are verified by comparing hashes of the data. By default, CIDs are retrieved over HTTP from [trustless gateways](https://specs.ipfs.tech/http-gateways/trustless-gateway/).\n *\n * This is a marked improvement over `fetch` which offers no such protections and is vulnerable to all sorts of attacks like [Content Spoofing](https://owasp.org/www-community/attacks/Content_Spoofing), [DNS Hijacking](https://en.wikipedia.org/wiki/DNS_hijacking), etc.\n *\n * A `verifiedFetch` function is exported to get up and running quickly, and a `createVerifiedFetch` function is also available that allows customizing the underlying [Helia](https://helia.io/) node for complete control over how content is retrieved.\n *\n * Browser-cache-friendly [Response](https://developer.mozilla.org/en-US/docs/Web/API/Response) objects are returned which should be instantly familiar to web developers.\n *\n * Learn more in the [announcement blog post](https://blog.ipfs.tech/verified-fetch/) and check out the [ready-to-run example](https://github.com/ipfs-examples/helia-examples/tree/main/examples/helia-browser-verified-fetch).\n *\n * You may use any supported resource argument to fetch content:\n *\n * - [CID](https://multiformats.github.io/js-multiformats/classes/cid.CID.html) instance\n * - IPFS URL\n * - IPNS URL\n *\n * @example Getting started\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const resp = await verifiedFetch('ipfs://bafy...')\n *\n * const json = await resp.json()\n *```\n *\n * @example Using a CID instance to fetch JSON\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n * import { CID } from 'multiformats/cid'\n *\n * const cid = CID.parse('bafyFoo') // some json file\n * const response = await verifiedFetch(cid)\n * const json = await response.json()\n * ```\n *\n * @example Using IPFS protocol to fetch an image\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const response = await verifiedFetch('ipfs://bafyFoo') // CID for some image file\n * const blob = await response.blob()\n * const image = document.createElement('img')\n * image.src = URL.createObjectURL(blob)\n * document.body.appendChild(image)\n * ```\n *\n * @example Using IPNS protocol to stream a big file\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const response = await verifiedFetch('ipns://mydomain.com/path/to/very-long-file.log')\n * const bigFileStreamReader = await response.body?.getReader()\n * ```\n *\n * ## Configuration\n *\n * ### Custom HTTP gateways and routers\n *\n * Out of the box `@helia/verified-fetch` uses a default set of [trustless gateways](https://specs.ipfs.tech/http-gateways/trustless-gateway/) for fetching blocks and [HTTP delegated routers](https://specs.ipfs.tech/routing/http-routing-v1/) for performing routing tasks - looking up peers, resolving/publishing [IPNS](https://docs.ipfs.tech/concepts/ipns/) names, etc.\n *\n * It's possible to override these by passing `gateways` and `routers` keys to the `createVerifiedFetch` function:\n *\n * @example Configuring gateways and routers\n *\n * ```typescript\n * import { createVerifiedFetch } from '@helia/verified-fetch'\n *\n * const fetch = await createVerifiedFetch({\n *   gateways: ['https://trustless-gateway.link'],\n *   routers: ['http://delegated-ipfs.dev']\n * })\n *\n * const resp = await fetch('ipfs://bafy...')\n *\n * const json = await resp.json()\n *```\n *\n * ### Usage with customized Helia\n *\n * For full control of how `@helia/verified-fetch` fetches content from the distributed web you can pass a preconfigured Helia node to `createVerifiedFetch`.\n *\n * The [helia](https://www.npmjs.com/package/helia) module is configured with a libp2p node that is suited for decentralized applications, alternatively [@helia/http](https://www.npmjs.com/package/@helia/http) is available which uses HTTP gateways for all network operations.\n *\n * You can see variations of Helia and js-libp2p configuration options at <https://helia.io/interfaces/helia.index.HeliaInit.html>.\n *\n * ```typescript\n * import { trustlessGateway } from '@helia/block-brokers'\n * import { createHeliaHTTP } from '@helia/http'\n * import { delegatedHTTPRouting, httpGatewayRouting } from '@helia/routers'\n * import { createVerifiedFetch } from '@helia/verified-fetch'\n *\n * const fetch = await createVerifiedFetch(\n *   await createHeliaHTTP({\n *     blockBrokers: [\n *       trustlessGateway()\n *     ],\n *     routers: [\n *       delegatedHTTPRouting('http://delegated-ipfs.dev'),\n *       httpGatewayRouting({\n *         gateways: ['https://mygateway.example.net', 'https://trustless-gateway.link']\n *       })\n *     ]\n *   })\n * )\n *\n * const resp = await fetch('ipfs://bafy...')\n *\n * const json = await resp.json()\n * ```\n *\n * ### Custom content-type parsing\n *\n * By default, if the response can be parsed as JSON, `@helia/verified-fetch` sets the `Content-Type` header as `application/json`, otherwise it sets it as `application/octet-stream` - this is because the `.json()`, `.text()`, `.blob()`, and `.arrayBuffer()` methods will usually work as expected without a detailed content type.\n *\n * If you require an accurate content-type you can provide a `contentTypeParser` function as an option to `createVerifiedFetch` to handle parsing the content type.\n *\n * The function you provide will be called with the first chunk of bytes from the file and should return a string or a promise of a string.\n *\n * @example Customizing content-type parsing\n *\n * ```typescript\n * import { createVerifiedFetch } from '@helia/verified-fetch'\n * import { fileTypeFromBuffer } from '@sgtpooki/file-type'\n *\n * const fetch = await createVerifiedFetch({\n *   gateways: ['https://trustless-gateway.link'],\n *   routers: ['http://delegated-ipfs.dev']\n * }, {\n *   contentTypeParser: async (bytes) => {\n *     // call to some magic-byte recognition library like magic-bytes, file-type, or your own custom byte recognition\n *     const result = await fileTypeFromBuffer(bytes)\n *     return result?.mime\n *   }\n * })\n * ```\n *\n * ### Custom DNS resolvers\n *\n * If you don't want to leak DNS queries to the default resolvers, you can provide your own list of DNS resolvers to `createVerifiedFetch`.\n *\n * Note that you do not need to provide both a DNS-over-HTTPS and a DNS-over-JSON resolver, and you should prefer `dnsJsonOverHttps` resolvers for usage in the browser for a smaller bundle size. See https://github.com/ipfs/helia/tree/main/packages/ipns#example---using-dns-json-over-https for more information.\n *\n * @example Customizing DNS resolvers\n *\n * ```typescript\n * import { createVerifiedFetch } from '@helia/verified-fetch'\n * import { dnsJsonOverHttps, dnsOverHttps } from '@multiformats/dns/resolvers'\n *\n * const fetch = await createVerifiedFetch({\n *   gateways: ['https://trustless-gateway.link'],\n *   routers: ['http://delegated-ipfs.dev'],\n *   dnsResolvers: [\n *     dnsJsonOverHttps('https://my-dns-resolver.example.com/dns-json'),\n *     dnsOverHttps('https://my-dns-resolver.example.com/dns-query')\n *   ]\n * })\n * ```\n *\n * @example Customizing DNS per-TLD resolvers\n *\n * DNS resolvers can be configured to only service DNS queries for specific\n * TLDs:\n *\n * ```typescript\n * import { createVerifiedFetch } from '@helia/verified-fetch'\n * import { dnsJsonOverHttps, dnsOverHttps } from '@multiformats/dns/resolvers'\n *\n * const fetch = await createVerifiedFetch({\n *   gateways: ['https://trustless-gateway.link'],\n *   routers: ['http://delegated-ipfs.dev'],\n *   dnsResolvers: {\n *     // this resolver will only be used for `.com` domains (note - this could\n *     // also be an array of resolvers)\n *     'com.': dnsJsonOverHttps('https://my-dns-resolver.example.com/dns-json'),\n *     // this resolver will be used for everything else (note - this could\n *     // also be an array of resolvers)\n *     '.': dnsOverHttps('https://my-dns-resolver.example.com/dns-query')\n *   }\n * })\n * ```\n *\n * ### IPLD codec handling\n *\n * IPFS supports several data formats (typically referred to as codecs) which are included in the CID. `@helia/verified-fetch` attempts to abstract away some of the details for easier consumption.\n *\n * #### DAG-PB\n *\n * [DAG-PB](https://ipld.io/docs/codecs/known/dag-pb/) is the codec we are most likely to encounter, it is what [UnixFS](https://github.com/ipfs/specs/blob/main/UNIXFS.md) uses under the hood.\n *\n * ##### Using the DAG-PB codec as a Blob\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://Qmfoo')\n * const blob = await res.blob()\n *\n * console.info(blob) // Blob { size: x, type: 'application/octet-stream' }\n * ```\n *\n * ##### Using the DAG-PB codec as an ArrayBuffer\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://Qmfoo')\n * const buf = await res.arrayBuffer()\n *\n * console.info(buf) // ArrayBuffer { [Uint8Contents]: < ... >, byteLength: x }\n * ```\n *\n * ##### Using the DAG-PB codec as a stream\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://Qmfoo')\n * const reader = res.body?.getReader()\n *\n * if (reader == null) {\n *   throw new Error('Could not create reader from response body')\n * }\n *\n * while (true) {\n *   const next = await reader.read()\n *\n *   if (next?.done === true) {\n *     break\n *   }\n *\n *   if (next?.value != null) {\n *     console.info(next.value) // Uint8Array(x) [ ... ]\n *   }\n * }\n * ```\n *\n * ##### Content-Type\n *\n * When fetching `DAG-PB` data, the content type will be set to `application/octet-stream` unless a custom content-type parser is configured.\n *\n * #### JSON\n *\n * The JSON codec is a very simple codec, a block parseable with this codec is a JSON string encoded into a `Uint8Array`.\n *\n * ##### Using the JSON codec\n *\n * ```typescript\n * import * as json from 'multiformats/codecs/json'\n *\n * const block = new TextEncoder().encode('{ \"hello\": \"world\" }')\n * const obj = json.decode(block)\n *\n * console.info(obj) // { hello: 'world' }\n * ```\n *\n * ##### Content-Type\n *\n * When the `JSON` codec is encountered, the `Content-Type` header of the response will be set to `application/json`.\n *\n * ### DAG-JSON\n *\n * [DAG-JSON](https://ipld.io/docs/codecs/known/dag-json/) expands on the `JSON` codec, adding the ability to contain [CID](https://docs.ipfs.tech/concepts/content-addressing/)s which act as links to other blocks, and byte arrays.\n *\n * `CID`s and byte arrays are represented using special object structures with a single `\"/\"` property.\n *\n * Using `DAG-JSON` has two important caveats:\n *\n * 1. Your `JSON` structure cannot contain an object with only a `\"/\"` property, as it will be interpreted as a special type.\n * 2. Since `JSON` has no technical limit on number sizes, `DAG-JSON` also allows numbers larger than `Number.MAX_SAFE_INTEGER`. JavaScript requires use of `BigInt`s to represent numbers larger than this, and `JSON.parse` does not support them, so precision will be lost.\n *\n * Otherwise this codec follows the same rules as the `JSON` codec.\n *\n * ##### Using the DAG-JSON codec\n *\n * ```typescript\n * import * as dagJson from '@ipld/dag-json'\n *\n * const block = new TextEncoder().encode(`{\n *   \"hello\": \"world\",\n *   \"cid\": {\n *     \"/\": \"baeaaac3imvwgy3zao5xxe3de\"\n *   },\n *   \"buf\": {\n *     \"/\": {\n *       \"bytes\": \"AAECAwQ\"\n *     }\n *   }\n * }`)\n *\n * const obj = dagJson.decode(block)\n *\n * console.info(obj)\n * // {\n * // hello: 'world',\n * // cid: CID(baeaaac3imvwgy3zao5xxe3de),\n * // buf: Uint8Array(5) [ 0, 1, 2, 3, 4 ]\n * // }\n * ```\n *\n * ##### Content-Type\n *\n * When the `DAG-JSON` codec is encountered in the requested CID, the `Content-Type` header of the response will be set to `application/json`.\n *\n * `DAG-JSON` data can be parsed from the response by using the `.json()` function, which will return `CID`s/byte arrays as plain `{ \"/\": ... }` objects:\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n * import * as dagJson from '@ipld/dag-json'\n *\n * const res = await verifiedFetch('ipfs://bafyDAGJSON')\n *\n * // either:\n * const obj = await res.json()\n * console.info(obj.cid) // { \"/\": \"baeaaac3imvwgy3zao5xxe3de\" }\n * console.info(obj.buf) // { \"/\": { \"bytes\": \"AAECAwQ\" } }\n * ```\n *\n * Alternatively, it can be decoded using the `@ipld/dag-json` module and the `.arrayBuffer()` method, in which case you will get `CID` objects and `Uint8Array`s:\n *\n *```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n * import * as dagJson from '@ipld/dag-json'\n *\n * const res = await verifiedFetch('ipfs://bafyDAGJSON')\n *\n * // or:\n * const obj = dagJson.decode<any>(await res.arrayBuffer())\n * console.info(obj.cid) // CID(baeaaac3imvwgy3zao5xxe3de)\n * console.info(obj.buf) // Uint8Array(5) [ 0, 1, 2, 3, 4 ]\n * ```\n *\n * #### DAG-CBOR\n *\n * [DAG-CBOR](https://ipld.io/docs/codecs/known/dag-cbor/) uses the [Concise Binary Object Representation](https://cbor.io/) format for serialization instead of JSON.\n *\n * This supports more datatypes in a safer way than JSON and is smaller on the wire to boot so is usually preferable to JSON or DAG-JSON.\n *\n * ##### Content-Type\n *\n * Not all data types supported by `DAG-CBOR` can be successfully turned into JSON and back into the same binary form.\n *\n * When a decoded block can be round-tripped to JSON, the `Content-Type` will be set to `application/json`. In this case the `.json()` method on the `Response` object can be used to obtain an object representation of the response.\n *\n * When it cannot, the `Content-Type` will be `application/octet-stream` - in this case the `@ipld/dag-json` module must be used to deserialize the return value from `.arrayBuffer()`.\n *\n * ##### Detecting JSON-safe DAG-CBOR\n *\n * If the `Content-Type` header of the response is `application/json`, the `.json()` method may be used to access the response body in object form, otherwise the `.arrayBuffer()` method must be used to decode the raw bytes using the `@ipld/dag-cbor` module.\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n * import * as dagCbor from '@ipld/dag-cbor'\n *\n * const res = await verifiedFetch('ipfs://bafyDagCborCID')\n * let obj\n *\n * if (res.headers.get('Content-Type') === 'application/json') {\n *   // DAG-CBOR data can be safely decoded as JSON\n *   obj = await res.json()\n * } else {\n *   // response contains non-JSON friendly data types\n *   obj = dagCbor.decode(await res.arrayBuffer())\n * }\n *\n * console.info(obj) // ...\n * ```\n *\n * ## The `Accept` header\n *\n * The `Accept` header can be passed to override certain response processing, or to ensure that the final `Content-Type` of the response is the one that is expected.\n *\n * If the final `Content-Type` does not match the `Accept` header, or if the content cannot be represented in the format dictated by the `Accept` header, or you have configured a custom content type parser, and that parser returns a value that isn't in the accept header, a [406: Not Acceptable](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/406) response will be returned:\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://bafyJPEGImageCID', {\n *   headers: {\n *     accept: 'image/png'\n *   }\n * })\n *\n * console.info(res.status) // 406 - the image was a JPEG but we specified PNG as the accept header\n * ```\n *\n * It can also be used to skip processing the data from some formats such as `DAG-CBOR` if you wish to handle decoding it yourself:\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://bafyDAGCBORCID', {\n *   headers: {\n *     accept: 'application/octet-stream'\n *   }\n * })\n *\n * console.info(res.headers.get('accept')) // application/octet-stream\n * const buf = await res.arrayBuffer() // raw bytes, not processed as JSON\n * ```\n *\n * ## Redirects\n *\n * If a requested URL contains a path component, that path component resolves to\n * a UnixFS directory, but the URL does not have a trailing slash, one will be\n * added to form a canonical URL for that resource, otherwise the request will\n * be resolved as normal.\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://bafyfoo/path/to/dir')\n *\n * console.info(res.url) // ipfs://bafyfoo/path/to/dir/\n * ```\n *\n * It's possible to prevent this behaviour and/or handle a redirect manually\n * through use of the [redirect](https://developer.mozilla.org/en-US/docs/Web/API/fetch#redirect)\n * option.\n *\n * @example Redirect: follow\n *\n * This is the default value and is what happens if no value is specified.\n *\n * ```typescript\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://bafyfoo/path/to/dir', {\n *   redirect: 'follow'\n * })\n *\n * console.info(res.status) // 200\n * console.info(res.url) // ipfs://bafyfoo/path/to/dir/\n * console.info(res.redirected) // true\n * ```\n *\n * @example Redirect: error\n *\n * This causes a `TypeError` to be thrown if a URL would cause a redirect.\n *\n * ```typescript\n *\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://bafyfoo/path/to/dir', {\n *   redirect: 'error'\n * })\n * // throw TypeError('Failed to fetch')\n * ```\n *\n * @example Redirect: manual\n *\n * Manual redirects allow the user to process the redirect. A [301](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/301)\n * is returned, and the location to redirect to is available as the \"location\"\n * response header.\n *\n * This differs slightly from HTTP fetch which returns an opaque response as the\n * browser itself is expected to process the redirect and hide all details from\n * the user.\n *\n * ```typescript\n *\n * import { verifiedFetch } from '@helia/verified-fetch'\n *\n * const res = await verifiedFetch('ipfs://bafyfoo/path/to/dir', {\n *   redirect: 'manual'\n * })\n *\n * console.info(res.status) // 301\n * console.info(res.url) // ipfs://bafyfoo/path/to/dir\n * console.info(res.redirected) // false\n * console.info(res.headers.get('location')) // ipfs://bafyfoo/path/to/dir/\n * ```\n *\n * ## Comparison to fetch\n *\n * This module attempts to act as similarly to the `fetch()` API as possible.\n *\n * [The `fetch()` API](https://developer.mozilla.org/en-US/docs/Web/API/fetch) takes two parameters:\n *\n * 1. A [resource](https://developer.mozilla.org/en-US/docs/Web/API/fetch#resource)\n * 2. An [options object](https://developer.mozilla.org/en-US/docs/Web/API/fetch#options)\n *\n * ### Resource argument\n *\n * This library supports the following methods of fetching web3 content from IPFS:\n *\n * 1. IPFS protocol: `ipfs://<cidv0>` & `ipfs://<cidv1>`\n * 2. IPNS protocol: `ipns://<peerId>` & `ipns://<publicKey>` & `ipns://<hostUri_Supporting_DnsLink_TxtRecords>`\n * 3. CID instances: An actual CID instance `CID.parse('bafy...')`\n *\n * As well as support for pathing & params for items 1 & 2 above according to [IPFS - Path Gateway Specification](https://specs.ipfs.tech/http-gateways/path-gateway) & [IPFS - Trustless Gateway Specification](https://specs.ipfs.tech/http-gateways/trustless-gateway/). Further refinement of those specifications specifically for web-based scenarios can be found in the [Web Pathing Specification IPIP](https://github.com/ipfs/specs/pull/453).\n *\n * If you pass a CID instance, it assumes you want the content for that specific CID only, and does not support pathing or params for that CID.\n *\n * ### Options argument\n *\n * This library does not plan to support the exact Fetch API options object, as some of the arguments don't make sense. Instead, it will only support options necessary to meet [IPFS specs](https://specs.ipfs.tech/) related to specifying the resultant shape of desired content.\n *\n * Some of those header specifications are:\n *\n * 1. https://specs.ipfs.tech/http-gateways/path-gateway/#request-headers\n * 2. https://specs.ipfs.tech/http-gateways/trustless-gateway/#request-headers\n * 3. https://specs.ipfs.tech/http-gateways/subdomain-gateway/#request-headers\n *\n * Where possible, options and Helia internals will be automatically configured to the appropriate codec & content type based on the `verified-fetch` configuration and `options` argument passed.\n *\n * Known Fetch API options that will be supported:\n *\n * 1. `signal` - An AbortSignal that a user can use to abort the request.\n * 2. `redirect` - A string that specifies the redirect type. One of `follow`, `error`, or `manual`. Defaults to `follow`. Best effort to adhere to the [Fetch API redirect](https://developer.mozilla.org/en-US/docs/Web/API/fetch#redirect) parameter.\n * 3. `headers` - An object of headers to be sent with the request. Best effort to adhere to the [Fetch API headers](https://developer.mozilla.org/en-US/docs/Web/API/fetch#headers) parameter.\n *     - `accept` - A string that specifies the accept header. Relevant values:\n *         - [`vnd.ipld.raw`](https://www.iana.org/assignments/media-types/application/vnd.ipld.raw). (default)\n *         - [`vnd.ipld.car`](https://www.iana.org/assignments/media-types/application/vnd.ipld.car)\n *         - [`vnd.ipfs.ipns-record`](https://www.iana.org/assignments/media-types/application/vnd.ipfs.ipns-record)\n * 4. `method` - A string that specifies the HTTP method to use for the request. Defaults to `GET`. Best effort to adhere to the [Fetch API method](https://developer.mozilla.org/en-US/docs/Web/API/fetch#method) parameter.\n * 5. `body` - An object that specifies the body of the request. Best effort to adhere to the [Fetch API body](https://developer.mozilla.org/en-US/docs/Web/API/fetch#body) parameter.\n * 6. `cache` - Will basically act as `force-cache` for the request. Best effort to adhere to the [Fetch API cache](https://developer.mozilla.org/en-US/docs/Web/API/fetch#cache) parameter.\n *\n * Non-Fetch API options that will be supported:\n *\n * 1. `onProgress` - Similar to Helia `onProgress` options, this will be a function that will be called with a progress event. Supported progress events are:\n *     - `helia:verified-fetch:error` - An error occurred during the request.\n *     - `helia:verified-fetch:request:start` - The request has been sent\n *     - `helia:verified-fetch:request:complete` - The request has been sent\n *     - `helia:verified-fetch:request:error` - An error occurred during the request.\n *     - `helia:verified-fetch:request:abort` - The request was aborted prior to completion.\n *     - `helia:verified-fetch:response:start` - The initial HTTP Response headers have been set, and response stream is started.\n *     - `helia:verified-fetch:response:complete` - The response stream has completed.\n *     - `helia:verified-fetch:response:error` - An error occurred while building the response.\n *\n * Some in-flight specs (IPIPs) that will affect the options object this library supports in the future can be seen at https://specs.ipfs.tech/ipips, a subset are:\n *\n * 1. [IPIP-0412: Signaling Block Order in CARs on HTTP Gateways](https://specs.ipfs.tech/ipips/ipip-0412/)\n * 2. [IPIP-0402: Partial CAR Support on Trustless Gateways](https://specs.ipfs.tech/ipips/ipip-0402/)\n * 3. [IPIP-0386: Subdomain Gateway Interop with _redirects](https://specs.ipfs.tech/ipips/ipip-0386/)\n * 4. [IPIP-0328: JSON and CBOR Response Formats on HTTP Gateways](https://specs.ipfs.tech/ipips/ipip-0328/)\n * 5. [IPIP-0288: TAR Response Format on HTTP Gateways](https://specs.ipfs.tech/ipips/ipip-0288/)\n *\n * ### Response types\n *\n * This library's purpose is to return reasonably representable content from IPFS. In other words, fetching content is intended for leaf-node content -- such as images/videos/audio & other assets, or other IPLD content (with link) -- that can be represented by https://developer.mozilla.org/en-US/docs/Web/API/Response#instance_methods. The content type you receive back will depend upon the CID you request as well as the `Accept` header value you provide.\n *\n * All content we retrieve from the IPFS network is obtained via an AsyncIterable, and will be set as the [body of the HTTP Response](https://developer.mozilla.org/en-US/docs/Web/API/Response/Response#body) via a [`ReadableStream`](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/Using_readable_streams#consuming_a_fetch_as_a_stream) or other efficient method that avoids loading the entire response into memory or getting the entire response from the network before returning a response to the user.\n *\n * If your content doesn't have a mime-type or an [IPFS spec](https://specs.ipfs.tech), this library will not support it, but you can use the [`helia`](https://github.com/ipfs/helia) library directly for those use cases. See [Unsupported response types](#unsupported-response-types) for more information.\n *\n * #### Handling response types\n *\n * For handling responses we want to follow conventions/abstractions from Fetch API where possible:\n *\n * - For JSON, assuming you abstract any differences between dag-json/dag-cbor/json/and json-file-on-unixfs, you would call `.json()` to get a JSON object.\n * - For images (or other web-relevant asset) you want to add to the DOM, use `.blob()` or `.arrayBuffer()` to get the raw bytes.\n * - For plain text in utf-8, you would call `.text()`\n * - For streaming response data, use something like `response.body.getReader()` to get a [`ReadableStream`](https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/Using_readable_streams#consuming_a_fetch_as_a_stream).\n *\n * #### Unsupported response types\n *\n * * Returning IPLD nodes or DAGs as JS objects is not supported, as there is no currently well-defined structure for representing this data in an [HTTP Response](https://developer.mozilla.org/en-US/docs/Web/API/Response). Instead, users should request `aplication/vnd.ipld.car` or use the [`helia`](https://github.com/ipfs/helia) library directly for this use case.\n * * Others? Open an issue or PR!\n *\n * ### Response headers\n *\n * This library will set the [HTTP Response](https://developer.mozilla.org/en-US/docs/Web/API/Response) headers to the appropriate values for the content type according to the appropriate [IPFS Specifications](https://specs.ipfs.tech/).\n *\n * Some known header specifications:\n *\n * * https://specs.ipfs.tech/http-gateways/path-gateway/#response-headers\n * * https://specs.ipfs.tech/http-gateways/trustless-gateway/#response-headers\n * * https://specs.ipfs.tech/http-gateways/subdomain-gateway/#response-headers\n *\n * ### Possible Scenarios that could cause confusion\n *\n * #### Attempting to fetch the CID for content that does not make sense\n *\n * If you request `bafybeiaysi4s6lnjev27ln5icwm6tueaw2vdykrtjkwiphwekaywqhcjze`, which points to the root of the en.wikipedia.org mirror, a response object does not make sense.\n *\n * ### Errors\n *\n * Known Errors that can be thrown:\n *\n * 1. `TypeError` - If the resource argument is not a string, CID, or CID string.\n * 2. `TypeError` - If the options argument is passed and not an object.\n * 3. `TypeError` - If the options argument is passed and is malformed.\n * 4. `AbortError` - If the content request is aborted due to user aborting provided AbortSignal. Note that this is a `AbortError` from `@libp2p/interface` and not the standard `AbortError` from the Fetch API.\n */\nimport { trustlessGateway } from '@helia/block-brokers';\nimport { createHeliaHTTP } from '@helia/http';\nimport { delegatedHTTPRouting, httpGatewayRouting } from '@helia/routers';\nimport { dns } from '@multiformats/dns';\nimport { VerifiedFetch as VerifiedFetchClass } from './verified-fetch.js';\n/**\n * Create and return a Helia node\n */\nexport async function createVerifiedFetch(init, options) {\n    if (!isHelia(init)) {\n        init = await createHeliaHTTP({\n            blockBrokers: [\n                trustlessGateway({\n                    allowInsecure: init?.allowInsecure,\n                    allowLocal: init?.allowLocal\n                })\n            ],\n            routers: [\n                ...(init?.routers ?? ['https://delegated-ipfs.dev']).map((routerUrl) => delegatedHTTPRouting(routerUrl)),\n                httpGatewayRouting({\n                    gateways: init?.gateways ?? ['https://trustless-gateway.link']\n                })\n            ],\n            dns: createDns(init?.dnsResolvers)\n        });\n    }\n    const verifiedFetchInstance = new VerifiedFetchClass({ helia: init }, options);\n    async function verifiedFetch(resource, options) {\n        return verifiedFetchInstance.fetch(resource, options);\n    }\n    verifiedFetch.stop = verifiedFetchInstance.stop.bind(verifiedFetchInstance);\n    verifiedFetch.start = verifiedFetchInstance.start.bind(verifiedFetchInstance);\n    return verifiedFetch;\n}\nexport { verifiedFetch } from './singleton.js';\nfunction isHelia(obj) {\n    // test for the presence of known Helia properties, return a boolean value\n    return obj?.blockstore != null &&\n        obj?.datastore != null &&\n        obj?.gc != null &&\n        obj?.stop != null &&\n        obj?.start != null;\n}\nfunction createDns(resolvers) {\n    if (resolvers == null) {\n        return;\n    }\n    if (Array.isArray(resolvers)) {\n        return dns({\n            resolvers: {\n                '.': resolvers\n            }\n        });\n    }\n    return dns({ resolvers });\n}\n//# sourceMappingURL=index.js.map","import { createVerifiedFetch } from './index.js';\nlet impl;\nexport const verifiedFetch = async function verifiedFetch(resource, options) {\n    if (impl == null) {\n        impl = await createVerifiedFetch();\n    }\n    return impl(resource, options);\n};\nverifiedFetch.start = async function () {\n    await impl?.start();\n};\nverifiedFetch.stop = async function () {\n    await impl?.stop();\n};\n//# sourceMappingURL=singleton.js.map","function isDeepKey(key) {\n    switch (typeof key) {\n        case 'number':\n        case 'symbol': {\n            return false;\n        }\n        case 'string': {\n            return key.includes('.') || key.includes('[') || key.includes(']');\n        }\n    }\n}\n\nexport { isDeepKey };\n","function toKey(value) {\n    if (Object.is(value, -0)) {\n        return '-0';\n    }\n    return value.toString();\n}\n\nexport { toKey };\n","import { isDeepKey } from '../_internal/isDeepKey.mjs';\nimport { toKey } from '../_internal/toKey.mjs';\nimport { toPath } from '../util/toPath.mjs';\n\nfunction get(object, path, defaultValue) {\n    if (object == null) {\n        return defaultValue;\n    }\n    switch (typeof path) {\n        case 'string': {\n            const result = object[path];\n            if (result === undefined) {\n                if (isDeepKey(path)) {\n                    return get(object, toPath(path), defaultValue);\n                }\n                else {\n                    return defaultValue;\n                }\n            }\n            return result;\n        }\n        case 'number':\n        case 'symbol': {\n            if (typeof path === 'number') {\n                path = toKey(path);\n            }\n            const result = object[path];\n            if (result === undefined) {\n                return defaultValue;\n            }\n            return result;\n        }\n        default: {\n            if (Array.isArray(path)) {\n                return getWithPath(object, path, defaultValue);\n            }\n            if (Object.is(path?.valueOf(), -0)) {\n                path = '-0';\n            }\n            else {\n                path = String(path);\n            }\n            const result = object[path];\n            if (result === undefined) {\n                return defaultValue;\n            }\n            return result;\n        }\n    }\n}\nfunction getWithPath(object, path, defaultValue) {\n    if (path.length === 0) {\n        return defaultValue;\n    }\n    let current = object;\n    for (let index = 0; index < path.length; index++) {\n        if (current == null) {\n            return defaultValue;\n        }\n        current = current[path[index]];\n    }\n    if (current === undefined) {\n        return defaultValue;\n    }\n    return current;\n}\n\nexport { get };\n","function toPath(deepKey) {\n    const result = [];\n    const length = deepKey.length;\n    if (length === 0) {\n        return result;\n    }\n    let index = 0;\n    let key = '';\n    let quoteChar = '';\n    let bracket = false;\n    if (deepKey.charCodeAt(0) === 46) {\n        result.push('');\n        index++;\n    }\n    while (index < length) {\n        const char = deepKey[index];\n        if (quoteChar) {\n            if (char === '\\\\' && index + 1 < length) {\n                index++;\n                key += deepKey[index];\n            }\n            else if (char === quoteChar) {\n                quoteChar = '';\n            }\n            else {\n                key += char;\n            }\n        }\n        else if (bracket) {\n            if (char === '\"' || char === \"'\") {\n                quoteChar = char;\n            }\n            else if (char === ']') {\n                bracket = false;\n                result.push(key);\n                key = '';\n            }\n            else {\n                key += char;\n            }\n        }\n        else {\n            if (char === '[') {\n                bracket = true;\n                if (key) {\n                    result.push(key);\n                    key = '';\n                }\n            }\n            else if (char === '.') {\n                if (key) {\n                    result.push(key);\n                    key = '';\n                }\n            }\n            else {\n                key += char;\n            }\n        }\n        index++;\n    }\n    if (key) {\n        result.push(key);\n    }\n    return result;\n}\n\nexport { toPath };\n"],"names":[],"sourceRoot":"","ignoreList":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374]}